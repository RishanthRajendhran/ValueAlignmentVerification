[{"question": "Where does the word christian come from in the bible?", "passages": [["Christians", "The first recorded use of the term (or its cognates in other languages) is in the New Testament, in Acts 11:26, after Barnabas brought Saul (Paul) to Antioch where they taught the disciples for about a year, the text says: \"[...] the disciples were called Christians first in Antioch.\"", "The second mention of the term follows in Acts 26:28, where Herod Agrippa II replied to Paul the Apostle, \"Then Agrippa said unto Paul, Almost thou persuadest me to be a Christian.\"", "The third and final New Testament reference to the term is in 1 Peter 4:16, which exhorts believers: \"Yet if \"[any man suffer]\" as a Christian, let him not be ashamed; but let him glorify God on this behalf.\"", "Kenneth Samuel Wuest holds that all three original New Testament verses' usages reflect a derisive element in the term \"Christian\" to refer to followers of Christ who did not acknowledge the emperor of Rome.", "The city of Antioch, where someone gave them the name \"Christians\", had a reputation for coming up with such nicknames."]], "gold": "The word Christian was first mentioned in the New Testament in chapter and verse Acts 11:26. In the narrative where after Barnabas brought Saul (Paul) to Antioch where they taught the disciples. The quote that mentions the word Christian first is \"[...] the disciples were called Christians first in Antioch.\"", "prediction 1": "The word Christian comes from the Old Testament, where it is used to refer to followers of Christ who did not acknowledge the emperor of Rome. The first recorded use of the term (or its cognates in other languages) is in the New Testament, in Acts 11:26, after Barnabas brought Saul (Paul) to Antioch where they taught the disciples for about a year, the text says: \"[...] the disciples were called Christians first in Antioch.\" The second mention of the term follows in Acts 26:28, where Herod Agrippa replied to Paul the Apostle, \"Then Agrippa said unto Paul, Almost thou persuadest me to be a Christian.\"", "prediction 2": "The word \"Christian\" is found in the New Testament, specifically in Acts 11:26. Others that mention the word include Acts 26:28, Acts 26:29, and 1 Peter 4:16.", "prediction 3": "The word Christian is found in the New Testament, the Old Testament, and the New Testament's Revelation which all come from the same source: Hebrews. The word Christian translates to \"Christ like\" in the New Testament. This puts the term Christian in its entirety in the original Greek.", "prediction 4": "The word \"Christian\" is a term found in the bible. It is a personified name given to followers of Christ, who did not acknowledge the emperor of Rome.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 0, "end": 142}, {"error type": "Irrelevant", "explanation": "", "start": 368, "end": 371}], "missing-info": [], "corrected-prediction": "The first recorded use of the term \"Christian\" (or its cognates in other languages) is in the New Testament, in Acts 11:26, after Barnabas brought Saul (Paul) to Antioch where they taught the disciples for about a year. The text says: \"[...] the disciples were called Christians first in Antioch.\" The second mention of the term follows in Acts 26:28, where Herod Agrippa II replied to Paul the Apostle, \"Then Agrippa said unto Paul, Almost thou persuadest me to be a Christian.\""}, "preference": [1, 1, 1, 2, 1, 1], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Christians\nS1. The first recorded use of the term (or its cognates in other languages) is in the New Testament, in Acts 11:26, after Barnabas brought Saul (Paul) to Antioch where they taught the disciples for about a year, the text says: \"[...] the disciples were called Christians first in Antioch.\"\nS2. The second mention of the term follows in Acts 26:28, where Herod Agrippa II replied to Paul the Apostle, \"Then Agrippa said unto Paul, Almost thou persuadest me to be a Christian.\"\nS3. The third and final New Testament reference to the term is in 1 Peter 4:16, which exhorts believers: \"Yet if \"[any man suffer]\" as a Christian, let him not be ashamed; but let him glorify God on this behalf.\"\nS4. Kenneth Samuel Wuest holds that all three original New Testament verses' usages reflect a derisive element in the term \"Christian\" to refer to followers of Christ who did not acknowledge the emperor of Rome.\nS5. The city of Antioch, where someone gave them the name \"Christians\", had a reputation for coming up with such nicknames.\n    \nInput Question:\nWhere does the word christian come from in the bible?\n\nCorrect Response:\nThe word Christian was first mentioned in the New Testament in chapter and verse Acts 11:26. In the narrative where after Barnabas brought Saul (Paul) to Antioch where they taught the disciples. The quote that mentions the word Christian first is \"[...] the disciples were called Christians first in Antioch.\"\n\nModel Prediction:\nThe word Christian comes from the Old Testament, where it is used to refer to followers of Christ who did not acknowledge the emperor of Rome. The first recorded use of the term (or its cognates in other languages) is in the New Testament, in Acts 11:26, after Barnabas brought Saul (Paul) to Antioch where they taught the disciples for about a year, the text says: \"[...] the disciples were called Christians first in Antioch.\" The second mention of the term follows in Acts 26:28, where Herod Agrippa replied to Paul the Apostle, \"Then Agrippa said unto Paul, Almost thou persuadest me to be a Christian.\"\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "[The word Christian comes from the Old Testament, where it is used to refer to followers of Christ who did not acknowledge the emperor of Rome.] The first recorded use of the term (or its cognates in other languages) is in the New Testament, in Acts 11:26, after Barnabas brought Saul (Paul) to Antioch where they taught the disciples for about a year, the text says: \"[...] the disciples were called Christians first in Antioch.\" The second mention of the term follows in Acts 26:28, where Herod Agrippa replied to Paul the Apostle, \"Then Agrippa said unto Paul, Almost thou persuadest me to be a Christian.\"\n\nExplanation:\nThe first sentence in the model prediction is irrelevant. The term \"Christian\" does not come from the Old Testament, and the reference to followers of Christ not acknowledging the emperor of Rome is not pertinent to the question asked."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The word Christian comes from the Old Testament, where it is used to refer to followers of Christ who did not acknowledge the emperor of Rome.\nS2. The first recorded use of the term (or its cognates in other languages) is in the New Testament, in Acts 11:26, after Barnabas brought Saul (Paul) to Antioch where they taught the disciples for about a year, the text says: \"[...] the disciples were called Christians first in Antioch.\"\nS3. The second mention of the term follows in Acts 26:28, where Herod Agrippa replied to Paul the Apostle, \"Then Agrippa said unto Paul, Almost thou persuadest me to be a Christian.\"\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "Inconsistent or Unverifiable Sentences:\n1. S1\n\nExplanation:\n1. The first sentence is factually inconsistent with the passages. The term \"Christian\" does not come from the Old Testament, and it is not used to refer to followers of Christ who did not acknowledge the emperor of Rome. This information is not found in any of the provided passages."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "None\n\nExplanation:\nThe model prediction includes all the necessary information from the passages to answer the question. There is no missing information."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The first recorded use of the term \"Christian\" (or its cognates in other languages) is in the New Testament, in Acts 11:26, after Barnabas brought Saul (Paul) to Antioch where they taught the disciples for about a year. The text says: \"[...] the disciples were called Christians first in Antioch.\" The second mention of the term follows in Acts 26:28, where Herod Agrippa II replied to Paul the Apostle, \"Then Agrippa said unto Paul, Almost thou persuadest me to be a Christian.\""}], "feedback_human": {"errors": [{"error type": "Unverifiable", "explanation": "", "start": 0, "end": 142}, {"error type": "Irrelevant", "explanation": "", "start": 419, "end": 607}], "missing-info": [], "corrected-prediction": "The first recorded use of the term (or its cognates in other languages) is in the New Testament, in Acts 11:26, after Barnabas brought Saul (Paul) to Antioch where they taught the disciples for about a year, the text says: \"[...] the disciples were called Christians first in Antioch.\""}}, {"question": "When did snape become defense against the dark arts teacher?", "passages": [["Harry Potter and the Half-Blood Prince", "Harry Potter and the Half-Blood Prince\n\nHarry Potter and the Half-Blood Prince is a fantasy novel written by British author J. K. Rowling and the sixth and penultimate novel in the \"Harry Potter\" series.", "Set during protagonist Harry Potter's sixth year at Hogwarts, the novel explores the past of Harry's nemesis, Lord Voldemort, and Harry's preparations for the final battle against Voldemort alongside his headmaster and mentor Albus Dumbledore.", "The book was published in the United Kingdom by Bloomsbury, and in the United States by Scholastic on 16 July 2005, as well as in several other countries.", "It sold nine million copies in the first 24\u00a0hours after its release, a record at the time which was eventually broken by its sequel, \"Harry Potter and the Deathly Hallows\".", "There were many controversies before and after it was published, including the right to read the copies delivered prior to the release date in Canada.", "Reception to the novel was generally positive and it won several awards and honours, including the 2006 British Book of the Year award.", "Reviewers noted that the book took on a darker tone than its previous predecessors, though it did contain some humour.", "Some considered the main themes to be love, death, trust, and redemption.", "The considerable character development of Harry and many other teenage characters also drew attention."]], "gold": "Severus Snape became the Defense Against the Dark Arts teacher in Harry Potter and the Half-Blood Prince, the sixth installment in the Harry Potter series. Though the book was published in 2005, its events take place in-universe in 1996\u20131997.", "prediction 1": "Harry Potter and the Half-Blood Prince is a 2005 fantasy novel written by British author J. K. Rowling and the sixth and penultimate novel in the Harry Potter series. It features Snape, a defense against the Dark Arts teacher, in the novel. Snape was introduced in the final chapter of the novel.", "prediction 2": "Harry Potter and the Half-Blood Prince is the sixth novel in the Harry Potter series. It's set during protagonist Harry Potter's sixth year at Hogwarts and examines the past of Harry's nemesis, Lord Voldemort, and Harry's preparations for the final battle against Voldemort alongside his headmaster and mentor Albus Dumbledore. Snape became defense against the dark arts teacher after Snape's second attack on Snape's house in the first attack on Snape was killed by Snape in the dark arts teacher. Snape was defeated by the Dark Arts teacher.", "prediction 3": "Harry Potter and the Half-Blood Prince is a fantasy novel written by British author J. K. Rowling and the sixth and penultimate novel in the Harry Potter series. It is set during protagonist Harry Potter's sixth year at Hogwarts, the novel explores the past of Harry's nemesis, Lord Voldemort, and Harry's preparations for the final battle against Voldemort alongside his headmaster and mentor Albus Dumbledore. Snape becomes defence against the Dark Arts teacher, snape, when Snape becomes defense against the Dark Arts teacher Snape. Snape becomes defense against the Dark Arts teacher, Snape becomes defense against the Dark Arts teacher, Snape becomes defense against the Dark Arts Teacher, when Snape becomes an attack against the Dark Arts teacher, Snape becomes defense against the Dark Arts Teacher Snape. Snape becomes defense against the Dark Arts", "prediction 4": "Harry Potter and the Half-Blood Prince is a fantasy novel written by British author J. K. Rowling and the sixth and penultimate novel in the Harry Potter series. The novel explores the past of protagonist Harry Potter's nemesis, Lord Voldemort, and Harry's preparations for the final battle against Voldemort alongside his headmaster and mentor Albus Dumbledore. Snape, a student at Hogwarts at the time, is the student Snape's second year at Hogwarts.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 0, "end": 166}, {"error type": "Irrelevant", "explanation": "", "start": 241, "end": 296}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 1, "sentence_id": [2]}], "corrected-prediction": "Severus Snape became the Defense Against the Dark Arts teacher during Harry Potter's sixth year at Hogwarts, as depicted in the novel \"Harry Potter and the Half-Blood Prince\"."}, "preference": [1, 1, 1, 1, 2, 2], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Harry Potter and the Half-Blood Prince\nS1. Harry Potter and the Half-Blood Prince  Harry Potter and the Half-Blood Prince is a fantasy novel written by British author J. K. Rowling and the sixth and penultimate novel in the \"Harry Potter\" series.\nS2. Set during protagonist Harry Potter's sixth year at Hogwarts, the novel explores the past of Harry's nemesis, Lord Voldemort, and Harry's preparations for the final battle against Voldemort alongside his headmaster and mentor Albus Dumbledore.\nS3. The book was published in the United Kingdom by Bloomsbury, and in the United States by Scholastic on 16 July 2005, as well as in several other countries.\nS4. It sold nine million copies in the first 24\u00a0hours after its release, a record at the time which was eventually broken by its sequel, \"Harry Potter and the Deathly Hallows\".\nS5. There were many controversies before and after it was published, including the right to read the copies delivered prior to the release date in Canada.\nS6. Reception to the novel was generally positive and it won several awards and honours, including the 2006 British Book of the Year award.\nS7. Reviewers noted that the book took on a darker tone than its previous predecessors, though it did contain some humour.\nS8. Some considered the main themes to be love, death, trust, and redemption.\nS9. The considerable character development of Harry and many other teenage characters also drew attention.\n    \nInput Question:\nWhen did snape become defense against the dark arts teacher?\n\nCorrect Response:\nSeverus Snape became the Defense Against the Dark Arts teacher in Harry Potter and the Half-Blood Prince, the sixth installment in the Harry Potter series. Though the book was published in 2005, its events take place in-universe in 1996\u20131997.\n\nModel Prediction:\nHarry Potter and the Half-Blood Prince is a 2005 fantasy novel written by British author J. K. Rowling and the sixth and penultimate novel in the Harry Potter series. It features Snape, a defense against the Dark Arts teacher, in the novel. Snape was introduced in the final chapter of the novel.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "[Harry Potter and the Half-Blood Prince is a 2005 fantasy novel written by British author J. K. Rowling and the sixth and penultimate novel in the Harry Potter series.] It features Snape, a defense against the Dark Arts teacher, in the novel. [Snape was introduced in the final chapter of the novel.]\n\nExplanation:\n1. The first sentence is irrelevant because it doesn't answer the question directly nor does it provide crucial auxiliary information.\n2. The third sentence is incorrect and irrelevant. Snape was not introduced in the final chapter of the novel. This information is not relevant to the question."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. Harry Potter and the Half-Blood Prince is a 2005 fantasy novel written by British author J. K. Rowling and the sixth and penultimate novel in the Harry Potter series.\nS2. It features Snape, a defense against the Dark Arts teacher, in the novel.\nS3. Snape was introduced in the final chapter of the novel.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "S3\n\nExplanation:\nThe third sentence is factually incorrect. Snape was not introduced in the final chapter of the novel. This is an \"Inconsistent Fact\"."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 2 [Missing Answer]\n\nExplanation:\n1. The model prediction does not mention that Snape became the Defense Against the Dark Arts teacher during Harry's sixth year at Hogwarts, which is the main answer to the question. This information can be found in Passage 1, sentence 2."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "Severus Snape became the Defense Against the Dark Arts teacher during Harry Potter's sixth year at Hogwarts, as depicted in the novel \"Harry Potter and the Half-Blood Prince\"."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 0, "end": 166}, {"error type": "Unverifiable", "explanation": "", "start": 167, "end": 240}, {"error type": "Unverifiable", "explanation": "", "start": 241, "end": 296}], "missing-info": [], "corrected-prediction": ""}}, {"question": "Who owns bass pro shops and cabela's?", "passages": [["Bass Pro Shops", "Bass Pro Shops\n\nBPS Direct, LLC (doing business as Bass Pro Shops) is an American privately held retailer of hunting, fishing, camping and related outdoor recreation merchandise.", "Bass Pro Shops supports and sells merchandise for the National Audubon Society.", "The majority owner, John Morris, began his career in sporting goods with a fishing section in the back of a Brown Derby liquor store owned by his father, located in Springfield MO on the road to Table Rock Lake and Branson, Missouri.", "That small fishing department sold homemade bait and worms, proving popular enough that Bass Pro Shops was incorporated in 1971.", "These homemade baits were so popular that many people wanted the opportunity to buy these when they had returned home.", "Thus began the Bass Pro Shops catalog, first mailed in 1974.", "Soon, it became the world's largest mail order sporting goods store.", "In 1975, to meet the burgeoning demand for Bass Pro Shops exclusive products, American Rod and Gun was established.", "Acting as a separate wholesaling entity ARG serves more than 7,000 independently owned retail stores worldwide.", "In 1977, Bass Pro Shops introduced the first fish-ready complete boat motor and trailer package with the Bass Tracker.", "In 1984, construction began on the Outdoor World Catalog Showroom in Springfield, Missouri.", "Big Cedar Lodge opened in 1988 on Table Rock Lake."]], "gold": "Cabela's is owned by Bass Pro Shops. Bass Pro Shops is owned by John Luke Morris.", "prediction 1": "The majority owner of the American sports retailer, Bass Pro Shops, is John Morris.", "prediction 2": "The majority owner of both Bass Pro Shops and Cabela's is John Morris. Morris began his career in sporting goods with a fishing section in the back of a Brown Derby liquor store owned by his father, located in Springfield MO on the road to Table Rock Lake and Branson, Missouri. That small fishing department sold homemade bait and worms, proving popular enough that Bass Pro Shops was incorporated in 1971. These homemade baits were so popular that many people wanted the opportunity to buy these when they had returned home. Thus began the Bass Pro Shops catalog, first mailed in 1975.", "prediction 3": "The majority owner of Bass Pro Shops is John Morris. Bass Pro Shops is an American privately held retailer of hunting, fishing, camping and related outdoor recreation merchandise.", "prediction 4": "The majority owner of Bass Pro Shops is John Morris. The majority owner of Bass Pro Shops is American Rod and Gun Corporation, which serves as a separate wholesaling entity for more than 7,000 independently owned retail stores worldwide.", "feedback": {"errors": [], "missing-info": [], "corrected-prediction": "The majority owner of the American sports retailer, Bass Pro Shops, is John Morris. Additionally, Bass Pro Shops owns Cabela's."}, "preference": [1, 1, 1, 2, 2, 1], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Bass Pro Shops\nS1. Bass Pro Shops  BPS Direct, LLC (doing business as Bass Pro Shops) is an American privately held retailer of hunting, fishing, camping and related outdoor recreation merchandise.\nS2. Bass Pro Shops supports and sells merchandise for the National Audubon Society.\nS3. The majority owner, John Morris, began his career in sporting goods with a fishing section in the back of a Brown Derby liquor store owned by his father, located in Springfield MO on the road to Table Rock Lake and Branson, Missouri.\nS4. That small fishing department sold homemade bait and worms, proving popular enough that Bass Pro Shops was incorporated in 1971.\nS5. These homemade baits were so popular that many people wanted the opportunity to buy these when they had returned home.\nS6. Thus began the Bass Pro Shops catalog, first mailed in 1974.\nS7. Soon, it became the world's largest mail order sporting goods store.\nS8. In 1975, to meet the burgeoning demand for Bass Pro Shops exclusive products, American Rod and Gun was established.\nS9. Acting as a separate wholesaling entity ARG serves more than 7,000 independently owned retail stores worldwide.\nS10. In 1977, Bass Pro Shops introduced the first fish-ready complete boat motor and trailer package with the Bass Tracker.\nS11. In 1984, construction began on the Outdoor World Catalog Showroom in Springfield, Missouri.\nS12. Big Cedar Lodge opened in 1988 on Table Rock Lake.\n    \nInput Question:\nWho owns bass pro shops and cabela's?\n\nCorrect Response:\nCabela's is owned by Bass Pro Shops. Bass Pro Shops is owned by John Luke Morris.\n\nModel Prediction:\nThe majority owner of the American sports retailer, Bass Pro Shops, is John Morris.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "The majority owner of the American sports retailer, Bass Pro Shops, is John Morris.\n\nExplanation: There are no irrelevant, incoherent, or repetitive spans in the model prediction. The information provided is relevant to the question, coherent, and not repetitive."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The majority owner of the American sports retailer, Bass Pro Shops, is John Morris.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "S1. The majority owner of the American sports retailer, Bass Pro Shops, is John Morris.\n\nExplanation: There are no inconsistent or unverifiable facts in the model prediction. The information provided in the sentence is factually consistent with the passages and can be verified from Passage 1, Sentence 3."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. [Missing Answer] - Cabela's is owned by Bass Pro Shops.\n\nExplanation:\n1. The model prediction does not mention that Cabela's is owned by Bass Pro Shops, which is part of the question. This information is missing from the model prediction."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The majority owner of the American sports retailer, Bass Pro Shops, is John Morris. Additionally, Bass Pro Shops owns Cabela's."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 22, "end": 51}], "missing-info": [], "corrected-prediction": "The majority owner of Bass Pro Shops is John Morris."}}, {"question": "Which person or group brought polyphonic music into the christian church?", "passages": [["Polyphony", "According to the Evolutionary Model, the origins of polyphonic singing are much deeper, and are connected to the earlier stages of human evolution; polyphony was an important part of a defence system of the hominids, and traditions of polyphony are gradually disappearing all over the world.", "Although the exact origins of polyphony in the Western church traditions are unknown, the treatises \"Musica enchiriadis\" and \"Scolica enchiriadis\", both dating from \"c\".", "900, are usually considered the oldest extant written examples of polyphony.", "These treatises provided examples of two-voice note-against-note embellishments of chants using parallel octaves, fifths, and fourths.", "Rather than being fixed works, they indicated ways of improvising polyphony during performance.", "The \"Winchester Troper\", from \"c\". 1000, is the oldest extant example of notated polyphony for chant performance, although the notation does not indicate precise pitch levels or durations.", "European polyphony rose out of melismatic organum, the earliest harmonization of the chant.", "Twelfth-century composers, such as L\u00e9onin and P\u00e9rotin developed the organum that was introduced centuries earlier, and also added a third and fourth voice to the now homophonic chant."], ["Polyphony", "The oldest extant polyphonic setting of the mass attributable to one composer is Guillaume de Machaut's Messe de Nostre Dame, dated to 1364, during the pontificate of Pope Urban V.\n\nMore recently, the Second Vatican Council (1962\u20131965) stated: \"Gregorian chant, other things being equal, should be given pride of place in liturgical services.", "But other kinds of sacred music, especially polyphony, are by no means excluded...", "Religious singing by the people is to be skillfully fostered, so that in devotions and sacred exercises, as also during liturgical services, the voices of the faithful may ring out\u201d.", "English Protestant west gallery music included polyphonic multi-melodic harmony, including fuguing tunes, by the mid-18th century.", "This tradition passed with emigrants to North America, where it was proliferated in tunebooks, including shape-note books like \"The Southern Harmony\" and \"The Sacred Harp\".", "While this style of singing has largely disappeared from British and North American sacred music, it survived in the rural Southern United States, until it again began to grow a following throughout the United States and even in places such as Ireland, the United Kingdom, Poland, Australia and New Zealand, among others.", "Polyphonic singing in the Balkans is traditional folk singing of this part of southern Europe."], ["Musica enchiriadis", "Musica enchiriadis\n\nMusica enchiriadis is an anonymous musical treatise of the 9th century.", "It is the first surviving attempt to set up a system of rules for polyphony in western art music.", "The treatise was once attributed to Hucbald, but this is no longer accepted.", "Some historians once attributed it to Odo of Cluny (879-942).", "It has also been attributed to Abbot Hoger (d. 906).", "This music theory treatise, along with its companion text, \"Scolica enchiriadis\", was widely circulated in medieval manuscripts, often in association with Boethius' \"De institutione musica\".", "It consists of nineteen chapters; the first nine are devoted to notation, modes, and monophonic plainchant.", "Chapters 10-18 deal with polyphonic music.", "The author here shows how consonant intervals should be used to compose or improvise the type of early-medieval polyphonic music called organum, an early style of note-against-note polyphony several examples of which are included in the treatise.", "(\"Scolica enchiriadis\" also observes that some melodies should be sung \"more quickly\" (\"celerius\"), others \"more slowly\" (\"morosius\").)"]], "gold": "The exact origins of polyphony in the Western church traditions are unknown, in part because the oldest extant written examples of polyphony were composed anonymously. However, the first instance of polyphonic church music attributed to a single named composer occurred when Guillaume de Machaut wrote Messe de Nostre Dame in 1364, during the pontificate of Pope Urban V.", "prediction 1": "The first known attempt to set up rules for polyphony in western art music is the Musica enchiriadis, an anonymous musical treatise of the 9th century. It is the first surviving attempt to set up a system of rules for polyphony in western art music. The music theory treatise, Scolica enchiriadis, is widely circulated in medieval manuscripts, often in association with Boethius' De institutione musica. Abbot Hoger is credited with introducing polyphonic music into the christian church music into the christian church. The oldest extant polyphony attributable to one composer is Guillaume de Machaut's Messe de Nostre Dame, dated to 1364, during the pontificate of Pope Urban V.", "prediction 2": "Musica enchiriadis is an anonymous musical treatise of the 9th century that is considered to be the first surviving attempt to set up a system of rules for polyphony in western art music. It is also credited to Abbot Hoger, who wrote the music theory treatise Scolica enchiriadis, which was widely circulated in medieval manuscripts, often in association with Boethius' De institutione musica. These treatises provided examples of two-voice note-against-note embellishments of chants using parallel oct-note embellishments of chants using parallel octaves, fifths, and fourths.", "prediction 3": "In the 9th century, an anonymous musical treatise, Musica enchiriadis, was published to set up a system of rules for polyphony in western art music. It is considered the first surviving attempt to set up a system of rules for polyphony in western art music. The oldest extant polyphonic setting of the mass attributable to one composer is Guillaume de Machaut's Messe de Nostre Dame, dated to 1364, during the pontificate of Pope Urban V.", "prediction 4": "Musica enchiriadis is an anonymous musical treatise of the 9th century, which is considered to be the first surviving attempt to set up a system of rules for polyphony in western art music. It is the first surviving attempt to set up a system of rules for polyphony in western art music. The treatise, along with its companion text, Scolica enchiriadis, was widely circulated in medieval manuscripts, often in association with Boethius' De institutione musica.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 152, "end": 249}, {"error type": "Irrelevant", "explanation": "", "start": 404, "end": 520}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [2]}], "corrected-prediction": "The exact origins of polyphony in the Western church traditions are unknown. However, the first known attempt to set up rules for polyphony in western art music is the Musica enchiriadis, an anonymous musical treatise of the 9th century. The music theory treatise, Scolica enchiriadis, is widely circulated in medieval manuscripts, often in association with Boethius' De institutione musica. The oldest extant polyphony attributable to one composer is Guillaume de Machaut's Messe de Nostre Dame, dated to 1364, during the pontificate of Pope Urban V."}, "preference": [2, 2, 2, 2, 2, 2], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Polyphony\nS1. According to the Evolutionary Model, the origins of polyphonic singing are much deeper, and are connected to the earlier stages of human evolution; polyphony was an important part of a defence system of the hominids, and traditions of polyphony are gradually disappearing all over the world.\nS2. Although the exact origins of polyphony in the Western church traditions are unknown, the treatises \"Musica enchiriadis\" and \"Scolica enchiriadis\", both dating from \"c\".\nS3. 900, are usually considered the oldest extant written examples of polyphony.\nS4. These treatises provided examples of two-voice note-against-note embellishments of chants using parallel octaves, fifths, and fourths.\nS5. Rather than being fixed works, they indicated ways of improvising polyphony during performance.\nS6. The \"Winchester Troper\", from \"c\". 1000, is the oldest extant example of notated polyphony for chant performance, although the notation does not indicate precise pitch levels or durations.\nS7. European polyphony rose out of melismatic organum, the earliest harmonization of the chant.\nS8. Twelfth-century composers, such as L\u00e9onin and P\u00e9rotin developed the organum that was introduced centuries earlier, and also added a third and fourth voice to the now homophonic chant.\n\nPassage 2: Title (S0) - Polyphony\nS1. The oldest extant polyphonic setting of the mass attributable to one composer is Guillaume de Machaut's Messe de Nostre Dame, dated to 1364, during the pontificate of Pope Urban V.  More recently, the Second Vatican Council (1962\u20131965) stated: \"Gregorian chant, other things being equal, should be given pride of place in liturgical services.\nS2. But other kinds of sacred music, especially polyphony, are by no means excluded...\nS3. Religious singing by the people is to be skillfully fostered, so that in devotions and sacred exercises, as also during liturgical services, the voices of the faithful may ring out\u201d.\nS4. English Protestant west gallery music included polyphonic multi-melodic harmony, including fuguing tunes, by the mid-18th century.\nS5. This tradition passed with emigrants to North America, where it was proliferated in tunebooks, including shape-note books like \"The Southern Harmony\" and \"The Sacred Harp\".\nS6. While this style of singing has largely disappeared from British and North American sacred music, it survived in the rural Southern United States, until it again began to grow a following throughout the United States and even in places such as Ireland, the United Kingdom, Poland, Australia and New Zealand, among others.\nS7. Polyphonic singing in the Balkans is traditional folk singing of this part of southern Europe.\n\nPassage 3: Title (S0) - Musica enchiriadis\nS1. Musica enchiriadis  Musica enchiriadis is an anonymous musical treatise of the 9th century.\nS2. It is the first surviving attempt to set up a system of rules for polyphony in western art music.\nS3. The treatise was once attributed to Hucbald, but this is no longer accepted.\nS4. Some historians once attributed it to Odo of Cluny (879-942).\nS5. It has also been attributed to Abbot Hoger (d. 906).\nS6. This music theory treatise, along with its companion text, \"Scolica enchiriadis\", was widely circulated in medieval manuscripts, often in association with Boethius' \"De institutione musica\".\nS7. It consists of nineteen chapters; the first nine are devoted to notation, modes, and monophonic plainchant.\nS8. Chapters 10-18 deal with polyphonic music.\nS9. The author here shows how consonant intervals should be used to compose or improvise the type of early-medieval polyphonic music called organum, an early style of note-against-note polyphony several examples of which are included in the treatise.\nS10. (\"Scolica enchiriadis\" also observes that some melodies should be sung \"more quickly\" (\"celerius\"), others \"more slowly\" (\"morosius\").)\n    \nInput Question:\nWhich person or group brought polyphonic music into the christian church?\n\nCorrect Response:\nThe exact origins of polyphony in the Western church traditions are unknown, in part because the oldest extant written examples of polyphony were composed anonymously. However, the first instance of polyphonic church music attributed to a single named composer occurred when Guillaume de Machaut wrote Messe de Nostre Dame in 1364, during the pontificate of Pope Urban V.\n\nModel Prediction:\nThe first known attempt to set up rules for polyphony in western art music is the Musica enchiriadis, an anonymous musical treatise of the 9th century. It is the first surviving attempt to set up a system of rules for polyphony in western art music. The music theory treatise, Scolica enchiriadis, is widely circulated in medieval manuscripts, often in association with Boethius' De institutione musica. Abbot Hoger is credited with introducing polyphonic music into the christian church music into the christian church. The oldest extant polyphony attributable to one composer is Guillaume de Machaut's Messe de Nostre Dame, dated to 1364, during the pontificate of Pope Urban V.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "The first known attempt to set up rules for polyphony in western art music is the Musica enchiriadis, an anonymous musical treatise of the 9th century. [It is the first surviving attempt to set up a system of rules for polyphony in western art music.] The music theory treatise, Scolica enchiriadis, is widely circulated in medieval manuscripts, often in association with Boethius' De institutione musica. [Abbot Hoger is credited with introducing polyphonic music into the christian church music into the christian church.] The oldest extant polyphony attributable to one composer is Guillaume de Machaut's Messe de Nostre Dame, dated to 1364, during the pontificate of Pope Urban V.\n\nExplanation:\n1. The second sentence is repetitive as it repeats the information from the first sentence.\n2. The claim that \"Abbot Hoger is credited with introducing polyphonic music into the christian church\" is not only unverifiable but also incoherent due to the repetition of \"music into the christian church\"."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The first known attempt to set up rules for polyphony in western art music is the Musica enchiriadis, an anonymous musical treatise of the 9th century.\nS2. It is the first surviving attempt to set up a system of rules for polyphony in western art music.\nS3. The music theory treatise, Scolica enchiriadis, is widely circulated in medieval manuscripts, often in association with Boethius' De institutione musica.\nS4. Abbot Hoger is credited with introducing polyphonic music into the christian church music into the christian church.\nS5. The oldest extant polyphony attributable to one composer is Guillaume de Machaut's Messe de Nostre Dame, dated to 1364, during the pontificate of Pope Urban V.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "Inconsistent or Unverifiable Sentences:\n1. S4\n\nExplanation:\n1. The claim that \"Abbot Hoger is credited with introducing polyphonic music into the christian church\" is unverifiable as there is no mention of Abbot Hoger introducing polyphonic music into the Christian church in the provided passages."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 2 [Missing Major Auxiliary Information]\n\nExplanation:\n1. The model prediction does not mention that the exact origins of polyphony in the Western church traditions are unknown, which is a crucial piece of information found in the reference response and in Passage 1, sentence 2. This information is important for understanding the context of the development of polyphony in the church."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The exact origins of polyphony in the Western church traditions are unknown. However, the first known attempt to set up rules for polyphony in western art music is the Musica enchiriadis, an anonymous musical treatise of the 9th century. The music theory treatise, Scolica enchiriadis, is widely circulated in medieval manuscripts, often in association with Boethius' De institutione musica. The oldest extant polyphony attributable to one composer is Guillaume de Machaut's Messe de Nostre Dame, dated to 1364, during the pontificate of Pope Urban V."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 152, "end": 249}, {"error type": "Irrelevant", "explanation": "", "start": 250, "end": 403}, {"error type": "Irrelevant", "explanation": "", "start": 404, "end": 520}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [2]}], "corrected-prediction": "The exact origins of polyphony in the Western church traditions are unknown. The first known attempt to set up rules for polyphony in western art music is the Musica enchiriadis, an anonymous musical treatise of the 9th century. The oldest extant polyphony attributable to one composer is Guillaume de Machaut's Messe de Nostre Dame, dated to 1364, during the pontificate of Pope Urban V."}}, {"question": "Who sang total eclipse of the heart in old school?", "passages": [["The Dan Band", "The Dan Band\n\nThe Dan Band is a comedy band created by actor/comedian Dan Finnerty.", "The band is known for its covers of originally female-performed pop songs, with added obscenities and swearing, made famous by Finnerty's appearance in the films \"Old School\" and \"The Hangover\"\n\nFinnerty has appeared in the hit movies \"Old School\" (singing \"Total Eclipse of the Heart\" and \"Lady\"), \"The Terminal\", \"Starsky & Hutch\", where he performed Roberta Flack's \"Feel Like Makin' Love\" at a bat mitzvah, and \"The Hangover\" (performing \"Candy Shop\" and \"Fame\") in a wedding scene reminiscent of his appearance in \"Old School\".", "In 2005, they released \"The Dan Band Live\", their live full-length debut album.", "They gained attention due to their expletive-heavy version of Bonnie Tyler's \"Total Eclipse of the Heart,\" as well as their cover versions of \"Lady\" by Styx, \"Milkshake\" by Kelis, Toni Basil's \"Mickey,\" and many others.", "They filmed a one-hour concert special of their live show called \"Dan Finnerty & The Dan Band: I Am Woman\", for the Bravo network, which was directed by McG and executive produced by Steven Spielberg."], ["Dan Finnerty", "Dan Finnerty\n\nDan Finnerty (born January 22, 1970) is an American actor and singer.", "Finnerty was born in Rochester, New York, and grew up in the small town of Bath, New York.", "He attended Emerson College in Boston.", "He was a member of the hit off-Broadway show \"Stomp\" in New York City.", "In August 1998, he married actress Kathy Najimy.", "Gloria Steinem officiated the ceremony.", "The couple has one daughter, Samia Najimy Finnerty, born December 1996.", "He created and is the lead singer of the cult hit group The Dan Band.", "His show, \"\", was filmed as a one-hour concert special on Cable TV's Bravo channel, directed by McG and executive produced by Steven Spielberg.", "Finnerty is best known for his foul-mouthed rendition of \"Total Eclipse of the Heart\" as the wedding singer at Will Ferrell's wedding in the movie \"Old School\", directed by Todd Phillips, who continued to feature Dan, using him as the sleazy bat-mitzvah singer in \"Starsky & Hutch\" and again as the irreverent wedding singer in \"The Hangover\".", "After seeing The Dan Band, Steven Spielberg cast him in \"The Terminal\"."]], "gold": "Dan Finnerty of The Dan Band sang the lead vocals for Total Eclipse of the Heart in the movie Old School.", "prediction 1": "The Dan Band is a comedy band created by actor/comedian Dan Finnerty, who is best known for his foul-mouthed rendition of Total Eclipse of the Heart as the wedding singer at Will Ferrell's wedding in the movie Old School.", "prediction 2": "The number \"Total Eclipse of the Heart\" was recorded by Bonnie Tyler in 1983. It was also recorded by Bonnie Tyler's band The Dan Band in 1985. The Dan Band is an American comedy band created by actor and comedian Dan Finnerty. The band is known for its covers of originally female-performed pop songs, with added obscenities and swearing, made famous by Finnerty's appearance in the hit movies Old School and The Hangover. Dan Finnerty sang the number \"Total Eclipse of the Heart\" as the wedding singer at Will Ferrell's wedding in the movie Old School.", "prediction 3": "\"Total Eclipse of the Heart\" is a song by American pop singer Bonnie Tyler. American actor and comedian Dan Finnerty sang the song as the wedding singer at Will Ferrell's wedding in the movie Old School. Other people who sang it in Old School included Bonnie Tyler, Roberta Flack, Roberta Flack, Toni Basil, and others.", "prediction 4": "The song Total Eclipse of the Heart was performed by Bonnie Tyler and was written and performed by Bonnie Tyler, who also wrote and performed the lyrics. The Dan Band is a comedy band created by American actor/comedian Dan Finnerty, best known for his foul-mouthed rendition of Total Eclipse of the Heart as the wedding singer at Will Ferrell's wedding in the movie Old School.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 70, "end": 221}], "missing-info": [], "corrected-prediction": "Dan Finnerty of The Dan Band sang \"Total Eclipse of the Heart\" in the movie Old School."}, "preference": [1, 1, 1, 2, 2, 2], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - The Dan Band\nS1. The Dan Band  The Dan Band is a comedy band created by actor/comedian Dan Finnerty.\nS2. The band is known for its covers of originally female-performed pop songs, with added obscenities and swearing, made famous by Finnerty's appearance in the films \"Old School\" and \"The Hangover\"  Finnerty has appeared in the hit movies \"Old School\" (singing \"Total Eclipse of the Heart\" and \"Lady\"), \"The Terminal\", \"Starsky & Hutch\", where he performed Roberta Flack's \"Feel Like Makin' Love\" at a bat mitzvah, and \"The Hangover\" (performing \"Candy Shop\" and \"Fame\") in a wedding scene reminiscent of his appearance in \"Old School\".\nS3. In 2005, they released \"The Dan Band Live\", their live full-length debut album.\nS4. They gained attention due to their expletive-heavy version of Bonnie Tyler's \"Total Eclipse of the Heart,\" as well as their cover versions of \"Lady\" by Styx, \"Milkshake\" by Kelis, Toni Basil's \"Mickey,\" and many others.\nS5. They filmed a one-hour concert special of their live show called \"Dan Finnerty & The Dan Band: I Am Woman\", for the Bravo network, which was directed by McG and executive produced by Steven Spielberg.\n\nPassage 2: Title (S0) - Dan Finnerty\nS1. Dan Finnerty  Dan Finnerty (born January 22, 1970) is an American actor and singer.\nS2. Finnerty was born in Rochester, New York, and grew up in the small town of Bath, New York.\nS3. He attended Emerson College in Boston.\nS4. He was a member of the hit off-Broadway show \"Stomp\" in New York City.\nS5. In August 1998, he married actress Kathy Najimy.\nS6. Gloria Steinem officiated the ceremony.\nS7. The couple has one daughter, Samia Najimy Finnerty, born December 1996.\nS8. He created and is the lead singer of the cult hit group The Dan Band.\nS9. His show, \"\", was filmed as a one-hour concert special on Cable TV's Bravo channel, directed by McG and executive produced by Steven Spielberg.\nS10. Finnerty is best known for his foul-mouthed rendition of \"Total Eclipse of the Heart\" as the wedding singer at Will Ferrell's wedding in the movie \"Old School\", directed by Todd Phillips, who continued to feature Dan, using him as the sleazy bat-mitzvah singer in \"Starsky & Hutch\" and again as the irreverent wedding singer in \"The Hangover\".\nS11. After seeing The Dan Band, Steven Spielberg cast him in \"The Terminal\".\n    \nInput Question:\nWho sang total eclipse of the heart in old school?\n\nCorrect Response:\nDan Finnerty of The Dan Band sang the lead vocals for Total Eclipse of the Heart in the movie Old School.\n\nModel Prediction:\nThe Dan Band is a comedy band created by actor/comedian Dan Finnerty, who is best known for his foul-mouthed rendition of Total Eclipse of the Heart as the wedding singer at Will Ferrell's wedding in the movie Old School.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "The Dan Band is a comedy band created by actor/comedian Dan Finnerty, [who is best known for his foul-mouthed rendition of Total Eclipse of the Heart as the wedding singer at Will Ferrell's wedding in the movie Old School.]\n\nExplanation:\n1. The span \"who is best known for his foul-mouthed rendition of Total Eclipse of the Heart as the wedding singer at Will Ferrell's wedding in the movie Old School\" is irrelevant. The question asks for the singer of \"Total Eclipse of the Heart\" in the movie \"Old School\", not for additional details about the performance or the character's role in the movie. This information is not necessary to answer the question and is not included in the reference response. Therefore, it should be marked as \"Irrelevant\"."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The Dan Band is a comedy band created by actor/comedian Dan Finnerty, who is best known for his foul-mouthed rendition of Total Eclipse of the Heart as the wedding singer at Will Ferrell's wedding in the movie Old School.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation:\nThere are no factual inconsistencies or unverifiable facts in the model prediction. All the information provided in the prediction is consistent with the passages and can be verified from the passages."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "None\n\nExplanation:\nThere is no missing information in the model prediction. The prediction correctly identifies Dan Finnerty of The Dan Band as the singer of \"Total Eclipse of the Heart\" in the movie \"Old School\", which directly answers the question."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "Dan Finnerty of The Dan Band sang \"Total Eclipse of the Heart\" in the movie Old School."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 16, "end": 55}, {"error type": "Irrelevant", "explanation": "", "start": 70, "end": 87}, {"error type": "Irrelevant", "explanation": "", "start": 149, "end": 196}], "missing-info": [], "corrected-prediction": "Dan Finnerty, from The Dan Band, was the singer of Total Eclipse of the Heart in the move Old School."}}, {"question": "When does the rockefeller tree get put up?", "passages": [["Rockefeller Center Christmas Tree", "The first Christmas tree at Rockefeller Center was erected in 1931, during the Depression-era construction of Rockefeller Center, when workers decorated a smaller balsam fir with \"strings of cranberries, garlands of paper, and even a few tin cans\" on Christmas Eve.", "With the lighting of the first official tree two years later, the tree became what Rockefeller Center dubbed \"a holiday beacon for New Yorkers and visitors alike.\"", "A skating rink was opened below the tree in the plaza in 1936.", "Since then, the Rockefeller Center Christmas Tree has been a yearly tradition.", "Workers pooled their money for that unlit tree, with the garlands made by workers' families.", "According to Rockefeller Center's website, the tree was \"from the beginning ... a gathering place and reflection of what was happening in the world around it.\"", "World War II ushered in simple, patriotic decorations, including red, white and blue unlit globes and painted wooden stars.", "In 1942, instead of one large tree, three more modest trees were raised, each decorated in one of the flag's colors.", "From 1944 until the war's end in 1945, the tree went unlit due to blackout regulations."], ["Rockefeller Center Christmas Tree", "Rockefeller Center Christmas Tree\n\nThe Rockefeller Center Christmas Tree is a large Christmas tree placed annually in Rockefeller Center, in Midtown Manhattan.", "The tree is erected in mid November and lit in a public ceremony in late November or early December.", "Since 1997, the lighting has been broadcast live, to hundreds of millions, on NBC's \"Christmas in Rockefeller Center\" telecast on a Wednesday after Thanksgiving.", "The broadcast features live entertainment and a tree lighting ceremony, where the tree is lit by the current Mayor of New York City and special guests.", "An estimated 125 million people visit the attraction each year.", "The tree, usually a Norway spruce tall, has been a national tradition each year since 1933.", "The 2018 Christmas Tree Lighting took place on November 28, 2018; the tree will remain on display until January 7, 2019.", "Trees are traditionally donated to Rockefeller Center, which in turn donates the lumber after display.", "Until his death in 2009, the late David Murbach, Manager of the Gardens Division of Rockefeller Center, scouted for the desired tree in upstate New York and surrounding states, and even Ottawa in Ontario, Canada.", "Erik Pauz\u00e9, Head Gardener at Rockefeller Center, looks for each year's Rockefeller Center Christmas tree.", "He visits nurseries throughout the tri-state area and looks for unique backyard trees.", "Trees are also submitted for consideration through Rockefeller Center's website."]], "gold": "The Rockefeller Center Christmas Tree is put in place in mid November and lit in a public ceremony on the Wednesday evening following Thanksgiving, continuing a tradition that has been practiced since 1931. The lighting of the tree has been broadcast live on NBC every year since 1997. ", "prediction 1": "The Rockefeller Center Christmas Tree is a large Christmas tree placed annually in Rockefeller Center, in Midtown Manhattan. The tree is erected in mid November and lit in a public ceremony in late November or early December. The 2018 Christmas Tree Lighting took place on November 28, 2018; the tree will remain on display until January 7, 2019.", "prediction 2": "Rockefeller Center Christmas Tree is a large Christmas tree placed annually in Rockefeller Center, in Midtown Manhattan. The tree is erected in mid November and lit in a public ceremony in late November or early December. The 2018 Christmas Tree Lighting took place on November 28, 2018; the tree will remain on display until January 7, 2019.", "prediction 3": "The Rockefeller Center Christmas Tree is a large Christmas tree placed annually in Rockefeller Center, in Midtown Manhattan. The tree is erected in mid November and lit in a public ceremony in late November or early December. Since 1997, the lighting has been broadcast live, to hundreds of millions, on NBC's \"Christmas in Rockefeller Center\" telecast on a Wednesday after Thanksgiving.", "prediction 4": "The Rockefeller Center Christmas Tree is a large Christmas tree placed annually in Rockefeller Center, in Midtown Manhattan. The tree is erected in mid November and lit in a public ceremony in late November or early December. In 2018, the tree was lit on November 28, 2018. In 2019, the tree will remain on display until January 7, 2019.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 226, "end": 346}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [4]}], "corrected-prediction": "The Rockefeller Center Christmas Tree is a large Christmas tree placed annually in Rockefeller Center, in Midtown Manhattan. The tree is erected in mid November and lit in a public ceremony in late November or early December. This has been a yearly tradition since 1931. Since 1997, the lighting has been broadcast live, on NBC's \"Christmas in Rockefeller Center\" telecast on a Wednesday after Thanksgiving."}, "preference": [0, 1, 0, 1, 0, 2], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Rockefeller Center Christmas Tree\nS1. The first Christmas tree at Rockefeller Center was erected in 1931, during the Depression-era construction of Rockefeller Center, when workers decorated a smaller balsam fir with \"strings of cranberries, garlands of paper, and even a few tin cans\" on Christmas Eve.\nS2. With the lighting of the first official tree two years later, the tree became what Rockefeller Center dubbed \"a holiday beacon for New Yorkers and visitors alike.\"\nS3. A skating rink was opened below the tree in the plaza in 1936.\nS4. Since then, the Rockefeller Center Christmas Tree has been a yearly tradition.\nS5. Workers pooled their money for that unlit tree, with the garlands made by workers' families.\nS6. According to Rockefeller Center's website, the tree was \"from the beginning ... a gathering place and reflection of what was happening in the world around it.\"\nS7. World War II ushered in simple, patriotic decorations, including red, white and blue unlit globes and painted wooden stars.\nS8. In 1942, instead of one large tree, three more modest trees were raised, each decorated in one of the flag's colors.\nS9. From 1944 until the war's end in 1945, the tree went unlit due to blackout regulations.\n\nPassage 2: Title (S0) - Rockefeller Center Christmas Tree\nS1. Rockefeller Center Christmas Tree  The Rockefeller Center Christmas Tree is a large Christmas tree placed annually in Rockefeller Center, in Midtown Manhattan.\nS2. The tree is erected in mid November and lit in a public ceremony in late November or early December.\nS3. Since 1997, the lighting has been broadcast live, to hundreds of millions, on NBC's \"Christmas in Rockefeller Center\" telecast on a Wednesday after Thanksgiving.\nS4. The broadcast features live entertainment and a tree lighting ceremony, where the tree is lit by the current Mayor of New York City and special guests.\nS5. An estimated 125 million people visit the attraction each year.\nS6. The tree, usually a Norway spruce tall, has been a national tradition each year since 1933.\nS7. The 2018 Christmas Tree Lighting took place on November 28, 2018; the tree will remain on display until January 7, 2019.\nS8. Trees are traditionally donated to Rockefeller Center, which in turn donates the lumber after display.\nS9. Until his death in 2009, the late David Murbach, Manager of the Gardens Division of Rockefeller Center, scouted for the desired tree in upstate New York and surrounding states, and even Ottawa in Ontario, Canada.\nS10. Erik Pauz\u00e9, Head Gardener at Rockefeller Center, looks for each year's Rockefeller Center Christmas tree.\nS11. He visits nurseries throughout the tri-state area and looks for unique backyard trees.\nS12. Trees are also submitted for consideration through Rockefeller Center's website.\n    \nInput Question:\nWhen does the rockefeller tree get put up?\n\nCorrect Response:\nThe Rockefeller Center Christmas Tree is put in place in mid November and lit in a public ceremony on the Wednesday evening following Thanksgiving, continuing a tradition that has been practiced since 1931. The lighting of the tree has been broadcast live on NBC every year since 1997. \n\nModel Prediction:\nThe Rockefeller Center Christmas Tree is a large Christmas tree placed annually in Rockefeller Center, in Midtown Manhattan. The tree is erected in mid November and lit in a public ceremony in late November or early December. The 2018 Christmas Tree Lighting took place on November 28, 2018; the tree will remain on display until January 7, 2019.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "The Rockefeller Center Christmas Tree is a large Christmas tree placed annually in Rockefeller Center, in Midtown Manhattan. The tree is erected in mid November and lit in a public ceremony in late November or early December. [The 2018 Christmas Tree Lighting took place on November 28, 2018; the tree will remain on display until January 7, 2019.]\n\nExplanation:\n1. The last sentence in the model prediction is irrelevant to the question as it provides specific information about the 2018 Christmas Tree Lighting, which is not asked in the question. The question is about when the tree gets put up in general, not about a specific year. Therefore, it should be marked as \"Irrelevant\"."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The Rockefeller Center Christmas Tree is a large Christmas tree placed annually in Rockefeller Center, in Midtown Manhattan.\nS2. The tree is erected in mid November and lit in a public ceremony in late November or early December.\nS3. The 2018 Christmas Tree Lighting took place on November 28, 2018; the tree will remain on display until January 7, 2019.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation:\nAll the facts mentioned in the model prediction are consistent with the provided passages and can be verified from the passages."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 4 [Missing Major Auxiliary Information]\n2. Passage 2, sentence 3 [Missing Major Auxiliary Information]\n\nExplanation:\n1. The model prediction misses the information that the Rockefeller Center Christmas Tree has been a yearly tradition since 1931, which is crucial for understanding the history and tradition of the event. This information can be found in Passage 1, sentence 4.\n2. The model prediction also misses the information that the lighting of the tree has been broadcast live on NBC's \"Christmas in Rockefeller Center\" telecast on a Wednesday after Thanksgiving since 1997. This information is important as it provides context on how the event is shared with the public. This information can be found in Passage 2, sentence 3."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The Rockefeller Center Christmas Tree is a large Christmas tree placed annually in Rockefeller Center, in Midtown Manhattan. The tree is erected in mid November and lit in a public ceremony in late November or early December. This has been a yearly tradition since 1931. Since 1997, the lighting has been broadcast live, on NBC's \"Christmas in Rockefeller Center\" telecast on a Wednesday after Thanksgiving."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 38, "end": 124}, {"error type": "Irrelevant", "explanation": "", "start": 226, "end": 346}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 2, "sentence_id": [3]}], "corrected-prediction": "The Rockefeller Center Christmas Tree is erected in mid November and lit in a public ceremony in late November or early December. Since 1997, the lighting has been broadcast live, to hundreds of millions, on NBC's \"Christmas in Rockefeller Center\" telecast on a Wednesday after Thanksgiving."}}, {"question": "Who played the first ryan on last man standing?", "passages": [["Last Man Standing (U.S. TV series)", "On June 19, 2012, it was also announced that twins Luke and Evan Kruntchev, who played the role of Boyd in season 1, would not be returning; they were replaced by Flynn Morrison in season 2.", "The character of Boyd was also age-advanced from two years old to five years old.", "Jordan Masterson plays Ryan, Boyd's father, in a recurring role beginning in season 2.", "The role was previously played by Nick Jonas, who guest-starred in one episode in season 1.", "The second season initially received a 13-episode order.", "ABC announced on November 12, 2012, that an additional three scripts had been ordered.", "On November 27, five more episodes were ordered to bring the second-season episode total to 18.", "On May 10, 2013, the series was renewed for a third season, which premiered on September 20, 2013, and ended on April 25, 2014, after 22 episodes.", "On May 10, 2014, ABC renewed \"Last Man Standing\" for a fourth season, which premiered on October 3, 2014.", "Allen and Elizondo guest-starred as their \"Last Man Standing\" characters in a crossover episode with the fellow ABC Friday sitcom \"Cristela\".", "On May 10, 2015, ABC announced the show had been renewed for a fifth season."]], "gold": "Jordan Masterson plays Ryan, Boyd's father, in a recurring role beginning in season 2. The role was previously played by Nick Jonas, who guest-starred in one episode in season 1.", "prediction 1": "Ryan, Boyd's father, is a character in the U.S. television series Last Man Standing, and is played by Jordan Masterson. Before Masterson, the role of Ryan was played by Nick Jonas in one episode of season 1.", "prediction 2": "Jordan Masterson plays Ryan, Boyd's father, in a recurring role beginning in season 2. The role was previously played by Nick Jonas, who guest-starred in one episode in season 1.", "prediction 3": "Ryan on Last Man Standing, is played by Jordan Masterson, who plays Ryan in season 2 after the character's father character, Boyd, was played by Nick Jonas, who guest-starred in one episode of season 1.", "prediction 4": "Ryan Masterson plays Ryan, Boyd's father, in a recurring role beginning in season 2. The role was previously played by Nick Jonas, who guest-starred in one episode in season 1.", "feedback": {"errors": [], "missing-info": [], "corrected-prediction": "Ryan, Boyd's father, is a character in the U.S. television series Last Man Standing, and is played by Jordan Masterson. Before Masterson, the role of Ryan was played by Nick Jonas in one episode of season 1."}, "preference": [1, 0, 0, 0, 0, 0], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Last Man Standing (U.S. TV series)\nS1. On June 19, 2012, it was also announced that twins Luke and Evan Kruntchev, who played the role of Boyd in season 1, would not be returning; they were replaced by Flynn Morrison in season 2.\nS2. The character of Boyd was also age-advanced from two years old to five years old.\nS3. Jordan Masterson plays Ryan, Boyd's father, in a recurring role beginning in season 2.\nS4. The role was previously played by Nick Jonas, who guest-starred in one episode in season 1.\nS5. The second season initially received a 13-episode order.\nS6. ABC announced on November 12, 2012, that an additional three scripts had been ordered.\nS7. On November 27, five more episodes were ordered to bring the second-season episode total to 18.\nS8. On May 10, 2013, the series was renewed for a third season, which premiered on September 20, 2013, and ended on April 25, 2014, after 22 episodes.\nS9. On May 10, 2014, ABC renewed \"Last Man Standing\" for a fourth season, which premiered on October 3, 2014.\nS10. Allen and Elizondo guest-starred as their \"Last Man Standing\" characters in a crossover episode with the fellow ABC Friday sitcom \"Cristela\".\nS11. On May 10, 2015, ABC announced the show had been renewed for a fifth season.\n    \nInput Question:\nWho played the first ryan on last man standing?\n\nCorrect Response:\nJordan Masterson plays Ryan, Boyd's father, in a recurring role beginning in season 2. The role was previously played by Nick Jonas, who guest-starred in one episode in season 1.\n\nModel Prediction:\nRyan, Boyd's father, is a character in the U.S. television series Last Man Standing, and is played by Jordan Masterson. Before Masterson, the role of Ryan was played by Nick Jonas in one episode of season 1.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "Ryan, Boyd's father, is a character in the U.S. television series Last Man Standing, and is played by Jordan Masterson. Before Masterson, the role of Ryan was played by Nick Jonas in one episode of season 1.\n\nExplanation: There are no irrelevant, incoherent, or repetitive spans in the model prediction. The information provided is relevant to the question, coherent, and not repetitive."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. Ryan, Boyd's father, is a character in the U.S. television series Last Man Standing, and is played by Jordan Masterson.\nS2. Before Masterson, the role of Ryan was played by Nick Jonas in one episode of season 1.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation: All the facts in the model prediction are consistent with the passages and can be verified by them."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "None\n\nExplanation: The model prediction includes all the necessary information to answer the question. It correctly identifies both actors who played the role of Ryan in the series \"Last Man Standing\"."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "Ryan, Boyd's father, is a character in the U.S. television series Last Man Standing, and is played by Jordan Masterson. Before Masterson, the role of Ryan was played by Nick Jonas in one episode of season 1."}], "feedback_human": {"errors": [], "missing-info": [], "corrected-prediction": "Ryan, Boyd's father, is a character in the U.S. television series Last Man Standing, and is played by Jordan Masterson. Before Masterson, the role of Ryan was played by Nick Jonas in one episode of season 1."}}, {"question": "What is a group of australian magpies called?", "passages": [["Court of Owls", "In the new \"Nightwing\" series, Lincoln March addresses the Parliament of Owls as they decide to cast aside their connection to the Court of Owls in Gotham and don black owl masks.", "As March begins to preach his new role in the Parliament, he is killed by Raptor, who reveals that both he and the Parliament agree that March's own desires began to become a hindrance to them and they needed a clean path to Nightwing.", "Dick Grayson has finally re-obtained his secret identity and has returned to the role of Nightwing.", "He willingly works for the Parliament in order to bring them down from the inside; they are wary of and suspect Grayson's true intentions, but they do not know that their leverage over him has been resolved.", "To keep him in check, the Parliament partners him with Raptor to aid in his missions.", "In the \"Watchmen\" sequel \"Doomsday Clock\", representatives of the Court of Owls are among the villains that attend the underground meeting held by Riddler to talk about the Superman Theory.", "Their judge states that the Court of Owls are not relocating to Kahndaq.", "The Talons are a breed of deadly assassins that are absolutely loyal to the Court of Owls.", "They remain \"sleeping\" deep within their inner sanctum until they are \"called\" upon."], ["Flock (birds)", "Flock (birds)\n\n", "A flock is a gathering of a group of same species animals in order to forage or travel with one another.", "In avians flocks are typically seen in association with migration.", "While this is true it can also be seen that flocking is important in safety from predation and foraging benefits.", "However it is also important to note that living in a flock can also come at a cost to the birds living within it.", "The definition of flock is narrow, only focusing on a single species existing within a flock.", "However the existence of mixed flocks are also present in the environment and consist of at least two or more species.", "In avians the species that tend to flock together are typically similar in taxonomy as well as morphological characters such as size and shape By having a flock with multiple species present, the defence against predation increases.", "Defence against predators is particularly important in closed habitats such as forests where early warning calls play a vital importance in the early recognition of danger.", "The result is the formation of many mixed-species feeding flocks.", "While mixed flocks are typically thought to be composed of two different species, it is specifically the two different behaviours of the species that compose a mixed flock.", "Within a mixed flock there can be two different behavioural characteristics: sally and gleaner."]], "gold": "A group of Australian magpies is usually called a parliament, which is also the name for a group of owls, but flock and tiding are what they are sometimes called. A flock is a gathering of a group of same-species animals to forage or travel.", "prediction 1": "A flock is a gathering of a group of same species animals in order to forage or travel with one another. In avians flocks are typically seen in association with migration. However the existence of mixed flocks are also present in the environment and consist of at least two or more species. In the Australian magpie, a flock is a group of magpies that have bonded together to form a single group.\n", "prediction 2": "The English word \"flock\" generally refers to a group of small, independent animals that are joined together by similar mates in order to forage or travel with one another. A group of Australian magpies, also known as a flock, is a group of still-living mosquito-eating pigeons. They live in colonies and are often found together as a species-specific group.", "prediction 3": "There are several ways a group of australian magpies can be called a flock. A flock of magpies can resemble a family or a colony of magpies. A colony is composed of a \u2018social\u2019 group of magpies who regularly lodge together in a den. In the Australian magpie, a \u201choard\u201d is a group of magpies that gather to forage or travel together. A colony is a collection of small, closely related birds which have been put into a protective chick mocking to each other magpies who live in a colony of birds known as a flock. In the Australian magpie, a colony of magpies known as a group, a colony.", "prediction 4": "A flock is a gathering of a group of same species animals in order to forage or travel with one another. In birds this is a group of singly or mixed magpie individuals and is sometimes called a \"single\" or \"double flock.\" In mammals this is a group of grebes or Godwits, sometimes called a \"double flock\". In Australia a single magpie is called a \"square flock\" which means a \"population of singly or mixed magpies\".", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 172, "end": 290}], "missing-info": [], "corrected-prediction": "A flock is a gathering of a group of same species animals in order to forage or travel with one another. In avians, flocks are typically seen in association with migration. In the case of the Australian magpie, a flock is a group of magpies that have bonded together to form a single group."}, "preference": [1, 1, 1, 1, 2, 2], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Court of Owls\nS1. In the new \"Nightwing\" series, Lincoln March addresses the Parliament of Owls as they decide to cast aside their connection to the Court of Owls in Gotham and don black owl masks.\nS2. As March begins to preach his new role in the Parliament, he is killed by Raptor, who reveals that both he and the Parliament agree that March's own desires began to become a hindrance to them and they needed a clean path to Nightwing.\nS3. Dick Grayson has finally re-obtained his secret identity and has returned to the role of Nightwing.\nS4. He willingly works for the Parliament in order to bring them down from the inside; they are wary of and suspect Grayson's true intentions, but they do not know that their leverage over him has been resolved.\nS5. To keep him in check, the Parliament partners him with Raptor to aid in his missions.\nS6. In the \"Watchmen\" sequel \"Doomsday Clock\", representatives of the Court of Owls are among the villains that attend the underground meeting held by Riddler to talk about the Superman Theory.\nS7. Their judge states that the Court of Owls are not relocating to Kahndaq.\nS8. The Talons are a breed of deadly assassins that are absolutely loyal to the Court of Owls.\nS9. They remain \"sleeping\" deep within their inner sanctum until they are \"called\" upon.\n\nPassage 2: Title (S0) - Flock (birds)\nS1. Flock (birds)  \nS2. A flock is a gathering of a group of same species animals in order to forage or travel with one another.\nS3. In avians flocks are typically seen in association with migration.\nS4. While this is true it can also be seen that flocking is important in safety from predation and foraging benefits.\nS5. However it is also important to note that living in a flock can also come at a cost to the birds living within it.\nS6. The definition of flock is narrow, only focusing on a single species existing within a flock.\nS7. However the existence of mixed flocks are also present in the environment and consist of at least two or more species.\nS8. In avians the species that tend to flock together are typically similar in taxonomy as well as morphological characters such as size and shape By having a flock with multiple species present, the defence against predation increases.\nS9. Defence against predators is particularly important in closed habitats such as forests where early warning calls play a vital importance in the early recognition of danger.\nS10. The result is the formation of many mixed-species feeding flocks.\nS11. While mixed flocks are typically thought to be composed of two different species, it is specifically the two different behaviours of the species that compose a mixed flock.\nS12. Within a mixed flock there can be two different behavioural characteristics: sally and gleaner.\n    \nInput Question:\nWhat is a group of australian magpies called?\n\nCorrect Response:\nA group of Australian magpies is usually called a parliament, which is also the name for a group of owls, but flock and tiding are what they are sometimes called. A flock is a gathering of a group of same-species animals to forage or travel.\n\nModel Prediction:\nA flock is a gathering of a group of same species animals in order to forage or travel with one another. In avians flocks are typically seen in association with migration. However the existence of mixed flocks are also present in the environment and consist of at least two or more species. In the Australian magpie, a flock is a group of magpies that have bonded together to form a single group.\n\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "A flock is a gathering of a group of same species animals in order to forage or travel with one another. In avians flocks are typically seen in association with migration. [However the existence of mixed flocks are also present in the environment and consist of at least two or more species.] In the Australian magpie, a flock is a group of magpies that have bonded together to form a single group.\n\nExplanation:\nThe information about mixed flocks is irrelevant to the question, which is asking about a group of Australian magpies. The question does not ask about mixed groups of different species. Therefore, the information about mixed flocks is marked as irrelevant."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. A flock is a gathering of a group of same species animals in order to forage or travel with one another.\nS2. In avians flocks are typically seen in association with migration.\nS3. However the existence of mixed flocks are also present in the environment and consist of at least two or more species.\nS4. In the Australian magpie, a flock is a group of magpies that have bonded together to form a single group.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation:\nAll the facts presented in the model prediction are consistent with the information in the passages. There are no unverifiable or inconsistent facts."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "None\n\nExplanation:\nThe model prediction does not miss any crucial information from the passages. The passages do not provide any additional information about what a group of Australian magpies is called."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "A flock is a gathering of a group of same species animals in order to forage or travel with one another. In avians, flocks are typically seen in association with migration. In the case of the Australian magpie, a flock is a group of magpies that have bonded together to form a single group."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 105, "end": 171}, {"error type": "Irrelevant", "explanation": "", "start": 172, "end": 290}], "missing-info": [], "corrected-prediction": "A flock is a gathering of a group of same species animals in order to forage or travel with one another. In the Australian magpie, a flock is a group of magpies that have bonded together to form a single group.\n"}}, {"question": "Little house on the prairie christmas blizzard episode?", "passages": [["Little House on the Prairie", "Little House on the Prairie\n\nThe \"Little House\" Books is a series of American children's novels written by Laura Ingalls Wilder, based on her childhood and adolescence in the American Midwest (Wisconsin, Kansas, Minnesota, South Dakota, and Missouri) between 1870 and 1894.", "Eight of the novels were completed by Wilder, and published by Harper & Brothers.", "The appellation \"Little House\" books comes from the first and third novels in the series of eight published in her lifetime.", "The second novel was about her husband's childhood.", "The first draft of a ninth novel was published posthumously in 1971 and is commonly included in the series.", "The \"Little House\" books have been adapted for stage or screen more than once, most successfully as the American television series \"Little House on the Prairie\", which ran from 1974 to 1983.", "As well as an anime, and many different kinds of books, such as cookbooks, there are also many licensed objects to buy that are representative of the books.", "A tenth book, the non-fiction \"On the Way Home\", is Laura Ingalls Wilder's diary of the years after 1894, when she, her husband and their infant daughter moved from De Smet, South Dakota to Mansfield, Missouri, where they settled permanently.", "It was published in 1962 and includes commentary by Rose Wilder Lane."], ["The Long Winter (novel)", "The Long Winter (novel)\n\nThe Long Winter is a historical fiction children's novel written by Laura Ingalls Wilder and published in 1940, the sixth of nine books in her \"Little House\" series.", "It is set in southeastern Dakota Territory during the severe winter of 1880\u20131881, when she turned 14 years old.", "The novel was one runner-up for the Newbery Medal in 1941, as all the fourth to eighth \"Little House\" books were from 1938 to 1943.", "In retrospect they are called Newbery Honor Books.", "On a hot August day in the 1880s, at the Ingalls' homestead in Dakota Territory, Laura offers to help Pa stack hay to feed their stock in the winter.", "As they work, she notices a muskrat den in the nearby Big Slough.", "Upon inspecting it, Pa notes that its walls are the thickest he has ever seen and fears the upcoming winter will be a hard one.", "In mid-October, the Ingalls wake to an unusually early blizzard howling around their poorly insulated claim shanty.", "Soon afterward, Pa receives another warning from an unexpected source: an old Native American man comes to the general store in town to warn the white settlers that there will be seven months of blizzards.", "Pa decides to move his family into his store building in town for the winter."], ["Mid-December 2007 North American winter storms", "Mid-December 2007 North American winter storms\n\nThe Mid-December 2007 North American winter storms were a series of winter storms that affected much of central and eastern North America, from December 8 to December 18, 2007.", "The systems affected areas from Oklahoma to Newfoundland and Labrador with freezing rain, thunderstorms, sleet, snow, damaging winds, and blizzard-like conditions in various areas.", "The first two storms produced copious amounts of ice across the Midwestern United States and Great Plains from December 8 to December 11, knocking out power to approximately 1.5\u00a0million customers from Oklahoma north to Iowa.", "The second storm moved northeast, producing heavy snow across New York and New England.", "A third storm was responsible for a major winter storm from Kansas to the Canadian Maritimes, bringing locally record-breaking snowfalls to Ontario, an icestorm across the Appalachians, and thunderstorms and tornadoes to the Southeastern United States.", "The ice storms were responsible for at least 22 deaths across three states.", "At least 25 additional deaths were blamed on the December 15\u201316 Midwest and Eastern snowstorm, and its aftermath across six US States and three Canadian provinces; 1 additional death was caused by the severe weather outbreak in the Southeast.", "Much of the affected areas were already hit by a significant winter storm during the weekend of December 1 and December 2."]], "gold": "Season 3 Episode 11 of Little House on the Prairie, titled Blizzard, originally aired on Januare 3, 1977. The Little House on the Prairie television series was based on The Little House Books by Laura Ingles Wilder. One of the books in the Little House series, The Long Winter, is an autobiographical children's novel that is set in the southeastern Dakota Territory during the severe winter of 1880 to1881, when Wilder turned 14 years old.", "prediction 1": "Little House on the Prairie aired a blizzard episode on Christmas Day, December 24, 2007.", "prediction 2": "The Christmas episode of the American television series Little House on the Prairie depicts a blizzard in mid-October, the episode of the show is titled \"The Christmas Blizzard\".", "prediction 3": "In the episode Little House on the Prairie's Christmas blizzard episode, the episode The Christmas Story, Pa wakes up to an unusually early blizzard howling around their poorly insulated claim shanty. Soon afterward, Pa receives another warning from an unexpected source: an old Native American man comes to the general store in town to warn the white settlers that there will be seven months of blizzards. Pa decides to move his family into his store building in town for the winter. Episode 2 of the series, was set in southeastern Dakota Territory during the severe winter of 1880\u20131881, when she turned 14 years old. Episode 3 of the blizzard was broadcast on the American television series.", "prediction 4": "Little House on the Prairie is an American television series that aired from 1974 to 1983, based on the children's book series Little House, as well as a series of American television shows that ran from 1974 to 1983. In the Christmas episode of the show, the blizzard in the house was caused by Mid-December 2007 North American winter storms.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 0, "end": 89}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 1, "sentence_id": [6]}], "corrected-prediction": "Season 3 Episode 11 of Little House on the Prairie, titled Blizzard, is based on The Little House Books by Laura Ingles Wilder. Specifically, it draws inspiration from The Long Winter, a book in the series set in the southeastern Dakota Territory during the severe winter of 1880 to 1881."}, "preference": [2, 2, 2, 2, 2, 2], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Little House on the Prairie\nS1. Little House on the Prairie  The \"Little House\" Books is a series of American children's novels written by Laura Ingalls Wilder, based on her childhood and adolescence in the American Midwest (Wisconsin, Kansas, Minnesota, South Dakota, and Missouri) between 1870 and 1894.\nS2. Eight of the novels were completed by Wilder, and published by Harper & Brothers.\nS3. The appellation \"Little House\" books comes from the first and third novels in the series of eight published in her lifetime.\nS4. The second novel was about her husband's childhood.\nS5. The first draft of a ninth novel was published posthumously in 1971 and is commonly included in the series.\nS6. The \"Little House\" books have been adapted for stage or screen more than once, most successfully as the American television series \"Little House on the Prairie\", which ran from 1974 to 1983.\nS7. As well as an anime, and many different kinds of books, such as cookbooks, there are also many licensed objects to buy that are representative of the books.\nS8. A tenth book, the non-fiction \"On the Way Home\", is Laura Ingalls Wilder's diary of the years after 1894, when she, her husband and their infant daughter moved from De Smet, South Dakota to Mansfield, Missouri, where they settled permanently.\nS9. It was published in 1962 and includes commentary by Rose Wilder Lane.\n\nPassage 2: Title (S0) - The Long Winter (novel)\nS1. The Long Winter (novel)  The Long Winter is a historical fiction children's novel written by Laura Ingalls Wilder and published in 1940, the sixth of nine books in her \"Little House\" series.\nS2. It is set in southeastern Dakota Territory during the severe winter of 1880\u20131881, when she turned 14 years old.\nS3. The novel was one runner-up for the Newbery Medal in 1941, as all the fourth to eighth \"Little House\" books were from 1938 to 1943.\nS4. In retrospect they are called Newbery Honor Books.\nS5. On a hot August day in the 1880s, at the Ingalls' homestead in Dakota Territory, Laura offers to help Pa stack hay to feed their stock in the winter.\nS6. As they work, she notices a muskrat den in the nearby Big Slough.\nS7. Upon inspecting it, Pa notes that its walls are the thickest he has ever seen and fears the upcoming winter will be a hard one.\nS8. In mid-October, the Ingalls wake to an unusually early blizzard howling around their poorly insulated claim shanty.\nS9. Soon afterward, Pa receives another warning from an unexpected source: an old Native American man comes to the general store in town to warn the white settlers that there will be seven months of blizzards.\nS10. Pa decides to move his family into his store building in town for the winter.\n\nPassage 3: Title (S0) - Mid-December 2007 North American winter storms\nS1. Mid-December 2007 North American winter storms  The Mid-December 2007 North American winter storms were a series of winter storms that affected much of central and eastern North America, from December 8 to December 18, 2007.\nS2. The systems affected areas from Oklahoma to Newfoundland and Labrador with freezing rain, thunderstorms, sleet, snow, damaging winds, and blizzard-like conditions in various areas.\nS3. The first two storms produced copious amounts of ice across the Midwestern United States and Great Plains from December 8 to December 11, knocking out power to approximately 1.5\u00a0million customers from Oklahoma north to Iowa.\nS4. The second storm moved northeast, producing heavy snow across New York and New England.\nS5. A third storm was responsible for a major winter storm from Kansas to the Canadian Maritimes, bringing locally record-breaking snowfalls to Ontario, an icestorm across the Appalachians, and thunderstorms and tornadoes to the Southeastern United States.\nS6. The ice storms were responsible for at least 22 deaths across three states.\nS7. At least 25 additional deaths were blamed on the December 15\u201316 Midwest and Eastern snowstorm, and its aftermath across six US States and three Canadian provinces; 1 additional death was caused by the severe weather outbreak in the Southeast.\nS8. Much of the affected areas were already hit by a significant winter storm during the weekend of December 1 and December 2.\n    \nInput Question:\nLittle house on the prairie christmas blizzard episode?\n\nCorrect Response:\nSeason 3 Episode 11 of Little House on the Prairie, titled Blizzard, originally aired on Januare 3, 1977. The Little House on the Prairie television series was based on The Little House Books by Laura Ingles Wilder. One of the books in the Little House series, The Long Winter, is an autobiographical children's novel that is set in the southeastern Dakota Territory during the severe winter of 1880 to1881, when Wilder turned 14 years old.\n\nModel Prediction:\nLittle House on the Prairie aired a blizzard episode on Christmas Day, December 24, 2007.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "[Little House on the Prairie aired a blizzard episode on Christmas Day, December 24, 2007.]\n\nExplanation:\nThe entire model prediction is irrelevant as it does not provide the correct information about the blizzard episode of Little House on the Prairie. The date provided is not mentioned in the passages and is not related to the correct response."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. Little House on the Prairie aired a blizzard episode on Christmas Day, December 24, 2007.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "S1\n\nExplanation:\nThe model prediction states that Little House on the Prairie aired a blizzard episode on Christmas Day, December 24, 2007. This is an unverifiable fact as there is no information in the passages to support this claim. The passages do not mention any episode airing on this date."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 6 [Missing Answer]\n2. Passage 2, sentence 2 [Missing Major Auxiliary Information]\n\nExplanation:\n1. The model prediction does not mention that the blizzard episode is Season 3 Episode 11 of Little House on the Prairie, titled Blizzard, which originally aired on January 3, 1977. This information is crucial to answer the question and is missing from the model prediction.\n2. The model prediction also misses the major auxiliary information that the Little House on the Prairie television series was based on The Little House Books by Laura Ingles Wilder, and one of the books, The Long Winter, is set during the severe winter of 1880 to 1881 in the southeastern Dakota Territory. This context is important for understanding the source material for the blizzard episode."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "Season 3 Episode 11 of Little House on the Prairie, titled Blizzard, is based on The Little House Books by Laura Ingles Wilder. Specifically, it draws inspiration from The Long Winter, a book in the series set in the southeastern Dakota Territory during the severe winter of 1880 to 1881."}], "feedback_human": {"errors": [{"error type": "Unverifiable", "explanation": "", "start": 0, "end": 89}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 2, "sentence_id": [1]}, {"error type": "Missing-Major-Auxiliary", "passage_id": 2, "sentence_id": [2]}], "corrected-prediction": "One of the books in the Little House series, The Long Winter, is an autobiographical children's novel that is set in the southeastern Dakota Territory during the severe winter of 1880 to1881, when Wilder turned 14 years old."}}, {"question": "When does season 6 of the arrow air?", "passages": [["Supergirl (season 3)", "Jordan too exited the series as a regular with this season, as he wanted to begin \"a new chapter in [his] life\".", "Filming for the season began on July 6, 2017 and ended on April 28, 2018, taking place in Vancouver.", "In May 2017, The CW president Mark Pedowitz officially announced plans for a four-show Arrowverse crossover event, crossing over episodes of the television series \"Supergirl\", \"The Flash\", \"Legends of Tomorrow\", and \"Arrow\".", "The crossover, \"Crisis on Earth-X\", began with \"Supergirl\" and a special airing of \"Arrow\" on November 27, 2017, and concluded on \"The Flash\" and \"Legends of Tomorrow\" on November 28.", "The crossover also sees Benoist, Brooks and Jordan playing the Earth-X versions of their characters.", "The season premiered on The CW in the United States on October 9, 2017, and ended on June 18, 2018.", "It premiered on October 16, 2017 in the United Kingdom on Sky One.", "The season was released on DVD on September 17, 2018, and Blu-ray on September 18, 2018.", "The review aggregator website Rotten Tomatoes gave the third season a 80% approval rating from critics with an average rating of 7.32/10, based on 13 reviews."], ["Legends of Tomorrow (season 3)", "They then created a whole new face and neck for me that was glued on and spray painted over the course of four hours.", "The end result was freakishly convincing.\"", "In May 2017, The CW president Mark Pedowitz officially announced plans for a four-show Arrowverse crossover event, crossing over episodes of the television series \"Supergirl\", \"The Flash\", \"Legends of Tomorrow\", and \"Arrow\".", "The crossover, \"Crisis on Earth-X\", began with \"Supergirl\" and a special airing of \"Arrow\" on November 27, 2017, and concluded on \"The Flash\" and \"Legends of Tomorrow\" on November 28.", "The third season began airing on October 10, 2017 on The CW in the United States, and concluded on April 9, 2018.", "The season was made available for streaming on Netflix in late April 2018, soon after the season finale aired.", "It was released on Blu-Ray on September 25, 2018.", "The review aggregator website Rotten Tomatoes reported a 100% approval rating with an average rating of 8.27/10 based on 13 reviews.", "The website's consensus reads, \"\"DC's Legends of Tomorrow\" lightens up the tone in its third season while spotlighting adventurous plots and a distinct sense of humor.\""], ["Oliver Queen (Arrowverse)", "Oliver Queen (Arrowverse)\n\nOliver Queen is a fictional character in the television series \"Arrow\", based on the DC Comics superhero Green Arrow, created by Mort Weisinger and George Papp.", "Adapted for television in 2012 by Greg Berlanti, Marc Guggenheim and Andrew Kreisberg, Oliver Queen has been continually portrayed by Stephen Amell and is the alter-ego of the vigilante Green Arrow.", "This is the second time the character has been adapted to a live-action television series; the first time was on the series \"Smallville\", where the character appeared over the course of five seasons and was portrayed by Justin Hartley.", "In the series, Oliver is a billionaire playboy who returns to Starling City after five years of being stranded after a shipwreck and presumed dead.", "He spends his nights as a hooded vigilante named the \"Arrow\" who stops crime in the city.", "During the first season, Oliver focuses on a list, written by his father, of targets that are taking advantage of the citizens.", "Subsequent seasons have him venturing into all criminal activity, and he shifts from being willing to kill to having a rule against all killing as a means of stopping assailants.", "In \"Arrow\", Oliver does not take up the name of Green Arrow until season four."]], "gold": "Arrow is an American superhero television series developed by Greg Berlanti, Marc Guggenheim, and Andrew Kreisberg based on the DC Comics character Green Arrow, a costumed crime-fighter created by Mort Weisinger and George Papp, and is set in the Arrowverse with other related television series. Season 6 began airing in the United States on The CW on October 12, 2017, and completed its 23-episode run on May 17, 2018. It began streaming on Netflix in May 2018, soon after the season finale aired.", "prediction 1": "Season 6 of the American television series Arrow began airing on October 9, 2017 and ended on June 18, 2018. It premiered on October 16, 2017 in the United Kingdom on Sky One. Season 6 of the British television series Arrow began airing on October 8, 2018 and ended on April 11, 2019. Season 6 of the American television series Arrow began airing on October 10, 2018 and concluded on April 9, 2018. Season 6 of the UK television series Arrow began airing on March 14, 2019 and ended on March 12, 2020.", "prediction 2": "Season 6 of the CW television series Arrow began airing on October 9, 2017 in the United States, and ended on June 18, 2018. Season 6 of Arrowverse began airing on October 16, 2017 in the United Kingdom and October 15, 2016 in the United States. Season 6 of Arrowverse: Legends of Tomorrow began airing on October 16, 2017 in the United Kingdom and ended on June 18, 2018.", "prediction 3": "Season 6 of the television series Arrow premiered on October 9, 2017 in the United States and ended on June 18, 2018. Season 6 of Arrowverse began airing in the United States on October 2, 2019, and ended on April 25, 2019. Season 6 of Arrowverse premiered in the United Kingdom and Ireland on Sky One on October 16, 2017.", "prediction 4": "Season 6 of Arrow first aired on January 6, 2021. Season 5 aired on January 6, 2021. Season 6 of Arrow first aired on January 7, 2021. Season 6 of Arrow first aired on November 12, 2022.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 176, "end": 501}], "missing-info": [], "corrected-prediction": "The passages do not provide any information about the airing dates of season 6 of Arrow."}, "preference": [1, 1, 1, 1, 1, 1], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Supergirl (season 3)\nS1. Jordan too exited the series as a regular with this season, as he wanted to begin \"a new chapter in [his] life\".\nS2. Filming for the season began on July 6, 2017 and ended on April 28, 2018, taking place in Vancouver.\nS3. In May 2017, The CW president Mark Pedowitz officially announced plans for a four-show Arrowverse crossover event, crossing over episodes of the television series \"Supergirl\", \"The Flash\", \"Legends of Tomorrow\", and \"Arrow\".\nS4. The crossover, \"Crisis on Earth-X\", began with \"Supergirl\" and a special airing of \"Arrow\" on November 27, 2017, and concluded on \"The Flash\" and \"Legends of Tomorrow\" on November 28.\nS5. The crossover also sees Benoist, Brooks and Jordan playing the Earth-X versions of their characters.\nS6. The season premiered on The CW in the United States on October 9, 2017, and ended on June 18, 2018.\nS7. It premiered on October 16, 2017 in the United Kingdom on Sky One.\nS8. The season was released on DVD on September 17, 2018, and Blu-ray on September 18, 2018.\nS9. The review aggregator website Rotten Tomatoes gave the third season a 80% approval rating from critics with an average rating of 7.32/10, based on 13 reviews.\n\nPassage 2: Title (S0) - Legends of Tomorrow (season 3)\nS1. They then created a whole new face and neck for me that was glued on and spray painted over the course of four hours.\nS2. The end result was freakishly convincing.\"\nS3. In May 2017, The CW president Mark Pedowitz officially announced plans for a four-show Arrowverse crossover event, crossing over episodes of the television series \"Supergirl\", \"The Flash\", \"Legends of Tomorrow\", and \"Arrow\".\nS4. The crossover, \"Crisis on Earth-X\", began with \"Supergirl\" and a special airing of \"Arrow\" on November 27, 2017, and concluded on \"The Flash\" and \"Legends of Tomorrow\" on November 28.\nS5. The third season began airing on October 10, 2017 on The CW in the United States, and concluded on April 9, 2018.\nS6. The season was made available for streaming on Netflix in late April 2018, soon after the season finale aired.\nS7. It was released on Blu-Ray on September 25, 2018.\nS8. The review aggregator website Rotten Tomatoes reported a 100% approval rating with an average rating of 8.27/10 based on 13 reviews.\nS9. The website's consensus reads, \"\"DC's Legends of Tomorrow\" lightens up the tone in its third season while spotlighting adventurous plots and a distinct sense of humor.\"\n\nPassage 3: Title (S0) - Oliver Queen (Arrowverse)\nS1. Oliver Queen (Arrowverse)  Oliver Queen is a fictional character in the television series \"Arrow\", based on the DC Comics superhero Green Arrow, created by Mort Weisinger and George Papp.\nS2. Adapted for television in 2012 by Greg Berlanti, Marc Guggenheim and Andrew Kreisberg, Oliver Queen has been continually portrayed by Stephen Amell and is the alter-ego of the vigilante Green Arrow.\nS3. This is the second time the character has been adapted to a live-action television series; the first time was on the series \"Smallville\", where the character appeared over the course of five seasons and was portrayed by Justin Hartley.\nS4. In the series, Oliver is a billionaire playboy who returns to Starling City after five years of being stranded after a shipwreck and presumed dead.\nS5. He spends his nights as a hooded vigilante named the \"Arrow\" who stops crime in the city.\nS6. During the first season, Oliver focuses on a list, written by his father, of targets that are taking advantage of the citizens.\nS7. Subsequent seasons have him venturing into all criminal activity, and he shifts from being willing to kill to having a rule against all killing as a means of stopping assailants.\nS8. In \"Arrow\", Oliver does not take up the name of Green Arrow until season four.\n    \nInput Question:\nWhen does season 6 of the arrow air?\n\nCorrect Response:\nArrow is an American superhero television series developed by Greg Berlanti, Marc Guggenheim, and Andrew Kreisberg based on the DC Comics character Green Arrow, a costumed crime-fighter created by Mort Weisinger and George Papp, and is set in the Arrowverse with other related television series. Season 6 began airing in the United States on The CW on October 12, 2017, and completed its 23-episode run on May 17, 2018. It began streaming on Netflix in May 2018, soon after the season finale aired.\n\nModel Prediction:\nSeason 6 of the American television series Arrow began airing on October 9, 2017 and ended on June 18, 2018. It premiered on October 16, 2017 in the United Kingdom on Sky One. Season 6 of the British television series Arrow began airing on October 8, 2018 and ended on April 11, 2019. Season 6 of the American television series Arrow began airing on October 10, 2018 and concluded on April 9, 2018. Season 6 of the UK television series Arrow began airing on March 14, 2019 and ended on March 12, 2020.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "Season 6 of the American television series Arrow began airing on October 9, 2017 and ended on June 18, 2018. It premiered on October 16, 2017 in the United Kingdom on Sky One. [Season 6 of the British television series Arrow began airing on October 8, 2018 and ended on April 11, 2019. Season 6 of the American television series Arrow began airing on October 10, 2018 and concluded on April 9, 2018. Season 6 of the UK television series Arrow began airing on March 14, 2019 and ended on March 12, 2020.]\n\nExplanation:\n1. The model prediction repeats the information about the airing of season 6 of Arrow multiple times with different and inconsistent dates. These repetitions are irrelevant to the question and do not provide any additional or accurate information. Therefore, they should be marked as \"Irrelevant\"."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. Season 6 of the American television series Arrow began airing on October 9, 2017 and ended on June 18, 2018.\nS2. It premiered on October 16, 2017 in the United Kingdom on Sky One.\nS3. Season 6 of the British television series Arrow began airing on October 8, 2018 and ended on April 11, 2019.\nS4. Season 6 of the American television series Arrow began airing on October 10, 2018 and concluded on April 9, 2018.\nS5. Season 6 of the UK television series Arrow began airing on March 14, 2019 and ended on March 12, 2020.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "Inconsistent or Unverifiable Sentences:\n1. S1\n2. S3\n3. S4\n4. S5\n\nExplanation:\n1. The first sentence is factually inconsistent with the passages. The passages do not provide any information about the airing dates of season 6 of Arrow.\n2. The third sentence is factually unverifiable as the passages do not mention a British television series Arrow or its airing dates.\n3. The fourth sentence is factually unverifiable as the passages do not provide any information about the airing dates of season 6 of Arrow in 2018.\n4. The fifth sentence is factually unverifiable as the passages do not mention a UK television series Arrow or its airing dates in 2019 and 2020."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "None\n\nExplanation:\nThe passages do not provide any information about the airing dates of season 6 of Arrow. Therefore, there is no missing information in the model prediction that can be found in the passages."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The passages do not provide any information about the airing dates of season 6 of Arrow."}], "feedback_human": {"errors": [{"error type": "Wrong-Grounding", "explanation": "{\"passage_id\":1,\"sentence_id\":[6]}", "start": 43, "end": 48}, {"error type": "Wrong-Grounding", "explanation": "{\"passage_id\":1,\"sentence_id\":[7]}", "start": 109, "end": 111}, {"error type": "Irrelevant", "explanation": "", "start": 112, "end": 175}, {"error type": "Unverifiable", "explanation": "", "start": 192, "end": 199}, {"error type": "Unverifiable", "explanation": "", "start": 240, "end": 255}, {"error type": "Unverifiable", "explanation": "", "start": 269, "end": 284}, {"error type": "Redundant", "explanation": "Season 6 of the American television series Arrow began airing on October 9, 2017 and ended on June 18, 2018.", "start": 176, "end": 191}, {"error type": "Redundant", "explanation": "Season 6 of the American television series Arrow began airing on October 9, 2017 and ended on June 18, 2018. ", "start": 285, "end": 346}, {"error type": "Unverifiable", "explanation": "", "start": 350, "end": 366}, {"error type": "Unverifiable", "explanation": "", "start": 384, "end": 398}, {"error type": "Redundant", "explanation": "Season 6 of the British television series Arrow began airing on October 8, 2018 and ended on April 11, 2019. ", "start": 399, "end": 441}, {"error type": "Unverifiable", "explanation": "", "start": 458, "end": 472}, {"error type": "Unverifiable", "explanation": "", "start": 486, "end": 501}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 3, "sentence_id": [1]}, {"error type": "Missing-Major-Auxiliary", "passage_id": 3, "sentence_id": [2]}], "corrected-prediction": "DC Comics superhero Green Arrow was created by Mort Weisinger and George Papp. The show was adapted by Greg Berlanti, Marc Guggenheim and Andrew Kreisberg."}}, {"question": "Who sings they shoot horses don't they?", "passages": [["Racing Cars", "Racing Cars\n\nRacing Cars are a Welsh pop band, formed in the Rhondda Valleys, Wales in 1973.", "They were signed to one of the biggest British record labels of the time, Chrysalis Records.", "Racing Cars's debut album yielded their only hit single with \"They Shoot Horses, Don't They?\"", "It reached number fourteen in the UK Singles Chart in 1977, and was inspired by the film, \"They Shoot Horses, Don't They?\"", "Touring to promote their debut releases, Racing Cars backed Bad Company in 1976, including dates at Earls Court and the York Theatre Royal.", "Without any similar further chart appearances, Racing Cars ultimately acquired the dreaded one hit wonder label.", "However, the band was sufficiently established on the touring circuit to issue two further albums which included bit parts for the session pianist Geraint Watkins; American saxophonist Jerry Jumonville; The Bowles Brothers Band (on vocal harmonies); and Ray Ennis from Newport who had previously played with a band called Good Habit.", "(\"Note.", "Not to be confused with Ray Ennis of Swinging Blue Jeans.\")", "These never reached the same commercial heights.", "Morty and Graham Williams had played together in local bands such as Morty and the Frantics and later evolutions including Strawberry Dust for years before.", "They were very well known in the Welsh club circuit."], ["They Shoot Horses, Don't They? (film)", "In 1996, \"Entertainment Weekly\" observed, \"Sydney Pollack's dance-marathon movie has probably aged better than any American film of its time.\"", "The film won one Academy Award and was nominated in eight other categories.", "The film currently holds the record for being nominated for the most Academy Awards (nine) without receiving a nod for Best Picture.", "In later years, Turner Classic Movies observed, \"By popularizing the title of McCoy\u2019s novel, [the film] gave American argot a catch-phrase that's as recognizable today as when the movie first caught on.\"", "The title has been imitated in various media for topics having little relation to the plot or themes of the original film.", "The question itself has become increasingly answerable correctly with \"No\" due to advances in equine veterinary medicine, capable of reducing the need for humane destruction of critically diseased or seriously injured horses, all of which the time-frame of both the film and its source novel pre-dated.", "The Rolling Stones used the film set as a rehearsal space, prior to a pair of shows at The Forum as part of their 1969 U.S. tour.", "Welsh band Racing Cars recorded a song called \"They Shoot Horses Don't They?\" inspired by this movie."]], "gold": "\"They Shoot Horses, Don't They?\" was sang by several bands. \"They Shoot Horses, Don't They?\" was released in 1976 by Racing cars, which was their only hit single. \"They Shoot Horses, Don't They?\" was also sang by Quickspace in 2000.", "prediction 1": "Racing Cars are a Welsh pop band, formed in the Rhondda Valleys, Wales in 1973, and were signed to one of the biggest British record labels of the time, Chrysalis Records. Racing Cars's debut album yielded their only hit single with \"They Shoot Horses, Don't They?\" It reached number fourteen in the UK Singles Chart in 1977, and was inspired by the movie.", "prediction 2": "Racing Cars are a Welsh pop band formed in the Rhondda Valleys, Wales in 1973. Their debut album yielded their only hit single with \"They Shoot Horses, Don't They?\" It reached number fourteen in the UK Singles Chart in 1977 and was inspired by the 1969 film. The Rolling Stones used the film set as a rehearsal space, prior to a pair of shows at The Forum as part of their 1969 U.S. tour.", "prediction 3": "Racing Cars, a Welsh pop band, formed in the Rhondda Valleys, Wales in 1973, recorded a song called \"They Shoot Horses, Don't They?\" inspired by the 1969 film They Shoot Horses, Don't They?, which was directed by Sydney Pollack. The song was sung by the Welsh pop band Racing Cars, an a cappella group formed from members of various Welsh bands and was released in 1977.", "prediction 4": "Racing Cars are a Welsh pop band, formed in the Rhondda Valleys, Wales in 1973, and were signed to one of the biggest British record labels of the time, Chrysalis Records. Racing Cars recorded a song called \"They Shoot Horses, Don't They?\" inspired by the 1969 movie. It reached number fourteen in the UK Singles Chart in 1977, and was inspired by the film. American saxophonist Jerry Jumonville, session pianist Geraint Watkins, American saxophonist Jerry Jumonville, The Bowles Brothers Band (on vocal harmonies), and Ray Ennis from Newport who had previously played with a band called Good Habit.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 266, "end": 325}], "missing-info": [], "corrected-prediction": "Racing Cars are a Welsh pop band, formed in the Rhondda Valleys, Wales in 1973, and were signed to one of the biggest British record labels of the time, Chrysalis Records. Racing Cars's debut album yielded their only hit single with \"They Shoot Horses, Don't They?\" which was inspired by the movie."}, "preference": [1, 1, 1, 2, 1, 1], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Racing Cars\nS1. Racing Cars  Racing Cars are a Welsh pop band, formed in the Rhondda Valleys, Wales in 1973.\nS2. They were signed to one of the biggest British record labels of the time, Chrysalis Records.\nS3. Racing Cars's debut album yielded their only hit single with \"They Shoot Horses, Don't They?\"\nS4. It reached number fourteen in the UK Singles Chart in 1977, and was inspired by the film, \"They Shoot Horses, Don't They?\"\nS5. Touring to promote their debut releases, Racing Cars backed Bad Company in 1976, including dates at Earls Court and the York Theatre Royal.\nS6. Without any similar further chart appearances, Racing Cars ultimately acquired the dreaded one hit wonder label.\nS7. However, the band was sufficiently established on the touring circuit to issue two further albums which included bit parts for the session pianist Geraint Watkins; American saxophonist Jerry Jumonville; The Bowles Brothers Band (on vocal harmonies); and Ray Ennis from Newport who had previously played with a band called Good Habit.\nS8. (\"Note.\nS9. Not to be confused with Ray Ennis of Swinging Blue Jeans.\")\nS10. These never reached the same commercial heights.\nS11. Morty and Graham Williams had played together in local bands such as Morty and the Frantics and later evolutions including Strawberry Dust for years before.\nS12. They were very well known in the Welsh club circuit.\n\nPassage 2: Title (S0) - They Shoot Horses, Don't They? (film)\nS1. In 1996, \"Entertainment Weekly\" observed, \"Sydney Pollack's dance-marathon movie has probably aged better than any American film of its time.\"\nS2. The film won one Academy Award and was nominated in eight other categories.\nS3. The film currently holds the record for being nominated for the most Academy Awards (nine) without receiving a nod for Best Picture.\nS4. In later years, Turner Classic Movies observed, \"By popularizing the title of McCoy\u2019s novel, [the film] gave American argot a catch-phrase that's as recognizable today as when the movie first caught on.\"\nS5. The title has been imitated in various media for topics having little relation to the plot or themes of the original film.\nS6. The question itself has become increasingly answerable correctly with \"No\" due to advances in equine veterinary medicine, capable of reducing the need for humane destruction of critically diseased or seriously injured horses, all of which the time-frame of both the film and its source novel pre-dated.\nS7. The Rolling Stones used the film set as a rehearsal space, prior to a pair of shows at The Forum as part of their 1969 U.S. tour.\nS8. Welsh band Racing Cars recorded a song called \"They Shoot Horses Don't They?\" inspired by this movie.\n    \nInput Question:\nWho sings they shoot horses don't they?\n\nCorrect Response:\n\"They Shoot Horses, Don't They?\" was sang by several bands. \"They Shoot Horses, Don't They?\" was released in 1976 by Racing cars, which was their only hit single. \"They Shoot Horses, Don't They?\" was also sang by Quickspace in 2000.\n\nModel Prediction:\nRacing Cars are a Welsh pop band, formed in the Rhondda Valleys, Wales in 1973, and were signed to one of the biggest British record labels of the time, Chrysalis Records. Racing Cars's debut album yielded their only hit single with \"They Shoot Horses, Don't They?\" It reached number fourteen in the UK Singles Chart in 1977, and was inspired by the movie.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "Racing Cars are a Welsh pop band, formed in the Rhondda Valleys, Wales in 1973, and were signed to one of the biggest British record labels of the time, Chrysalis Records. Racing Cars's debut album yielded their only hit single with \"They Shoot Horses, Don't They?\" [It reached number fourteen in the UK Singles Chart in 1977,] and was inspired by the movie.\n\nExplanation:\nThe information about the song reaching number fourteen in the UK Singles Chart in 1977 is not relevant to the question asked. The question is asking who sings the song, not how well it did in the charts. Therefore, this information is marked as \"Irrelevant\"."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. Racing Cars are a Welsh pop band, formed in the Rhondda Valleys, Wales in 1973, and were signed to one of the biggest British record labels of the time, Chrysalis Records.\nS2. Racing Cars's debut album yielded their only hit single with \"They Shoot Horses, Don't They?\"\nS3. It reached number fourteen in the UK Singles Chart in 1977, and was inspired by the movie.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation:\nAll the facts in the model prediction are consistent with the provided passages and can be verified. Therefore, there are no spans that contain inconsistent or unverifiable facts."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "None\n\nExplanation:\nThe model prediction includes all the necessary information to answer the question. It correctly identifies Racing Cars as the band that sings \"They Shoot Horses, Don't They?\" and provides some background information about the band and the song. Therefore, there is no missing information in the model prediction."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "Racing Cars are a Welsh pop band, formed in the Rhondda Valleys, Wales in 1973, and were signed to one of the biggest British record labels of the time, Chrysalis Records. Racing Cars's debut album yielded their only hit single with \"They Shoot Horses, Don't They?\" which was inspired by the movie."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 0, "end": 171}, {"error type": "Irrelevant", "explanation": "", "start": 266, "end": 356}], "missing-info": [], "corrected-prediction": "RaRacing Cars's debut album yielded their only hit single with \"They Shoot Horses, Don't They?\"."}}, {"question": "The pre-industrial level of co2 in the atmosphere in ppmv is about?", "passages": [["Carbon dioxide in Earth's atmosphere", "When Earth first formed, Earth's atmosphere may have contained more greenhouse gases and concentrations may have been higher, with estimated partial pressure as large as , because there was no bacterial photosynthesis to reduce the gas to carbon compounds and oxygen.", "Methane, a very active greenhouse gas which reacts with oxygen to produce and water vapor, may have been more prevalent as well, with a mixing ratio of 10 (100 parts per million by volume).", "Though water is responsible for most (about 36-70%) of the total greenhouse effect, the role of water vapor as a greenhouse gas depends on temperature.", "On Earth, carbon dioxide is the most relevant, direct anthropologically influenced greenhouse gas.", "Carbon dioxide is often mentioned in the context of its increased influence as a greenhouse gas since the pre-industrial (1750) era.", "In the IPCC Fifth Assessment Report the increase in CO was estimated to be responsible for 1.82 W\u00b7m of the 2.63 W\u00b7m change in radiative forcing on Earth (about 70%).", "The concept of atmospheric CO increasing ground temperature was first published by Svante Arrhenius in 1896.", "The increased radiative forcing due to increased CO in the Earth's atmosphere is based on the physical properties of CO and the non-saturated absorption windows where CO absorbs outgoing long-wave energy."]], "gold": "On Earth, carbon dioxide is the most relevant, direct anthropologically influenced greenhouse gas, often mentioned in the context of its increased influence as a greenhouse gas since the pre-industrial era. It is commonly assumed that the level of carbon dioxide in the atmosphere before this time was of 290 ppmv, but more recent indirect data points at a value closer to 260-270 ppmv.", "prediction 1": "The pre-industrial level of carbon dioxide in the atmosphere in parts per million by volume is about. The pre-industrial level of CO2 in the atmosphere in ppmv is about.", "prediction 2": "Carbon dioxide is often mentioned in the context of its increased influence as a greenhouse gas since the pre-industrial (1750) era, in the IPCC Fifth Assessment Report, the increase in CO was estimated to be responsible for 1.82 Wm of the 2.63 Wm change in radiative forcing on Earth (about 70%).", "prediction 3": "Carbon dioxide is often mentioned in the context of its increased influence as a greenhouse gas since the pre-industrial (1750) era. In the IPCC Fifth Assessment Report the increase in CO was estimated to be responsible for 1.82 Wm of the 2.63 Wm change in radiative forcing on Earth (about 70%).", "prediction 4": "The pre-industrial level of carbon dioxide in the atmosphere in ppmv is about. The IPCC Fifth Assessment Report estimated the pre-industrial level of carbon dioxide in the atmosphere to be about 1750 ppmv.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 0, "end": 169}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 1, "sentence_id": [5]}], "corrected-prediction": "The pre-industrial level of carbon dioxide in the atmosphere in parts per million by volume is not explicitly stated in the provided passages. However, it is mentioned that the influence of CO2 as a greenhouse gas has increased since the pre-industrial era."}, "preference": [2, 2, 1, 0, 1, 1], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Carbon dioxide in Earth's atmosphere\nS1. When Earth first formed, Earth's atmosphere may have contained more greenhouse gases and concentrations may have been higher, with estimated partial pressure as large as , because there was no bacterial photosynthesis to reduce the gas to carbon compounds and oxygen.\nS2. Methane, a very active greenhouse gas which reacts with oxygen to produce and water vapor, may have been more prevalent as well, with a mixing ratio of 10 (100 parts per million by volume).\nS3. Though water is responsible for most (about 36-70%) of the total greenhouse effect, the role of water vapor as a greenhouse gas depends on temperature.\nS4. On Earth, carbon dioxide is the most relevant, direct anthropologically influenced greenhouse gas.\nS5. Carbon dioxide is often mentioned in the context of its increased influence as a greenhouse gas since the pre-industrial (1750) era.\nS6. In the IPCC Fifth Assessment Report the increase in CO was estimated to be responsible for 1.82 W\u00b7m of the 2.63 W\u00b7m change in radiative forcing on Earth (about 70%).\nS7. The concept of atmospheric CO increasing ground temperature was first published by Svante Arrhenius in 1896.\nS8. The increased radiative forcing due to increased CO in the Earth's atmosphere is based on the physical properties of CO and the non-saturated absorption windows where CO absorbs outgoing long-wave energy.\n    \nInput Question:\nThe pre-industrial level of co2 in the atmosphere in ppmv is about?\n\nCorrect Response:\nOn Earth, carbon dioxide is the most relevant, direct anthropologically influenced greenhouse gas, often mentioned in the context of its increased influence as a greenhouse gas since the pre-industrial era. It is commonly assumed that the level of carbon dioxide in the atmosphere before this time was of 290 ppmv, but more recent indirect data points at a value closer to 260-270 ppmv.\n\nModel Prediction:\nThe pre-industrial level of carbon dioxide in the atmosphere in parts per million by volume is about. The pre-industrial level of CO2 in the atmosphere in ppmv is about.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "[The pre-industrial level of carbon dioxide in the atmosphere in parts per million by volume is about. The pre-industrial level of CO2 in the atmosphere in ppmv is about.]\n\nExplanation:\n1. The entire model prediction is repetitive as it repeats the same information twice. The second sentence is a repetition of the first sentence.\n2. The model prediction is also incoherent as it does not provide a complete answer to the question. The sentences end abruptly without providing the actual pre-industrial level of CO2 in the atmosphere in ppmv."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The pre-industrial level of carbon dioxide in the atmosphere in parts per million by volume is about.\nS2. The pre-industrial level of CO2 in the atmosphere in ppmv is about.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation:\nThe model prediction does not provide any factual information that could be checked against the passages for consistency or verifiability. It merely restates the question without providing an answer."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 5 [Missing Answer]\n\nExplanation:\n1. The model prediction does not provide the pre-industrial level of CO2 in the atmosphere in ppmv, which is the direct answer to the question. This information is not explicitly stated in the passages, but it is implied in Passage 1, sentence 5 where it mentions the increased influence of CO2 as a greenhouse gas since the pre-industrial era."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The pre-industrial level of carbon dioxide in the atmosphere in parts per million by volume is not explicitly stated in the provided passages. However, it is mentioned that the influence of CO2 as a greenhouse gas has increased since the pre-industrial era."}], "feedback_human": {"errors": [{"error type": "Incoherent", "explanation": "", "start": 102, "end": 169}, {"error type": "Incoherent", "explanation": "", "start": 0, "end": 101}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [4]}, {"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [5]}], "corrected-prediction": "On Earth, carbon dioxide is the most relevant, direct anthropologically influenced greenhouse gas. Carbon dioxide is often mentioned in the context of its increased influence as a greenhouse gas since the pre-industrial era. "}}, {"question": "Who presides over the joint session of parliament?", "passages": [["Joint Session of Indian Parliament", "Joint Session of Indian Parliament\n\nThe Parliament of India is bicameral.", "Concurrence of both houses are required to pass any bill.", "However, the makers of the Constitution of India visualised situations of deadlock between the upper house i.e. Rajya Sabha and the lower house i.e. Lok Sabha.", "Therefore, the Constitution of India provides for Joint sittings of both the Houses to break this deadlock.", "The joint sitting of the Parliament is called by the President (Article 108) and is presided over by the Speaker or, in his absence, by the Deputy Speaker of the Lok Sabha or in his absence, the Deputy-Chairman of the Rajya Sabha.", "The Chairman doesn't preside over the joint session at any mens/cost.", "If any of the above officers are not present then any other member of the Parliament can preside by consensus of both the House.", "As per Article 108 of Constitution, a Joint session of Parliament can be summoned in the following situations."]], "gold": "The joint sitting of the Parliament is called by the President (Article 108) and is presided over by the Speaker or, in his absence, by the Deputy Speaker of the Lok Sabha or in his absence, the Deputy-Chairman of the Rajya Sabha. The Chairman doesn't preside over the joint session at any means/cost.", "prediction 1": "The Joint Session of Indian Parliament is called by the President (Article 108) and is presided over by the Speaker or, in his absence, by the Deputy Speaker of the Lok Sabha or in his absence, the Deputy-Chairman of the Rajya Sabha. If any of the above officers are not present then any other member of the Parliament can preside by consensus of both the House.", "prediction 2": "The Joint session of the Indian Parliament is called by the President and is presided over by the Speaker or, in his absence, by the Deputy Speaker of the Lok Sabha or in his absence, the Deputy-Chairman of the Rajya Sabha. The Chairman doesn't preside over the joint session at any mens/cost. If any of the above officers are not present then any other member of the Parliament can preside by consensus of both the House.", "prediction 3": "The Joint Session of India's Parliament is called by the President of India under Article 108 of the Constitution of India and is presided over by the Speaker or, in his absence, by the Deputy Speaker of the Lok Sabha or in his absence, the Deputy-Chairman of the Rajya Sabha.", "prediction 4": "The joint sitting of the Parliament is called by the President (Article 108) and is presided over by the Speaker or, in his absence, by the Deputy Speaker of the Lok Sabha or in his absence, the Deputy-Chairman of the Rajya Sabha. The Chairman doesn't preside over the joint session at any cost. If any of the above officers are not present then any other member of the Parliament can preside by consensus of both the House.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 234, "end": 362}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [6]}], "corrected-prediction": "The Joint Session of Indian Parliament is called by the President (Article 108) and is presided over by the Speaker or, in his absence, by the Deputy Speaker of the Lok Sabha or in his absence, the Deputy-Chairman of the Rajya Sabha. The Chairman doesn't preside over the joint session at any means/cost."}, "preference": [1, 1, 1, 1, 1, 2], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Joint Session of Indian Parliament\nS1. Joint Session of Indian Parliament  The Parliament of India is bicameral.\nS2. Concurrence of both houses are required to pass any bill.\nS3. However, the makers of the Constitution of India visualised situations of deadlock between the upper house i.e. Rajya Sabha and the lower house i.e. Lok Sabha.\nS4. Therefore, the Constitution of India provides for Joint sittings of both the Houses to break this deadlock.\nS5. The joint sitting of the Parliament is called by the President (Article 108) and is presided over by the Speaker or, in his absence, by the Deputy Speaker of the Lok Sabha or in his absence, the Deputy-Chairman of the Rajya Sabha.\nS6. The Chairman doesn't preside over the joint session at any mens/cost.\nS7. If any of the above officers are not present then any other member of the Parliament can preside by consensus of both the House.\nS8. As per Article 108 of Constitution, a Joint session of Parliament can be summoned in the following situations.\n    \nInput Question:\nWho presides over the joint session of parliament?\n\nCorrect Response:\nThe joint sitting of the Parliament is called by the President (Article 108) and is presided over by the Speaker or, in his absence, by the Deputy Speaker of the Lok Sabha or in his absence, the Deputy-Chairman of the Rajya Sabha. The Chairman doesn't preside over the joint session at any means/cost.\n\nModel Prediction:\nThe Joint Session of Indian Parliament is called by the President (Article 108) and is presided over by the Speaker or, in his absence, by the Deputy Speaker of the Lok Sabha or in his absence, the Deputy-Chairman of the Rajya Sabha. If any of the above officers are not present then any other member of the Parliament can preside by consensus of both the House.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "The Joint Session of Indian Parliament is called by the President (Article 108) and is presided over by the Speaker or, in his absence, by the Deputy Speaker of the Lok Sabha or in his absence, the Deputy-Chairman of the Rajya Sabha. [If any of the above officers are not present then any other member of the Parliament can preside by consensus of both the House.]\n\nExplanation:\nThe last sentence in the model prediction is not relevant to the question asked. The question asks about the primary individuals who preside over the joint session of parliament, not about what happens if those individuals are not present. Therefore, it should be marked as \"Irrelevant\"."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The Joint Session of Indian Parliament is called by the President (Article 108) and is presided over by the Speaker or, in his absence, by the Deputy Speaker of the Lok Sabha or in his absence, the Deputy-Chairman of the Rajya Sabha.\nS2. If any of the above officers are not present then any other member of the Parliament can preside by consensus of both the House.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation:\nThere are no factual inconsistencies or unverifiable facts in the model prediction. All the information provided in the model prediction is consistent with the passages."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 6 [Missing Major Auxiliary Information]\n\nExplanation:\n1. The model prediction is missing the important information that the Chairman doesn't preside over the joint session at any means/cost. This information is crucial to fully answer the question about who presides over the joint session of parliament."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The Joint Session of Indian Parliament is called by the President (Article 108) and is presided over by the Speaker or, in his absence, by the Deputy Speaker of the Lok Sabha or in his absence, the Deputy-Chairman of the Rajya Sabha. The Chairman doesn't preside over the joint session at any means/cost."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 234, "end": 362}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [6]}], "corrected-prediction": "The Joint Session of Indian Parliament is called by the President (Article 108) and is presided over by the Speaker or, in his absence, by the Deputy Speaker of the Lok Sabha or in his absence, the Deputy-Chairman of the Rajya Sabha. The Chairman doesn't preside over the joint session at any mens/cost."}}, {"question": "Who has the biggest ballpark in the mlb?", "passages": [["Dodger Stadium", "Prior to 1976, the Dodgers were rained out only once, against the St. Louis Cardinals, on April 21, 1967, ending a streak of 737 consecutive games without a postponement.", "On April 12, 1976, the second home rainout ended a streak of 724 straight games.", "April 19\u201321, 1988 saw three consecutive rainouts, the only time consecutive games have been rained out at Dodger Stadium.", "No rainouts occurred between April 21, 1988 and April 11, 1999 \u2013 a major league record of 856 straight home games without a rainout.", "That record has since been broken, with no rainouts since April 17, 2000, 1,471 consecutive games through April 15th, 2018 \n\n", "In order to comply with a conditional-use permit limiting Dodger Stadium's seating capacity to 56,000 it was the only current MLB park (through 2005 ) that had never increased its capacity.", "Whenever higher revenue lower seats were added some in the upper deck or pavilion were removed to keep the number the same.", "Through the sale of standing room only tickets, the Dodgers' 2009 home opener drew 57,099 fans, the largest crowd in stadium history.", "Following a number of incidents in the early 1970s in which fans showered Cincinnati Reds left fielder Pete Rose with beer, bottles, cups, and trash, the sale of beer was discontinued in both pavilions."], ["Minute Maid Park", "Minute Maid Park\n\nMinute Maid Park, previously known as The Ballpark at Union Station, Enron Field, and Astros Field, is a ballpark in Downtown Houston, Texas, United States, that opened in 2000 to house the Houston Astros of Major League Baseball (MLB).", "The ballpark is Houston's first retractable-roofed stadium, and features a natural grass playing field.", "The ballpark was built as a replacement of the Astrodome, the first domed sports stadium ever built, which opened in 1965.", "It is named for beverage brand Minute Maid, a subsidiary of The Coca-Cola Company, which acquired naming rights in 2002 for $100 million over 30 years.", "As of 2016, Minute Maid Park has a seating capacity of 41,168, which includes 5,197 club seats and 63 luxury suites.", "In 1909, during the time when West End Park was Houston's premier ballpark, the Houston Belt and Terminal Railway Company commissioned the design of a new union station for the city from New York City-based architects Warren and Wetmore.", "The location called for the demolition of several structures of Houston prominence.", "Horace Baldwin Rice's residence and Adath Yeshurun Congregation's synagogue among other structures were removed.", "With an original estimated cost of $1 million USD, Union Station was constructed by the American Construction Company for an eventual total of five times that amount."], ["Dodger Stadium", "Dodger Stadium\n\nDodger Stadium, occasionally called by the metonym Chavez Ravine, is a baseball park located in the Elysian Park neighborhood of Los Angeles, California, the home field to the Los Angeles Dodgers, the city's National League franchise of Major League Baseball (MLB).", "Opened on April 10, 1962, it was constructed in less than three years at a cost of US$23 million, financed by private sources.", "Dodger Stadium is currently the oldest ballpark in MLB west of the Mississippi River, and third-oldest overall, after Fenway Park in Boston (1912) and Wrigley Field in Chicago (1914) and is the world's largest baseball stadium by seat capacity.", "Often referred to as a \"pitcher's ballpark\", the stadium has seen twelve no-hitters, two of which were perfect games.", "The stadium hosted the Major League Baseball All-Star Game in 1980 - and will host in 2020 - as well as games of 10 World Series (1963, 1965, 1966, 1974, 1977, 1978, 1981, 1988, 2017, and 2018).", "It also hosted the semifinals and finals of the 2009 and 2017 World Baseball Classics.", "It also hosted exhibition baseball during the 1984 Summer Olympics.", "It will also host baseball and softball during the 2028 Summer Olympics."]], "gold": "The biggest ballpark in the MLB by capacity is the Dodgers Stadium with a capacity of 56,000 people. The biggest ballpark in the MLB by field dimensions is the Houston Astros Stadium, currently called Minute Maid Park.", "prediction 1": "The world's largest baseball stadium by seat capacity is at Dodger Stadium located in Los Angeles, California, and is the home field of the Los Angeles Dodgers. Prior to 1976, the Dodgers were rained out only once, against the St. Louis Cardinals, on April 21, 1967, ending a streak of 737 consecutive games without a postponement. As of 2016, Minute Maid Park has a seating capacity of 41,168, which includes 5,197 club seats and 63 luxury suites.", "prediction 2": "The world's largest baseball stadium by seat capacity is the Dodger Stadium in Los Angeles, California, USA. As of June 30, 2016, Minute Maid Park has a seating capacity of 42,168, which includes 5,197 club seats and 63 luxury suites. The ballpark was built in 2000 to house the Houston Astros of Major League Baseball. The stadium is the oldest in MLB west of the Mississippi River and third-oldest overall, after Fenway Park in Boston (1912) and Wrigley Field in Chicago (1914).", "prediction 3": "The MLB currently has 17 stadiums with the largest seats, and the stadium with the largest capacity is the Dodger Stadium in Los Angeles. The other major league baseball stadiums with the largest seats are Minute Maid Park and the Chase Field in Chicago.", "prediction 4": "The world's largest baseball stadium by seat capacity is Dodger Stadium in Los Angeles. It is also the oldest ballpark in MLB west of the Mississippi River, and third-oldest overall, after Fenway Park in Boston in 1912 and Wrigley Field in Chicago in 1914. Minute Maid Park, previously known as The Ballpark at Union Station, Enron Field, and Astros Field, is a ballpark in Downtown Houston, Texas, United States, that opened in 2000 to house the Houston Astros of Major League Baseball. The stadium has a seating capacity of 41,168.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 161, "end": 331}], "missing-info": [], "corrected-prediction": "The world's largest baseball stadium by seat capacity is Dodger Stadium located in Los Angeles, California, and is the home field of the Los Angeles Dodgers. As of 2016, Minute Maid Park has a seating capacity of 41,168, which includes 5,197 club seats and 63 luxury suites."}, "preference": [1, 2, 1, 2, 1, 1], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Dodger Stadium\nS1. Prior to 1976, the Dodgers were rained out only once, against the St. Louis Cardinals, on April 21, 1967, ending a streak of 737 consecutive games without a postponement.\nS2. On April 12, 1976, the second home rainout ended a streak of 724 straight games.\nS3. April 19\u201321, 1988 saw three consecutive rainouts, the only time consecutive games have been rained out at Dodger Stadium.\nS4. No rainouts occurred between April 21, 1988 and April 11, 1999 \u2013 a major league record of 856 straight home games without a rainout.\nS5. That record has since been broken, with no rainouts since April 17, 2000, 1,471 consecutive games through April 15th, 2018   \nS6. In order to comply with a conditional-use permit limiting Dodger Stadium's seating capacity to 56,000 it was the only current MLB park (through 2005 ) that had never increased its capacity.\nS7. Whenever higher revenue lower seats were added some in the upper deck or pavilion were removed to keep the number the same.\nS8. Through the sale of standing room only tickets, the Dodgers' 2009 home opener drew 57,099 fans, the largest crowd in stadium history.\nS9. Following a number of incidents in the early 1970s in which fans showered Cincinnati Reds left fielder Pete Rose with beer, bottles, cups, and trash, the sale of beer was discontinued in both pavilions.\n\nPassage 2: Title (S0) - Minute Maid Park\nS1. Minute Maid Park  Minute Maid Park, previously known as The Ballpark at Union Station, Enron Field, and Astros Field, is a ballpark in Downtown Houston, Texas, United States, that opened in 2000 to house the Houston Astros of Major League Baseball (MLB).\nS2. The ballpark is Houston's first retractable-roofed stadium, and features a natural grass playing field.\nS3. The ballpark was built as a replacement of the Astrodome, the first domed sports stadium ever built, which opened in 1965.\nS4. It is named for beverage brand Minute Maid, a subsidiary of The Coca-Cola Company, which acquired naming rights in 2002 for $100 million over 30 years.\nS5. As of 2016, Minute Maid Park has a seating capacity of 41,168, which includes 5,197 club seats and 63 luxury suites.\nS6. In 1909, during the time when West End Park was Houston's premier ballpark, the Houston Belt and Terminal Railway Company commissioned the design of a new union station for the city from New York City-based architects Warren and Wetmore.\nS7. The location called for the demolition of several structures of Houston prominence.\nS8. Horace Baldwin Rice's residence and Adath Yeshurun Congregation's synagogue among other structures were removed.\nS9. With an original estimated cost of $1 million USD, Union Station was constructed by the American Construction Company for an eventual total of five times that amount.\n\nPassage 3: Title (S0) - Dodger Stadium\nS1. Dodger Stadium  Dodger Stadium, occasionally called by the metonym Chavez Ravine, is a baseball park located in the Elysian Park neighborhood of Los Angeles, California, the home field to the Los Angeles Dodgers, the city's National League franchise of Major League Baseball (MLB).\nS2. Opened on April 10, 1962, it was constructed in less than three years at a cost of US$23 million, financed by private sources.\nS3. Dodger Stadium is currently the oldest ballpark in MLB west of the Mississippi River, and third-oldest overall, after Fenway Park in Boston (1912) and Wrigley Field in Chicago (1914) and is the world's largest baseball stadium by seat capacity.\nS4. Often referred to as a \"pitcher's ballpark\", the stadium has seen twelve no-hitters, two of which were perfect games.\nS5. The stadium hosted the Major League Baseball All-Star Game in 1980 - and will host in 2020 - as well as games of 10 World Series (1963, 1965, 1966, 1974, 1977, 1978, 1981, 1988, 2017, and 2018).\nS6. It also hosted the semifinals and finals of the 2009 and 2017 World Baseball Classics.\nS7. It also hosted exhibition baseball during the 1984 Summer Olympics.\nS8. It will also host baseball and softball during the 2028 Summer Olympics.\n    \nInput Question:\nWho has the biggest ballpark in the mlb?\n\nCorrect Response:\nThe biggest ballpark in the MLB by capacity is the Dodgers Stadium with a capacity of 56,000 people. The biggest ballpark in the MLB by field dimensions is the Houston Astros Stadium, currently called Minute Maid Park.\n\nModel Prediction:\nThe world's largest baseball stadium by seat capacity is at Dodger Stadium located in Los Angeles, California, and is the home field of the Los Angeles Dodgers. Prior to 1976, the Dodgers were rained out only once, against the St. Louis Cardinals, on April 21, 1967, ending a streak of 737 consecutive games without a postponement. As of 2016, Minute Maid Park has a seating capacity of 41,168, which includes 5,197 club seats and 63 luxury suites.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "The world's largest baseball stadium by seat capacity is at Dodger Stadium located in Los Angeles, California, and is the home field of the Los Angeles Dodgers. [Prior to 1976, the Dodgers were rained out only once, against the St. Louis Cardinals, on April 21, 1967, ending a streak of 737 consecutive games without a postponement.] As of 2016, Minute Maid Park has a seating capacity of 41,168, which includes 5,197 club seats and 63 luxury suites.\n\nExplanation:\n1. The second sentence in the model prediction is irrelevant to the question asked. The question is about the largest baseball stadium in terms of capacity, not about the history of rainouts at Dodger Stadium. Therefore, it should be marked as \"Irrelevant\"."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The world's largest baseball stadium by seat capacity is at Dodger Stadium located in Los Angeles, California, and is the home field of the Los Angeles Dodgers.\nS2. Prior to 1976, the Dodgers were rained out only once, against the St. Louis Cardinals, on April 21, 1967, ending a streak of 737 consecutive games without a postponement.\nS3. As of 2016, Minute Maid Park has a seating capacity of 41,168, which includes 5,197 club seats and 63 luxury suites.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation:\nAll the facts presented in the model prediction are consistent with the provided passages and can be verified. Therefore, there are no spans that contain inconsistent or unverifiable facts."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "None\n\nExplanation:\nThe model prediction includes all the necessary information to answer the question. It correctly identifies Dodger Stadium as the largest baseball stadium by seat capacity and provides the seating capacity of Minute Maid Park for comparison. Therefore, there is no missing information in the model prediction."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The world's largest baseball stadium by seat capacity is Dodger Stadium located in Los Angeles, California, and is the home field of the Los Angeles Dodgers. As of 2016, Minute Maid Park has a seating capacity of 41,168, which includes 5,197 club seats and 63 luxury suites."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 75, "end": 160}, {"error type": "Irrelevant", "explanation": "", "start": 161, "end": 331}, {"error type": "Irrelevant", "explanation": "", "start": 332, "end": 448}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [6]}], "corrected-prediction": "The world's largest baseball stadium by seat capacity is at Dodger Stadium with a seating capacity to 56,000.  "}}, {"question": "What year did the black album come out?", "passages": [["The Black Album (Jay-Z album)", "The Black Album (Jay-Z album)\n\nThe Black Album is the eighth studio album by American rapper Jay-Z, released on November 14, 2003, by Roc-A-Fella Records.", "It was advertised as his final album before retiring, which is also a recurring theme throughout the songs, although Jay-Z resumed his recording career in 2006.", "For the album, Jay-Z wanted to enlist a different producer for each song, working with Just Blaze, Kanye West, The Neptunes, DJ Quik, Timbaland, 9th Wonder and Rick Rubin, among others.", "When \"The Black Album\" was released, it received widespread acclaim from critics.", "In its first week, the album debuted at number one on the \"Billboard\" 200, selling 463,000 copies in the United States.", "It became Jay-Z's top selling record of the 2000s decade, and by July 2013, it had sold 3,516,000 copies in the US.", "\"The Black Album\" was promoted with a retirement tour by Jay-Z and three singles that also achieved \"Billboard\" chart success, including the top-ten hits \"Change Clothes\" and \"Dirt off Your Shoulder\".", "Jay-Z had announced that \"The Black Album\" would be his final record and went on a retirement tour after its release."], ["The Black Album (Prince album)", "The Black Album (Prince album)\n\nThe Black Album is the sixteenth studio album by American recording artist Prince.", "It was released on November 22, 1994, by Warner Bros. Records.", "It was originally planned for release on December 8, 1987, as the follow-up to \"Sign o' the Times\" and was to appear in an entirely black sleeve with no title or even a credit to Prince; hence it was referred to as \"The Black Album\".", "Dubbed \"The Funk Bible\" by preceding press releases, and in a hidden message within the album itself, the work seemed to be a reaction to criticism that Prince had become too pop-oriented.", "It was his attempt to regain his Black audience.", "The 1987 promo-only release had no printed title, artist name, production credits or photography printed; a simple black sleeve accompanied the disc.", "On promotional copies, only a song listing and catalog number\u201425677\u2014were printed on the disc itself.", "The commercial version was to only have the catalog number\u2014printed in pink\u2014on the spine.", "The original compact disc pressing was made by Sony DADC rather than WEA Manufacturing.", "After Prince became convinced that the album was \"evil\", he ordered it to be withdrawn a week before its release date."], ["Metallica discography", "The band's first release to feature the new member was \",\" and then followed by \"...", "And Justice for All\" in August 1988, which peaked at number six on the \"Billboard\" 200.", "Metallica's fifth, self-titled album, often called The Black Album, was released in 1991 and debuted at number one on the \"Billboard\" 200.", "The band embarked on a two-year tour in support of the album.", "\"Metallica\" has since been certified 16 times platinum by the RIAA.", "Metallica followed with the release of \"Load\" and \"Reload\", respectively.", "After the release of \"Garage Inc.\" and \"S&M\", Newsted (who would later join Voivod) departed from the band.", "Metallica recorded \"St. Anger\" without an official bassist (bass parts for the writing & recording during the album sessions were played by the band's long-time producer Bob Rock).", "Bassist Robert Trujillo joined Metallica in 2003.", "In 2008, the band released its ninth studio album, \"Death Magnetic\", which was produced by Rick Rubin and distributed through Warner Bros. Records.", "In April 2009, the band's catalogue was released on the iTunes Store as \"the Metallica Collection\".", "In 2013, Metallica released the movie, \"\", together with its soundtrack."], ["Weezer (2019 album)", "Weezer (2019 album)\n\nWeezer, also known as the Black Album, is the upcoming thirteenth studio album by American rock band Weezer.", "Produced by Dave Sitek, it is set to be released on March 1, 2019, through Crush Music and Atlantic Records.", "Weezer frontman Rivers Cuomo first hinted at the album in April 2016, shortly after the band released their tenth album \"Weezer\" (The White Album).", "\"What could stand out more against 'White' than 'Black'?", "I think it's going to maybe be like Beach Boys gone bad.", "I'm thinking of swearing, which is something I've never done in songs.\"", "While promoting the band's eleventh album \"Pacific Daydream\" in August 2017, Cuomo said \"The original plan was the Black Album but \"Pacific Daydream\" really came together.", "The Black Album is pretty much ready, it's coming.\"", "Cuomo first told Australian radio station Double J in February 2018 that the album would be released on May 25, later hinting at dates such as June 1 and June 12 on his Twitter account.", "On October 11, the first single from the album, \"Can't Knock the Hustle\", was released."], ["The Black Album/Come On Feel The Dandy Warhols", "The Black Album/Come On Feel The Dandy Warhols\n\nThe Black Album/Come On", "Feel The Dandy Warhols is a 2004 double album released by American alternative band, The Dandy Warhols.", "The two-disc set was released on their own Beat the World Records label.", "Initially, the album was only available to purchase through the band's website.", "It is now available to own via other sources.", "Disc one marks the first, official release of the band's 1996 demo album (\"The Black Album\") which was described as \"lost\".", "The album, recorded before \"...", "The Dandy Warhols Come Down\", was rejected by Capitol Records and dismissed by the band themselves.", "Three songs that were included on the original recording of the album are not included on this release, namely: \"Traci Lords\", \"Alien\" and \"You Get High\".", "The second disc (\"Come On Feel The Dandy Warhols\") is the first compilation album released by the band.", "It contains B-sides, covers, and previously unreleased material.", "\"Glide Magazine\" stated that the cover of Crosby, Stills, Nash and Young's \"Ohio\" used \"droning synthesizers\" to produce an \"alt/psychedelia sound.\""], ["The Black Keys", "At the 2013 Grammy Awards, \"El Camino\" and \"Lonely Boy\" were nominated in five categories and were winners in three; the album won Best Rock Album, while \"Lonely Boy\" won Best Rock Performance and Best Rock Song.", "For their eighth studio album, \"Turn Blue\", the band once again collaborated with Danger Mouse, who co-produced and co-wrote the album.", "It was recorded primarily at Sunset Sound in Hollywood, California, from July\u2013August 2013, with additional recording at Key Club in Benton Harbor, Michigan, and Nashville's Easy Eye Sound in early 2014.", "The album was announced in March 2014 via Mike Tyson's Twitter account, with a link to a cryptic teaser video on YouTube featuring a hypnotist, and was released on May 13, 2014.", "The record exhibits psychedelic rock and soul influences and features a more melancholy tone, largely in part due to Auerbach dealing with the divorce from his wife during the album sessions.", "The first single, \"Fever\" was released on March 24, while a second single, \"Turn Blue\", followed on April 14.", "The album debuted at number one in the US and Australia, the band's first record to top the album charts in either country; 164,000 copies were sold in the US in its first week."]], "gold": "There are several artists with an album titled The Black Album. Metallica and Prince are two earlier artists who released an album under the title in the 90s, in 1991 and 1994, respectively. In the 2000s, Jay-Z released his album in 2003, and Dandy Warhol released theirs in 2004. In the 2010s, an unofficial Beatles album was released in 2014, and Weezer's album was released in 2019.", "prediction 1": "The Black Album is a series of studio albums by various artists. The eighth studio album by American rapper Jay-Z, The Black Album, was released on November 14, 2003. The sixteenth studio album by American recording artist Prince was released on November 22, 1994, by Warner Bros. Records. The Black Album was also the title of the album by Metallica's fifth studio album, often called The Black Album, which was released in 1991. The thirteenth studio album by American rock band Weezer, also known as The Black Album, was released on March 1, 2019.\n", "prediction 2": "The Black Album, or Black Album, was released 10 times. The first was in 1987 and the second in 1994. The third was released in 2015. The fourth was released in 2019. The fifth was released in 2015. The sixth was released in 2018. It came out in 2015.", "prediction 3": "The Black Album, often called The Black Album, was an album released by various artists. These include rapper Jay-Z's eighth studio album, released on November 14, 2003, and Prince's sixteenth studio album, released November 22, 1994. American rock band Weezer's 13th studio album, The Black Album, was announced in April 2016, shortly after the band released their tenth album Weezer.", "prediction 4": "The Black Album is the title of two studio albums by American musicians. The first, the eighth studio album by rapper Jay-Z, came out on November 14, 2003. The second, the sixteenth studio album by American recording artist Prince came out on November 22, 1994. The third, the new album by British rock band Weezer, came out on March 1, 2019, and was available on November 1, 2018.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 290, "end": 340}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 5, "sentence_id": [2]}], "corrected-prediction": "The Black Album is a series of studio albums by various artists. The eighth studio album by American rapper Jay-Z, The Black Album, was released on November 14, 2003. The sixteenth studio album by American recording artist Prince was released on November 22, 1994, by Warner Bros. Records. Metallica's fifth studio album, often called The Black Album, was released in 1991. The thirteenth studio album by American rock band Weezer, also known as The Black Album, was released on March 1, 2019. The Dandy Warhols also released an album titled The Black Album in 2004."}, "preference": [1, 1, 1, 2, 2, 1], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - The Black Album (Jay-Z album)\nS1. The Black Album (Jay-Z album)  The Black Album is the eighth studio album by American rapper Jay-Z, released on November 14, 2003, by Roc-A-Fella Records.\nS2. It was advertised as his final album before retiring, which is also a recurring theme throughout the songs, although Jay-Z resumed his recording career in 2006.\nS3. For the album, Jay-Z wanted to enlist a different producer for each song, working with Just Blaze, Kanye West, The Neptunes, DJ Quik, Timbaland, 9th Wonder and Rick Rubin, among others.\nS4. When \"The Black Album\" was released, it received widespread acclaim from critics.\nS5. In its first week, the album debuted at number one on the \"Billboard\" 200, selling 463,000 copies in the United States.\nS6. It became Jay-Z's top selling record of the 2000s decade, and by July 2013, it had sold 3,516,000 copies in the US.\nS7. \"The Black Album\" was promoted with a retirement tour by Jay-Z and three singles that also achieved \"Billboard\" chart success, including the top-ten hits \"Change Clothes\" and \"Dirt off Your Shoulder\".\nS8. Jay-Z had announced that \"The Black Album\" would be his final record and went on a retirement tour after its release.\n\nPassage 2: Title (S0) - The Black Album (Prince album)\nS1. The Black Album (Prince album)  The Black Album is the sixteenth studio album by American recording artist Prince.\nS2. It was released on November 22, 1994, by Warner Bros. Records.\nS3. It was originally planned for release on December 8, 1987, as the follow-up to \"Sign o' the Times\" and was to appear in an entirely black sleeve with no title or even a credit to Prince; hence it was referred to as \"The Black Album\".\nS4. Dubbed \"The Funk Bible\" by preceding press releases, and in a hidden message within the album itself, the work seemed to be a reaction to criticism that Prince had become too pop-oriented.\nS5. It was his attempt to regain his Black audience.\nS6. The 1987 promo-only release had no printed title, artist name, production credits or photography printed; a simple black sleeve accompanied the disc.\nS7. On promotional copies, only a song listing and catalog number\u201425677\u2014were printed on the disc itself.\nS8. The commercial version was to only have the catalog number\u2014printed in pink\u2014on the spine.\nS9. The original compact disc pressing was made by Sony DADC rather than WEA Manufacturing.\nS10. After Prince became convinced that the album was \"evil\", he ordered it to be withdrawn a week before its release date.\n\nPassage 3: Title (S0) - Metallica discography\nS1. The band's first release to feature the new member was \",\" and then followed by \"...\nS2. And Justice for All\" in August 1988, which peaked at number six on the \"Billboard\" 200.\nS3. Metallica's fifth, self-titled album, often called The Black Album, was released in 1991 and debuted at number one on the \"Billboard\" 200.\nS4. The band embarked on a two-year tour in support of the album.\nS5. \"Metallica\" has since been certified 16 times platinum by the RIAA.\nS6. Metallica followed with the release of \"Load\" and \"Reload\", respectively.\nS7. After the release of \"Garage Inc.\" and \"S&M\", Newsted (who would later join Voivod) departed from the band.\nS8. Metallica recorded \"St. Anger\" without an official bassist (bass parts for the writing & recording during the album sessions were played by the band's long-time producer Bob Rock).\nS9. Bassist Robert Trujillo joined Metallica in 2003.\nS10. In 2008, the band released its ninth studio album, \"Death Magnetic\", which was produced by Rick Rubin and distributed through Warner Bros. Records.\nS11. In April 2009, the band's catalogue was released on the iTunes Store as \"the Metallica Collection\".\nS12. In 2013, Metallica released the movie, \"\", together with its soundtrack.\n\nPassage 4: Title (S0) - Weezer (2019 album)\nS1. Weezer (2019 album)  Weezer, also known as the Black Album, is the upcoming thirteenth studio album by American rock band Weezer.\nS2. Produced by Dave Sitek, it is set to be released on March 1, 2019, through Crush Music and Atlantic Records.\nS3. Weezer frontman Rivers Cuomo first hinted at the album in April 2016, shortly after the band released their tenth album \"Weezer\" (The White Album).\nS4. \"What could stand out more against 'White' than 'Black'?\nS5. I think it's going to maybe be like Beach Boys gone bad.\nS6. I'm thinking of swearing, which is something I've never done in songs.\"\nS7. While promoting the band's eleventh album \"Pacific Daydream\" in August 2017, Cuomo said \"The original plan was the Black Album but \"Pacific Daydream\" really came together.\nS8. The Black Album is pretty much ready, it's coming.\"\nS9. Cuomo first told Australian radio station Double J in February 2018 that the album would be released on May 25, later hinting at dates such as June 1 and June 12 on his Twitter account.\nS10. On October 11, the first single from the album, \"Can't Knock the Hustle\", was released.\n\nPassage 5: Title (S0) - The Black Album/Come On Feel The Dandy Warhols\nS1. The Black Album/Come On Feel The Dandy Warhols  The Black Album/Come On\nS2. Feel The Dandy Warhols is a 2004 double album released by American alternative band, The Dandy Warhols.\nS3. The two-disc set was released on their own Beat the World Records label.\nS4. Initially, the album was only available to purchase through the band's website.\nS5. It is now available to own via other sources.\nS6. Disc one marks the first, official release of the band's 1996 demo album (\"The Black Album\") which was described as \"lost\".\nS7. The album, recorded before \"...\nS8. The Dandy Warhols Come Down\", was rejected by Capitol Records and dismissed by the band themselves.\nS9. Three songs that were included on the original recording of the album are not included on this release, namely: \"Traci Lords\", \"Alien\" and \"You Get High\".\nS10. The second disc (\"Come On Feel The Dandy Warhols\") is the first compilation album released by the band.\nS11. It contains B-sides, covers, and previously unreleased material.\nS12. \"Glide Magazine\" stated that the cover of Crosby, Stills, Nash and Young's \"Ohio\" used \"droning synthesizers\" to produce an \"alt/psychedelia sound.\"\n\nPassage 6: Title (S0) - The Black Keys\nS1. At the 2013 Grammy Awards, \"El Camino\" and \"Lonely Boy\" were nominated in five categories and were winners in three; the album won Best Rock Album, while \"Lonely Boy\" won Best Rock Performance and Best Rock Song.\nS2. For their eighth studio album, \"Turn Blue\", the band once again collaborated with Danger Mouse, who co-produced and co-wrote the album.\nS3. It was recorded primarily at Sunset Sound in Hollywood, California, from July\u2013August 2013, with additional recording at Key Club in Benton Harbor, Michigan, and Nashville's Easy Eye Sound in early 2014.\nS4. The album was announced in March 2014 via Mike Tyson's Twitter account, with a link to a cryptic teaser video on YouTube featuring a hypnotist, and was released on May 13, 2014.\nS5. The record exhibits psychedelic rock and soul influences and features a more melancholy tone, largely in part due to Auerbach dealing with the divorce from his wife during the album sessions.\nS6. The first single, \"Fever\" was released on March 24, while a second single, \"Turn Blue\", followed on April 14.\nS7. The album debuted at number one in the US and Australia, the band's first record to top the album charts in either country; 164,000 copies were sold in the US in its first week.\n    \nInput Question:\nWhat year did the black album come out?\n\nCorrect Response:\nThere are several artists with an album titled The Black Album. Metallica and Prince are two earlier artists who released an album under the title in the 90s, in 1991 and 1994, respectively. In the 2000s, Jay-Z released his album in 2003, and Dandy Warhol released theirs in 2004. In the 2010s, an unofficial Beatles album was released in 2014, and Weezer's album was released in 2019.\n\nModel Prediction:\nThe Black Album is a series of studio albums by various artists. The eighth studio album by American rapper Jay-Z, The Black Album, was released on November 14, 2003. The sixteenth studio album by American recording artist Prince was released on November 22, 1994, by Warner Bros. Records. The Black Album was also the title of the album by Metallica's fifth studio album, often called The Black Album, which was released in 1991. The thirteenth studio album by American rock band Weezer, also known as The Black Album, was released on March 1, 2019.\n\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "The Black Album is a series of studio albums by various artists. The eighth studio album by American rapper Jay-Z, The Black Album, was released on November 14, 2003. The sixteenth studio album by American recording artist Prince was released on November 22, 1994, by Warner Bros. Records. [The Black Album was also the title of the album by] Metallica's fifth studio album, often called The Black Album, which was released in 1991. The thirteenth studio album by American rock band Weezer, also known as The Black Album, was released on March 1, 2019.\n\nExplanation:\nThe phrase \"The Black Album was also the title of the album by\" is redundant and doesn't add any new information to the sentence. It should be marked as \"Repetitive\". The phrase being repeated is \"The Black Album\"."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The Black Album is a series of studio albums by various artists.\nS2. The eighth studio album by American rapper Jay-Z, The Black Album, was released on November 14, 2003.\nS3. The sixteenth studio album by American recording artist Prince was released on November 22, 1994, by Warner Bros. Records.\nS4. The Black Album was also the title of the album by Metallica's fifth studio album, often called The Black Album, which was released in 1991.\nS5. The thirteenth studio album by American rock band Weezer, also known as The Black Album, was released on March 1, 2019.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation:\nAll the facts in the model prediction are consistent with the information provided in the passages."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 5, sentence 2 [Missing Answer]\n\nExplanation:\n1. The model prediction is missing the release year of The Black Album by The Dandy Warhols, which was released in 2004 as stated in Passage 5, sentence 2."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The Black Album is a series of studio albums by various artists. The eighth studio album by American rapper Jay-Z, The Black Album, was released on November 14, 2003. The sixteenth studio album by American recording artist Prince was released on November 22, 1994, by Warner Bros. Records. Metallica's fifth studio album, often called The Black Album, was released in 1991. The thirteenth studio album by American rock band Weezer, also known as The Black Album, was released on March 1, 2019. The Dandy Warhols also released an album titled The Black Album in 2004."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 69, "end": 75}, {"error type": "Irrelevant", "explanation": "", "start": 148, "end": 160}, {"error type": "Irrelevant", "explanation": "", "start": 171, "end": 180}, {"error type": "Irrelevant", "explanation": "", "start": 246, "end": 258}, {"error type": "Irrelevant", "explanation": "", "start": 265, "end": 289}, {"error type": "Irrelevant", "explanation": "", "start": 353, "end": 358}, {"error type": "Irrelevant", "explanation": "", "start": 435, "end": 445}, {"error type": "Irrelevant", "explanation": "", "start": 536, "end": 544}, {"error type": "Irrelevant", "explanation": "", "start": 16, "end": 30}, {"error type": "Irrelevant", "explanation": "", "start": 446, "end": 452}, {"error type": "Redundant", "explanation": "The Black Album", "start": 373, "end": 402}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 5, "sentence_id": [2]}], "corrected-prediction": "There are several artists with an album titled The Black Album. Metallica released an album under the title in 1991. The album by American recording artist Prince was released in 1994. The album by American rapper Jay-Z was released in 2003. The Dandy Warhols released theirs in 2004. The American rock band Weezer's album was released in 2019.\n"}}, {"question": "When did the modern venture capital industry in the usa most likely begin?", "passages": [["Venture capital", "Only after 1945 did \"true\" private equity investments begin to emerge, notably with the founding of the first two venture capital firms in 1946: American Research and Development Corporation (ARDC) and J.H. Whitney & Company.", "Georges Doriot, the \"father of venture capitalism\" (and former assistant dean of Harvard Business School), founded the graduate business school INSEAD in 1957.", "Along with Ralph Flanders and Karl Compton (former president of MIT), Doriot founded ARDC in 1946 to encourage private-sector investment in businesses run by soldiers returning from World War II.", "ARDC became the first institutional private-equity investment firm to raise capital from sources other than wealthy families, although it had several notable investment successes as well.", "ARDC is credited with the first trick when its 1957 investment of $70,000 in Digital Equipment Corporation (DEC) would be valued at over $355 million after the company's initial public offering in 1968 (representing a return of over 1200 times on its investment and an annualized rate of return of 101%).", "Former employees of ARDC went on to establish several prominent venture-capital firms including Greylock Partners (founded in 1965 by Charlie Waite and Bill Elfers) and Morgan, Holland Ventures, the predecessor of Flagship Ventures (founded in 1982 by James Morgan).", "ARDC continued investing until 1971, when Doriot retired."], ["Early history of private equity", "The 1958 Act officially allowed the U.S. Small Business Administration (SBA) to license private \"Small Business Investment Companies\" (SBICs) to help the financing and management of the small entrepreneurial businesses in the United States.", "Passage of the Act addressed concerns raised in a Federal Reserve Board report to Congress that concluded that a major gap existed in the capital markets for long-term funding for growth-oriented small businesses.", "Additionally, it was thought that fostering entrepreneurial companies would spur technological advances to compete against the Soviet Union.", "Facilitating the flow of capital through the economy up to the pioneering small concerns in order to stimulate the U.S. economy was and still is the main goal of the SBIC program today.", "The 1958 Act provided venture capital firms structured either as SBICs or Minority Enterprise Small Business Investment Companies (MESBICs) access to federal funds which could be leveraged at a ratio of up to 4:1 against privately raised investment funds.", "The success of the Small Business Administration's efforts are viewed primarily in terms of the pool of professional private equity investors that the program developed as the rigid regulatory limitations imposed by the program minimized the role of SBICs.", "In 2005, the SBA significantly reduced its SBIC program, though SBICs continue to make private equity investments.", "During the 1960s and 1970s, venture capital firms focused their investment activity primarily on starting and expanding companies."], ["Venture capital", "During the 1960s and 1970s, venture capital firms focused their investment activity primarily on starting and expanding companies.", "More often than not, these companies were exploiting breakthroughs in electronic, medical, or data-processing technology.", "As a result, venture capital came to be almost synonymous with technology finance.", "An early West Coast venture capital company was Draper and Johnson Investment Company, formed in 1962 by William Henry Draper III and Franklin P. Johnson, Jr.", "In 1965, Sutter Hill Ventures acquired the portfolio of Draper and Johnson as a founding action.", "Bill Draper and Paul Wythes were the founders, and Pitch Johnson formed Asset Management Company at that time.", "It is commonly noted that the first venture-backed startup is Fairchild Semiconductor (which produced the first commercially practical integrated circuit), funded in 1959 by what would later become Venrock Associates.", "Venrock was founded in 1969 by Laurance S. Rockefeller, the fourth of John D. Rockefeller's six children, as a way to allow other Rockefeller children to develop exposure to venture capital investments.", "It was also in the 1960s that the common form of private equity fund, still in use today, emerged.", "Private equity firms organized limited partnerships to hold investments in which the investment professionals served as general partner and the investors, who were passive limited partners, put up the capital."]], "gold": "Before World War II venture capital was primarily the domain of wealthy individuals and families. Following World War II, in 1946, Georges Doriot, the \"father of venture capitalism\" along with Ralph Flanders and Karl Compton founded American Research and Development Corporation or ARDC to encourage private-sector investment in businesses run by soldiers returning from World War II. ARDC became the first institutional private-equity investment firm to raise capital from sources other than wealthy families. Then, in 1958, one of the first steps toward a professionally managed venture capital industry in the United States was the passage of the Small Business Investment Act of 1958. The Small Business Investment Act of 1958 provided tax breaks that helped contribute to the rise of private equity firms. Then in 1959, it is commonly noted that the first venture-backed startup, Fairchild Semiconductor, was funded by what would later become Venrock Associates. Venrock, a compound of \"Venture\" and \"Rockefeller\" is a venture capital firm formed in 1969 to build upon the successful investing activities of the Rockefeller family that began in the late 1930s.", "prediction 1": "The modern venture capital industry in the US most likely began in the 1960s with the founding of two venture capital companies: American Research and Development Corporation (ARDC) and J.H. Whitney & Company. During the 1960s and 1970s, venture capital firms focused their investment activity primarily on starting and expanding companies. More often than not, these companies were exploiting breakthroughs in electronic, medical, or data-processing technology, as a result, venture capital came to be almost synonymous with technology finance.", "prediction 2": "The modern venture capital industry in the usa most likely began in the 1960s and 1970s, when venture capital firms focused their investment activity primarily on starting and expanding companies. More often than not, these companies were exploiting breakthroughs in electronic, medical, or data-processing technology.", "prediction 3": "The modern venture capital industry in the United States most likely began in the 1960s. In 1946, the first venture capital firm was American Research and Development Corporation (ARDC), and the second, J.H. Whitney & Company. It was in the 1960s that the common form of private equity fund, still in use today, emerged.", "prediction 4": "The modern venture capital industry in the United States most likely began in the 1960s and 1970s. It was notably with the founding of the first two venture capital firms in 1946: American Research and Development Corporation and J.H. Whitney & Company.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 210, "end": 545}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 1, "sentence_id": [1]}], "corrected-prediction": "The modern venture capital industry in the US most likely began in 1946 with the founding of two venture capital companies: American Research and Development Corporation (ARDC) and J.H. Whitney & Company. Then, in 1958, the Small Business Investment Act officially allowed the U.S. Small Business Administration (SBA) to license private \"Small Business Investment Companies\" (SBICs) to help the financing and management of the small entrepreneurial businesses in the United States. Furthermore, it is commonly noted that the first venture-backed startup, Fairchild Semiconductor, was funded in 1959 by what would later become Venrock Associates. Venrock, a venture capital firm, was formed in 1969 by Laurance S. Rockefeller, further contributing to the development of the venture capital industry."}, "preference": [1, 1, 1, 1, 1, 1], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Venture capital\nS1. Only after 1945 did \"true\" private equity investments begin to emerge, notably with the founding of the first two venture capital firms in 1946: American Research and Development Corporation (ARDC) and J.H. Whitney & Company.\nS2. Georges Doriot, the \"father of venture capitalism\" (and former assistant dean of Harvard Business School), founded the graduate business school INSEAD in 1957.\nS3. Along with Ralph Flanders and Karl Compton (former president of MIT), Doriot founded ARDC in 1946 to encourage private-sector investment in businesses run by soldiers returning from World War II.\nS4. ARDC became the first institutional private-equity investment firm to raise capital from sources other than wealthy families, although it had several notable investment successes as well.\nS5. ARDC is credited with the first trick when its 1957 investment of $70,000 in Digital Equipment Corporation (DEC) would be valued at over $355 million after the company's initial public offering in 1968 (representing a return of over 1200 times on its investment and an annualized rate of return of 101%).\nS6. Former employees of ARDC went on to establish several prominent venture-capital firms including Greylock Partners (founded in 1965 by Charlie Waite and Bill Elfers) and Morgan, Holland Ventures, the predecessor of Flagship Ventures (founded in 1982 by James Morgan).\nS7. ARDC continued investing until 1971, when Doriot retired.\n\nPassage 2: Title (S0) - Early history of private equity\nS1. The 1958 Act officially allowed the U.S. Small Business Administration (SBA) to license private \"Small Business Investment Companies\" (SBICs) to help the financing and management of the small entrepreneurial businesses in the United States.\nS2. Passage of the Act addressed concerns raised in a Federal Reserve Board report to Congress that concluded that a major gap existed in the capital markets for long-term funding for growth-oriented small businesses.\nS3. Additionally, it was thought that fostering entrepreneurial companies would spur technological advances to compete against the Soviet Union.\nS4. Facilitating the flow of capital through the economy up to the pioneering small concerns in order to stimulate the U.S. economy was and still is the main goal of the SBIC program today.\nS5. The 1958 Act provided venture capital firms structured either as SBICs or Minority Enterprise Small Business Investment Companies (MESBICs) access to federal funds which could be leveraged at a ratio of up to 4:1 against privately raised investment funds.\nS6. The success of the Small Business Administration's efforts are viewed primarily in terms of the pool of professional private equity investors that the program developed as the rigid regulatory limitations imposed by the program minimized the role of SBICs.\nS7. In 2005, the SBA significantly reduced its SBIC program, though SBICs continue to make private equity investments.\nS8. During the 1960s and 1970s, venture capital firms focused their investment activity primarily on starting and expanding companies.\n\nPassage 3: Title (S0) - Venture capital\nS1. During the 1960s and 1970s, venture capital firms focused their investment activity primarily on starting and expanding companies.\nS2. More often than not, these companies were exploiting breakthroughs in electronic, medical, or data-processing technology.\nS3. As a result, venture capital came to be almost synonymous with technology finance.\nS4. An early West Coast venture capital company was Draper and Johnson Investment Company, formed in 1962 by William Henry Draper III and Franklin P. Johnson, Jr.\nS5. In 1965, Sutter Hill Ventures acquired the portfolio of Draper and Johnson as a founding action.\nS6. Bill Draper and Paul Wythes were the founders, and Pitch Johnson formed Asset Management Company at that time.\nS7. It is commonly noted that the first venture-backed startup is Fairchild Semiconductor (which produced the first commercially practical integrated circuit), funded in 1959 by what would later become Venrock Associates.\nS8. Venrock was founded in 1969 by Laurance S. Rockefeller, the fourth of John D. Rockefeller's six children, as a way to allow other Rockefeller children to develop exposure to venture capital investments.\nS9. It was also in the 1960s that the common form of private equity fund, still in use today, emerged.\nS10. Private equity firms organized limited partnerships to hold investments in which the investment professionals served as general partner and the investors, who were passive limited partners, put up the capital.\n    \nInput Question:\nWhen did the modern venture capital industry in the usa most likely begin?\n\nCorrect Response:\nBefore World War II venture capital was primarily the domain of wealthy individuals and families. Following World War II, in 1946, Georges Doriot, the \"father of venture capitalism\" along with Ralph Flanders and Karl Compton founded American Research and Development Corporation or ARDC to encourage private-sector investment in businesses run by soldiers returning from World War II. ARDC became the first institutional private-equity investment firm to raise capital from sources other than wealthy families. Then, in 1958, one of the first steps toward a professionally managed venture capital industry in the United States was the passage of the Small Business Investment Act of 1958. The Small Business Investment Act of 1958 provided tax breaks that helped contribute to the rise of private equity firms. Then in 1959, it is commonly noted that the first venture-backed startup, Fairchild Semiconductor, was funded by what would later become Venrock Associates. Venrock, a compound of \"Venture\" and \"Rockefeller\" is a venture capital firm formed in 1969 to build upon the successful investing activities of the Rockefeller family that began in the late 1930s.\n\nModel Prediction:\nThe modern venture capital industry in the US most likely began in the 1960s with the founding of two venture capital companies: American Research and Development Corporation (ARDC) and J.H. Whitney & Company. During the 1960s and 1970s, venture capital firms focused their investment activity primarily on starting and expanding companies. More often than not, these companies were exploiting breakthroughs in electronic, medical, or data-processing technology, as a result, venture capital came to be almost synonymous with technology finance.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "The modern venture capital industry in the US most likely began in the 1960s with the founding of two venture capital companies: American Research and Development Corporation (ARDC) and J.H. Whitney & Company. [During the 1960s and 1970s, venture capital firms focused their investment activity primarily on starting and expanding companies. More often than not, these companies were exploiting breakthroughs in electronic, medical, or data-processing technology, as a result, venture capital came to be almost synonymous with technology finance.]\n\nExplanation:\nThe last two sentences in the model prediction are irrelevant as they do not provide direct answers or crucial auxiliary information to the question. The question asks about the beginning of the modern venture capital industry in the US, not about the focus of venture capital firms during the 1960s and 1970s or the association of venture capital with technology finance."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The modern venture capital industry in the US most likely began in the 1960s with the founding of two venture capital companies: American Research and Development Corporation (ARDC) and J.H.\nS2. Whitney & Company.\nS3. During the 1960s and 1970s, venture capital firms focused their investment activity primarily on starting and expanding companies.\nS4. More often than not, these companies were exploiting breakthroughs in electronic, medical, or data-processing technology, as a result, venture capital came to be almost synonymous with technology finance.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "S1\n\nExplanation:\nThe first sentence is factually inconsistent with the passages. According to Passage 1, Sentence 1, the two venture capital firms, American Research and Development Corporation (ARDC) and J.H. Whitney & Company, were founded in 1946, not in the 1960s."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 1 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Major Auxiliary Information]\n3. Passage 3, sentence 7 [Missing Major Auxiliary Information]\n4. Passage 3, sentence 8 [Missing Major Auxiliary Information]\n\nExplanation:\n1. The model prediction misses the fact that the first two venture capital firms, American Research and Development Corporation (ARDC) and J.H. Whitney & Company, were founded in 1946, which is a direct answer to the question.\n2. The model prediction does not mention the Small Business Investment Act of 1958, which is a major auxiliary information as it officially allowed the U.S. Small Business Administration (SBA) to license private \"Small Business Investment Companies\" (SBICs) to help the financing and management of the small entrepreneurial businesses in the United States.\n3. The model prediction does not mention the first venture-backed startup, Fairchild Semiconductor, which was funded in 1959 by what would later become Venrock Associates. This is a major auxiliary information as it shows the beginning of venture-backed startups.\n4. The model prediction does not mention the formation of Venrock in 1969 by Laurance S. Rockefeller, which is a major auxiliary information as it shows the development of the venture capital industry."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The modern venture capital industry in the US most likely began in 1946 with the founding of two venture capital companies: American Research and Development Corporation (ARDC) and J.H. Whitney & Company. Then, in 1958, the Small Business Investment Act officially allowed the U.S. Small Business Administration (SBA) to license private \"Small Business Investment Companies\" (SBICs) to help the financing and management of the small entrepreneurial businesses in the United States. Furthermore, it is commonly noted that the first venture-backed startup, Fairchild Semiconductor, was funded in 1959 by what would later become Venrock Associates. Venrock, a venture capital firm, was formed in 1969 by Laurance S. Rockefeller, further contributing to the development of the venture capital industry."}], "feedback_human": {"errors": [{"error type": "Wrong-Grounding", "explanation": "{\"passage_id\":1,\"sentence_id\":[1]}", "start": 71, "end": 76}, {"error type": "Wrong-Grounding", "explanation": "{\"passage_id\":1,\"sentence_id\":[1]}", "start": 4, "end": 35}, {"error type": "Irrelevant", "explanation": "", "start": 210, "end": 340}, {"error type": "Irrelevant", "explanation": "", "start": 341, "end": 545}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [2, 3]}, {"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [4]}, {"error type": "Missing-Major-Auxiliary", "passage_id": 2, "sentence_id": [5]}, {"error type": "Missing-Major-Auxiliary", "passage_id": 3, "sentence_id": [7]}], "corrected-prediction": "Only after 1945 did \"true\" private equity investments begin to emerge with the founding of two venture capital companies: American Research and Development Corporation (ARDC) and J.H. Whitney & Company.  Georges Doriot, the \"father of venture capitalism\", along with Ralph Flanders and Karl Compton, founded ARDC. ARDC became the first institutional private-equity investment firm to raise capital from sources other than wealthy families. The 1958 Act provided venture capital firms structure. It is commonly noted that the first venture-backed startup is Fairchild Semiconductor was funded to be what would later become Venrock Associates."}}, {"question": "Dil hai ki manta nahi is remake of?", "passages": [["Dil Hai Ke Manta Nahin", "Dil Hai Ke Manta Nahin\n\nDil Hai Ke Manta Nahin (English: \"The Heart Is Such, It Doesn't Agree\") is a 1991 Indian Hindi-language romantic comedy film.", "It was produced by Gulshan Kumar, directed by Mahesh Bhatt, and starred his daughter Pooja Bhatt in her first major lead female role, while the lead male role was played by Aamir Khan.", "Supporting roles were played by Anupam Kher, Sameer Chitre, and Tiku Talsania, while Deepak Tijori made a special appearance.", "The movie was commercially not successful at the box office.", "The movie revolves around a spoilt heiress who runs away from home to marry a gold-digging film star.", "En route, she is helped by a smart-alecky journalist only to end up falling for him.", "It is an unofficial remake of the 1956 Bollywood film \"Chori Chori\" and 1966 Tamil language film \"Chandhrodhayam\", which in turn were adaptations of the 1934 Hollywood film \"It Happened One Night\".", "In turn, \"Dil Hai Ke Manta Nahin\" was remade in Tamil as \"Kadhal Rojavae\" (2000) and inspired the Kannada movie \"Hudugaata\" (2007)."], ["Chori Chori", "Chori Chori\n\nChori Chori (Hindi: \u091a\u094b\u0930\u0940 \u091a\u094b\u0930\u0940; English: \"Surreptitiously\") is a 1956 Indian Hindi-language romantic comedy film directed by Anant Thakur, with music by Shankar Jaikishan and lyrics by Hasrat Jaipuri and Shailendra.", "The film is an unofficial remake of the American film \"It Happened One Night\".", "Bhagwan Dada, Pran, David, and Johnny Walker have character parts.", "This was the last film of Nargis-Raj Kapoor, with Nargis doing one cameo appearance in the Raj Kapoor starrer Jagte Raho.", "The music of \"Chori Chori\" had popular tracks including \"Aaja Sanam\", \"Yeh Raat Bheegi Bheegi\" in the voices of Lata Mangeshkar and Manna Dey; \"Jahan Mein Jati Hun\" by Lata and Manna and \"Sawa Lakh Ki Lottery,\" by Mohammad Rafi.", "The movie would later inspire the unofficial 1991 Hindi re-make \"Dil Hai Ke Manta Nahin\", directed by Mahesh Bhatt and starring Aamir Khan and Pooja Bhatt.", "Like \"Chori Chori\" it too became a hit."], ["Chandhrodhayam", "The reporter is helped in his quest by a friend, a photographer of the newspaper, Alwar (Nagesh), (a husband who is often corrected by his wife Ahalya (Manorama).", "Chandran wants at all costs to help another young woman wounded cruelly by life since her birth, Kamala (Bharathi Vishnuvardhan).", "She had previously been a victim of a predator, the rich Paranthaman (M. N. Nambiar).", "Chandra puts everything in its place by uniting Kamala with Paranthaman and he himself marrying Devi, with the blessings of the elders from both the families.", "Duriyothanan regrets his misdeeds and asks Chandran to start a new newspaper and name it as he wants.", "The newspaper is named \"Chandrodayam\", the first issue carrying the wedding news of Chandran and Devi.", "The casting is established according to the original order of the credits of opening of the movie, except those not mentioned\n\nThe film was inspired by the 1934 American film \"It Happened One Night\".", "The climactic fight sequence between M. N. Nambiar and MGR was shot with the use of only one light source: a rolling, broken small table lamp.", "The soundtrack is composed by M. S. Viswanathan."]], "gold": "\"Dil Hai Ke Manta Nahi\" is an unofficial remake of the 1956 Hindi film \"Chori Chori\" and 1966 Tamil film \"Chandhrodhayam\". Both those films are remakes of the 1934 American film \"It Happened One Night\". ", "prediction 1": "Dil Hai Ke Manta Nahin is a 1991 Indian Hindi-language romantic comedy film. It was produced by Gulshan Kumar, directed by Mahesh Bhatt, and starred his daughter Pooja Bhatt in her first major lead female role. The movie revolves around a spoilt heiress who runs away from home to marry a gold-digging film star. The movie was commercially not successful at the box office. The 1956 Bollywood film Chori Chori is an unofficial remake of the 1956 Bollywood film Chori Chori Chori and 1966 Tamil language film Chandhrodhayam, which in turn were adaptations of the 1934 Hollywood film It Happened One Night.", "prediction 2": "Dil Hai Ke Manta Nahin is an unofficial remake of the 1956 Bollywood film Chori Chori and the 1966 Tamil language film Chandhrodhayam, which in turn were adaptations of the 1934 Hollywood film It Happened One Night. Dil Hai Ke Manta Nahin was remade in Tamil as Kadhal Rojavae in 2000 and inspired the Kannada movie Hudugaata in 2007.", "prediction 3": "Chori Chori is a 1956 Indian Hindi-language romantic comedy film directed by Anant Thakur, with music by Shankar Jaikishan and lyrics by Hasrat Jaipuri and Shailendra. It is an unofficial remake of the 1934 American film It Happened One Night. Dil Hai Ke Manta Nahin is a 1991 Indian Hindi-language romantic comedy film. It was produced by Gulshan Kumar, directed by Mahesh Bhatt, and starred his daughter Pooja Bhatt in her first major lead female role.", "prediction 4": "Chori Chori Chori is a 1956 Indian Hindi romantic comedy film directed by Anant Thakur, with music by Shankar Jaikishan and lyrics by Hasrat Jaipuri and Shailendra. The film is an unofficial remake of the 1934 American film It Happened One Night. Dil Hai Ke Manta Nahin is an unofficial remake of the 1991 Indian Hindi-language romantic comedy film. In turn, Dil Hai Ke Manta Nahin was remade in Tamil as Kadhal Rojavae (2000) and inspired the Kannada movie Hudugaataataataata Nahin.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 0, "end": 373}, {"error type": "Irrelevant", "explanation": "", "start": 441, "end": 478}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 1, "sentence_id": [7]}], "corrected-prediction": "\"Dil Hai Ke Manta Nahin\" is an unofficial remake of the 1956 Bollywood film \"Chori Chori\" and the 1966 Tamil language film \"Chandhrodhayam\", which in turn were adaptations of the 1934 Hollywood film \"It Happened One Night\"."}, "preference": [2, 2, 2, 1, 1, 1], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Dil Hai Ke Manta Nahin\nS1. Dil Hai Ke Manta Nahin  Dil Hai Ke Manta Nahin (English: \"The Heart Is Such, It Doesn't Agree\") is a 1991 Indian Hindi-language romantic comedy film.\nS2. It was produced by Gulshan Kumar, directed by Mahesh Bhatt, and starred his daughter Pooja Bhatt in her first major lead female role, while the lead male role was played by Aamir Khan.\nS3. Supporting roles were played by Anupam Kher, Sameer Chitre, and Tiku Talsania, while Deepak Tijori made a special appearance.\nS4. The movie was commercially not successful at the box office.\nS5. The movie revolves around a spoilt heiress who runs away from home to marry a gold-digging film star.\nS6. En route, she is helped by a smart-alecky journalist only to end up falling for him.\nS7. It is an unofficial remake of the 1956 Bollywood film \"Chori Chori\" and 1966 Tamil language film \"Chandhrodhayam\", which in turn were adaptations of the 1934 Hollywood film \"It Happened One Night\".\nS8. In turn, \"Dil Hai Ke Manta Nahin\" was remade in Tamil as \"Kadhal Rojavae\" (2000) and inspired the Kannada movie \"Hudugaata\" (2007).\n\nPassage 2: Title (S0) - Chori Chori\nS1. Chori Chori  Chori Chori (Hindi: \u091a\u094b\u0930\u0940 \u091a\u094b\u0930\u0940; English: \"Surreptitiously\") is a 1956 Indian Hindi-language romantic comedy film directed by Anant Thakur, with music by Shankar Jaikishan and lyrics by Hasrat Jaipuri and Shailendra.\nS2. The film is an unofficial remake of the American film \"It Happened One Night\".\nS3. Bhagwan Dada, Pran, David, and Johnny Walker have character parts.\nS4. This was the last film of Nargis-Raj Kapoor, with Nargis doing one cameo appearance in the Raj Kapoor starrer Jagte Raho.\nS5. The music of \"Chori Chori\" had popular tracks including \"Aaja Sanam\", \"Yeh Raat Bheegi Bheegi\" in the voices of Lata Mangeshkar and Manna Dey; \"Jahan Mein Jati Hun\" by Lata and Manna and \"Sawa Lakh Ki Lottery,\" by Mohammad Rafi.\nS6. The movie would later inspire the unofficial 1991 Hindi re-make \"Dil Hai Ke Manta Nahin\", directed by Mahesh Bhatt and starring Aamir Khan and Pooja Bhatt.\nS7. Like \"Chori Chori\" it too became a hit.\n\nPassage 3: Title (S0) - Chandhrodhayam\nS1. The reporter is helped in his quest by a friend, a photographer of the newspaper, Alwar (Nagesh), (a husband who is often corrected by his wife Ahalya (Manorama).\nS2. Chandran wants at all costs to help another young woman wounded cruelly by life since her birth, Kamala (Bharathi Vishnuvardhan).\nS3. She had previously been a victim of a predator, the rich Paranthaman (M. N. Nambiar).\nS4. Chandra puts everything in its place by uniting Kamala with Paranthaman and he himself marrying Devi, with the blessings of the elders from both the families.\nS5. Duriyothanan regrets his misdeeds and asks Chandran to start a new newspaper and name it as he wants.\nS6. The newspaper is named \"Chandrodayam\", the first issue carrying the wedding news of Chandran and Devi.\nS7. The casting is established according to the original order of the credits of opening of the movie, except those not mentioned  The film was inspired by the 1934 American film \"It Happened One Night\".\nS8. The climactic fight sequence between M. N. Nambiar and MGR was shot with the use of only one light source: a rolling, broken small table lamp.\nS9. The soundtrack is composed by M. S. Viswanathan.\n    \nInput Question:\nDil hai ki manta nahi is remake of?\n\nCorrect Response:\n\"Dil Hai Ke Manta Nahi\" is an unofficial remake of the 1956 Hindi film \"Chori Chori\" and 1966 Tamil film \"Chandhrodhayam\". Both those films are remakes of the 1934 American film \"It Happened One Night\". \n\nModel Prediction:\nDil Hai Ke Manta Nahin is a 1991 Indian Hindi-language romantic comedy film. It was produced by Gulshan Kumar, directed by Mahesh Bhatt, and starred his daughter Pooja Bhatt in her first major lead female role. The movie revolves around a spoilt heiress who runs away from home to marry a gold-digging film star. The movie was commercially not successful at the box office. The 1956 Bollywood film Chori Chori is an unofficial remake of the 1956 Bollywood film Chori Chori Chori and 1966 Tamil language film Chandhrodhayam, which in turn were adaptations of the 1934 Hollywood film It Happened One Night.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "[Dil Hai Ke Manta Nahin is a 1991 Indian Hindi-language romantic comedy film. It was produced by Gulshan Kumar, directed by Mahesh Bhatt, and starred his daughter Pooja Bhatt in her first major lead female role. The movie revolves around a spoilt heiress who runs away from home to marry a gold-digging film star. The movie was commercially not successful at the box office.] The 1956 Bollywood film Chori Chori is an unofficial remake of the [1956 Bollywood film Chori Chori Chori] and 1966 Tamil language film Chandhrodhayam, which in turn were adaptations of the 1934 Hollywood film It Happened One Night.\n\nExplanation:\n1. The first four sentences in the model prediction are neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, they should be marked as \"Irrelevant\". \n2. The phrase \"1956 Bollywood film Chori Chori Chori\" is incorrect and seems to be a repetition error. Therefore, it should be marked as \"Repetitive\"."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. Dil Hai Ke Manta Nahin is a 1991 Indian Hindi-language romantic comedy film.\nS2. It was produced by Gulshan Kumar, directed by Mahesh Bhatt, and starred his daughter Pooja Bhatt in her first major lead female role.\nS3. The movie revolves around a spoilt heiress who runs away from home to marry a gold-digging film star.\nS4. The movie was commercially not successful at the box office.\nS5. The 1956 Bollywood film Chori Chori is an unofficial remake of the 1956 Bollywood film Chori Chori Chori and 1966 Tamil language film Chandhrodhayam, which in turn were adaptations of the 1934 Hollywood film It Happened One Night.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "Inconsistent or Unverifiable Sentences:\n1. S5\n\nExplanation:\n1. The phrase \"1956 Bollywood film Chori Chori Chori\" in sentence 5 is factually inconsistent with the passages. The correct information, as per Passage 1, sentence 7, is that \"Dil Hai Ke Manta Nahin\" is an unofficial remake of the 1956 Bollywood film \"Chori Chori\" and the 1966 Tamil language film \"Chandhrodhayam\"."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 7 [Missing Answer]\n\nExplanation:\n1. The model prediction does not mention that \"Dil Hai Ke Manta Nahin\" is an unofficial remake of the 1956 Bollywood film \"Chori Chori\" and the 1966 Tamil language film \"Chandhrodhayam\". This information is present in Passage 1, sentence 7 and is a direct answer to the question."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "\"Dil Hai Ke Manta Nahin\" is an unofficial remake of the 1956 Bollywood film \"Chori Chori\" and the 1966 Tamil language film \"Chandhrodhayam\", which in turn were adaptations of the 1934 Hollywood film \"It Happened One Night\"."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 0, "end": 76}, {"error type": "Irrelevant", "explanation": "", "start": 77, "end": 210}, {"error type": "Irrelevant", "explanation": "", "start": 211, "end": 312}, {"error type": "Irrelevant", "explanation": "", "start": 313, "end": 373}], "missing-info": [], "corrected-prediction": "The 1956 Bollywood film Chori Chori is an unofficial remake of the 1956 Bollywood film Chori Chori Chori and 1966 Tamil language film Chandhrodhayam, which in turn were adaptations of the 1934 Hollywood film It Happened One Night."}}, {"question": "When was the first pair of glasses invented?", "passages": [["Glasses", "The development of the first eyeglasses took place in Northern Italy in the second half of the 13th century.", "Independently of the development of optical lenses, some cultures developed \"sunglasses\" for eye protection, without any corrective properties.", "Thus, flat panes of smoky quartz, were used in 12th-century China.", "Similarly, the Inuit have used snow goggles for eye protection.", "The first eyeglasses were made in Northern Italy, most likely in Pisa, by about 1290:\n", "In a sermon delivered on 23 February 1306, the Dominican friar Giordano da Pisa (ca. 1255\u20131311) wrote \"It is not yet twenty years since there was found the art of making eyeglasses, which make for good vision...", "And it is so short a time that this new art, never before extant, was discovered. ...", "I saw the one who first discovered and practiced it, and I talked to him.\"", "Giordano's colleague Friar Alessandro della Spina of Pisa (d. 1313) was soon making eyeglasses.", "The \"Ancient Chronicle of the Dominican Monastery of St. Catherine in Pisa\" records: \"Eyeglasses, having first been made by someone else, who was unwilling to share them, he [Spina] made them and shared them with everyone with a cheerful and willing heart.\""], ["Bifocals", "Bifocals\n\nBifocals are eyeglasses with two distinct optical powers.", "Bifocals are commonly prescribed to people with presbyopia who also require a correction for myopia, hyperopia, and/or astigmatism.", "Benjamin Franklin is generally credited with the invention of bifocals\n.", "Historians have produced some evidence to suggest that others may have come before him in the invention; however, a correspondence between George Whatley and John Fenno, editor of The Gazette of the United States, suggested that Franklin had indeed invented bifocals, and perhaps 50 years earlier than had been originally thought.", "However the College of Optometrists concluded:\nSince many inventions are developed independently by more than one person, it is possible that the invention of bifocals may have been such a case.", "John Isaac Hawkins, the inventor of trifocal lenses, coined the term \"bifocals\" in 1824 and credited Dr. Franklin.", "In 1955, Irving Rips of Younger Optics created the first seamless or \"invisible\" bifocal, a precursor to all progressive lenses.", "Construction\n\nOriginal bifocals were designed with the most convex lenses (for close viewing) in the lower half of the frame and the least convex lenses on the upper."], ["Glasses", "Serious historians have from time to time produced evidence to suggest that others may have preceded him in the invention; however, a correspondence between George Whatley and John Fenno, editor of \"The Gazette of the United States\", suggested that Franklin had indeed invented bifocals, and perhaps 50 years earlier than had been originally thought.", "The first lenses for correcting astigmatism were designed by the British astronomer George Airy in 1825.", "Over time, the construction of frames for glasses also evolved.", "Early eyepieces were designed to be either held in place by hand or by exerting pressure on the nose (\"pince-nez\").", "Girolamo Savonarola suggested that eyepieces could be held in place by a ribbon passed over the wearer's head, this in turn secured by the weight of a hat.", "The modern style of glasses, held by temples passing over the ears, was developed some time before 1727, possibly by the British optician Edward Scarlett.", "These designs were not immediately successful, however, and various styles with attached handles such as \"scissors-glasses\" and lorgnettes were also fashionable from the second half of the 18th century and into the early 19th century."]], "gold": "Eyeglasses are estimated to have been invented by 1290 in Northern Italy, most likely in Pisa. Eyeglasses were referenced in a sermon in 1306 by the Dominican friar Giordano da Pisa writing,  \"It is not yet twenty years since there was found the art of making eyeglasses, which make for good vision ... And it is so short a time that this new art, never before extant, was discovered. ... I saw the one who first discovered and practiced it, and I talked to him.\"  British astronomer George Airy designed the first lenses for correcting astigmatism in 1825. The modern design of glasses, with temples passing over the ears may have been invented before 1727 by British optician Edward Scarlett. ", "prediction 1": "The development of the first pair of glasses took place in Northern Italy in the second half of the 13th century. The first eyeglasses were made in Northern Italy, most likely in Pisa, by about 1290: In a sermon delivered on 23 February 1306, the Dominican friar Giordano da Pisa wrote \"It is not yet twenty years since there was found the art of making eyeglasses, which make for good vision... And it is so short a time that this new art, never before extant, was discovered.\"", "prediction 2": "The development of the first pair of glasses took place in Northern Italy in the second half of the 13th century. The first eyeglasses were made in Northern Italy, most likely in Pisa, by about 1290. In a sermon delivered on 23 February 1306, the Dominican friar Giordano da Pisa wrote: \"It is not yet twenty years since there was found the art of making eyeglasses, which make for good vision... And it is so short a time that this new art, never before extant, was discovered.\"", "prediction 3": "In 1290, the Dominican friar Giordano da Pisa wrote: \"It is not yet twenty years since there was found the art of making eyeglasses, which make for good vision. And it is so short a time that this new art, never before extant, was discovered.\" The first pair of eyeglasses made in Northern Italy, most likely in Pisa, by about 1290. In 1826, the English optician Edward Scarlett, who was also known as Edward Scarlett, a British optician Edward Scarlett, possibly by Edward Scarlett.", "prediction 4": "The first pair of eyeglasses were invented in Northern Italy in the second half of the 13th century. In a sermon delivered on 23 February 1306, the Dominican friar Giordano da Pisa wrote, \"It is not yet twenty years since there was found the art of making eyeglasses, which make for good vision... And it is so short a time that this new art, never before extant, was discovered.\" Bifocals are eyeglasses with two distinct optical powers. The first lenses for correcting astigmatism were designed by the British astronomer George Airy in 1825.", "feedback": {"errors": [], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 3, "sentence_id": [2]}], "corrected-prediction": "The development of the first pair of glasses took place in Northern Italy in the second half of the 13th century. The first eyeglasses were made in Northern Italy, most likely in Pisa, by about 1290: In a sermon delivered on 23 February 1306, the Dominican friar Giordano da Pisa wrote \"It is not yet twenty years since there was found the art of making eyeglasses, which make for good vision... And it is so short a time that this new art, never before extant, was discovered.\" The first lenses for correcting astigmatism were designed by the British astronomer George Airy in 1825. The modern design of glasses, with temples passing over the ears, may have been invented before 1727 by British optician Edward Scarlett."}, "preference": [0, 1, 1, 1, 1, 2], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Glasses\nS1. The development of the first eyeglasses took place in Northern Italy in the second half of the 13th century.\nS2. Independently of the development of optical lenses, some cultures developed \"sunglasses\" for eye protection, without any corrective properties.\nS3. Thus, flat panes of smoky quartz, were used in 12th-century China.\nS4. Similarly, the Inuit have used snow goggles for eye protection.\nS5. The first eyeglasses were made in Northern Italy, most likely in Pisa, by about 1290: \nS6. In a sermon delivered on 23 February 1306, the Dominican friar Giordano da Pisa (ca. 1255\u20131311) wrote \"It is not yet twenty years since there was found the art of making eyeglasses, which make for good vision...\nS7. And it is so short a time that this new art, never before extant, was discovered. ...\nS8. I saw the one who first discovered and practiced it, and I talked to him.\"\nS9. Giordano's colleague Friar Alessandro della Spina of Pisa (d. 1313) was soon making eyeglasses.\nS10. The \"Ancient Chronicle of the Dominican Monastery of St. Catherine in Pisa\" records: \"Eyeglasses, having first been made by someone else, who was unwilling to share them, he [Spina] made them and shared them with everyone with a cheerful and willing heart.\"\n\nPassage 2: Title (S0) - Bifocals\nS1. Bifocals  Bifocals are eyeglasses with two distinct optical powers.\nS2. Bifocals are commonly prescribed to people with presbyopia who also require a correction for myopia, hyperopia, and/or astigmatism.\nS3. Benjamin Franklin is generally credited with the invention of bifocals .\nS4. Historians have produced some evidence to suggest that others may have come before him in the invention; however, a correspondence between George Whatley and John Fenno, editor of The Gazette of the United States, suggested that Franklin had indeed invented bifocals, and perhaps 50 years earlier than had been originally thought.\nS5. However the College of Optometrists concluded: Since many inventions are developed independently by more than one person, it is possible that the invention of bifocals may have been such a case.\nS6. John Isaac Hawkins, the inventor of trifocal lenses, coined the term \"bifocals\" in 1824 and credited Dr. Franklin.\nS7. In 1955, Irving Rips of Younger Optics created the first seamless or \"invisible\" bifocal, a precursor to all progressive lenses.\nS8. Construction  Original bifocals were designed with the most convex lenses (for close viewing) in the lower half of the frame and the least convex lenses on the upper.\n\nPassage 3: Title (S0) - Glasses\nS1. Serious historians have from time to time produced evidence to suggest that others may have preceded him in the invention; however, a correspondence between George Whatley and John Fenno, editor of \"The Gazette of the United States\", suggested that Franklin had indeed invented bifocals, and perhaps 50 years earlier than had been originally thought.\nS2. The first lenses for correcting astigmatism were designed by the British astronomer George Airy in 1825.\nS3. Over time, the construction of frames for glasses also evolved.\nS4. Early eyepieces were designed to be either held in place by hand or by exerting pressure on the nose (\"pince-nez\").\nS5. Girolamo Savonarola suggested that eyepieces could be held in place by a ribbon passed over the wearer's head, this in turn secured by the weight of a hat.\nS6. The modern style of glasses, held by temples passing over the ears, was developed some time before 1727, possibly by the British optician Edward Scarlett.\nS7. These designs were not immediately successful, however, and various styles with attached handles such as \"scissors-glasses\" and lorgnettes were also fashionable from the second half of the 18th century and into the early 19th century.\n    \nInput Question:\nWhen was the first pair of glasses invented?\n\nCorrect Response:\nEyeglasses are estimated to have been invented by 1290 in Northern Italy, most likely in Pisa. Eyeglasses were referenced in a sermon in 1306 by the Dominican friar Giordano da Pisa writing,  \"It is not yet twenty years since there was found the art of making eyeglasses, which make for good vision ... And it is so short a time that this new art, never before extant, was discovered. ... I saw the one who first discovered and practiced it, and I talked to him.\"  British astronomer George Airy designed the first lenses for correcting astigmatism in 1825. The modern design of glasses, with temples passing over the ears may have been invented before 1727 by British optician Edward Scarlett. \n\nModel Prediction:\nThe development of the first pair of glasses took place in Northern Italy in the second half of the 13th century. The first eyeglasses were made in Northern Italy, most likely in Pisa, by about 1290: In a sermon delivered on 23 February 1306, the Dominican friar Giordano da Pisa wrote \"It is not yet twenty years since there was found the art of making eyeglasses, which make for good vision... And it is so short a time that this new art, never before extant, was discovered.\"\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "The development of the first pair of glasses took place in Northern Italy in the second half of the 13th century. The first eyeglasses were made in Northern Italy, most likely in Pisa, by about 1290: In a sermon delivered on 23 February 1306, the Dominican friar Giordano da Pisa wrote \"It is not yet twenty years since there was found the art of making eyeglasses, which make for good vision... And it is so short a time that this new art, never before extant, was discovered.\"\n\nExplanation: There are no irrelevant, incoherent, or repetitive spans in the model prediction. The information provided is relevant to the question, coherent, and not repetitive."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The development of the first pair of glasses took place in Northern Italy in the second half of the 13th century.\nS2. The first eyeglasses were made in Northern Italy, most likely in Pisa, by about 1290: In a sermon delivered on 23 February 1306, the Dominican friar Giordano da Pisa wrote \"It is not yet twenty years since there was found the art of making eyeglasses, which make for good vision... And it is so short a time that this new art, never before extant, was discovered.\"\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation: All the facts in the model prediction are consistent with the information provided in the passages. Therefore, there are no inconsistent or unverifiable facts in the model prediction."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 3, sentence 2 [Missing Major Auxiliary Information]\n2. Passage 3, sentence 6 [Missing Major Auxiliary Information]\n\nExplanation:\n1. The model prediction misses the information about the first lenses for correcting astigmatism being designed by the British astronomer George Airy in 1825, which is a significant development in the history of glasses.\n2. The model prediction also omits the information about the modern design of glasses, with temples passing over the ears, possibly being invented before 1727 by British optician Edward Scarlett. This is also a significant development in the history of glasses."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The development of the first pair of glasses took place in Northern Italy in the second half of the 13th century. The first eyeglasses were made in Northern Italy, most likely in Pisa, by about 1290: In a sermon delivered on 23 February 1306, the Dominican friar Giordano da Pisa wrote \"It is not yet twenty years since there was found the art of making eyeglasses, which make for good vision... And it is so short a time that this new art, never before extant, was discovered.\" The first lenses for correcting astigmatism were designed by the British astronomer George Airy in 1825. The modern design of glasses, with temples passing over the ears, may have been invented before 1727 by British optician Edward Scarlett."}], "feedback_human": {"errors": [], "missing-info": [{"error type": "Missing-Minor-Auxiliary", "passage_id": 1, "sentence_id": [8]}, {"error type": "Missing-Major-Auxiliary", "passage_id": 3, "sentence_id": [2]}, {"error type": "Missing-Major-Auxiliary", "passage_id": 3, "sentence_id": [6]}], "corrected-prediction": "The development of the first pair of glasses took place in Northern Italy in the second half of the 13th century. The first eyeglasses were made in Northern Italy, most likely in Pisa, by about 1290: In a sermon delivered on 23 February 1306, the Dominican friar Giordano da Pisa wrote \"It is not yet twenty years since there was found the art of making eyeglasses, which make for good vision... And it is so short a time that this new art, never before extant, was discovered. I saw the one who first discovered and practiced it, and I talked to him.\"  The first lenses for correcting astigmatism were designed by the British astronomer George Airy in 1825. The modern style of glasses, held by temples passing over the ears, was developed some time before 1727, possibly by the British optician Edward Scarlett."}}, {"question": "Who governed the kingdom of naples and sicily 1815?", "passages": [["Joachim Murat", "Joachim Murat\n\nJoachim-Napol\u00e9on Murat (; born Joachim Murat; ; ; 25 March 1767 \u2013 13 October 1815) was a Marshal of France and Admiral of France under the reign of Napoleon.", "He was also the 1st Prince Murat, Grand Duke of Berg from 1806 to 1808, and King of Naples from 1808 to 1815.", "Murat received his titles in part by being Napoleon's brother-in-law through marriage to his younger sister, Caroline Bonaparte, as well as personal merit.", "He was noted as a daring, brave, and charismatic cavalry officer as well as a flamboyant dresser, for which he was known as \"the Dandy King\".", "Joachim Murat was born on 25 March 1767 in La Bastide-Fortuni\u00e8re, (renamed Labastide-Murat after its renowned citizen), in Guyenne (present-day Lot department of France) to Pierre Murat-Jordy, (d. 27 July 1799), an affluent farmer and an innkeeper, and his wife Jeanne Loubi\u00e8res (La Bastide Fortuni\u00e8re, b. 1722 \u2013 La Bastide Fortuni\u00e8re, d. 11 March 1806), daughter of Pierre Loubi\u00e8res and of his wife Jeanne Viellescazes."], ["Kingdom of Naples", "After Napoleon's defeat in 1814, Murat reached an agreement with Austria and was allowed to retain the throne of Naples, despite the lobbying efforts of Ferdinand and his supporters.", "However, with most of the other powers, particularly Britain, hostile towards him and dependent on the uncertain support of Austria, Murat's position became less and less secure.", "Therefore, when Napoleon returned to France for the Hundred Days in 1815, Murat once again sided with him.", "Realising the Austrians would soon attempt to remove him, Murat gave the Rimini Proclamation in a hope to save his kingdom by allying himself with Italian nationalists.", "The ensuing Neapolitan War between Murat and the Austrians was short, ending with a decisive victory for the Austrian forces at the Battle of Tolentino.", "Murat was forced to flee, and Ferdinand IV of Sicily was restored to the throne of Naples.", "Murat would attempt to regain his throne but was quickly captured and executed by firing squad in Pizzo, Calabria.", "The next year, 1816, finally saw the formal union of the Kingdom of Naples with the Kingdom of Sicily into the new Kingdom of the Two Sicilies."], ["Kingdom of Naples", "Kingdom of Naples\n\nThe Kingdom of Naples (; ; ; ; ) comprised that part of the Italian Peninsula south of the Papal States between 1282 and 1816.", "It was created as a result of the War of the Sicilian Vespers (1282\u20131302), when the island of Sicily revolted and was conquered by the Crown of Aragon, becoming a separate Kingdom of Sicily.", "Naples continued to be officially known as the Kingdom of Sicily, the name of the formerly unified kingdom.", "For much of its existence, the realm was contested between French and Spanish dynasties.", "In 1816, it was reunified with the island kingdom of Sicily once again to form the Kingdom of the Two Sicilies.", "The name \"Kingdom of Naples\" was not used officially.", "Officially, under the Angevins it was still the Kingdom of Sicily (\"regnum Siciliae\").", "The Peace of Caltabellotta (1302) that ended the War of the Vespers provided that the name of the island kingdom would be Trinacria (\"regnum Trinacriae\").", "This usage did not become established.", "In the late Middle Ages, it was common to distinguish the two kingdoms named Sicily as being on this or that side of the Punta del Faro, i.e., the Strait of Messina."]], "gold": "The Kingdom of Naples, officially known as the Kingdom of Sicily, comprised the part of the Italian Peninsula south of the Papal States between 1282 and 1816. At the beginning of 1815, the ruler of the Kingdom was Joachim-Napol\u00e9on Murat, who had retained the throne through a series of agreements with Austria, with most of the other powers, particularly Britain, hostile towards him, meaning he was dependent on Austrian support. Due to this, he decided to side with Napoleon once he returned to France for the Hundred Days, ensuing a war between Murat and the Austrians that ended with a decisive Austrian victory. Murat was then forced to flee, and Ferdinand IV of Sicily was restored to the throne of Naples by the end of 1815.", "prediction 1": "The Kingdom of Naples was a part of the Italian Peninsula south of the Papal States between 1282 and 1816. It was created as a result of the War of the Sicilian Vespers, when the island of Sicily revolted and was conquered by the Crown of Aragon, becoming a separate Kingdom of Sicily. The next year, 1816, finally saw the formal union of the Kingdom of Naples with the Kingdom of Sicily into the new Kingdom of the Two Sicilies. Joachim-Napol\u00e9on Murat was a Marshal of France and Admiral of France under the reign of Napoleon.\n", "prediction 2": "The Kingdom of Naples was a French colony in Italy that existed mainly in the south of the Papal States between 1282 and 1815. The most recent occupant of the throne was Joachim-Napol\u00e9on Murat, who was Marshal of France and Admiral of France under Napoleon I. Murat's successor, Ferdinand IV, was King of Naples from 1808 until 1815.", "prediction 3": "Joachim-Napol\u00e9on Murat ruled the Kingdom of Naples and Sicily from 1808 to 1815. He was Marshal of France and Admiral of France under the reign of Napoleon I. Thus, Murat ruled from 1815 to 1822 and was also Grand Duke of Berg from 1806 to 1808.", "prediction 4": "The Kingdom of Naples was a part of the Italian Peninsula south of the Papal States from 1282 to 1816, when it was formed as a result of the war of the Sicilian Vespers (1282\u20131302). The first free king of Naples was Joachim Murat, a Marshal of France and Admiral of France under the reign of Napoleon. Joachim Murat was the first King of Naples.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 107, "end": 285}, {"error type": "Irrelevant", "explanation": "", "start": 430, "end": 527}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 2, "sentence_id": [1]}], "corrected-prediction": "The Kingdom of Naples was a part of the Italian Peninsula south of the Papal States between 1282 and 1816. At the beginning of 1815, the ruler of the Kingdom was Joachim-Napol\u00e9on Murat, who had retained the throne through a series of agreements with Austria. However, when Napoleon returned to France for the Hundred Days in 1815, Murat once again sided with him. This led to a war between Murat and the Austrians that ended with a decisive Austrian victory. Murat was then forced to flee, and Ferdinand IV of Sicily was restored to the throne of Naples by the end of 1815. The next year, 1816, finally saw the formal union of the Kingdom of Naples with the Kingdom of Sicily into the new Kingdom of the Two Sicilies."}, "preference": [1, 1, 1, 2, 0, 1], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Joachim Murat\nS1. Joachim Murat  Joachim-Napol\u00e9on Murat (; born Joachim Murat; ; ; 25 March 1767 \u2013 13 October 1815) was a Marshal of France and Admiral of France under the reign of Napoleon.\nS2. He was also the 1st Prince Murat, Grand Duke of Berg from 1806 to 1808, and King of Naples from 1808 to 1815.\nS3. Murat received his titles in part by being Napoleon's brother-in-law through marriage to his younger sister, Caroline Bonaparte, as well as personal merit.\nS4. He was noted as a daring, brave, and charismatic cavalry officer as well as a flamboyant dresser, for which he was known as \"the Dandy King\".\nS5. Joachim Murat was born on 25 March 1767 in La Bastide-Fortuni\u00e8re, (renamed Labastide-Murat after its renowned citizen), in Guyenne (present-day Lot department of France) to Pierre Murat-Jordy, (d. 27 July 1799), an affluent farmer and an innkeeper, and his wife Jeanne Loubi\u00e8res (La Bastide Fortuni\u00e8re, b. 1722 \u2013 La Bastide Fortuni\u00e8re, d. 11 March 1806), daughter of Pierre Loubi\u00e8res and of his wife Jeanne Viellescazes.\n\nPassage 2: Title (S0) - Kingdom of Naples\nS1. After Napoleon's defeat in 1814, Murat reached an agreement with Austria and was allowed to retain the throne of Naples, despite the lobbying efforts of Ferdinand and his supporters.\nS2. However, with most of the other powers, particularly Britain, hostile towards him and dependent on the uncertain support of Austria, Murat's position became less and less secure.\nS3. Therefore, when Napoleon returned to France for the Hundred Days in 1815, Murat once again sided with him.\nS4. Realising the Austrians would soon attempt to remove him, Murat gave the Rimini Proclamation in a hope to save his kingdom by allying himself with Italian nationalists.\nS5. The ensuing Neapolitan War between Murat and the Austrians was short, ending with a decisive victory for the Austrian forces at the Battle of Tolentino.\nS6. Murat was forced to flee, and Ferdinand IV of Sicily was restored to the throne of Naples.\nS7. Murat would attempt to regain his throne but was quickly captured and executed by firing squad in Pizzo, Calabria.\nS8. The next year, 1816, finally saw the formal union of the Kingdom of Naples with the Kingdom of Sicily into the new Kingdom of the Two Sicilies.\n\nPassage 3: Title (S0) - Kingdom of Naples\nS1. Kingdom of Naples  The Kingdom of Naples (; ; ; ; ) comprised that part of the Italian Peninsula south of the Papal States between 1282 and 1816.\nS2. It was created as a result of the War of the Sicilian Vespers (1282\u20131302), when the island of Sicily revolted and was conquered by the Crown of Aragon, becoming a separate Kingdom of Sicily.\nS3. Naples continued to be officially known as the Kingdom of Sicily, the name of the formerly unified kingdom.\nS4. For much of its existence, the realm was contested between French and Spanish dynasties.\nS5. In 1816, it was reunified with the island kingdom of Sicily once again to form the Kingdom of the Two Sicilies.\nS6. The name \"Kingdom of Naples\" was not used officially.\nS7. Officially, under the Angevins it was still the Kingdom of Sicily (\"regnum Siciliae\").\nS8. The Peace of Caltabellotta (1302) that ended the War of the Vespers provided that the name of the island kingdom would be Trinacria (\"regnum Trinacriae\").\nS9. This usage did not become established.\nS10. In the late Middle Ages, it was common to distinguish the two kingdoms named Sicily as being on this or that side of the Punta del Faro, i.e., the Strait of Messina.\n    \nInput Question:\nWho governed the kingdom of naples and sicily 1815?\n\nCorrect Response:\nThe Kingdom of Naples, officially known as the Kingdom of Sicily, comprised the part of the Italian Peninsula south of the Papal States between 1282 and 1816. At the beginning of 1815, the ruler of the Kingdom was Joachim-Napol\u00e9on Murat, who had retained the throne through a series of agreements with Austria, with most of the other powers, particularly Britain, hostile towards him, meaning he was dependent on Austrian support. Due to this, he decided to side with Napoleon once he returned to France for the Hundred Days, ensuing a war between Murat and the Austrians that ended with a decisive Austrian victory. Murat was then forced to flee, and Ferdinand IV of Sicily was restored to the throne of Naples by the end of 1815.\n\nModel Prediction:\nThe Kingdom of Naples was a part of the Italian Peninsula south of the Papal States between 1282 and 1816. It was created as a result of the War of the Sicilian Vespers, when the island of Sicily revolted and was conquered by the Crown of Aragon, becoming a separate Kingdom of Sicily. The next year, 1816, finally saw the formal union of the Kingdom of Naples with the Kingdom of Sicily into the new Kingdom of the Two Sicilies. Joachim-Napol\u00e9on Murat was a Marshal of France and Admiral of France under the reign of Napoleon.\n\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "The Kingdom of Naples was a part of the Italian Peninsula south of the Papal States between 1282 and 1816. [It was created as a result of the War of the Sicilian Vespers, when the island of Sicily revolted and was conquered by the Crown of Aragon, becoming a separate Kingdom of Sicily.] The next year, 1816, finally saw the formal union of the Kingdom of Naples with the Kingdom of Sicily into the new Kingdom of the Two Sicilies. [Joachim-Napol\u00e9on Murat was a Marshal of France and Admiral of France under the reign of Napoleon.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". \n2. The last sentence is also irrelevant as it does not provide any information about who governed the Kingdom of Naples and Sicily in 1815."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The Kingdom of Naples was a part of the Italian Peninsula south of the Papal States between 1282 and 1816.\nS2. It was created as a result of the War of the Sicilian Vespers, when the island of Sicily revolted and was conquered by the Crown of Aragon, becoming a separate Kingdom of Sicily.\nS3. The next year, 1816, finally saw the formal union of the Kingdom of Naples with the Kingdom of Sicily into the new Kingdom of the Two Sicilies.\nS4. Joachim-Napol\u00e9on Murat was a Marshal of France and Admiral of France under the reign of Napoleon.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation:\nAll the facts presented in the model prediction are consistent with the information provided in the passages."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 2, sentence 1 [Missing Answer]\n2. Passage 2, sentence 3 [Missing Answer]\n3. Passage 2, sentence 5 [Missing Answer]\n4. Passage 2, sentence 6 [Missing Answer]\n5. Passage 2, sentence 7 [Missing Answer]\n\nExplanation:\n1. The model prediction does not mention that after Napoleon's defeat in 1814, Murat reached an agreement with Austria and was allowed to retain the throne of Naples, despite the lobbying efforts of Ferdinand and his supporters.\n2. The model prediction does not mention that when Napoleon returned to France for the Hundred Days in 1815, Murat once again sided with him.\n3. The model prediction does not mention that the ensuing Neapolitan War between Murat and the Austrians was short, ending with a decisive victory for the Austrian forces at the Battle of Tolentino.\n4. The model prediction does not mention that Murat was forced to flee, and Ferdinand IV of Sicily was restored to the throne of Naples.\n5. The model prediction does not mention that Murat would attempt to regain his throne but was quickly captured and executed by firing squad in Pizzo, Calabria."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The Kingdom of Naples was a part of the Italian Peninsula south of the Papal States between 1282 and 1816. At the beginning of 1815, the ruler of the Kingdom was Joachim-Napol\u00e9on Murat, who had retained the throne through a series of agreements with Austria. However, when Napoleon returned to France for the Hundred Days in 1815, Murat once again sided with him. This led to a war between Murat and the Austrians that ended with a decisive Austrian victory. Murat was then forced to flee, and Ferdinand IV of Sicily was restored to the throne of Naples by the end of 1815. The next year, 1816, finally saw the formal union of the Kingdom of Naples with the Kingdom of Sicily into the new Kingdom of the Two Sicilies."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 107, "end": 285}, {"error type": "Irrelevant", "explanation": "", "start": 286, "end": 429}, {"error type": "Irrelevant", "explanation": "", "start": 457, "end": 528}], "missing-info": [{"error type": "Missing-Minor-Auxiliary", "passage_id": 3, "sentence_id": [3]}, {"error type": "Missing-Answer", "passage_id": 1, "sentence_id": [2]}, {"error type": "Missing-Major-Auxiliary", "passage_id": 2, "sentence_id": [1, 2]}, {"error type": "Missing-Major-Auxiliary", "passage_id": 2, "sentence_id": [3, 5, 6]}], "corrected-prediction": "The Kingdom of Naples was a part of the Italian Peninsula south of the Papal States between 1282 and 1816. It was officially known as the Kingdom of Sicily. Joachim-Napol\u00e9on Murat was the King of Naples from 1808 to 1815. Murat reached an agreement with Austria and was allowed to retain the throne of Naples. However, most of the other powers, particularly Britain, were hostile towards him, making him dependent on Austria's support. When Napoleon returned to France for the Hundred Days in 1815, Murat once again sided with him. The ensuing Neapolitan War between Murat and the Austrians was short, ending with a decisive victory for the Austrian forces. Murat was forced to flee, and Ferdinand IV of Sicily was restored to the throne of Naples.\n"}}, {"question": "When did the stock market crash in 2008?", "passages": [["Financial crisis of 2007\u20132008", "According to David Brooks from the New York Times, \"Taleb not only has an explanation for what's happening, he saw it coming.\"", "A report by the International Labour Organization concluded that cooperative financial institutions were less likely to fail than their competitors during the crisis.", "The cooperative banking sector had 20% market share of the European banking sector, but accounted for only 7 per cent of all the write-downs and losses between the third quarter of 2007 and first quarter of 2011.", "Similarly, credit unions in the US had five times lower failure rate than other banks during the crisis and increased their lending to small- and medium sized businesses while overall lending to those businesses decreased.", "The US stock market peaked in October 2007, when the Dow Jones Industrial Average index exceeded 14,000 points.", "It then entered a pronounced decline, which accelerated markedly in October 2008.", "By March 2009, the Dow Jones average had reached a trough of around 6,600.", "Four years later,\nit hit an all-time high.", "It is probable, but debated, that the Federal Reserve's aggressive policy of quantitative easing spurred the partial recovery in the stock market.", "Market strategist Phil Dow believes distinctions exist \"between the current market malaise\" and the Great Depression."], ["Stock market crash", "On October 11, 2008, the head of the International Monetary Fund (IMF) warned that the world financial system was teetering on the \"brink of systemic meltdown\".", "The economic crisis caused countries to close their markets temporarily.", "On October 8, the Indonesian stock market halted trading, after a 10% drop in one day.", "\"The Times\" of London reported that the meltdown was being called the \"Crash of 2008\", and older traders were comparing it with Black Monday in 1987.", "The fall that week of 21% compared to a 28.3% fall 21 years earlier, but some traders were saying it was worse.", "\"At least then it was a short, sharp, shock on one day.", "This has been relentless all week.\"", "Business Week also referred to the crisis as a \"stock market crash\" or the \"Panic of 2008\".", "From October 6\u201310 the Dow Jones Industrial Average (DJIA) closed lower in all five sessions.", "Volume levels were record-breaking.", "The DJIA fell over 1,874 points, or 18%, in its worst weekly decline ever on both a points and percentage basis.", "The S&P 500 fell more than 20%.", "The week also set 3 top ten NYSE Group Volume Records with October 8 at #5, October 9 at #10, and October 10 at #1."], ["2008\u20132011 Icelandic financial crisis", "The decision was made to do so due to \"unusual market conditions\", with share prices having fallen 30% since the start of the month.", "The closure was extended through Monday 13 October due to continuing \"unusual market conditions\".", "The market reopened on 14 October with the main index, the OMX Iceland 15, at 678.4, which corresponds to a plunge of about 77% compared with 3,004.6 before the closure.", "This reflects the fact that the value of the three big banks, which form 73.2% of the value of the OMX Iceland 15, had been set to zero.", "The values of other equities varied from +8% to \u221215%.", "Trading in shares of Exista, SPRON and Straumur-Bur\u00f0ar\u00e1s (13.66% of the OMX Iceland 15) remains suspended.", "After a week of very thin trading, the OMX Iceland 15 closed on 17 October at 643.1, down 93% in kr\u00f3na terms and 96% in euro terms from its historic high of 9016 (18 July 2007).", "Trading in the shares of two financial services companies, Straumur\u2013Bur\u00f0ar\u00e1s and Exista, resumed on 9 December: together the companies account for 12.04% of the OMX Iceland 15."]], "gold": "The stock market crash of 2008, considered by many economists to have been one of the most serious financial crises of the last century, began in October 2008 following the collapse of several American and European financial institutions. This resulted in sharp reductions in the value of stocks and commodities worldwide. As a result, the Icelandic stock market suspended trading on 6 October, and the Indonesian stock market followed on October 8.", "prediction 1": "The stock market crashed on October 11, 2008, when the head of the International Monetary Fund warned that the world financial system was teetering on the \"brink of systemic meltdown\". The Icelandic stock market closed temporarily on October 8 and reopened on 14 October.", "prediction 2": "In the United States the stock market crashed on October 11, 2008, which coincided with the global financial crisis. In Iceland, the stock market crashed on October 14 and was reopened on 14 October, but was shut down for a further two weeks. In Indonesia, the stock market crashed on October 8 and October 9.", "prediction 3": "Stock market crashed in Iceland on October 11, 2008, after the head of the International Monetary Fund warned that the world financial system was teetering on the edge of a systemic meltdown.", "prediction 4": "The US stock market peaked in October 2007, when the Dow Jones Industrial Average index exceeded 14,000 points. Then entered a pronounced decline, which accelerated markedly in October 2008. By March 2009, the Dow Jones average had reached a trough of around 6,600. Four years later, it hit an all-time high. In Iceland on October 8, the stock market halted trading, after a 10% drop in one day.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 185, "end": 271}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [5]}], "corrected-prediction": "The stock market crash of 2008 began in October when the Dow Jones Industrial Average entered a pronounced decline, which accelerated markedly. From October 6\u201310, the Dow Jones Industrial Average closed lower in all five sessions, culminating in the worst weekly decline ever on both a points and percentage basis. By March 2009, the Dow Jones average had reached a trough of around 6,600."}, "preference": [1, 1, 1, 1, 1, 1], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Financial crisis of 2007\u20132008\nS1. According to David Brooks from the New York Times, \"Taleb not only has an explanation for what's happening, he saw it coming.\"\nS2. A report by the International Labour Organization concluded that cooperative financial institutions were less likely to fail than their competitors during the crisis.\nS3. The cooperative banking sector had 20% market share of the European banking sector, but accounted for only 7 per cent of all the write-downs and losses between the third quarter of 2007 and first quarter of 2011.\nS4. Similarly, credit unions in the US had five times lower failure rate than other banks during the crisis and increased their lending to small- and medium sized businesses while overall lending to those businesses decreased.\nS5. The US stock market peaked in October 2007, when the Dow Jones Industrial Average index exceeded 14,000 points.\nS6. It then entered a pronounced decline, which accelerated markedly in October 2008.\nS7. By March 2009, the Dow Jones average had reached a trough of around 6,600.\nS8. Four years later, it hit an all-time high.\nS9. It is probable, but debated, that the Federal Reserve's aggressive policy of quantitative easing spurred the partial recovery in the stock market.\nS10. Market strategist Phil Dow believes distinctions exist \"between the current market malaise\" and the Great Depression.\n\nPassage 2: Title (S0) - Stock market crash\nS1. On October 11, 2008, the head of the International Monetary Fund (IMF) warned that the world financial system was teetering on the \"brink of systemic meltdown\".\nS2. The economic crisis caused countries to close their markets temporarily.\nS3. On October 8, the Indonesian stock market halted trading, after a 10% drop in one day.\nS4. \"The Times\" of London reported that the meltdown was being called the \"Crash of 2008\", and older traders were comparing it with Black Monday in 1987.\nS5. The fall that week of 21% compared to a 28.3% fall 21 years earlier, but some traders were saying it was worse.\nS6. \"At least then it was a short, sharp, shock on one day.\nS7. This has been relentless all week.\"\nS8. Business Week also referred to the crisis as a \"stock market crash\" or the \"Panic of 2008\".\nS9. From October 6\u201310 the Dow Jones Industrial Average (DJIA) closed lower in all five sessions.\nS10. Volume levels were record-breaking.\nS11. The DJIA fell over 1,874 points, or 18%, in its worst weekly decline ever on both a points and percentage basis.\nS12. The S&P 500 fell more than 20%.\nS13. The week also set 3 top ten NYSE Group Volume Records with October 8 at #5, October 9 at #10, and October 10 at #1.\n\nPassage 3: Title (S0) - 2008\u20132011 Icelandic financial crisis\nS1. The decision was made to do so due to \"unusual market conditions\", with share prices having fallen 30% since the start of the month.\nS2. The closure was extended through Monday 13 October due to continuing \"unusual market conditions\".\nS3. The market reopened on 14 October with the main index, the OMX Iceland 15, at 678.4, which corresponds to a plunge of about 77% compared with 3,004.6 before the closure.\nS4. This reflects the fact that the value of the three big banks, which form 73.2% of the value of the OMX Iceland 15, had been set to zero.\nS5. The values of other equities varied from +8% to \u221215%.\nS6. Trading in shares of Exista, SPRON and Straumur-Bur\u00f0ar\u00e1s (13.66% of the OMX Iceland 15) remains suspended.\nS7. After a week of very thin trading, the OMX Iceland 15 closed on 17 October at 643.1, down 93% in kr\u00f3na terms and 96% in euro terms from its historic high of 9016 (18 July 2007).\nS8. Trading in the shares of two financial services companies, Straumur\u2013Bur\u00f0ar\u00e1s and Exista, resumed on 9 December: together the companies account for 12.04% of the OMX Iceland 15.\n    \nInput Question:\nWhen did the stock market crash in 2008?\n\nCorrect Response:\nThe stock market crash of 2008, considered by many economists to have been one of the most serious financial crises of the last century, began in October 2008 following the collapse of several American and European financial institutions. This resulted in sharp reductions in the value of stocks and commodities worldwide. As a result, the Icelandic stock market suspended trading on 6 October, and the Indonesian stock market followed on October 8.\n\nModel Prediction:\nThe stock market crashed on October 11, 2008, when the head of the International Monetary Fund warned that the world financial system was teetering on the \"brink of systemic meltdown\". The Icelandic stock market closed temporarily on October 8 and reopened on 14 October.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "The stock market crashed on October 11, 2008, when the head of the International Monetary Fund warned that the world financial system was teetering on the \"brink of systemic meltdown\". [The Icelandic stock market closed temporarily on October 8 and reopened on 14 October.]\n\nExplanation:\nThe information about the Icelandic stock market closing temporarily is irrelevant to the question about when the stock market crashed in 2008. The question is asking for a general date of the crash, not specific events in individual countries. Therefore, the last sentence should be marked as \"Irrelevant\"."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The stock market crashed on October 11, 2008, when the head of the International Monetary Fund warned that the world financial system was teetering on the \"brink of systemic meltdown\".\nS2. The Icelandic stock market closed temporarily on October 8 and reopened on 14 October.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "S1\n\nExplanation:\nThe first sentence of the model prediction is factually inconsistent with the passages. According to Passage 2, sentence 3, the Indonesian stock market halted trading after a 10% drop in one day on October 8, 2008. This suggests that the stock market crash had already begun by October 8, 2008, not on October 11, 2008 as stated in the model prediction. Therefore, \"October 11, 2008\" in the first sentence is an \"Inconsistent Fact\"."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 5 [Missing Major Auxiliary Information]\n2. Passage 1, sentence 6 [Missing Major Auxiliary Information]\n3. Passage 1, sentence 7 [Missing Major Auxiliary Information]\n4. Passage 2, sentence 9 [Missing Major Auxiliary Information]\n5. Passage 2, sentence 11 [Missing Major Auxiliary Information]\n\nExplanation:\n1. The model prediction fails to mention that the US stock market peaked in October 2007, when the Dow Jones Industrial Average index exceeded 14,000 points (Passage 1, sentence 5). This is crucial information that provides context to the crash in 2008.\n2. The model prediction also omits the fact that the US stock market entered a pronounced decline, which accelerated markedly in October 2008 (Passage 1, sentence 6). This is a key piece of information that directly answers the question.\n3. The model prediction does not include the information that by March 2009, the Dow Jones average had reached a trough of around 6,600 (Passage 1, sentence 7). This information is important as it shows the extent of the crash.\n4. The model prediction does not mention that from October 6\u201310 the Dow Jones Industrial Average (DJIA) closed lower in all five sessions (Passage 2, sentence 9). This is a significant detail that provides a more accurate timeline of the crash.\n5. The model prediction fails to mention that the DJIA fell over 1,874 points, or 18%, in its worst weekly decline ever on both a points and percentage basis (Passage 2, sentence 11). This information is crucial as it illustrates the severity of the crash."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The stock market crash of 2008 began in October when the Dow Jones Industrial Average entered a pronounced decline, which accelerated markedly. From October 6\u201310, the Dow Jones Industrial Average closed lower in all five sessions, culminating in the worst weekly decline ever on both a points and percentage basis. By March 2009, the Dow Jones average had reached a trough of around 6,600."}], "feedback_human": {"errors": [{"error type": "Wrong-Grounding", "explanation": "{\"passage_id\":2,\"sentence_id\":[3]}", "start": 248, "end": 271}, {"error type": "Irrelevant", "explanation": "", "start": 46, "end": 184}, {"error type": "Wrong-Grounding", "explanation": "{\"passage_id\":2,\"sentence_id\":[3]}", "start": 189, "end": 198}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 2, "sentence_id": [2]}], "corrected-prediction": "The stock market crashed on October 11, 2008,  economic crisis caused countries to close their markets temporarily. The Indonesian stock market closed temporarily on October 8."}}, {"question": "Who dies in guardians of the galexy 2?", "passages": [["Guardians of the Galaxy Vol. 2", "Ayesha, leader of the Sovereign race, has the Guardians protect valuable batteries from an inter-dimensional monster in exchange for Gamora's estranged sister Nebula, who was caught attempting to steal the batteries.", "After Rocket steals some for himself, the Sovereign attacks the Guardians' ship with a fleet of drones.", "These are destroyed by a mysterious figure, and the Guardians crash-land on a nearby planet.", "There, this figure reveals himself as Quill's father, Ego, and invites Quill, Gamora, and Drax to his home planet.", "Rocket and Groot remain behind to repair the ship and guard Nebula.", "Ayesha hires Yondu Udonta and his crew, who have been exiled from the greater Ravager community for child trafficking, to recapture the Guardians.", "They capture Rocket, but when Yondu hesitates to turn over Quill, whom he raised, his lieutenant Taserface leads a mutiny with help from Nebula.", "Taserface imprisons Rocket and Yondu aboard the latter's ship and executes his loyalists by releasing them into space.", "Nebula leaves to find and kill Gamora, whom she blames for the torture inflicted on her by their father, Thanos.", "While imprisoned, Rocket and Yondu bond."], ["Guardians of the Galaxy Vol. 2", "The Guardians hold a funeral for Yondu, which is attended by Kraglin and dozens of Ravager ships, acknowledging Yondu's sacrifice and accepting him as a Ravager again.", "In a series of mid- and post-credit scenes, Kraglin takes up Yondu's telekinetic arrow and control-fin; Ravager leader Stakar Ogord reunites with his ex-teammates; Groot has grown into a teenager; Ayesha creates a new artificial being with whom she plans to destroy the Guardians, naming him Adam; and a group of uninterested Watchers abandon their informant, who is discussing his experiences on Earth.", "Additionally, reprising their roles from the first film are Laura Haddock as Meredith Quill, Gregg Henry as her father, Seth Green as the voice of Howard the Duck, and canine actor Fred as Cosmo."]], "gold": "There are several deaths in Guardians of the Galaxy 2. Taserface warns the Soverign and dies. Ego dies due to a bomb blast, and Yondu Udonta dies after sacrificing himself to save Quill.", "prediction 1": "In Guardians of the Galaxy Vol. 2, Ego dies after he is shot by a drone, and Yondu dies after he is shot by Taserface.", "prediction 2": "In Guardians of the Galaxy Vol. 2, Yondu Udonta dies. The Guardians hold a funeral for him, attended by Kraglin and dozens of Ravager ships, acknowledging his sacrifice and accepting him as a Ravager again.", "prediction 3": "Yondu dies in Guardians of the Galaxy Vol. 2 after being beaten to death by Taserface, a mutiny leader who has been imprisoned for child trafficking.", "prediction 4": "In the second Guardian of the Galaxy film, Gamora's estranged sister Nebula dies. Gamora's father Ego dies in the film. Yondu Udonta dies in the film, as does Rocket Udonta.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 35, "end": 71}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 1, "sentence_id": [8]}], "corrected-prediction": "In Guardians of the Galaxy Vol. 2, Yondu Udonta dies after sacrificing himself to save Quill. Taserface also dies after warning the Sovereign. The cause of Ego's death is not specified in the provided passages."}, "preference": [2, 2, 2, 1, 1, 2], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Guardians of the Galaxy Vol. 2\nS1. Ayesha, leader of the Sovereign race, has the Guardians protect valuable batteries from an inter-dimensional monster in exchange for Gamora's estranged sister Nebula, who was caught attempting to steal the batteries.\nS2. After Rocket steals some for himself, the Sovereign attacks the Guardians' ship with a fleet of drones.\nS3. These are destroyed by a mysterious figure, and the Guardians crash-land on a nearby planet.\nS4. There, this figure reveals himself as Quill's father, Ego, and invites Quill, Gamora, and Drax to his home planet.\nS5. Rocket and Groot remain behind to repair the ship and guard Nebula.\nS6. Ayesha hires Yondu Udonta and his crew, who have been exiled from the greater Ravager community for child trafficking, to recapture the Guardians.\nS7. They capture Rocket, but when Yondu hesitates to turn over Quill, whom he raised, his lieutenant Taserface leads a mutiny with help from Nebula.\nS8. Taserface imprisons Rocket and Yondu aboard the latter's ship and executes his loyalists by releasing them into space.\nS9. Nebula leaves to find and kill Gamora, whom she blames for the torture inflicted on her by their father, Thanos.\nS10. While imprisoned, Rocket and Yondu bond.\n\nPassage 2: Title (S0) - Guardians of the Galaxy Vol. 2\nS1. The Guardians hold a funeral for Yondu, which is attended by Kraglin and dozens of Ravager ships, acknowledging Yondu's sacrifice and accepting him as a Ravager again.\nS2. In a series of mid- and post-credit scenes, Kraglin takes up Yondu's telekinetic arrow and control-fin; Ravager leader Stakar Ogord reunites with his ex-teammates; Groot has grown into a teenager; Ayesha creates a new artificial being with whom she plans to destroy the Guardians, naming him Adam; and a group of uninterested Watchers abandon their informant, who is discussing his experiences on Earth.\nS3. Additionally, reprising their roles from the first film are Laura Haddock as Meredith Quill, Gregg Henry as her father, Seth Green as the voice of Howard the Duck, and canine actor Fred as Cosmo.\n    \nInput Question:\nWho dies in guardians of the galexy 2?\n\nCorrect Response:\nThere are several deaths in Guardians of the Galaxy 2. Taserface warns the Soverign and dies. Ego dies due to a bomb blast, and Yondu Udonta dies after sacrificing himself to save Quill.\n\nModel Prediction:\nIn Guardians of the Galaxy Vol. 2, Ego dies after he is shot by a drone, and Yondu dies after he is shot by Taserface.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "In Guardians of the Galaxy Vol. 2, [Ego dies after he is shot by a drone], and Yondu dies after he is shot by Taserface.\n\nExplanation:\n1. The information about Ego's death in the model prediction is incorrect according to the passages. Ego's cause of death is not mentioned in the passages, making this information irrelevant."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. In Guardians of the Galaxy Vol.\nS2. 2, Ego dies after he is shot by a drone, and Yondu dies after he is shot by Taserface.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "S1. In Guardians of the Galaxy Vol.\nS2. 2, Ego dies after he is shot by a drone, and Yondu dies after he is shot by Taserface.\n\nInconsistent or Unverifiable Sentences:\n1. S2"}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 8 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Answer]\n\nExplanation:\n1. The model prediction does not mention Taserface's death, which is mentioned in Passage 1, sentence 8.\n2. The model prediction does not accurately describe Yondu's death as a sacrifice, which is mentioned in Passage 2, sentence 1."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "In Guardians of the Galaxy Vol. 2, Yondu Udonta dies after sacrificing himself to save Quill. Taserface also dies after warning the Sovereign. The cause of Ego's death is not specified in the provided passages."}], "feedback_human": {"errors": [{"error type": "Unverifiable", "explanation": "", "start": 35, "end": 72}], "missing-info": [], "corrected-prediction": "In Guardians of the Galaxy Vol. 2, Yondu dies after he is shot by Taserface."}}, {"question": "When did singer start making electric sewing machines?", "passages": [["Singer Corporation", "In 1885, Singer produced its first \"vibrating shuttle\" sewing machine, an improvement over contemporary transverse shuttle designs; (see bobbin drivers).", "Singer began to market its machines internationally in 1855 and won first prize at the Paris World's Fair.", "The company demonstrated the first workable electric sewing machine at the Philadelphia electric exhibition in 1889 and began mass-producing domestic electric machines in 1910.", "Singer was also a marketing innovator and was a pioneer in promoting the use of installment payment plans.", "Source:\n\nBy 1876, Singer was claiming cumulative sales of 2 million machines and displaying the 2 millionth in Philadelphia.", "In 1867, the Singer Company decided that the demand for their sewing machines in the UK was sufficiently high to open a local factory in Glasgow on John Street.", "Glasgow was selected for its iron making industries, cheap labour and possibly because at the time the General Manager of the US Singer Manufacturing Company was George McKenzie, who was of Scottish descent.", "Demand for sewing machines outstripped production at the new plant and by 1873, a new larger factory was completed on James Street, Bridgeton.", "By now, Singer employed over 2,000 people in Scotland, but they still could not produce enough machines.", "In 1882, George McKenzie, now President-elect of the Singer Manufacturing Company, undertook the ground breaking ceremony on 46 acres of farmland at Kilbowie, Clydebank."], ["Singer Corporation", "Singer Corporation\n\nSinger Corporation is an American manufacturer of sewing machines, first established as I. M. Singer & Co. in 1851 by Isaac Merritt Singer with New York lawyer Edward Clark.", "Best known for its sewing machines, it was renamed Singer Manufacturing Company in 1865, then The Singer Company in 1963.", "It is based in La Vergne, Tennessee, near Nashville.", "Its first large factory for mass production was built in Elizabeth, New Jersey, in 1863.", "Singer's original design, which was the first practical sewing machine for general domestic use, incorporated the basic eye-pointed needle and lock stitch developed by Elias Howe, who won a patent-infringement suit against Singer in 1854.", "Patent No. 8294, of August 12, 1851, introduced one of the most useful machines, and one of the most remarkable men, that have figured in the development of the sewing machine.", "Isaac Merritt Singer, strolling player, theater manager, inventor, and millionaire, brought into the business a new machine and novel methods of exploitation, which gave a powerful impulse to the youthful industry.", "The Singer improvements met the demand of the tailoring, and leather industries for a heavier and more powerful machine.", "Singer consolidated enough patents in the field to enable him to engage in mass production, and by 1860, his company was the largest manufacturer of sewing machines in the world."]], "gold": "The original Singer sewing machine was the first for general domestic use. The company introduced the first workable electric sewing machine at the Philadelphia electric exhibition in 1889.  The machines were massed produced staring in 1910.", "prediction 1": "Singer began making domestic electric sewing machines in 1910, starting with the demonstration of the first workable electric sewing machine at the Philadelphia electric exhibition. In 1867, the Singer Company decided that the demand for their sewing machines in the UK was sufficiently high to open a local factory in Glasgow on John Street. Demand for sewing machines outstripped production at the new plant and by 1873, a new larger factory for mass production was built in Elizabeth, New Jersey, in 1863.", "prediction 2": "Singer Corporation is an American manufacturer of sewing machines, first established as I. M. Singer & Co. in 1851 by Isaac Merritt Singer with New York lawyer Edward Clark. The company demonstrated the first workable electric sewing machine at the Philadelphia Electric Exhibition in 1889 and began mass-producing domestic electric machines in 1910. Singer began to market its machines internationally in 1855 and won first prize at the Paris World's Fair. The company began mass-producing domestic electric machines in 1910.", "prediction 3": "Singer Corporation is an American manufacturer of sewing machines, first established as I. M. Singer & Co. in 1851 by Isaac Merritt Singer with New York lawyer Edward Clark. In 1889, the company demonstrated the first workable electric sewing machine at the Philadelphia electric exhibition and began mass-producing domestic electric machines in 1910. Singer began marketing its machines internationally in 1855 and won first prize at the Paris World's Fair. In 1867, the Singer Company decided that the demand for their sewing machines in the UK was sufficiently high to open a local factory in Glasgow on John Street. In 1873, a new larger factory was completed on James Street, Bridgeton, Bridgeton. In 1873, a new larger factory was completed on James Street, Bridgeton.", "prediction 4": "Singer Corporation is an American manufacturer of sewing machines, first established as I. M. Singer & Co. in 1851 by Isaac Merritt Singer with New York lawyer Edward Clark. Singer began marketing its machines internationally in 1855 and won first prize at the Paris World's Fair. In 1889, the company demonstrated the first workable electric sewing machine at the Philadelphia electric exhibition and began mass-producing domestic electric machines in 1910.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 182, "end": 508}], "missing-info": [], "corrected-prediction": "Singer began making domestic electric sewing machines in 1910, starting with the demonstration of the first workable electric sewing machine at the Philadelphia electric exhibition."}, "preference": [1, 1, 1, 1, 2, 2], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Singer Corporation\nS1. In 1885, Singer produced its first \"vibrating shuttle\" sewing machine, an improvement over contemporary transverse shuttle designs; (see bobbin drivers).\nS2. Singer began to market its machines internationally in 1855 and won first prize at the Paris World's Fair.\nS3. The company demonstrated the first workable electric sewing machine at the Philadelphia electric exhibition in 1889 and began mass-producing domestic electric machines in 1910.\nS4. Singer was also a marketing innovator and was a pioneer in promoting the use of installment payment plans.\nS5. Source:  By 1876, Singer was claiming cumulative sales of 2 million machines and displaying the 2 millionth in Philadelphia.\nS6. In 1867, the Singer Company decided that the demand for their sewing machines in the UK was sufficiently high to open a local factory in Glasgow on John Street.\nS7. Glasgow was selected for its iron making industries, cheap labour and possibly because at the time the General Manager of the US Singer Manufacturing Company was George McKenzie, who was of Scottish descent.\nS8. Demand for sewing machines outstripped production at the new plant and by 1873, a new larger factory was completed on James Street, Bridgeton.\nS9. By now, Singer employed over 2,000 people in Scotland, but they still could not produce enough machines.\nS10. In 1882, George McKenzie, now President-elect of the Singer Manufacturing Company, undertook the ground breaking ceremony on 46 acres of farmland at Kilbowie, Clydebank.\n\nPassage 2: Title (S0) - Singer Corporation\nS1. Singer Corporation  Singer Corporation is an American manufacturer of sewing machines, first established as I. M. Singer & Co. in 1851 by Isaac Merritt Singer with New York lawyer Edward Clark.\nS2. Best known for its sewing machines, it was renamed Singer Manufacturing Company in 1865, then The Singer Company in 1963.\nS3. It is based in La Vergne, Tennessee, near Nashville.\nS4. Its first large factory for mass production was built in Elizabeth, New Jersey, in 1863.\nS5. Singer's original design, which was the first practical sewing machine for general domestic use, incorporated the basic eye-pointed needle and lock stitch developed by Elias Howe, who won a patent-infringement suit against Singer in 1854.\nS6. Patent No. 8294, of August 12, 1851, introduced one of the most useful machines, and one of the most remarkable men, that have figured in the development of the sewing machine.\nS7. Isaac Merritt Singer, strolling player, theater manager, inventor, and millionaire, brought into the business a new machine and novel methods of exploitation, which gave a powerful impulse to the youthful industry.\nS8. The Singer improvements met the demand of the tailoring, and leather industries for a heavier and more powerful machine.\nS9. Singer consolidated enough patents in the field to enable him to engage in mass production, and by 1860, his company was the largest manufacturer of sewing machines in the world.\n    \nInput Question:\nWhen did singer start making electric sewing machines?\n\nCorrect Response:\nThe original Singer sewing machine was the first for general domestic use. The company introduced the first workable electric sewing machine at the Philadelphia electric exhibition in 1889.  The machines were massed produced staring in 1910.\n\nModel Prediction:\nSinger began making domestic electric sewing machines in 1910, starting with the demonstration of the first workable electric sewing machine at the Philadelphia electric exhibition. In 1867, the Singer Company decided that the demand for their sewing machines in the UK was sufficiently high to open a local factory in Glasgow on John Street. Demand for sewing machines outstripped production at the new plant and by 1873, a new larger factory for mass production was built in Elizabeth, New Jersey, in 1863.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "Singer began making domestic electric sewing machines in 1910, starting with the demonstration of the first workable electric sewing machine at the Philadelphia electric exhibition. [In 1867, the Singer Company decided that the demand for their sewing machines in the UK was sufficiently high to open a local factory in Glasgow on John Street. Demand for sewing machines outstripped production at the new plant and by 1873, a new larger factory for mass production was built in Elizabeth, New Jersey, in 1863.]\n\nExplanation:\nThe information about the Singer Company opening a factory in Glasgow and the demand for their sewing machines outstripping production is irrelevant to the question about when Singer started making electric sewing machines. Similarly, the information about a new larger factory for mass production being built in Elizabeth, New Jersey, in 1863 is also irrelevant. Therefore, these parts of the model prediction should be marked as \"Irrelevant\"."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. Singer began making domestic electric sewing machines in 1910, starting with the demonstration of the first workable electric sewing machine at the Philadelphia electric exhibition.\nS2. In 1867, the Singer Company decided that the demand for their sewing machines in the UK was sufficiently high to open a local factory in Glasgow on John Street.\nS3. Demand for sewing machines outstripped production at the new plant and by 1873, a new larger factory for mass production was built in Elizabeth, New Jersey, in 1863.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation:\nAll the factual information in the model prediction is consistent with the passages and can be verified. Therefore, there are no sentences that contain inconsistent or unverifiable facts."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "None\n\nExplanation:\nThe model prediction includes all the necessary information to answer the question about when Singer started making electric sewing machines. It correctly states that Singer began making domestic electric sewing machines in 1910, starting with the demonstration of the first workable electric sewing machine at the Philadelphia electric exhibition. Therefore, there is no missing information in the model prediction."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "Singer began making domestic electric sewing machines in 1910, starting with the demonstration of the first workable electric sewing machine at the Philadelphia electric exhibition."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 182, "end": 342}, {"error type": "Irrelevant", "explanation": "", "start": 343, "end": 508}], "missing-info": [{"error type": "Missing-Minor-Auxiliary", "passage_id": 1, "sentence_id": [3]}, {"error type": "Missing-Minor-Auxiliary", "passage_id": 2, "sentence_id": [5]}], "corrected-prediction": "Singer's original design, which was the first practical sewing machine for general domestic use. Singer began mass-producing domestic electric sewing machines in 1910, starting with the demonstration of the first workable electric sewing machine at the Philadelphia electric exhibition, in 1889. "}}, {"question": "Which country has lost the most matches in the world cup?", "passages": [["FIFA Club World Cup records and statistics", "Wael Gomaa, Hossam Ashour and Mohamed Aboutrika have the record number of matches played in the FIFA Club World Cup, taking part in 11 matches.", "The following is a list of the top ten clubs with the most points gained in the FIFA Club World Cup.", "The clubs are primarily ranked by their points gained, on a basis of three points for a win, one for a draw and no point for a loss.", "\"After 2017 tournament.\""], ["Ghana national under-17 football team", "Squad that played in the 2013 African U-17 Championship from 13 \u2013 27 April 2013.", "\"*Draws include knockout matches decided on penalty kicks.\"", "FIFA U-17 World Cup Record by team\n\n\"*Denotes draws including the 1991 & 1999 Semi-Final matches decided on penalty kicks v Qatar (4-2p) & Brazil (2-4p).\"", "Africa U-17 Cup of Nations Record by team\n\n\"*Denotes draws including the 2017 Semi-Final match decided on penalty kicks v Niger (6-5p).\"", "CAF U-16 and U-17 World Cup Qualifiers record by team\n\n", "The following list consist of previous Ghana U-17 national team players who have won or were influential at the FIFA U-17 World Cup with the Ghana U-17 national team or the FIFA U-20 World Cup with the Ghana U-20 national team, and those who were part of the Ghana U-23 national team that won the Bronze medal at the 1992 Summer Olympics.", "The list also includes the players who have graduated from the Ghana U-20 national team and gone on to represent the senior Ghana national team at the FIFA World Cup or African Cup of Nations:"], ["History of the France national football team", "They were victors in the second match defeating Mexico 3\u20132, but were unable to advance to the next round due to their head-to-head result with Yugoslavia, who advanced.", "Following the World Cup, France went on an eight-match unbeaten streak defeating the likes of Germany, Spain, England, and Sweden.", "The consistent play from the team led to the team again cruising through qualification for the 1958 FIFA World Cup in Sweden.", "France, for the second consecutive qualification, went undefeated scoring 19 goals and conceding only 4.", "Of the 19 goals scored, Racing de France striker Thad\u00e9e Cisowski scored seven including five in the 6\u20133 defeat of Belgium.", "At the 1958 World Cup, the team finished in third place.", "In the group stage, France again faced Yugoslavia, but were given unfamiliar opposition in Paraguay and Scotland.", "In the opening match against Paraguay, France got a 7\u20133 victory, with Reims striker Just Fontaine getting a hat trick.", "In the match against Yugoslavia, they were defeated 2\u20133 with Fontaine scoring both of his team's goals.", "The 2\u20131 victory over Scotland was enough to win the group and advance to the knockout rounds, a first for France.", "In the knockout rounds, France beat Northern Ireland 4\u20130 with Fontaine recording another two goals."]], "gold": "Mexico holds the record for the most losses in total matches in the World Cup with 27. Mexico also holds the record for most consecutive losses in matches in the World Cup with 9. Germany holds the record for the most knockout losses in matches in the World Cup with 14. ", "prediction 1": "The country with the most lost matches in the world cup is France, with 11 matches. The country with the most losses in the world cup is Yugoslavia, with 3 losses, and the most wins, with 7.", "prediction 2": "The country with the most losses in a world cup is France, with a total of 78. France has lost the most matches in a single tournament, with a total of 83. In the history of the France national football team, they have lost the most matches in the same tournament.", "prediction 3": "The country that has lost the most matches in a World Cup is France. In the history of the FIFA World Cup, that country was Yugoslavia. However, since 1958, the team has lost the most matches in a World Cup. For example, in the 1958 World Cup, France lost the most matches, in the 1958 World Cup they lost the most games against Serbia.", "prediction 4": "The country that has lost the most matches in the FIFA World Cup is France, with 19 matches. The country that has lost the most matches in the FIFA Club World Cup is Yugoslavia. The country that has lost the most matches in the FIFA World Cup is Belgium, with 3 losses.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 0, "end": 190}, {"error type": "Unverifiable", "start": 0, "end": 83}], "missing-info": [], "corrected-prediction": "The passages do not provide information on which country has lost the most matches in the World Cup."}, "preference": [1, 1, 1, 1, 1, 2], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - FIFA Club World Cup records and statistics\nS1. Wael Gomaa, Hossam Ashour and Mohamed Aboutrika have the record number of matches played in the FIFA Club World Cup, taking part in 11 matches.\nS2. The following is a list of the top ten clubs with the most points gained in the FIFA Club World Cup.\nS3. The clubs are primarily ranked by their points gained, on a basis of three points for a win, one for a draw and no point for a loss.\nS4. \"After 2017 tournament.\"\n\nPassage 2: Title (S0) - Ghana national under-17 football team\nS1. Squad that played in the 2013 African U-17 Championship from 13 \u2013 27 April 2013.\nS2. \"*Draws include knockout matches decided on penalty kicks.\"\nS3. FIFA U-17 World Cup Record by team  \"*Denotes draws including the 1991 & 1999 Semi-Final matches decided on penalty kicks v Qatar (4-2p) & Brazil (2-4p).\"\nS4. Africa U-17 Cup of Nations Record by team  \"*Denotes draws including the 2017 Semi-Final match decided on penalty kicks v Niger (6-5p).\"\nS5. CAF U-16 and U-17 World Cup Qualifiers record by team  \nS6. The following list consist of previous Ghana U-17 national team players who have won or were influential at the FIFA U-17 World Cup with the Ghana U-17 national team or the FIFA U-20 World Cup with the Ghana U-20 national team, and those who were part of the Ghana U-23 national team that won the Bronze medal at the 1992 Summer Olympics.\nS7. The list also includes the players who have graduated from the Ghana U-20 national team and gone on to represent the senior Ghana national team at the FIFA World Cup or African Cup of Nations:\n\nPassage 3: Title (S0) - History of the France national football team\nS1. They were victors in the second match defeating Mexico 3\u20132, but were unable to advance to the next round due to their head-to-head result with Yugoslavia, who advanced.\nS2. Following the World Cup, France went on an eight-match unbeaten streak defeating the likes of Germany, Spain, England, and Sweden.\nS3. The consistent play from the team led to the team again cruising through qualification for the 1958 FIFA World Cup in Sweden.\nS4. France, for the second consecutive qualification, went undefeated scoring 19 goals and conceding only 4.\nS5. Of the 19 goals scored, Racing de France striker Thad\u00e9e Cisowski scored seven including five in the 6\u20133 defeat of Belgium.\nS6. At the 1958 World Cup, the team finished in third place.\nS7. In the group stage, France again faced Yugoslavia, but were given unfamiliar opposition in Paraguay and Scotland.\nS8. In the opening match against Paraguay, France got a 7\u20133 victory, with Reims striker Just Fontaine getting a hat trick.\nS9. In the match against Yugoslavia, they were defeated 2\u20133 with Fontaine scoring both of his team's goals.\nS10. The 2\u20131 victory over Scotland was enough to win the group and advance to the knockout rounds, a first for France.\nS11. In the knockout rounds, France beat Northern Ireland 4\u20130 with Fontaine recording another two goals.\n    \nInput Question:\nWhich country has lost the most matches in the world cup?\n\nCorrect Response:\nMexico holds the record for the most losses in total matches in the World Cup with 27. Mexico also holds the record for most consecutive losses in matches in the World Cup with 9. Germany holds the record for the most knockout losses in matches in the World Cup with 14. \n\nModel Prediction:\nThe country with the most lost matches in the world cup is France, with 11 matches. The country with the most losses in the world cup is Yugoslavia, with 3 losses, and the most wins, with 7.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "[The country with the most lost matches in the world cup is France, with 11 matches. The country with the most losses in the world cup is Yugoslavia, with 3 losses, and the most wins, with 7.]\n\nExplanation:\n1. The entire model prediction is irrelevant as it does not provide the correct answer to the question nor does it provide any crucial auxiliary information. The information provided in the model prediction is not found in the reference response and is not factually consistent with the passages."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The country with the most lost matches in the world cup is France, with 11 matches.\nS2. The country with the most losses in the world cup is Yugoslavia, with 3 losses, and the most wins, with 7.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "1. S1\n2. S2\n\nExplanation:\n1. The claim in sentence 1 that France has lost the most matches in the World Cup with 11 losses is unverifiable as there is no information in the passages to support this claim.\n2. The claim in sentence 2 that Yugoslavia has the most losses in the World Cup with 3 losses and the most wins with 7 is also unverifiable as there is no information in the passages to support this claim."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "None\n\nExplanation:\nThere is no missing information in the model prediction as the passages do not provide any information that could be used to answer the question."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The passages do not provide information on which country has lost the most matches in the World Cup."}], "feedback_human": {"errors": [{"error type": "Unverifiable", "explanation": "", "start": 0, "end": 83}, {"error type": "Unverifiable", "explanation": "", "start": 84, "end": 190}], "missing-info": [], "corrected-prediction": ""}}, {"question": "Where is the common site for obtaining a pulse rate?", "passages": [["Pulse", "Pulse\n\nIn medicine, a pulse represents the tactile arterial palpation of the heartbeat by trained fingertips.", "The pulse may be palpated in any place that allows an artery to be compressed near the surface of the body, such as at the neck (carotid artery), wrist (radial artery), at the groin (femoral artery), behind the knee (popliteal artery), near the ankle joint (posterior tibial artery), and on foot (dorsalis pedis artery).", "Pulse (or the count of arterial pulse per minute) is equivalent to measuring the heart rate.", "The heart rate can also be measured by listening to the heart beat by auscultation, traditionally using a stethoscope and counting it for a minute.", "The radial pulse is commonly measured using three fingers.", "This has a reason: the finger closest to the heart is used to occlude the pulse pressure, the middle finger is used get a crude estimate of the blood pressure, and the finger most distal to the heart (usually the ring finger) is used to nullify the effect of the ulnar pulse as the two arteries are connected via the palmar arches (superficial and deep).", "The study of the pulse is known as sphygmology.", "Claudius Galen was perhaps the first physiologist to describe the pulse."]], "gold": "In medicine, a pulse represents the tactile arterial palpation of the cardiac cycle, or heartbeat, by trained fingertips. The pulse may be palpated in any place that allows an artery to be compressed near the surface of the body, such as at the neck, the site of the carotid artery, wrist, the site of the radial artery, at the groin, the site of the femoral artery, behind the knee, the site of the popliteal artery, near the ankle joint, the site of the posterior tibial artery, and on foot, the site of the dorsalis pedis artery. Pulse, or the count of arterial pulse per minute, is equivalent to measuring the heart rate. The heart rate can also be measured by listening to the heart beat by auscultation, traditionally using a stethoscope and counting it for a minute, while the radial pulse is commonly measured using three fingers.", "prediction 1": "The radial pulse is commonly measured using three fingers, because the finger closest to the heart is used to occlude the pulse pressure, the middle finger is used get a crude estimate of the blood pressure, and the finger most distal to the heart (usually the ring finger) is used to nullify the effect of the ulnar pulse as the two arteries are connected via the palmar arches. The study of the pulse is known as sphygmology. The study of the pulse is known as a pulse rate.", "prediction 2": "In medicine, a pulse represents the tactile arterial palpation of the heartbeat by trained fingertips. The pulse may be palpated in any place that allows an artery to be compressed near the surface of the body, such as at the neck (carotid artery), wrist (radial artery), at the groin (femoral artery), behind the knee (popliteal artery), near the ankle joint (posterior tibial artery), and on foot (dorsalis pedis artery). The radial pulse is commonly measured using three fingers.", "prediction 3": "The pulse may be palpated in any place that allows an artery to be compressed near the surface of the body, such as at the neck (carotid artery), wrist (radial artery), at the groin (femoral artery), behind the knee (popliteal artery), near the ankle joint (posterior tibial artery), and on foot (dorsalis pedis artery).", "prediction 4": "In medicine, a pulse represents the tactile arterial palpation of the heartbeat by trained fingertips. The pulse may be palpated in any place that allows an artery to be compressed near the surface of the body, such as at the neck (carotid artery), wrist (radial artery), at the groin (femoral artery), behind the knee (popliteal artery), near the ankle joint (posterior tibial artery), and on foot (dorsalis pedis artery).", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 380, "end": 476}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [2]}], "corrected-prediction": "The pulse may be palpated in any place that allows an artery to be compressed near the surface of the body, such as at the neck (carotid artery), wrist (radial artery), at the groin (femoral artery), behind the knee (popliteal artery), near the ankle joint (posterior tibial artery), and on foot (dorsalis pedis artery). The radial pulse is commonly measured using three fingers, because the finger closest to the heart is used to occlude the pulse pressure, the middle finger is used get a crude estimate of the blood pressure, and the finger most distal to the heart (usually the ring finger) is used to nullify the effect of the ulnar pulse as the two arteries are connected via the palmar arches. Pulse (or the count of arterial pulse per minute) is equivalent to measuring the heart rate. The heart rate can also be measured by listening to the heart beat by auscultation, traditionally using a stethoscope and counting it for a minute. The study of the pulse is known as sphygmology."}, "preference": [2, 1, 2, 1, 1, 2], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Pulse\nS1. Pulse  In medicine, a pulse represents the tactile arterial palpation of the heartbeat by trained fingertips.\nS2. The pulse may be palpated in any place that allows an artery to be compressed near the surface of the body, such as at the neck (carotid artery), wrist (radial artery), at the groin (femoral artery), behind the knee (popliteal artery), near the ankle joint (posterior tibial artery), and on foot (dorsalis pedis artery).\nS3. Pulse (or the count of arterial pulse per minute) is equivalent to measuring the heart rate.\nS4. The heart rate can also be measured by listening to the heart beat by auscultation, traditionally using a stethoscope and counting it for a minute.\nS5. The radial pulse is commonly measured using three fingers.\nS6. This has a reason: the finger closest to the heart is used to occlude the pulse pressure, the middle finger is used get a crude estimate of the blood pressure, and the finger most distal to the heart (usually the ring finger) is used to nullify the effect of the ulnar pulse as the two arteries are connected via the palmar arches (superficial and deep).\nS7. The study of the pulse is known as sphygmology.\nS8. Claudius Galen was perhaps the first physiologist to describe the pulse.\n    \nInput Question:\nWhere is the common site for obtaining a pulse rate?\n\nCorrect Response:\nIn medicine, a pulse represents the tactile arterial palpation of the cardiac cycle, or heartbeat, by trained fingertips. The pulse may be palpated in any place that allows an artery to be compressed near the surface of the body, such as at the neck, the site of the carotid artery, wrist, the site of the radial artery, at the groin, the site of the femoral artery, behind the knee, the site of the popliteal artery, near the ankle joint, the site of the posterior tibial artery, and on foot, the site of the dorsalis pedis artery. Pulse, or the count of arterial pulse per minute, is equivalent to measuring the heart rate. The heart rate can also be measured by listening to the heart beat by auscultation, traditionally using a stethoscope and counting it for a minute, while the radial pulse is commonly measured using three fingers.\n\nModel Prediction:\nThe radial pulse is commonly measured using three fingers, because the finger closest to the heart is used to occlude the pulse pressure, the middle finger is used get a crude estimate of the blood pressure, and the finger most distal to the heart (usually the ring finger) is used to nullify the effect of the ulnar pulse as the two arteries are connected via the palmar arches. The study of the pulse is known as sphygmology. The study of the pulse is known as a pulse rate.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "The radial pulse is commonly measured using three fingers, because the finger closest to the heart is used to occlude the pulse pressure, the middle finger is used get a crude estimate of the blood pressure, and the finger most distal to the heart (usually the ring finger) is used to nullify the effect of the ulnar pulse as the two arteries are connected via the palmar arches. [The study of the pulse is known as sphygmology. The study of the pulse is known as a pulse rate.]\n\nExplanation:\n1. The last sentence is repetitive as it repeats the information \"The study of the pulse\" from the previous sentence. Therefore, it should be marked as \"Repetitive\".\n2. The phrase \"is known as a pulse rate\" in the last sentence is incorrect and does not make sense in the context, making it \"Incoherent\"."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The radial pulse is commonly measured using three fingers, because the finger closest to the heart is used to occlude the pulse pressure, the middle finger is used get a crude estimate of the blood pressure, and the finger most distal to the heart (usually the ring finger) is used to nullify the effect of the ulnar pulse as the two arteries are connected via the palmar arches.\nS2. The study of the pulse is known as sphygmology.\nS3. The study of the pulse is known as a pulse rate.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "S3\n\nExplanation:\n1. The phrase \"The study of the pulse is known as a pulse rate\" in sentence 3 is factually incorrect. The study of the pulse is known as sphygmology, not a pulse rate. Therefore, it should be marked as \"Inconsistent Fact\"."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 2 [Missing Major Auxiliary Information]\n2. Passage 1, sentence 3 [Missing Major Auxiliary Information]\n3. Passage 1, sentence 4 [Missing Major Auxiliary Information]\n\nExplanation:\n1. The model prediction does not mention that the pulse can be palpated in any place that allows an artery to be compressed near the surface of the body, such as at the neck (carotid artery), wrist (radial artery), at the groin (femoral artery), behind the knee (popliteal artery), near the ankle joint (posterior tibial artery), and on foot (dorsalis pedis artery). This is a major auxiliary information missing from the model prediction.\n2. The model prediction also does not mention that the pulse (or the count of arterial pulse per minute) is equivalent to measuring the heart rate. This is another major auxiliary information missing from the model prediction.\n3. The model prediction does not mention that the heart rate can also be measured by listening to the heart beat by auscultation, traditionally using a stethoscope and counting it for a minute. This is another major auxiliary information missing from the model prediction."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The pulse may be palpated in any place that allows an artery to be compressed near the surface of the body, such as at the neck (carotid artery), wrist (radial artery), at the groin (femoral artery), behind the knee (popliteal artery), near the ankle joint (posterior tibial artery), and on foot (dorsalis pedis artery). The radial pulse is commonly measured using three fingers, because the finger closest to the heart is used to occlude the pulse pressure, the middle finger is used get a crude estimate of the blood pressure, and the finger most distal to the heart (usually the ring finger) is used to nullify the effect of the ulnar pulse as the two arteries are connected via the palmar arches. Pulse (or the count of arterial pulse per minute) is equivalent to measuring the heart rate. The heart rate can also be measured by listening to the heart beat by auscultation, traditionally using a stethoscope and counting it for a minute. The study of the pulse is known as sphygmology."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 59, "end": 379}, {"error type": "Irrelevant", "explanation": "", "start": 380, "end": 427}, {"error type": "Redundant", "explanation": "The radial pulse is commonly measured using three fingers, because the finger closest to the heart is used to occlude the pulse pressure, the middle finger is used get a crude estimate of the blood pressure, and the finger most distal to the heart (usually the ring finger) is used to nullify the effect of the ulnar pulse as the two arteries are connected via the palmar arches. The study of the pulse is known as sphygmology. ", "start": 428, "end": 476}], "missing-info": [{"error type": "Missing-Minor-Auxiliary", "passage_id": 1, "sentence_id": [4]}, {"error type": "Missing-Minor-Auxiliary", "passage_id": 1, "sentence_id": [1]}, {"error type": "Missing-Answer", "passage_id": 1, "sentence_id": [2]}, {"error type": "Missing-Minor-Auxiliary", "passage_id": 1, "sentence_id": [3]}], "corrected-prediction": "Pulse In medicine, a pulse represents the tactile arterial palpation of the heartbeat by trained fingertips. The pulse may be palpated in any place that allows an artery to be compressed near the surface of the body, such as at the neck (carotid artery), wrist (radial artery), at the groin (femoral artery), behind the knee (popliteal artery), near the ankle joint (posterior tibial artery), and on foot (dorsalis pedis artery).  Pulse (or the count of arterial pulse per minute) is equivalent to measuring the heart rate. The radial pulse is commonly measured using three fingers, while the heart rate can also be measured by listening to the heart beat by auscultation, traditionally using a stethoscope and counting it for a minute. "}}, {"question": "What is the record score for the world cup?", "passages": [["Ernst Wilimowski", "Willimowski's appearances for Poland include two performances that were both historic and memorable.", "In a match against Brazil played in Strasbourg, France during the 1938 FIFA World Cup, \"Ezi\" put on a stunning display by becoming the first player ever to score four goals in a single World Cup match.", "His continued attacks on the opposition net also drew a penalty as he was fouled to the ground by Brazilian keeper Batatais, which led to Poland's fifth goal scored from the spot by German-born Fritz Scherfke, from Pozna\u0144.", "However, it was not enough - Poland lost the match 5-6 and was eliminated from the tournament.", "Willimowski's record was later equalled by other players, but was bettered only 56 years later, when Oleg Salenko scored five goals against Cameroon during the 1994 FIFA World Cup.", "It still remains the only World Cup match when a player from the losing side scored four goals.", "Willimowski put on another memorable display on 27 August 1939 in Warsaw in an international friendly against what was then one of the best teams in the world - Hungary, the 1938 World Cup runner-up.", "After 33 minutes of play the Hungarians were ahead 2:0.", "Willimowski scored three goals and again drew a penalty through his attacking play which was converted by teammate Leonard Pi\u0105tek, giving Poland a 4:2 win."], ["FIFA World Cup top goalscorers", "FIFA World Cup top goalscorers\n\nMore than 2,000 goals have been scored at the 21 editions of the FIFA World Cup final tournaments, not counting penalties scored during shoot-outs.", "Since the first goal scored by French player Lucien Laurent at the 1930 FIFA World Cup, more than 1,250 footballers have scored goals at the World Cup, of which just 97 have scored at least five.", "The top goalscorer of the inaugural competition was Argentina's Guillermo St\u00e1bile with eight goals.", "Since then, only 22 players have scored more at all the games played at the World Cup than St\u00e1bile did throughout the 1930 tournament.", "The first was Hungary's S\u00e1ndor Kocsis with eleven in 1954.", "At the next tournament, France's Just Fontaine improved on this record with 13 goals in only six games.", "Gerd M\u00fcller scored 10 for West Germany in 1970 and broke the overall record when he scored his 14th goal at the World Cup during West Germany's win at the 1974 final.", "His record stood for more than three decades until Ronaldo's 15 goals between 1998 and 2006 for Brazil.", "Germany's Miroslav Klose went on to score a record 16 goals across four consecutive tournaments between 2002 and 2014."]], "gold": "There are several record scores for the World Cup. In the World Cup, the record score for a player in a match is 5, for a player in a single tournament is 13, for a team in a match is 10, and for a team in a single tournament is 27.", "prediction 1": "The world record for a goal scored at the World Cup is a goal scored by an opponent in each of the four quarterfinals. The record for a goal scored during the tournament is a goal scored by an opponent in each of the four quarterfinals. The record for a goal scored during a World Cup is a goal scored by an opponent in each of the four quarterfinals.", "prediction 2": "The record score for a match at the World Cup is 4:2. Fritz Scherfke scored four goals in a single World Cup match in 1938, in a match played in Strasbourg, France. The record score for a match at the World Cup in 1939 was 4:0. The record score for a match at the World Cup in 1994 was 5:4.", "prediction 3": "The record total goals scored at a World Cup is 4 goals. The record total goals scored for a single World Cup match is 4 goals. The record total goals scored for a double World Cup is 10 goals.", "prediction 4": "The record score for a single match at the World Cup is 4 - 0 \u2013 1 \u2013 0. The record score for a quarterfinal match at the World Cup is 1 \u2013 0 \u2013 1 \u2013 2 \u2013 0 \u2013 1 \u2013 1, 0 \u2013 1. The record score for a quarterfinal match at the World Cup is 4-0 \u2013 2 \u2013 4. The record for a quarterfinal match at the World Cup is 4 \u2013 1 \u2013 0.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 0, "end": 351}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 1, "sentence_id": [2]}], "corrected-prediction": "In the World Cup, the record for the most goals scored by a player in a single match is 5, achieved by Oleg Salenko in 1994. This surpassed the previous record of 4 goals in a single match, set by Ernst Wilimowski in 1938, which remains the only instance of a player from the losing side scoring four goals. The record for the most goals scored by a player in a single tournament is 13, set by Just Fontaine in 1958. The overall record for the most goals scored by a player across all World Cup tournaments is 16, set by Miroslav Klose between 2002 and 2014."}, "preference": [2, 2, 2, 1, 1, 1], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Ernst Wilimowski\nS1. Willimowski's appearances for Poland include two performances that were both historic and memorable.\nS2. In a match against Brazil played in Strasbourg, France during the 1938 FIFA World Cup, \"Ezi\" put on a stunning display by becoming the first player ever to score four goals in a single World Cup match.\nS3. His continued attacks on the opposition net also drew a penalty as he was fouled to the ground by Brazilian keeper Batatais, which led to Poland's fifth goal scored from the spot by German-born Fritz Scherfke, from Pozna\u0144.\nS4. However, it was not enough - Poland lost the match 5-6 and was eliminated from the tournament.\nS5. Willimowski's record was later equalled by other players, but was bettered only 56 years later, when Oleg Salenko scored five goals against Cameroon during the 1994 FIFA World Cup.\nS6. It still remains the only World Cup match when a player from the losing side scored four goals.\nS7. Willimowski put on another memorable display on 27 August 1939 in Warsaw in an international friendly against what was then one of the best teams in the world - Hungary, the 1938 World Cup runner-up.\nS8. After 33 minutes of play the Hungarians were ahead 2:0.\nS9. Willimowski scored three goals and again drew a penalty through his attacking play which was converted by teammate Leonard Pi\u0105tek, giving Poland a 4:2 win.\n\nPassage 2: Title (S0) - FIFA World Cup top goalscorers\nS1. FIFA World Cup top goalscorers  More than 2,000 goals have been scored at the 21 editions of the FIFA World Cup final tournaments, not counting penalties scored during shoot-outs.\nS2. Since the first goal scored by French player Lucien Laurent at the 1930 FIFA World Cup, more than 1,250 footballers have scored goals at the World Cup, of which just 97 have scored at least five.\nS3. The top goalscorer of the inaugural competition was Argentina's Guillermo St\u00e1bile with eight goals.\nS4. Since then, only 22 players have scored more at all the games played at the World Cup than St\u00e1bile did throughout the 1930 tournament.\nS5. The first was Hungary's S\u00e1ndor Kocsis with eleven in 1954.\nS6. At the next tournament, France's Just Fontaine improved on this record with 13 goals in only six games.\nS7. Gerd M\u00fcller scored 10 for West Germany in 1970 and broke the overall record when he scored his 14th goal at the World Cup during West Germany's win at the 1974 final.\nS8. His record stood for more than three decades until Ronaldo's 15 goals between 1998 and 2006 for Brazil.\nS9. Germany's Miroslav Klose went on to score a record 16 goals across four consecutive tournaments between 2002 and 2014.\n    \nInput Question:\nWhat is the record score for the world cup?\n\nCorrect Response:\nThere are several record scores for the World Cup. In the World Cup, the record score for a player in a match is 5, for a player in a single tournament is 13, for a team in a match is 10, and for a team in a single tournament is 27.\n\nModel Prediction:\nThe world record for a goal scored at the World Cup is a goal scored by an opponent in each of the four quarterfinals. The record for a goal scored during the tournament is a goal scored by an opponent in each of the four quarterfinals. The record for a goal scored during a World Cup is a goal scored by an opponent in each of the four quarterfinals.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "[The world record for a goal scored at the World Cup is a goal scored by an opponent in each of the four quarterfinals. The record for a goal scored during the tournament is a goal scored by an opponent in each of the four quarterfinals. The record for a goal scored during a World Cup is a goal scored by an opponent in each of the four quarterfinals.]\n\nExplanation:\n1. The entire model prediction is marked as \"Incoherent\" because it is not clear what it is trying to convey. The phrase \"a goal scored by an opponent in each of the four quarterfinals\" is not understandable in the context of the question about World Cup record scores.\n2. The model prediction is also \"Repetitive\" as it repeats the same incoherent information three times.\n3. The model prediction is also \"Irrelevant\" as it does not provide any answer or crucial auxiliary information to the question. The information about \"a goal scored by an opponent in each of the four quarterfinals\" is not related to the question about World Cup record scores."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The world record for a goal scored at the World Cup is a goal scored by an opponent in each of the four quarterfinals.\nS2. The record for a goal scored during the tournament is a goal scored by an opponent in each of the four quarterfinals.\nS3. The record for a goal scored during a World Cup is a goal scored by an opponent in each of the four quarterfinals.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "S1\nS2\nS3\n\nExplanation:\n1. All three sentences in the model prediction are marked as \"Unverifiable Fact\" because there is no information in the provided passages that supports the claim about a goal being scored by an opponent in each of the four quarterfinals. This information cannot be verified from the passages."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 2 [Missing Answer]\n2. Passage 1, sentence 5 [Missing Answer]\n3. Passage 2, sentence 6 [Missing Answer]\n4. Passage 2, sentence 9 [Missing Answer]\n\nExplanation:\n1. The model prediction does not mention the record of the first player ever to score four goals in a single World Cup match, which is mentioned in Passage 1, sentence 2.\n2. The model prediction also misses the information about the only World Cup match when a player from the losing side scored four goals, which is mentioned in Passage 1, sentence 6.\n3. The record score for a player in a single tournament is 13, which is mentioned in Passage 2, sentence 6, but is not included in the model prediction.\n4. The record for the most goals scored by a player across all World Cup tournaments is 16, which is mentioned in Passage 2, sentence 9, but is not included in the model prediction."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "In the World Cup, the record for the most goals scored by a player in a single match is 5, achieved by Oleg Salenko in 1994. This surpassed the previous record of 4 goals in a single match, set by Ernst Wilimowski in 1938, which remains the only instance of a player from the losing side scoring four goals. The record for the most goals scored by a player in a single tournament is 13, set by Just Fontaine in 1958. The overall record for the most goals scored by a player across all World Cup tournaments is 16, set by Miroslav Klose between 2002 and 2014."}], "feedback_human": {"errors": [{"error type": "Unverifiable", "explanation": "", "start": 0, "end": 118}, {"error type": "Redundant", "explanation": "The world record for a goal scored at the World Cup is a goal scored by an opponent in each of the four quarterfinals. ", "start": 119, "end": 236}, {"error type": "Redundant", "explanation": "The world record for a goal scored at the World Cup is a goal scored by an opponent in each of the four quarterfinals. ", "start": 237, "end": 351}], "missing-info": [], "corrected-prediction": ""}}, {"question": "Who wrote the music to the lion king?", "passages": [["The Lion King (soundtrack)", "The Lion King (soundtrack)\n\nThe Lion King: Original Motion Picture Soundtrack is the original motion picture soundtrack for the 1994 Disney animated film, \"The Lion King\".", "It contains songs from the film written by Elton John and Tim Rice, and a score composed by Hans Zimmer.", "Elton John has a dual role of performer for several tracks.", "Additional performers include Carmen Twillie, Jason Weaver, Rowan Atkinson, Whoopi Goldberg, Jeremy Irons, Cheech Marin, Jim Cummings, Nathan Lane, Ernie Sabella, and Sally Dworsky.", "The album was released on April 27, 1994 on CD and audio cassette.", "The soundtrack was recorded in three different countries: the U.S., the U.K. and South Africa.", "It is the best-selling soundtrack album to an animated film in the United States with over 7 million copies sold, with 4,934,000 copies sold in 1994.", "An expanded version of \"The Lion King\" soundtrack, featuring 30 minutes of previously-unreleased material, was released as part of the \"\" series on June 24, 2014.", "In 2014, Hot Topic released a vinyl picture disc of the soundtrack.", "Walt Disney Records released an expanded edition of \"The Lion King\" soundtrack containing an additional thirty minutes of previously-unheard material from the film, as well as a collection of demo versions of cues."], ["Lebo M.", "Lebo M.\n\nLebohang \"Lebo M.\" Morake (born 20 May 1964) is a South African producer and composer.", "He arranged and performed music for \"The Lion King\" movies and stage productions.", "He was recommended to Disney by Hans Zimmer, the score composer of \"The Lion King\", and was later hired to form and conduct the African choir that sang for the movies.", "His voice is the first voice heard in the beginning of the film, singing a chant over the opening sequence which is often considered synonymous with the film's image in popular culture.", "He also contributed to the sequel to the film's soundtrack, \"Rhythm of the Pride Lands\", and the film's direct-to-video sequel \".", "Lebo Morake was born on 20 May 1964 in the Apartheid-ridden Soweto in Johannesburg, South Africa and inspired by Nelson Mandela, he spent years working hard in the South African slums but was exiled from South Africa in 1979.", "He made his way to the U.S. and to Los Angeles where he worked in a variety of jobs, including begging and serving at McDonald's.", "He returned to South Africa 5 years after the elimination of the Apartheid regime after being gone for 20 years.", "He lives with his family in Johannesburg and Los Angeles.", "He founded the Lebo M Foundation and Till Dawn Entertainment."]], "gold": "The 1994 Lion King film had music written by Elton John and Tim Rice and Hans Zimmer. In the 2019 Lion King film the music was written by Elton John and Tim Rice, Hans Zimmer, Lebohang \"Lebo M\" Morake and Beyonce.", "prediction 1": "The music for the 1994 Disney animated film The Lion King was written by Tim Rice, Elton John, and Lebo Morake. The Lion King: Original Motion Picture Soundtrack is the original motion picture soundtrack for the 1994 Disney animated film, The Lion King. It contains songs from the film written by Elton John and Tim Rice, and a score composed by Hans Zimmer.\n", "prediction 2": "There are several English-language songs for The Lion King. Other songs are written by Tim Rice, Elton John for the ending theme song, Jack the Ripper for the theme song, George Harrison for the opening theme song, and Keith Urban for the closing theme song. Lebo Morake wrote the music for this film.", "prediction 3": "The 1994 Disney animated film, The Lion King, has an original motion picture soundtrack which includes songs written by Tim Rice, Elton John, and Lebo Morake.", "prediction 4": "The Lion King: Original Motion Picture Soundtrack is the original motion picture soundtrack for the 1994 Disney animated film, The Lion King. It contains songs from the film written by Elton John and Tim Rice, and a score composed by Hans Zimmer. Additionally, an expanded version of the soundtrack, featuring 30 minutes of previously-unreleased material, was released as part of the \"\" series on June 24, 2014. A South African producer and composer called Lebo Morake is credited with being the first voice heard in the beginning of The Lion King. Unknown for his music for his own song, and the film's Rhythm of the Pride Lands, and its direct-to sequel.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 99, "end": 110}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [2]}], "corrected-prediction": "The music for the 1994 Disney animated film The Lion King was written by Tim Rice and Elton John, with the score composed by Hans Zimmer. The Lion King: Original Motion Picture Soundtrack is the original motion picture soundtrack for the film. It contains songs from the film written by Elton John and Tim Rice, and a score composed by Hans Zimmer."}, "preference": [1, 1, 2, 2, 2, 2], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - The Lion King (soundtrack)\nS1. The Lion King (soundtrack)  The Lion King: Original Motion Picture Soundtrack is the original motion picture soundtrack for the 1994 Disney animated film, \"The Lion King\".\nS2. It contains songs from the film written by Elton John and Tim Rice, and a score composed by Hans Zimmer.\nS3. Elton John has a dual role of performer for several tracks.\nS4. Additional performers include Carmen Twillie, Jason Weaver, Rowan Atkinson, Whoopi Goldberg, Jeremy Irons, Cheech Marin, Jim Cummings, Nathan Lane, Ernie Sabella, and Sally Dworsky.\nS5. The album was released on April 27, 1994 on CD and audio cassette.\nS6. The soundtrack was recorded in three different countries: the U.S., the U.K. and South Africa.\nS7. It is the best-selling soundtrack album to an animated film in the United States with over 7 million copies sold, with 4,934,000 copies sold in 1994.\nS8. An expanded version of \"The Lion King\" soundtrack, featuring 30 minutes of previously-unreleased material, was released as part of the \"\" series on June 24, 2014.\nS9. In 2014, Hot Topic released a vinyl picture disc of the soundtrack.\nS10. Walt Disney Records released an expanded edition of \"The Lion King\" soundtrack containing an additional thirty minutes of previously-unheard material from the film, as well as a collection of demo versions of cues.\n\nPassage 2: Title (S0) - Lebo M.\nS1. Lebo M.  Lebohang \"Lebo M.\" Morake (born 20 May 1964) is a South African producer and composer.\nS2. He arranged and performed music for \"The Lion King\" movies and stage productions.\nS3. He was recommended to Disney by Hans Zimmer, the score composer of \"The Lion King\", and was later hired to form and conduct the African choir that sang for the movies.\nS4. His voice is the first voice heard in the beginning of the film, singing a chant over the opening sequence which is often considered synonymous with the film's image in popular culture.\nS5. He also contributed to the sequel to the film's soundtrack, \"Rhythm of the Pride Lands\", and the film's direct-to-video sequel \".\nS6. Lebo Morake was born on 20 May 1964 in the Apartheid-ridden Soweto in Johannesburg, South Africa and inspired by Nelson Mandela, he spent years working hard in the South African slums but was exiled from South Africa in 1979.\nS7. He made his way to the U.S. and to Los Angeles where he worked in a variety of jobs, including begging and serving at McDonald's.\nS8. He returned to South Africa 5 years after the elimination of the Apartheid regime after being gone for 20 years.\nS9. He lives with his family in Johannesburg and Los Angeles.\nS10. He founded the Lebo M Foundation and Till Dawn Entertainment.\n    \nInput Question:\nWho wrote the music to the lion king?\n\nCorrect Response:\nThe 1994 Lion King film had music written by Elton John and Tim Rice and Hans Zimmer. In the 2019 Lion King film the music was written by Elton John and Tim Rice, Hans Zimmer, Lebohang \"Lebo M\" Morake and Beyonce.\n\nModel Prediction:\nThe music for the 1994 Disney animated film The Lion King was written by Tim Rice, Elton John, and Lebo Morake. The Lion King: Original Motion Picture Soundtrack is the original motion picture soundtrack for the 1994 Disney animated film, The Lion King. It contains songs from the film written by Elton John and Tim Rice, and a score composed by Hans Zimmer.\n\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "The music for the 1994 Disney animated film The Lion King was written by Tim Rice, Elton John, and [Lebo Morake]. The Lion King: Original Motion Picture Soundtrack is the original motion picture soundtrack for the 1994 Disney animated film, The Lion King. It contains songs from the film written by Elton John and Tim Rice, and a score composed by Hans Zimmer.\n\nExplanation:\n1. The inclusion of \"Lebo Morake\" as one of the writers of the music for the 1994 Disney animated film The Lion King is irrelevant. While Lebo M. did contribute to the music of The Lion King, he did not write the songs or the score, which is what the question is asking about. Therefore, this information is irrelevant to the question."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The music for the 1994 Disney animated film The Lion King was written by Tim Rice, Elton John, and Lebo Morake.\nS2. The Lion King: Original Motion Picture Soundtrack is the original motion picture soundtrack for the 1994 Disney animated film, The Lion King.\nS3. It contains songs from the film written by Elton John and Tim Rice, and a score composed by Hans Zimmer.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "S1\n\nExplanation:\n1. The first sentence of the model prediction is factually inconsistent with the passages. While Lebo M. did contribute to the music of The Lion King, he did not write the songs or the score, which is what the question is asking about. This information is inconsistent with the information provided in Passage 1, Sentence 2, which states that the songs were written by Elton John and Tim Rice and the score was composed by Hans Zimmer."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 2 [Missing Major Auxiliary Information]\n\nExplanation:\n1. The model prediction does not mention Hans Zimmer's role in composing the score for The Lion King, which is a crucial piece of information in answering the question about who wrote the music for the film. This information can be found in Passage 1, Sentence 2."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The music for the 1994 Disney animated film The Lion King was written by Tim Rice and Elton John, with the score composed by Hans Zimmer. The Lion King: Original Motion Picture Soundtrack is the original motion picture soundtrack for the film. It contains songs from the film written by Elton John and Tim Rice, and a score composed by Hans Zimmer."}], "feedback_human": {"errors": [{"error type": "Wrong-Grounding", "explanation": "{\"passage_id\":1,\"sentence_id\":[2]}", "start": 99, "end": 111}, {"error type": "Irrelevant", "explanation": "", "start": 112, "end": 253}, {"error type": "Irrelevant", "explanation": "", "start": 254, "end": 321}], "missing-info": [{"error type": "Missing-Minor-Auxiliary", "passage_id": 2, "sentence_id": [2]}], "corrected-prediction": "The music for the 1994 Disney animated film The Lion King was written by Tim Rice, Elton John, and a score composed by Hans Zimmer. Lebohang \"Lebo M.\" Morake arranged and performed music for \"The Lion King\" movies and stage productions.\n"}}, {"question": "Who plays the mom in american horror story season 1?", "passages": [["American Horror Story: Murder House", "American Horror Story: Murder House\n\nAmerican Horror Story: Murder House (originally titled as American Horror Story) is the first season of the FX television series \"American Horror Story\".", "It aired between October 5, and December 21, 2011.", "The season was produced by 20th Century Fox Television, and the executive producers were Dante Di Loreto and series creators Brad Falchuk and Ryan Murphy.", "It centers on the Harmon family: , and their daughter , who move from Boston to Los Angeles after Vivien has a miscarriage and Ben has an affair.", "They move into a restored mansion, unaware that the house is haunted by the ghosts of its former residents and their victims.", "The first season of \"American Horror Story\" received generally positive reviews from critics.", "The series drew consistently high ratings for the FX network, ending its first season as the biggest new cable series of the year.", "The season was nominated for various industry awards, including the Golden Globe Award for Best Television Series \u2013 Drama, and received a total of seventeen Emmy Award nominations.", "In addition, Lange won the Golden Globe for Best Supporting Actress, the Screen Actors Guild Award for Outstanding Performance by a Female Actor in a Drama Series, and the Primetime Emmy Award for Outstanding Supporting Actress in a Miniseries or a Movie."], ["American Horror Story", "Although reception to individual seasons has varied, \"American Horror Story\" largely has been well received by television critics, with the majority of the praise going towards the cast, particularly Jessica Lange, who won two Emmy Awards, a Golden Globe Award, and a Screen Actors Guild Award for her performances.", "Kathy Bates and James Cromwell each won an Emmy Award for their performances, while Lady Gaga won a Golden Globe Award.", "The series draws consistently high ratings for the FX network, with its first season being the most-viewed new cable series of 2011.", "Set in the year 2011, the season follows the Harmons, consisting of wife and mother Vivien (Connie Britton), her psychiatrist husband Ben (Dylan McDermott), and their teenage daughter Violet (Taissa Farmiga), as they move from Boston to Los Angeles to make a fresh start after Vivien's miscarriage led to Ben having an affair with one of his students, which almost tore their family apart.", "They move into a restored mansion and soon encounter the residence's housekeeper, Moira O'Hara (Frances Conroy and Alexandra Breckenridge), as well as their neighbors \u2013 the eccentric Langdon family consisting of Constance (Jessica Lange) and her daughter Adelaide (Jamie Brewer)."], ["American Horror Story: Apocalypse", "People inside include hairdresser Mr. Gallant (Evan Peters), his grandmother Evie (Joan Collins), talk show host Dinah Stevens (Adina Porter), her son Andre (Jeffrey Bowyer-Chapman), the billionaire Coco St. Pierre Vanderbilt (Leslie Grossman), her assistant Mallory (Billie Lourd), and couple Timothy Campbell (Kyle Allen) and Emily (Ash Santos), all of whom face the wrath of the two women.", "However, Michael Langdon (Cody Fern), the Antichrist, arrives and begins to throw the order into chaos as he intends to bring those worthy to a \"sanctuary\".", "Later in the season, the arrival of Cordelia Goode (Paulson), Madison Montgomery (Emma Roberts), Myrtle Snow (Frances Conroy) as well as the return of Zoe Benson (Taissa Farmiga), Queenie (Gabourey Sidibe) and Misty Day (Lily Rabe), provides background of the world before the fateful apocalypse as well as the inclusion of characters from \"Murder House\", such as Michael's grandmother, Constance Langdon (Jessica Lange).", "<onlyinclude></onlyinclude>\n\nOn January 12, 2017, the series was renewed for an eighth season, which premiered on September 12, 2018."]], "gold": "American Horror Story: Murder House, originally titled American Horror Story, is the first season of the FX horror anthology television series American Horror Story. Connie Britton portrays Violet's mom, Jessica Lange portrays Tate's mom, Rebecca Wisocky portrays Margaret and Angie's mom, Lily Rabe portrays Thaddeus Montgomery's mom, and Lisa Vidal portrays Gabe's mom.", "prediction 1": "American Horror Story: Murder House is the first season of the FX television series American Horror Story which follows the Harmon family, consisting of wife and mother Vivien (Connie Britton), her psychiatrist husband Ben (Dylan McDermott), and their teenage daughter Violet (Taissa Farmiga) as they move from Boston to Los Angeles to make a fresh start after Vivien has a miscarriage led to Ben having an affair. The season follows the family as they move into a restored mansion, unaware that the house is haunted by the ghosts of its former residents and their victims.", "prediction 2": "American Horror Story: Murder House is the first season of the FX television series American Horror Story. It centers on the Harmon family of the Harmons, consisting of wife and mother Vivien (Connie Britton), her psychiatrist husband Ben (Dylan McDermott), and their teenage daughter Violet (Taissa Farmiga), who move from Boston to Los Angeles to make a fresh start after Vivien has a miscarriage led to Ben having an affair with one of his students, which almost to tear their family apart.", "prediction 3": "The first season of the FX television series American Horror Story, which is based on the book by the same name, is the first season of the television series. The season follows the Harmon family, consisting of husband and mother Vivien, played by Connie Britton, and their teenage daughter Violet played by Taissa Farmiga. The season is produced by 20th Century Fox Television and was produced by Dante Di Loreto and series creators Brad Falchuk and Ryan Murphy.", "prediction 4": "American Horror Story is an American horror television series that aired between October 5, and December 21, 2011. The first season follows the Harmon family consisting of wife and mother Vivien and their teenage daughter Violet, played by Taissa Farmiga. The season also features a guest appearance by actress Jessica Lange as Constance Langdon, Vivien's grandmother and the mother of Michael Langdon.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 415, "end": 573}], "missing-info": [], "corrected-prediction": "American Horror Story: Murder House is the first season of the FX television series American Horror Story. The Harmon family, consisting of wife and mother Vivien, is portrayed by Connie Britton."}, "preference": [2, 2, 2, 1, 1, 2], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - American Horror Story: Murder House\nS1. American Horror Story: Murder House  American Horror Story: Murder House (originally titled as American Horror Story) is the first season of the FX television series \"American Horror Story\".\nS2. It aired between October 5, and December 21, 2011.\nS3. The season was produced by 20th Century Fox Television, and the executive producers were Dante Di Loreto and series creators Brad Falchuk and Ryan Murphy.\nS4. It centers on the Harmon family: , and their daughter , who move from Boston to Los Angeles after Vivien has a miscarriage and Ben has an affair.\nS5. They move into a restored mansion, unaware that the house is haunted by the ghosts of its former residents and their victims.\nS6. The first season of \"American Horror Story\" received generally positive reviews from critics.\nS7. The series drew consistently high ratings for the FX network, ending its first season as the biggest new cable series of the year.\nS8. The season was nominated for various industry awards, including the Golden Globe Award for Best Television Series \u2013 Drama, and received a total of seventeen Emmy Award nominations.\nS9. In addition, Lange won the Golden Globe for Best Supporting Actress, the Screen Actors Guild Award for Outstanding Performance by a Female Actor in a Drama Series, and the Primetime Emmy Award for Outstanding Supporting Actress in a Miniseries or a Movie.\n\nPassage 2: Title (S0) - American Horror Story\nS1. Although reception to individual seasons has varied, \"American Horror Story\" largely has been well received by television critics, with the majority of the praise going towards the cast, particularly Jessica Lange, who won two Emmy Awards, a Golden Globe Award, and a Screen Actors Guild Award for her performances.\nS2. Kathy Bates and James Cromwell each won an Emmy Award for their performances, while Lady Gaga won a Golden Globe Award.\nS3. The series draws consistently high ratings for the FX network, with its first season being the most-viewed new cable series of 2011.\nS4. Set in the year 2011, the season follows the Harmons, consisting of wife and mother Vivien (Connie Britton), her psychiatrist husband Ben (Dylan McDermott), and their teenage daughter Violet (Taissa Farmiga), as they move from Boston to Los Angeles to make a fresh start after Vivien's miscarriage led to Ben having an affair with one of his students, which almost tore their family apart.\nS5. They move into a restored mansion and soon encounter the residence's housekeeper, Moira O'Hara (Frances Conroy and Alexandra Breckenridge), as well as their neighbors \u2013 the eccentric Langdon family consisting of Constance (Jessica Lange) and her daughter Adelaide (Jamie Brewer).\n\nPassage 3: Title (S0) - American Horror Story: Apocalypse\nS1. People inside include hairdresser Mr. Gallant (Evan Peters), his grandmother Evie (Joan Collins), talk show host Dinah Stevens (Adina Porter), her son Andre (Jeffrey Bowyer-Chapman), the billionaire Coco St. Pierre Vanderbilt (Leslie Grossman), her assistant Mallory (Billie Lourd), and couple Timothy Campbell (Kyle Allen) and Emily (Ash Santos), all of whom face the wrath of the two women.\nS2. However, Michael Langdon (Cody Fern), the Antichrist, arrives and begins to throw the order into chaos as he intends to bring those worthy to a \"sanctuary\".\nS3. Later in the season, the arrival of Cordelia Goode (Paulson), Madison Montgomery (Emma Roberts), Myrtle Snow (Frances Conroy) as well as the return of Zoe Benson (Taissa Farmiga), Queenie (Gabourey Sidibe) and Misty Day (Lily Rabe), provides background of the world before the fateful apocalypse as well as the inclusion of characters from \"Murder House\", such as Michael's grandmother, Constance Langdon (Jessica Lange).\nS4. <onlyinclude></onlyinclude>  On January 12, 2017, the series was renewed for an eighth season, which premiered on September 12, 2018.\n    \nInput Question:\nWho plays the mom in american horror story season 1?\n\nCorrect Response:\nAmerican Horror Story: Murder House, originally titled American Horror Story, is the first season of the FX horror anthology television series American Horror Story. Connie Britton portrays Violet's mom, Jessica Lange portrays Tate's mom, Rebecca Wisocky portrays Margaret and Angie's mom, Lily Rabe portrays Thaddeus Montgomery's mom, and Lisa Vidal portrays Gabe's mom.\n\nModel Prediction:\nAmerican Horror Story: Murder House is the first season of the FX television series American Horror Story which follows the Harmon family, consisting of wife and mother Vivien (Connie Britton), her psychiatrist husband Ben (Dylan McDermott), and their teenage daughter Violet (Taissa Farmiga) as they move from Boston to Los Angeles to make a fresh start after Vivien has a miscarriage led to Ben having an affair. The season follows the family as they move into a restored mansion, unaware that the house is haunted by the ghosts of its former residents and their victims.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "American Horror Story: Murder House is the first season of the FX television series American Horror Story which follows the Harmon family, consisting of wife and mother Vivien (Connie Britton), her psychiatrist husband Ben (Dylan McDermott), and their teenage daughter Violet (Taissa Farmiga) as they move from Boston to Los Angeles to make a fresh start after Vivien has a miscarriage led to Ben having an affair. [The season follows the family as they move into a restored mansion, unaware that the house is haunted by the ghosts of its former residents and their victims.]\n\nExplanation:\nThe last sentence in the model prediction is irrelevant to the question asked. The question is about who plays the mom in the first season of American Horror Story, not about the plot of the season. Thus, the last sentence should be marked as \"Irrelevant\"."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. American Horror Story: Murder House is the first season of the FX television series American Horror Story which follows the Harmon family, consisting of wife and mother Vivien (Connie Britton), her psychiatrist husband Ben (Dylan McDermott), and their teenage daughter Violet (Taissa Farmiga) as they move from Boston to Los Angeles to make a fresh start after Vivien has a miscarriage led to Ben having an affair.\nS2. The season follows the family as they move into a restored mansion, unaware that the house is haunted by the ghosts of its former residents and their victims.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation:\nAll the facts in the model prediction are consistent with the passages and can be verified. Therefore, there are no spans that contain inconsistent or unverifiable facts."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "None\n\nExplanation:\nThe model prediction correctly identifies Connie Britton as the actress who plays the mother in the first season of American Horror Story. There is no missing information in the model prediction."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "American Horror Story: Murder House is the first season of the FX television series American Horror Story. The Harmon family, consisting of wife and mother Vivien, is portrayed by Connie Britton."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 293, "end": 414}, {"error type": "Irrelevant", "explanation": "", "start": 415, "end": 573}], "missing-info": [{"error type": "Missing-Minor-Auxiliary", "passage_id": 1, "sentence_id": [1]}], "corrected-prediction": "American Horror Story: Murder House, , originally titled American Horror Story, is the first season of the FX television series American Horror Story which follows the Harmon family, consisting of wife and mother Vivien (Connie Britton), her psychiatrist husband Ben (Dylan McDermott), and their teenage daughter Violet (Taissa Farmiga)."}}, {"question": "Who is the state minister for primary education in uganda?", "passages": [["Rosemary Seninde", "Rosemary Seninde\n\nRosemary Nansubuga Seninde, also Rosemary Nansubuga Sseninde (n\u00e9e Rosemary Nansubuga) (born 7 January 1965), is a Ugandan educator and politician.", "She is the State Minister for Primary Education in the Ugandan Cabinet.", "She was appointed to that position on 6 June 2016, replacing John Chrysostom Muyingo who became State Minister for Higher Education.", "She concurrently serves as the Wakiso District Women's Representative in the Parliament of Uganda.", "Rosemary Nansubuga was born in Wakiso District on 7 January 1965.", "She went to St. Agnes Boarding Primary School in Naggalama for her early elementary schooling.", "She then attended St. Joseph's Senior Secondary School in Nsambya for her O-Level studies, graduating in 1982.", "She studied at Trinity College Nabbingo for her A-Level education, graduating in 1985.", "In 1997 she obtained a Teaching Certificate from Lady Irene College, in Ndejje, now a component of Ndejje University.", "The following year, she attended a 10-week course at the \"National Institute of Small Industries Extension Training\" (NISIET), in Hyderabad, India, graduating with a certificate."], ["John Chrysestom Muyingo", "John Chrysestom Muyingo\n\nJohn Chrysestom Muyingo is a Ugandan educator and politician.", "He is the State Minister for Higher Education in the Ugandan Cabinet.", "He was appointed to that position on 6 June 2016.", "He previously served as the Stat Minister for Primary Education from 1 March 2015 until 5 June 2016.", "Before that, from 27 May 2011 until 1 March 2015, he served as the State Minister for Higher Education, having replaced Mwesigwa Rukutana in May 2011.", "Muyingo is also the elected Member of Parliament for Bamunanika County, Luweero District.", "Muyingo was born on 22 February 1960 to John Chrysestom Ssekidde of Kakoola Village, Bamunanika County, Luwero District and Victoria Nakiwala of Naakulabye, Lubaga Division, in Kampala, Uganda's capital.", "He attended the Mulajje Primary School, Kisubi Seminary, and Makerere College School, before joining Makerere University in 1983.", "He graduated in 1986 with a Bachelor of Science with a Diploma in Education.", "He also holds a Master of Arts in Educational Management, obtained in 1996, and a Doctor of Philosophy obtained in 2004, both from Makerere University.", "The dissertation for his doctorate focused on the financing of university education in Uganda."], ["Ministry of Education and Sports (Uganda)", "Ministry of Education and Sports (Uganda)\n\nThe Ministry of Education and Sports (MES), is a cabinet-level ministry of Uganda.", "It is mandated \"to provide technical support, guide, coordinate, regulate and promote quality education, training and sports to all persons in Uganda for national integration, development and individual advancement\", according to the website of the ministry.", "The headquarters of the ministry are located in Embassy House, on King George VI Way, at the corner with Parliament Avenue, in the Central Division of Kampala, Uganda's capital and largest city.", "The coordinates of the ministry headquarters are:0\u00b018'50.0\"N, 32\u00b035'15.0\"E (Latitude:0.313889; Longitude:32.587500).", "The ministry is overseen by a cabinet minister, currently Janet Museveni, since 6 June 2016.", "She is assisted by three ministers of state; (a) Rosemary Seninde serves as Minister of State for Primary Education, (b)", "John Chrysestom Muyingo serves as Minister of State for Secondary Education, and Charles Bakkabulindi serves as Minister of State for sports."]], "gold": "Uganda has had several State Ministers for Primary Education. Rosemary Seninde is the State Minister for Primary Education in the Ugandan Cabinet. She was appointed to that position on 6 June 2016, replacing John Chrysostom Muyingo who previously served as the State Minister for Primary Education from 1 March 2015 until 5 June 2016.", "prediction 1": "There are several officials in Uganda's government who are the State Ministers of Education. Rosemary Seninde is the State Minister for Primary Education in the Ugandan Cabinet. John Chrysestom Muyingo is the State Minister for Higher Education. Charles Bakkabulindi is the Minister of State for sports.", "prediction 2": "Rosemary Annunsubuga Seninde, also Rosemary Nansubuga Sseninde, is the State Minister for Primary Education in Uganda. She was appointed to that position on 6 June 2016 replacing John Chrysostom Muyingo, who became State Minister for Higher Education.", "prediction 3": "The state minister for primary education in Uganda is Rosemary Nansubuga Seninde. She has held the position since June 6, 2016. John Chrysestom Muyingo is the state minister for higher education in Uganda. Charles Bakkabulindi serves as the state minister for sports.", "prediction 4": "Currently, Rosemary Seninde is the State Minister for Primary Education in Uganda. She was appointed to that position on June 6, 2016, replacing John Chrysestom Muyingo, who became State Minister for Higher Education. Charles Bakkabulindi is the Minister of State for sports.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 178, "end": 303}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [3]}], "corrected-prediction": "Rosemary Seninde is the State Minister for Primary Education in the Ugandan Cabinet. She was appointed to that position on 6 June 2016. Prior to her, John Chrysostom Muyingo served as the State Minister for Primary Education from 1 March 2015 until 5 June 2016."}, "preference": [1, 1, 1, 1, 1, 1], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Rosemary Seninde\nS1. Rosemary Seninde  Rosemary Nansubuga Seninde, also Rosemary Nansubuga Sseninde (n\u00e9e Rosemary Nansubuga) (born 7 January 1965), is a Ugandan educator and politician.\nS2. She is the State Minister for Primary Education in the Ugandan Cabinet.\nS3. She was appointed to that position on 6 June 2016, replacing John Chrysostom Muyingo who became State Minister for Higher Education.\nS4. She concurrently serves as the Wakiso District Women's Representative in the Parliament of Uganda.\nS5. Rosemary Nansubuga was born in Wakiso District on 7 January 1965.\nS6. She went to St. Agnes Boarding Primary School in Naggalama for her early elementary schooling.\nS7. She then attended St. Joseph's Senior Secondary School in Nsambya for her O-Level studies, graduating in 1982.\nS8. She studied at Trinity College Nabbingo for her A-Level education, graduating in 1985.\nS9. In 1997 she obtained a Teaching Certificate from Lady Irene College, in Ndejje, now a component of Ndejje University.\nS10. The following year, she attended a 10-week course at the \"National Institute of Small Industries Extension Training\" (NISIET), in Hyderabad, India, graduating with a certificate.\n\nPassage 2: Title (S0) - John Chrysestom Muyingo\nS1. John Chrysestom Muyingo  John Chrysestom Muyingo is a Ugandan educator and politician.\nS2. He is the State Minister for Higher Education in the Ugandan Cabinet.\nS3. He was appointed to that position on 6 June 2016.\nS4. He previously served as the Stat Minister for Primary Education from 1 March 2015 until 5 June 2016.\nS5. Before that, from 27 May 2011 until 1 March 2015, he served as the State Minister for Higher Education, having replaced Mwesigwa Rukutana in May 2011.\nS6. Muyingo is also the elected Member of Parliament for Bamunanika County, Luweero District.\nS7. Muyingo was born on 22 February 1960 to John Chrysestom Ssekidde of Kakoola Village, Bamunanika County, Luwero District and Victoria Nakiwala of Naakulabye, Lubaga Division, in Kampala, Uganda's capital.\nS8. He attended the Mulajje Primary School, Kisubi Seminary, and Makerere College School, before joining Makerere University in 1983.\nS9. He graduated in 1986 with a Bachelor of Science with a Diploma in Education.\nS10. He also holds a Master of Arts in Educational Management, obtained in 1996, and a Doctor of Philosophy obtained in 2004, both from Makerere University.\nS11. The dissertation for his doctorate focused on the financing of university education in Uganda.\n\nPassage 3: Title (S0) - Ministry of Education and Sports (Uganda)\nS1. Ministry of Education and Sports (Uganda)  The Ministry of Education and Sports (MES), is a cabinet-level ministry of Uganda.\nS2. It is mandated \"to provide technical support, guide, coordinate, regulate and promote quality education, training and sports to all persons in Uganda for national integration, development and individual advancement\", according to the website of the ministry.\nS3. The headquarters of the ministry are located in Embassy House, on King George VI Way, at the corner with Parliament Avenue, in the Central Division of Kampala, Uganda's capital and largest city.\nS4. The coordinates of the ministry headquarters are:0\u00b018'50.0\"N, 32\u00b035'15.0\"E (Latitude:0.313889; Longitude:32.587500).\nS5. The ministry is overseen by a cabinet minister, currently Janet Museveni, since 6 June 2016.\nS6. She is assisted by three ministers of state; (a) Rosemary Seninde serves as Minister of State for Primary Education, (b)\nS7. John Chrysestom Muyingo serves as Minister of State for Secondary Education, and Charles Bakkabulindi serves as Minister of State for sports.\n    \nInput Question:\nWho is the state minister for primary education in uganda?\n\nCorrect Response:\nUganda has had several State Ministers for Primary Education. Rosemary Seninde is the State Minister for Primary Education in the Ugandan Cabinet. She was appointed to that position on 6 June 2016, replacing John Chrysostom Muyingo who previously served as the State Minister for Primary Education from 1 March 2015 until 5 June 2016.\n\nModel Prediction:\nThere are several officials in Uganda's government who are the State Ministers of Education. Rosemary Seninde is the State Minister for Primary Education in the Ugandan Cabinet. John Chrysestom Muyingo is the State Minister for Higher Education. Charles Bakkabulindi is the Minister of State for sports.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "There are several officials in Uganda's government who are the State Ministers of Education. Rosemary Seninde is the State Minister for Primary Education in the Ugandan Cabinet. [John Chrysestom Muyingo is the State Minister for Higher Education. Charles Bakkabulindi is the Minister of State for sports.]\n\nExplanation:\n1. The information about John Chrysestom Muyingo being the State Minister for Higher Education and Charles Bakkabulindi being the Minister of State for sports is irrelevant to the question asking about the State Minister for Primary Education. Therefore, these spans are marked as \"Irrelevant\"."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. There are several officials in Uganda's government who are the State Ministers of Education.\nS2. Rosemary Seninde is the State Minister for Primary Education in the Ugandan Cabinet.\nS3. John Chrysestom Muyingo is the State Minister for Higher Education.\nS4. Charles Bakkabulindi is the Minister of State for sports.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation:\nAll the facts presented in the model prediction are consistent with the information provided in the passages."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 3 [Missing Major Auxiliary Information]\n2. Passage 2, sentence 4 [Missing Major Auxiliary Information]\n\nExplanation:\n1. The model prediction failed to mention that Rosemary Seninde was appointed to the position of State Minister for Primary Education on 6 June 2016, which is crucial auxiliary information that helps to understand the current status of the position.\n2. The model prediction also missed the information that John Chrysostom Muyingo served as the State Minister for Primary Education from 1 March 2015 until 5 June 2016, which is important to understand the history of the position."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "Rosemary Seninde is the State Minister for Primary Education in the Ugandan Cabinet. She was appointed to that position on 6 June 2016. Prior to her, John Chrysostom Muyingo served as the State Minister for Primary Education from 1 March 2015 until 5 June 2016."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 178, "end": 245}, {"error type": "Irrelevant", "explanation": "", "start": 246, "end": 303}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [3]}, {"error type": "Missing-Minor-Auxiliary", "passage_id": 2, "sentence_id": [4]}], "corrected-prediction": "There are several officials in Uganda's government who are the State Ministers of Education. Rosemary Seninde is the State Minister for Primary Education in the Ugandan Cabinet. She was appointed to that position on 6 June 2016, replacing John Chrysostom Muyingo who previously served as the State Minister for Primary Education from 1 March 2015 until 5 June 2016."}}, {"question": "Who was the dallas cowboys quarterback in 2002?", "passages": [["Dallas Cowboys", "That game was very costly when veteran quarterback Troy Aikman suffered a serious concussion which ultimately ended his career.", "Longtime NFL QB Randall Cunningham filled in for Aikman for the rest of the season at QB.", "The Cowboys finished the season in 4th place with a 5\u201311 record.", "The only highlights of 2000 were Emmitt Smith having his 10th consecutive 1,000 yard rushing season and a season sweep over the Redskins.", "2001 was another hard year in Dallas.", "Prior to the season starting Aikman was released from the team and he retired due to the concussions he had received.", "Jerry Jones signed Tony Banks as a QB.", "Banks had been a starter for half of the season the previous year for the Super Bowl Champion Baltimore Ravens before being benched.", "Jones also drafted QB Quincy Carter in the second round of that year's draft, but Banks was released during the preseason.", "Ryan Leaf, Anthony Wright, and Clint Stoerner all competed for the quarterback position that season.", "Dallas again finished at 5\u201311, last place in the NFC East.", "They did sweep the Redskins for the 4th consecutive season.", "Prior to the 2002 season Dallas drafted safety Roy Williams with the 8th overall pick.", "The season started out low as the Cowboys lost to the expansion Houston Texans 19\u201310 on Week 1."]], "gold": "There were several quarterbacks for the Dallas Cowboys in 2002. Chad Hutchinson and Quincy Carter were both quarterbacks in 2002. Quincy Carter started the most that year.", "prediction 1": "Ryan Leaf, Anthony Wright, and Clint Stoerner all competed for the quarterback position that season. The Cowboys finished the season in 4th place with a 5\u201311 record. Prior to the 2002 season Dallas drafted safety Roy Williams with the 8th overall pick.", "prediction 2": "The 2002 Dallas Cowboys quarterback was Tony Banks, who had been the team's starter for half of the season the previous year for the Super Bowl Champion Baltimore Ravens before being benched. Ryan Leaf, Anthony Wright, and Clint Stoerner all competed for the quarterback position that season. Before the 2002 season Dallas drafted safety Roy Williams with the 8th overall pick. The Cowboys finished the season in 4th place with a 5\u201311 record.", "prediction 3": "Tony Banks was the Dallas Cowboys quarterback in 2002. Bryan Bryant was the quarterback for the Dallas Cowboys in 2001.", "prediction 4": "Ryan Leaf, Anthony Wright, and Clint Stoerner all competed for the quarterback position that season. Dallas finished the 2002 season at 5\u201311, last place in the NFC East.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 0, "end": 100}, {"error type": "Irrelevant", "explanation": "", "start": 166, "end": 252}, {"error type": "Unverifiable", "start": 0, "end": 100}], "missing-info": [], "corrected-prediction": "The quarterbacks for the Dallas Cowboys in 2002 were Chad Hutchinson and Quincy Carter. Quincy Carter started the most that year."}, "preference": [1, 1, 1, 2, 2, 2], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Dallas Cowboys\nS1. That game was very costly when veteran quarterback Troy Aikman suffered a serious concussion which ultimately ended his career.\nS2. Longtime NFL QB Randall Cunningham filled in for Aikman for the rest of the season at QB.\nS3. The Cowboys finished the season in 4th place with a 5\u201311 record.\nS4. The only highlights of 2000 were Emmitt Smith having his 10th consecutive 1,000 yard rushing season and a season sweep over the Redskins.\nS5. 2001 was another hard year in Dallas.\nS6. Prior to the season starting Aikman was released from the team and he retired due to the concussions he had received.\nS7. Jerry Jones signed Tony Banks as a QB.\nS8. Banks had been a starter for half of the season the previous year for the Super Bowl Champion Baltimore Ravens before being benched.\nS9. Jones also drafted QB Quincy Carter in the second round of that year's draft, but Banks was released during the preseason.\nS10. Ryan Leaf, Anthony Wright, and Clint Stoerner all competed for the quarterback position that season.\nS11. Dallas again finished at 5\u201311, last place in the NFC East.\nS12. They did sweep the Redskins for the 4th consecutive season.\nS13. Prior to the 2002 season Dallas drafted safety Roy Williams with the 8th overall pick.\nS14. The season started out low as the Cowboys lost to the expansion Houston Texans 19\u201310 on Week 1.\n    \nInput Question:\nWho was the dallas cowboys quarterback in 2002?\n\nCorrect Response:\nThere were several quarterbacks for the Dallas Cowboys in 2002. Chad Hutchinson and Quincy Carter were both quarterbacks in 2002. Quincy Carter started the most that year.\n\nModel Prediction:\nRyan Leaf, Anthony Wright, and Clint Stoerner all competed for the quarterback position that season. The Cowboys finished the season in 4th place with a 5\u201311 record. Prior to the 2002 season Dallas drafted safety Roy Williams with the 8th overall pick.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "[Ryan Leaf, Anthony Wright, and Clint Stoerner all competed for the quarterback position that season.] The Cowboys finished the season in 4th place with a 5\u201311 record. [Prior to the 2002 season Dallas drafted safety Roy Williams with the 8th overall pick.]\n\nExplanation:\n1. The first sentence is irrelevant as it does not provide the correct information about the Dallas Cowboys' quarterback in 2002.\n2. The third sentence is also irrelevant as it talks about a safety player drafted by the Cowboys, not about their quarterback."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. Ryan Leaf, Anthony Wright, and Clint Stoerner all competed for the quarterback position that season.\nS2. The Cowboys finished the season in 4th place with a 5\u201311 record.\nS3. Prior to the 2002 season Dallas drafted safety Roy Williams with the 8th overall pick.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "1. S1\n\nExplanation:\n1. The first sentence is inconsistent with the passages. The passages do not mention Ryan Leaf, Anthony Wright, and Clint Stoerner as quarterbacks for the Dallas Cowboys in 2002."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. [Missing Answer] - The model prediction does not mention the correct quarterbacks for the Dallas Cowboys in 2002, which are Chad Hutchinson and Quincy Carter.\n\nExplanation:\n1. The model prediction does not provide the correct answer to the question. The passages do not provide information on who the quarterbacks were for the Dallas Cowboys in 2002, but the correct answer is Chad Hutchinson and Quincy Carter."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The quarterbacks for the Dallas Cowboys in 2002 were Chad Hutchinson and Quincy Carter. Quincy Carter started the most that year."}], "feedback_human": {"errors": [{"error type": "Wrong-Grounding", "explanation": "{\"passage_id\":1,\"sentence_id\":[5]}", "start": 166, "end": 252}, {"error type": "Wrong-Grounding", "explanation": "{\"passage_id\":1,\"sentence_id\":[5]}", "start": 0, "end": 165}], "missing-info": [], "corrected-prediction": ""}}, {"question": "Who died in harry potter half blood prince?", "passages": [["Harry Potter and the Half-Blood Prince", "Rowling revealed the title of \"Half-Blood Prince\" on her website on 24 June 2004.", "This was the title she had once considered for the second book, \"Chamber of Secrets\", though she decided that the information disclosed belonged later on in the story, in book six.", "On 21 December 2004, she announced she had finished writing it, along with the release date of 16 July.", "Bloomsbury unveiled the cover on 8 March 2005.", "The record-breaking publication of \"Half-Blood Prince\" was accompanied by controversy.", "In May 2005, bookmakers in the UK suspended bets on which main character would die in the book amid fears of insider knowledge.", "A number of high value bets were made on the death of Albus Dumbledore, many coming from the town of Bungay where, it was believed, the books were being printed at the time.", "Betting was later reopened.", "Additionally, in response to Greenpeace's campaign on using forest friendly paper for big-name authors, Bloomsbury published the book on 30% recycled paper.", "In early July 2005, a Real Canadian Superstore in Coquitlam, British Columbia, Canada, accidentally sold fourteen copies of \"The Half-Blood Prince\" before the authorised release date."], ["Harry Potter and the Half-Blood Prince (film)", "Harry Potter and the Half-Blood Prince (film)\n\nHarry Potter and the Half-Blood Prince is a 2009 fantasy film directed by David Yates and distributed by Warner Bros. Pictures.", "It is based on J. K. Rowling's 2005 novel of the same name.", "The film, which is the sixth instalment in the \"Harry Potter\" film series, was written by Steve Kloves and produced by David Heyman and David Barron.", "The story follows Harry Potter's sixth year at Hogwarts as he receives a mysterious textbook, falls in love, and attempts to retrieve a memory that holds the key to Lord Voldemort's downfall.", "The film stars Daniel Radcliffe as Harry Potter, alongside Rupert Grint and Emma Watson as Harry's best friends Ron Weasley and Hermione Granger.", "It is the sequel to \"Harry Potter and the Order of the Phoenix\" and is followed by \"Harry Potter and the Deathly Hallows \u2013 Part 1\".", "Filming began on 24 September 2007, leading to the film's worldwide cinematic release on 15 July 2009, one day short of the fourth anniversary of the corresponding novel's release.", "The film was simultaneously released in regular cinemas and IMAX 3D everywhere except North America, where its IMAX release was delayed for two weeks."], ["Harry Potter and the Half-Blood Prince", "Harry Potter and the Half-Blood Prince\n\nHarry Potter and the Half-Blood Prince is a fantasy novel written by British author J. K. Rowling and the sixth and penultimate novel in the \"Harry Potter\" series.", "Set during protagonist Harry Potter's sixth year at Hogwarts, the novel explores the past of Harry's nemesis, Lord Voldemort, and Harry's preparations for the final battle against Voldemort alongside his headmaster and mentor Albus Dumbledore.", "The book was published in the United Kingdom by Bloomsbury, and in the United States by Scholastic on 16 July 2005, as well as in several other countries.", "It sold nine million copies in the first 24\u00a0hours after its release, a record at the time which was eventually broken by its sequel, \"Harry Potter and the Deathly Hallows\".", "There were many controversies before and after it was published, including the right to read the copies delivered prior to the release date in Canada.", "Reception to the novel was generally positive and it won several awards and honours, including the 2006 British Book of the Year award.", "Reviewers noted that the book took on a darker tone than its previous predecessors, though it did contain some humour.", "Some considered the main themes to be love, death, trust, and redemption.", "The considerable character development of Harry and many other teenage characters also drew attention."]], "gold": "Harry Potter and the Half-Blood Prince is both a fantasy novel written by British author J.K. Rowling and a 2009 fantasy film directed by David Yates. One of the main characters, Albus Dumbledore, dies in both the book and the film. There is also an enormous, sentient spider capable of speech, who made a unique clicking noise as he moved named Aragog the Acromantula, who dies.", "prediction 1": "Harry Potter and the Half-Blood Prince is a 2005 fantasy novel written by British author J. K. Rowling. It is the sixth and penultimate novel in the Harry Potter series. Albus Dumbledore dies in the novel, which was published in the United Kingdom by Bloomsbury and in the United States by Scholastic on 16 July 2005. A 2009 fantasy film based on the book was released in the United States on 15 July 2009.", "prediction 2": "Harry Potter and the Half-Blood Prince is a fantasy novel written by British author J. K. Rowling, and the sixth and penultimate novel in the Harry Potter series. The book explores the past of Harry's nemesis, Lord Voldemort, and Harry's preparations for the final battle against Voldemort alongside his headmaster and mentor Albus Dumbledore. In the book, several characters die, including the teacher Albus Dumbledore, who dies in the book.", "prediction 3": "Harry Potter and the Half-Blood Prince is a 2005 fantasy novel written by British author J. K. Rowling and the sixth and penultimate novel in the Harry Potter series. It was written by Rowling and set during protagonist Harry Potter's sixth year at Hogwarts. In the book, several characters die, including Albus Dumbledore, Ron Weasley, Hermione Granger, and more. In the 2009 film, the death of Ron Weasley is included.", "prediction 4": "Harry Potter and the Half-Blood Prince is a fantasy novel written by British author J. K. Rowling and the sixth and penultimate novel in the Harry Potter series. The novel explores the past of Harry's nemesis, Lord Voldemort, and Harry's preparations for the final battle against Voldemort alongside his headmaster and mentor Albus Dumbledore. In the book, there is a death of Professor Snape, a professor of magical knowledge, and a few deaths of others. However, there is also a number of characters who die in the book. In the 2009, a couple dies. In the film, there is a number of high value bets were made on the death of Albus Dumbledore.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 318, "end": 406}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 1, "sentence_id": [7]}], "corrected-prediction": "Harry Potter and the Half-Blood Prince is a 2005 fantasy novel written by British author J. K. Rowling. It is the sixth and penultimate novel in the Harry Potter series. In this novel, Albus Dumbledore and Aragog the Acromantula die. The book was published in the United Kingdom by Bloomsbury and in the United States by Scholastic on 16 July 2005."}, "preference": [1, 1, 1, 1, 1, 1], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Harry Potter and the Half-Blood Prince\nS1. Rowling revealed the title of \"Half-Blood Prince\" on her website on 24 June 2004.\nS2. This was the title she had once considered for the second book, \"Chamber of Secrets\", though she decided that the information disclosed belonged later on in the story, in book six.\nS3. On 21 December 2004, she announced she had finished writing it, along with the release date of 16 July.\nS4. Bloomsbury unveiled the cover on 8 March 2005.\nS5. The record-breaking publication of \"Half-Blood Prince\" was accompanied by controversy.\nS6. In May 2005, bookmakers in the UK suspended bets on which main character would die in the book amid fears of insider knowledge.\nS7. A number of high value bets were made on the death of Albus Dumbledore, many coming from the town of Bungay where, it was believed, the books were being printed at the time.\nS8. Betting was later reopened.\nS9. Additionally, in response to Greenpeace's campaign on using forest friendly paper for big-name authors, Bloomsbury published the book on 30% recycled paper.\nS10. In early July 2005, a Real Canadian Superstore in Coquitlam, British Columbia, Canada, accidentally sold fourteen copies of \"The Half-Blood Prince\" before the authorised release date.\n\nPassage 2: Title (S0) - Harry Potter and the Half-Blood Prince (film)\nS1. Harry Potter and the Half-Blood Prince (film)  Harry Potter and the Half-Blood Prince is a 2009 fantasy film directed by David Yates and distributed by Warner Bros. Pictures.\nS2. It is based on J. K. Rowling's 2005 novel of the same name.\nS3. The film, which is the sixth instalment in the \"Harry Potter\" film series, was written by Steve Kloves and produced by David Heyman and David Barron.\nS4. The story follows Harry Potter's sixth year at Hogwarts as he receives a mysterious textbook, falls in love, and attempts to retrieve a memory that holds the key to Lord Voldemort's downfall.\nS5. The film stars Daniel Radcliffe as Harry Potter, alongside Rupert Grint and Emma Watson as Harry's best friends Ron Weasley and Hermione Granger.\nS6. It is the sequel to \"Harry Potter and the Order of the Phoenix\" and is followed by \"Harry Potter and the Deathly Hallows \u2013 Part 1\".\nS7. Filming began on 24 September 2007, leading to the film's worldwide cinematic release on 15 July 2009, one day short of the fourth anniversary of the corresponding novel's release.\nS8. The film was simultaneously released in regular cinemas and IMAX 3D everywhere except North America, where its IMAX release was delayed for two weeks.\n\nPassage 3: Title (S0) - Harry Potter and the Half-Blood Prince\nS1. Harry Potter and the Half-Blood Prince  Harry Potter and the Half-Blood Prince is a fantasy novel written by British author J. K. Rowling and the sixth and penultimate novel in the \"Harry Potter\" series.\nS2. Set during protagonist Harry Potter's sixth year at Hogwarts, the novel explores the past of Harry's nemesis, Lord Voldemort, and Harry's preparations for the final battle against Voldemort alongside his headmaster and mentor Albus Dumbledore.\nS3. The book was published in the United Kingdom by Bloomsbury, and in the United States by Scholastic on 16 July 2005, as well as in several other countries.\nS4. It sold nine million copies in the first 24\u00a0hours after its release, a record at the time which was eventually broken by its sequel, \"Harry Potter and the Deathly Hallows\".\nS5. There were many controversies before and after it was published, including the right to read the copies delivered prior to the release date in Canada.\nS6. Reception to the novel was generally positive and it won several awards and honours, including the 2006 British Book of the Year award.\nS7. Reviewers noted that the book took on a darker tone than its previous predecessors, though it did contain some humour.\nS8. Some considered the main themes to be love, death, trust, and redemption.\nS9. The considerable character development of Harry and many other teenage characters also drew attention.\n    \nInput Question:\nWho died in harry potter half blood prince?\n\nCorrect Response:\nHarry Potter and the Half-Blood Prince is both a fantasy novel written by British author J.K. Rowling and a 2009 fantasy film directed by David Yates. One of the main characters, Albus Dumbledore, dies in both the book and the film. There is also an enormous, sentient spider capable of speech, who made a unique clicking noise as he moved named Aragog the Acromantula, who dies.\n\nModel Prediction:\nHarry Potter and the Half-Blood Prince is a 2005 fantasy novel written by British author J. K. Rowling. It is the sixth and penultimate novel in the Harry Potter series. Albus Dumbledore dies in the novel, which was published in the United Kingdom by Bloomsbury and in the United States by Scholastic on 16 July 2005. A 2009 fantasy film based on the book was released in the United States on 15 July 2009.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "Harry Potter and the Half-Blood Prince is a 2005 fantasy novel written by British author J. K. Rowling. It is the sixth and penultimate novel in the Harry Potter series. Albus Dumbledore dies in the novel, which was published in the United Kingdom by Bloomsbury and in the United States by Scholastic on 16 July 2005. [A 2009 fantasy film based on the book was released in the United States on 15 July 2009.]\n\nExplanation:\n1. The last sentence in the model prediction is irrelevant as it does not provide any information about who died in the Harry Potter Half-Blood Prince, which is the main question. It is neither an answer nor crucial auxiliary information. Thus, it should be marked as \"Irrelevant\"."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. Harry Potter and the Half-Blood Prince is a 2005 fantasy novel written by British author J. K. Rowling.\nS2. It is the sixth and penultimate novel in the Harry Potter series.\nS3. Albus Dumbledore dies in the novel, which was published in the United Kingdom by Bloomsbury and in the United States by Scholastic on 16 July 2005.\nS4. A 2009 fantasy film based on the book was released in the United States on 15 July 2009.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation:\nAll the facts in the model prediction are consistent with the information provided in the passages."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 7 [Missing Answer]\n\nExplanation:\n1. The model prediction does not mention the death of Aragog the Acromantula, which is a missing answer from the question."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "Harry Potter and the Half-Blood Prince is a 2005 fantasy novel written by British author J. K. Rowling. It is the sixth and penultimate novel in the Harry Potter series. In this novel, Albus Dumbledore and Aragog the Acromantula die. The book was published in the United Kingdom by Bloomsbury and in the United States by Scholastic on 16 July 2005."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 104, "end": 169}, {"error type": "Irrelevant", "explanation": "", "start": 206, "end": 317}, {"error type": "Irrelevant", "explanation": "", "start": 318, "end": 406}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 2, "sentence_id": [1]}], "corrected-prediction": "Harry Potter and the Half-Blood Prince is a 2005 fantasy novel written by British author J. K. Rowling and a 2009 fantasy film directed by David Yates. It is the sixth and penultimate novel in the Harry Potter series. The character, Albus Dumbledore, dies in the novel."}}, {"question": "Shapes with diagonals that are not equal in length?", "passages": [["Quadrilateral", "In two-dimensional Euclidean space, expressing vector AC as a free vector in Cartesian space equal to (x\",\"y\") and BD as (x\",\"y\"), this can be rewritten as:\n\nIn the following table it is listed if the diagonals in some of the most basic quadrilaterals bisect each other, if their diagonals are perpendicular, and if their diagonals have equal length.", "The list applies to the most general cases, and excludes named subsets.", "\"Note 1: The most general trapezoids and isosceles trapezoids do not have perpendicular diagonals, but there are infinite numbers of (non-similar) trapezoids and isosceles trapezoids that do have perpendicular diagonals and are not any other named quadrilateral.\"", "\"Note 2: In a kite, one diagonal bisects the other.", "The most general kite has unequal diagonals, but there is an infinite number of (non-similar) kites in which the diagonals are equal in length (and the kites are not any other named quadrilateral).\"", "The lengths of the diagonals in a convex quadrilateral \"ABCD\" can be calculated using the law of cosines on each triangle formed by one diagonal and two sides of the quadrilateral."], ["Rectangle", "Rectangle\n\nIn Euclidean plane geometry, a rectangle is a quadrilateral with four right angles.", "It can also be defined as an equiangular quadrilateral, since equiangular means that all of its angles are equal (360\u00b0/4 = 90\u00b0).", "It can also be defined as a parallelogram containing a right angle.", "A rectangle with four sides of equal length is a square.", "The term oblong is occasionally used to refer to a non-square rectangle.", "A rectangle with vertices \"ABCD\" would be denoted as .", "The word rectangle comes from the Latin \"rectangulus\", which is a combination of \"rectus\" (as an adjective, right, proper) and \"angulus\" (angle).", "A crossed rectangle is a crossed (self-intersecting) quadrilateral which consists of two opposite sides of a rectangle along with the two diagonals.", "It is a special case of an antiparallelogram, and its angles are not right angles.", "Other geometries, such as spherical, elliptic, and hyperbolic, have so-called rectangles with opposite sides equal in length and equal angles that are not right angles.", "Rectangles are involved in many tiling problems, such as tiling the plane by rectangles or tiling a rectangle by polygons."]], "gold": "There are several shapes that have diagonal sides that are not equal in length. For instance, a rhomboid is a shape that has diagonal adjacent sides that are unequal in length. Another shape is the oblong, which is rectangular with diagonal adjacent sides that are not equal in length. And, the most general kite shape has diagonals that are not equal in length.", "prediction 1": "In Euclidean plane geometry, a quadrilateral is a quadrilateral with four right angles. In other geometries, such as spherical, elliptic, and hyperbolic, have so-called rectangles with opposite sides equal in length and equal angles that are not right angles.", "prediction 2": "In Euclidean plane geometry, a quadrilateral is a quadrilateral with four right angles and can also be defined as an equiangular quadrilateral, since equiangular means that all of its angles are equal. A rectangle with four sides of equal length is a square. In non-square quadrilaterals, where opposite sides of a quadrilateral are equal in length and the diagonals are perpendicular, there is a single diagonal that bisect the other.", "prediction 3": "The most basic quadrilaterals have diagonals that are not equal in length, they bisect each other, and they are called a kite, trapezoidal, isosceles trapezoidal, or a triangular. Other geometries, such as spherical, elliptic, and hyperbolic, have so-called rectangles with opposite sides equal in length and equal angles that are not right angles.", "prediction 4": "In Euclidean plane geometry, a quadrilateral is a quadrilateral with four right angles. It can also be defined as an equiangular quadrilateral, since equiangular means that all of its angles are equal. A rectangle with four sides of equal length is a square. The lengths of the diagonals in a cross quadrilateral \"ABCD\" can be calculated using the law of cosines on each triangle formed by one diagonal and two sides of the quadrilateral.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 0, "end": 87}, {"error type": "Irrelevant", "explanation": "", "start": 88, "end": 259}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 1, "sentence_id": [5]}], "corrected-prediction": "Several shapes have diagonals that are not equal in length. For instance, the most general kite shape has diagonals that are not equal in length. Another shape is the oblong, which is a non-square rectangle with diagonals that are not equal in length."}, "preference": [1, 2, 2, 2, 2, 1], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Quadrilateral\nS1. In two-dimensional Euclidean space, expressing vector AC as a free vector in Cartesian space equal to (x\",\"y\") and BD as (x\",\"y\"), this can be rewritten as:  In the following table it is listed if the diagonals in some of the most basic quadrilaterals bisect each other, if their diagonals are perpendicular, and if their diagonals have equal length.\nS2. The list applies to the most general cases, and excludes named subsets.\nS3. \"Note 1: The most general trapezoids and isosceles trapezoids do not have perpendicular diagonals, but there are infinite numbers of (non-similar) trapezoids and isosceles trapezoids that do have perpendicular diagonals and are not any other named quadrilateral.\"\nS4. \"Note 2: In a kite, one diagonal bisects the other.\nS5. The most general kite has unequal diagonals, but there is an infinite number of (non-similar) kites in which the diagonals are equal in length (and the kites are not any other named quadrilateral).\"\nS6. The lengths of the diagonals in a convex quadrilateral \"ABCD\" can be calculated using the law of cosines on each triangle formed by one diagonal and two sides of the quadrilateral.\n\nPassage 2: Title (S0) - Rectangle\nS1. Rectangle  In Euclidean plane geometry, a rectangle is a quadrilateral with four right angles.\nS2. It can also be defined as an equiangular quadrilateral, since equiangular means that all of its angles are equal (360\u00b0/4 = 90\u00b0).\nS3. It can also be defined as a parallelogram containing a right angle.\nS4. A rectangle with four sides of equal length is a square.\nS5. The term oblong is occasionally used to refer to a non-square rectangle.\nS6. A rectangle with vertices \"ABCD\" would be denoted as .\nS7. The word rectangle comes from the Latin \"rectangulus\", which is a combination of \"rectus\" (as an adjective, right, proper) and \"angulus\" (angle).\nS8. A crossed rectangle is a crossed (self-intersecting) quadrilateral which consists of two opposite sides of a rectangle along with the two diagonals.\nS9. It is a special case of an antiparallelogram, and its angles are not right angles.\nS10. Other geometries, such as spherical, elliptic, and hyperbolic, have so-called rectangles with opposite sides equal in length and equal angles that are not right angles.\nS11. Rectangles are involved in many tiling problems, such as tiling the plane by rectangles or tiling a rectangle by polygons.\n    \nInput Question:\nShapes with diagonals that are not equal in length?\n\nCorrect Response:\nThere are several shapes that have diagonal sides that are not equal in length. For instance, a rhomboid is a shape that has diagonal adjacent sides that are unequal in length. Another shape is the oblong, which is rectangular with diagonal adjacent sides that are not equal in length. And, the most general kite shape has diagonals that are not equal in length.\n\nModel Prediction:\nIn Euclidean plane geometry, a quadrilateral is a quadrilateral with four right angles. In other geometries, such as spherical, elliptic, and hyperbolic, have so-called rectangles with opposite sides equal in length and equal angles that are not right angles.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "[In Euclidean plane geometry, a quadrilateral is a quadrilateral with four right angles.] [In other geometries, such as spherical, elliptic, and hyperbolic, have so-called rectangles with opposite sides equal in length and equal angles that are not right angles.]\n\nExplanation:\n1. The first sentence is incoherent as it states that a quadrilateral is a quadrilateral with four right angles, which is incorrect. A quadrilateral with four right angles is a rectangle, not a general quadrilateral.\n2. The second sentence is irrelevant as it does not answer the question about shapes with diagonals that are not equal in length. Instead, it talks about rectangles in different geometries, which is not related to the question."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. In Euclidean plane geometry, a quadrilateral is a quadrilateral with four right angles.\nS2. In other geometries, such as spherical, elliptic, and hyperbolic, have so-called rectangles with opposite sides equal in length and equal angles that are not right angles.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "S1\n\nExplanation:\n1. The first sentence is inconsistent with the information in the passages. According to Passage 2, Sentence 1, a quadrilateral with four right angles is a rectangle, not a general quadrilateral."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 5 [Missing Answer]\n2. Passage 2, sentence 5 [Missing Answer]\n\nExplanation:\n1. The model prediction does not mention that the most general kite has unequal diagonals, which is an answer to the question found in Passage 1, Sentence 5.\n2. The model prediction also does not mention that an oblong, which is a non-square rectangle, has unequal diagonals. This is another answer to the question found in Passage 2, Sentence 5."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "Several shapes have diagonals that are not equal in length. For instance, the most general kite shape has diagonals that are not equal in length. Another shape is the oblong, which is a non-square rectangle with diagonals that are not equal in length."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 0, "end": 87}, {"error type": "Irrelevant", "explanation": "", "start": 88, "end": 259}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 1, "sentence_id": [5]}], "corrected-prediction": "The most general kite has unequal diagonals."}}, {"question": "Who got the powers in wizards of waverly place?", "passages": [["Wizards of Waverly Place", "Excluding the crossover programming special, it was the franchise's most-watched episode.", "The closer also set series best among kids 6\u201311 (4.2 million) and teens 9\u201314 (3.8 million).", "It also obtained a solid 1.9 rating with adults 18\u201349.", "Notably, the finale is the current TV season's most-watched cable telecast among scripted programs.", "The show ended with Alex becoming the family wizard, Justin being declared new Headmaster of WizTech (also keeping his wizard powers), and Max getting to run the sub shop.", "On September 27, 2012, Disney Channel announced that \"Wizards of Waverly Place\" would return for an hour-long special, that began production on October 22, 2012, and ended production on November 10, 2012, for a premiere telecast on the cable channel in early 2013.", "The special, executive-produced by Selena Gomez, alongside series executive producers Vince Cheung and Ben Montanio (who also co-wrote the special with Dan Berendsen), centers on the Russos', Mason, and Harper's visit to Italy to meet long-lost relatives from Jerry's side of the family."], ["Wizards of Waverly Place", "The Russos live on Waverly Place in Manhattan's Greenwich Village, above a sandwich shop which they own and run.", "The family consists of siblings Alex (Selena Gomez), Justin (David Henrie), and Max (Jake T. Austin).", "The three teenagers are wizards and live with their Italian father, Jerry (David DeLuise), a former family wizard, and their mortal Mexican mother, Theresa (Maria Canals Barrera).", "When the Russo siblings complete their wizard training, they have to participate in a competition to decide who will become the Family Wizard (the one to keep his/her magical powers forever) of their generation, while the others lose their powers and become mortals.", "Because of this, Jerry tries to teach his children to not become dependent on magic.", "Since one of them gets to keep their powers, though, Jerry also gives his children wizard lessons (the lessons end mid Season four).", "The storage room of the Russo family's sub station is a wizard's lair.", "In the lair is a Portal which allows them to visit the wizard world, and other creatures to visit them.", "The headmaster of the wizard council, Professor Crumbs (Ian Abercrombie), regularly pays visits to the Russo home."]], "gold": "On Wizards of Waverly Place, three siblings, Alex, Justin, and Max Russo, received daily lessons from their father, Jerry Russo, to use their wizard magic correctly. Once they completed their training, the Russo children competed to determine which sibling would retain their powers permanently and become the sole wizard of the family. Alex Russo got the family wizard powers, and Justin Russo got to keep his powers after being declared Headmaster at the end of Waverly Place. Max Russo got the powers but lost them and went on to run the family's sub shop.", "prediction 1": "The show Wizards of Waverly Place begins with Alex, Justin, and Max Russo, all of whom are wizards, living with their Italian father, Jerry, a former family wizard, and their mortal Mexican mother, Theresa. When the Russo siblings finish their wizard training, they have to participate in a competition to decide who will become the Family Wizard of their generation, the one to keep his/her magical powers forever. Justin gets the powers in the final episode, and Alex gets the powers in the final episode.", "prediction 2": "The show Wizards of Waverly Place is a reality TV series that centers on the Russo family, who are wizards living with their Italian father, Jerry (David DeLuise), a former family wizard, and their mortal Mexican mother, Theresa (Maria Canals Barrera). Alex, Justin, and Jake T. Austin, played by Selena Gomez, become the family wizard after completing their wizard training, and are competing to be the one to keep their powers forever. Since one of them gets to keep their powers, though, Jerry also gives his children wizard lessons.", "prediction 3": "The show Wizards of Waverly Place is an American fantasy television series that centers on the Russo family, a group of three teenagers who are wizards living with their Italian father, Jerry (David DeLuise), a former family wizard, and their mortal Mexican mother, Theresa (Maria Canals Barrera). When the Russo siblings complete their wizard training, they have to participate in a competition to decide who will become the Family Wizard (the one to keep his/her magical powers forever) of their generation, while the others lose their powers and become mortals. Since one of them gets to keep their powers, though, Jerry also gives his children wizard lessons.", "prediction 4": "Wizard of Waverly Place focuses on the Russo family, a wizard family that lives with their Mexican mother, Theresa (Maria Canals Barrera). In Season 4, Alex, Justin, and Max get the powers, while Justin gets them from their Uncle Jim, the Headmaster of WizTech.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 416, "end": 507}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 1, "sentence_id": [5]}], "corrected-prediction": "The show Wizards of Waverly Place begins with Alex, Justin, and Max Russo, all of whom are wizards, living with their Italian father, Jerry, a former family wizard, and their mortal Mexican mother, Theresa. When the Russo siblings finish their wizard training, they have to participate in a competition to decide who will become the Family Wizard of their generation, the one to keep his/her magical powers forever. In the end, Alex Russo became the family wizard. Justin Russo was declared the new Headmaster of WizTech and got to keep his wizard powers. Max Russo also initially got the powers but lost them and went on to run the family's sub shop."}, "preference": [1, 1, 1, 1, 1, 1], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Wizards of Waverly Place\nS1. Excluding the crossover programming special, it was the franchise's most-watched episode.\nS2. The closer also set series best among kids 6\u201311 (4.2 million) and teens 9\u201314 (3.8 million).\nS3. It also obtained a solid 1.9 rating with adults 18\u201349.\nS4. Notably, the finale is the current TV season's most-watched cable telecast among scripted programs.\nS5. The show ended with Alex becoming the family wizard, Justin being declared new Headmaster of WizTech (also keeping his wizard powers), and Max getting to run the sub shop.\nS6. On September 27, 2012, Disney Channel announced that \"Wizards of Waverly Place\" would return for an hour-long special, that began production on October 22, 2012, and ended production on November 10, 2012, for a premiere telecast on the cable channel in early 2013.\nS7. The special, executive-produced by Selena Gomez, alongside series executive producers Vince Cheung and Ben Montanio (who also co-wrote the special with Dan Berendsen), centers on the Russos', Mason, and Harper's visit to Italy to meet long-lost relatives from Jerry's side of the family.\n\nPassage 2: Title (S0) - Wizards of Waverly Place\nS1. The Russos live on Waverly Place in Manhattan's Greenwich Village, above a sandwich shop which they own and run.\nS2. The family consists of siblings Alex (Selena Gomez), Justin (David Henrie), and Max (Jake T. Austin).\nS3. The three teenagers are wizards and live with their Italian father, Jerry (David DeLuise), a former family wizard, and their mortal Mexican mother, Theresa (Maria Canals Barrera).\nS4. When the Russo siblings complete their wizard training, they have to participate in a competition to decide who will become the Family Wizard (the one to keep his/her magical powers forever) of their generation, while the others lose their powers and become mortals.\nS5. Because of this, Jerry tries to teach his children to not become dependent on magic.\nS6. Since one of them gets to keep their powers, though, Jerry also gives his children wizard lessons (the lessons end mid Season four).\nS7. The storage room of the Russo family's sub station is a wizard's lair.\nS8. In the lair is a Portal which allows them to visit the wizard world, and other creatures to visit them.\nS9. The headmaster of the wizard council, Professor Crumbs (Ian Abercrombie), regularly pays visits to the Russo home.\n    \nInput Question:\nWho got the powers in wizards of waverly place?\n\nCorrect Response:\nOn Wizards of Waverly Place, three siblings, Alex, Justin, and Max Russo, received daily lessons from their father, Jerry Russo, to use their wizard magic correctly. Once they completed their training, the Russo children competed to determine which sibling would retain their powers permanently and become the sole wizard of the family. Alex Russo got the family wizard powers, and Justin Russo got to keep his powers after being declared Headmaster at the end of Waverly Place. Max Russo got the powers but lost them and went on to run the family's sub shop.\n\nModel Prediction:\nThe show Wizards of Waverly Place begins with Alex, Justin, and Max Russo, all of whom are wizards, living with their Italian father, Jerry, a former family wizard, and their mortal Mexican mother, Theresa. When the Russo siblings finish their wizard training, they have to participate in a competition to decide who will become the Family Wizard of their generation, the one to keep his/her magical powers forever. Justin gets the powers in the final episode, and Alex gets the powers in the final episode.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "The show Wizards of Waverly Place begins with Alex, Justin, and Max Russo, all of whom are wizards, living with their Italian father, Jerry, a former family wizard, and their mortal Mexican mother, Theresa. When the Russo siblings finish their wizard training, they have to participate in a competition to decide who will become the Family Wizard of their generation, the one to keep his/her magical powers forever. [Justin gets the powers in the final episode, and Alex gets the powers in the final episode.]\n\nExplanation:\nThe last sentence is repetitive as it mentions twice that both Justin and Alex get the powers in the final episode. This is incorrect as Justin was declared the new Headmaster of WizTech and kept his wizard powers, while Alex became the family wizard."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The show Wizards of Waverly Place begins with Alex, Justin, and Max Russo, all of whom are wizards, living with their Italian father, Jerry, a former family wizard, and their mortal Mexican mother, Theresa.\nS2. When the Russo siblings finish their wizard training, they have to participate in a competition to decide who will become the Family Wizard of their generation, the one to keep his/her magical powers forever.\nS3. Justin gets the powers in the final episode, and Alex gets the powers in the final episode.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "Inconsistent or Unverifiable Sentences:\n1. S3\n\nExplanation:\nThe third sentence is inconsistent with the information provided in the passages. According to Passage 1, sentence 5, Justin was declared the new Headmaster of WizTech and kept his wizard powers, while Alex became the family wizard. The model prediction incorrectly states that both Justin and Alex get the powers in the final episode."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 5 [Missing Answer]\n2. Passage 1, sentence 5 [Missing Major Auxiliary Information]\n\nExplanation:\n1. The model prediction does not mention that Max Russo also got the powers but lost them and went on to run the family's sub shop. This information is found in Passage 1, sentence 5 and is a direct answer to the question.\n2. The model prediction also misses the major auxiliary information that Justin was declared the new Headmaster of WizTech and kept his wizard powers. This information is also found in Passage 1, sentence 5 and is crucial for understanding the answer."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The show Wizards of Waverly Place begins with Alex, Justin, and Max Russo, all of whom are wizards, living with their Italian father, Jerry, a former family wizard, and their mortal Mexican mother, Theresa. When the Russo siblings finish their wizard training, they have to participate in a competition to decide who will become the Family Wizard of their generation, the one to keep his/her magical powers forever. In the end, Alex Russo became the family wizard. Justin Russo was declared the new Headmaster of WizTech and got to keep his wizard powers. Max Russo also initially got the powers but lost them and went on to run the family's sub shop."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 165, "end": 206}], "missing-info": [{"error type": "Missing-Minor-Auxiliary", "passage_id": 2, "sentence_id": [6]}, {"error type": "Missing-Minor-Auxiliary", "passage_id": 1, "sentence_id": [5]}], "corrected-prediction": "The show Wizards of Waverly Place begins with Alex, Justin, and Max Russo, all of whom are wizards, living with their Italian father, Jerry, a former family wizard.  Jerry also gives his children wizard lessons. When the Russo siblings finish their wizard training, they have to participate in a competition to decide who will become the Family Wizard of their generation, the one to keep his/her magical powers forever. The show ended with Alex becoming the family wizard, Justin being declared new Headmaster of WizTech (also keeping his wizard powers), and Max getting to run the sub shop."}}, {"question": "Who sings the theme song of doc mcstuffins?", "passages": [["Doc McStuffins", "Doc McStuffins\n\nDoc McStuffins (also known as Doc McStuffins: Toy Hospital in the fourth season and Doc McStuffins: Pet Rescue for the fifth season) is an American-Irish animated children's television series produced by Brown Bag Films.", "It was created and executive produced by Chris Nee and premiered on March 23, 2012, on Disney Channel and Disney Junior.", "The series is about a girl who can \"fix\" toys, with help from her toy friends.", "It features songs written and composed by Kay Hanley and Michelle Lewis.", "The series received positive reviews due to the show's concept and the main character, as well as its portrayal of African-Americans (Nee stated in 2013 that Doc is African-American, proposed by Disney during her initial pitch, Nee initially only knowing she wanted a girl doctor) in a Disney series.", "Chris Nee describes the series as \"\"Cheers\" for Preschoolers.\"", "On November 16, 2016, the series was renewed for a fifth season by Disney Junior.", "On April 4, 2018, Lara Jill Miller, the voice of Lambie, said that the final episode of the final season has been recorded.", "The show will end after five seasons."], ["China Anne McClain", "China Anne McClain\n\nChina Anne McClain (born August 25, 1998) is an American actress and singer.", "She is a member of the sister girl group McClain.", "McClain's career began in 2005 when she was seven years old, acting in the film \"The Gospel\" (2005).", "She also played China James in \"Tyler Perry's Daddy's Little Girls\" (2007), along with Idris Elba and her two sisters.", "However, she became nationally known after 2007, when she joined the cast of the series \"Tyler Perry's House of Payne\" as Jazmine Payne.", "In 2010, she co-starred in \"Grown Ups\" (2010) as Charlotte McKenzie.", "McClain became internationally known after starring in the Disney Channel original television series \"A.N.T. Farm\", landing the role as Chyna Parks, from 2011 to 2014.", "Disney released the soundtrack of the television series \"A.N.T. Farm\" on October 11, 2011.", "McClain sings six songs and two solos with her sisters on the soundtrack, which debuted in the \"Billboard\" 200 at number 29 with 14,000 copies sold in its first week.", "On the soundtrack, McClain sang her version of Taio Cruz's \"Dynamite.\""], ["Amber Riley", "Amber Riley\n\nAmber Patrice Riley (born February 15, 1986) is an American actress, singer and author.", "She is best known for her portrayal of Mercedes Jones on the Fox comedy-drama series \"Glee\" (2009\u20132015).", "For her performance on the series, she won a Screen Actors Guild Award, and has been nominated for three Teen Choice Awards, three NAACP Image Awards, and a Grammy Award.", "In November 2016, Riley led the West End debut of \"Dreamgirls\", playing the lead role of Effie White.", "She won the Laurence Olivier Award for Best Actress in a Musical in 2017 for her role in \"Dreamgirls\".", "Riley won season 17 of \"Dancing with the Stars\" in 2013.", "In 2017, Riley appeared as a judge on BBC One musical theatre talent show \"Let It Shine\" and formed a musical theatre supergroup with Beverley Knight and Cassidy Janson, known collectively as Leading Ladies and signed to East West Records/Warner.", "Their debut album, \"Songs from the Stage\", was released on November 17, 2017.", "Riley was born in Los Angeles, California, the daughter of Tiny (n\u00e9e Hightower) and Elwin Riley.", "She has two older sisters, Toyia and Ashley.", "Riley auditioned for \"American Idol\" when she was 17 years old, during the show's second season, but was turned down by the producers."]], "gold": "Several singers have sung the theme song of the children's TV series Doc McStuffins. China Anne McClain, an American actress and singer, sang it in Seasons 1 to 3 of the series. Amber Patrice Riley sang it after Season 4. Riley is an American actress, singer, author, and activist.", "prediction 1": "American actress, singer and songwriter Amber Riley sings the theme song of the American-Irish animated children's television series Doc McStuffins.", "prediction 2": "American actress and singer Amber Riley sings the theme song of the American-Irish animated children's television series Doc McStuffins. Every episode of Doc McStuffins begins with the song \"Dynamite.\" The theme song was sang by American actress and singer China Anne McClain from the soundtrack of Disney Channel's A.N.T. Farm and was first released on October 11, 2011.", "prediction 3": "Doc McStuffins is an American-Irish animated children's television series produced by Brown Bag Films. Doc McStuffins's theme song was sung by several artists. Amber Riley, an American actress, and singer, sang a version of Taio Cruz's \"Dynamite\". On April 14, 2019, Lambie had her final episode recorded.", "prediction 4": "American actress Amber Riley, who plays Mercedes Jones in the American animated television series Doc McStuffins, also sings the title song of the show. The song is performed by the all-female group, The McClain Sisters. The song is sung by American singer, songwriter, and songwriter Pippa Ruff, who sings the theme song of the show.", "feedback": {"errors": [], "missing-info": [{"error type": "Missing-Answer", "passage_id": 2, "sentence_id": [7]}], "corrected-prediction": "China Anne McClain, an American actress and singer, sang the theme song for the children's TV series Doc McStuffins in Seasons 1 to 3."}, "preference": [1, 2, 1, 2, 0, 1], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Doc McStuffins\nS1. Doc McStuffins  Doc McStuffins (also known as Doc McStuffins: Toy Hospital in the fourth season and Doc McStuffins: Pet Rescue for the fifth season) is an American-Irish animated children's television series produced by Brown Bag Films.\nS2. It was created and executive produced by Chris Nee and premiered on March 23, 2012, on Disney Channel and Disney Junior.\nS3. The series is about a girl who can \"fix\" toys, with help from her toy friends.\nS4. It features songs written and composed by Kay Hanley and Michelle Lewis.\nS5. The series received positive reviews due to the show's concept and the main character, as well as its portrayal of African-Americans (Nee stated in 2013 that Doc is African-American, proposed by Disney during her initial pitch, Nee initially only knowing she wanted a girl doctor) in a Disney series.\nS6. Chris Nee describes the series as \"\"Cheers\" for Preschoolers.\"\nS7. On November 16, 2016, the series was renewed for a fifth season by Disney Junior.\nS8. On April 4, 2018, Lara Jill Miller, the voice of Lambie, said that the final episode of the final season has been recorded.\nS9. The show will end after five seasons.\n\nPassage 2: Title (S0) - China Anne McClain\nS1. China Anne McClain  China Anne McClain (born August 25, 1998) is an American actress and singer.\nS2. She is a member of the sister girl group McClain.\nS3. McClain's career began in 2005 when she was seven years old, acting in the film \"The Gospel\" (2005).\nS4. She also played China James in \"Tyler Perry's Daddy's Little Girls\" (2007), along with Idris Elba and her two sisters.\nS5. However, she became nationally known after 2007, when she joined the cast of the series \"Tyler Perry's House of Payne\" as Jazmine Payne.\nS6. In 2010, she co-starred in \"Grown Ups\" (2010) as Charlotte McKenzie.\nS7. McClain became internationally known after starring in the Disney Channel original television series \"A.N.T. Farm\", landing the role as Chyna Parks, from 2011 to 2014.\nS8. Disney released the soundtrack of the television series \"A.N.T. Farm\" on October 11, 2011.\nS9. McClain sings six songs and two solos with her sisters on the soundtrack, which debuted in the \"Billboard\" 200 at number 29 with 14,000 copies sold in its first week.\nS10. On the soundtrack, McClain sang her version of Taio Cruz's \"Dynamite.\"\n\nPassage 3: Title (S0) - Amber Riley\nS1. Amber Riley  Amber Patrice Riley (born February 15, 1986) is an American actress, singer and author.\nS2. She is best known for her portrayal of Mercedes Jones on the Fox comedy-drama series \"Glee\" (2009\u20132015).\nS3. For her performance on the series, she won a Screen Actors Guild Award, and has been nominated for three Teen Choice Awards, three NAACP Image Awards, and a Grammy Award.\nS4. In November 2016, Riley led the West End debut of \"Dreamgirls\", playing the lead role of Effie White.\nS5. She won the Laurence Olivier Award for Best Actress in a Musical in 2017 for her role in \"Dreamgirls\".\nS6. Riley won season 17 of \"Dancing with the Stars\" in 2013.\nS7. In 2017, Riley appeared as a judge on BBC One musical theatre talent show \"Let It Shine\" and formed a musical theatre supergroup with Beverley Knight and Cassidy Janson, known collectively as Leading Ladies and signed to East West Records/Warner.\nS8. Their debut album, \"Songs from the Stage\", was released on November 17, 2017.\nS9. Riley was born in Los Angeles, California, the daughter of Tiny (n\u00e9e Hightower) and Elwin Riley.\nS10. She has two older sisters, Toyia and Ashley.\nS11. Riley auditioned for \"American Idol\" when she was 17 years old, during the show's second season, but was turned down by the producers.\n    \nInput Question:\nWho sings the theme song of doc mcstuffins?\n\nCorrect Response:\nSeveral singers have sung the theme song of the children's TV series Doc McStuffins. China Anne McClain, an American actress and singer, sang it in Seasons 1 to 3 of the series. Amber Patrice Riley sang it after Season 4. Riley is an American actress, singer, author, and activist.\n\nModel Prediction:\nAmerican actress, singer and songwriter Amber Riley sings the theme song of the American-Irish animated children's television series Doc McStuffins.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "American actress, singer and songwriter Amber Riley sings the theme song of the American-Irish animated children's television series Doc McStuffins.\n\nExplanation: There are no irrelevant, incoherent or repetitive spans in the model prediction. The information provided is relevant to the question, coherent, and not repetitive."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. American actress, singer and songwriter Amber Riley sings the theme song of the American-Irish animated children's television series Doc McStuffins.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "S1\n\nExplanation:\nThe model prediction states that Amber Riley sings the theme song of Doc McStuffins, but this fact is unverifiable as the passages do not provide any information to support this claim."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 2, sentence 7 [Missing Answer]\n\nExplanation:\n1. The model prediction is missing the information that China Anne McClain also sang the theme song for Doc McStuffins in Seasons 1 to 3. This information is crucial to fully answer the question and can be found in Passage 2, sentence 7."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "China Anne McClain, an American actress and singer, sang the theme song for the children's TV series Doc McStuffins in Seasons 1 to 3."}], "feedback_human": {"errors": [{"error type": "Wrong-Grounding", "explanation": "{\"passage_id\":3,\"sentence_id\":[1]}", "start": 29, "end": 39}, {"error type": "Unverifiable", "explanation": "", "start": 52, "end": 79}], "missing-info": [], "corrected-prediction": "Doc McStuffins is a children's television series. "}}, {"question": "What profile has the most followers on instagram?", "passages": [["Cristiano Ronaldo", "He topped the list for the second straight year with earnings of $93\u00a0million in 2016\u201317.", "Ronaldo is one of the world's most marketable athletes: \"SportsPro\" rated him the fifth most marketable athlete in 2012, and eighth most marketable athlete in 2013, with Brazilian footballer Neymar topping both lists.", "Sports market research company Repucom named Ronaldo the most marketable and most recognised football player in the world in May 2014.", "He was additionally named in the 2014 Time 100, \"Time\"s annual list of the most influential people in the world.", "ESPN named Ronaldo the world's most famous athlete in 2016, 2017 and 2018.", "Ronaldo has established a strong online presence; the most popular sportsperson on social media, he counted 158\u00a0million total followers across Facebook, Twitter and Instagram by June 2015.", ", he has the world's biggest Facebook fanbase with 103\u00a0million followers: he became the first sportsperson to reach 50\u00a0million followers in August 2010, and in October 2014, he became the first sportsperson, and the second person after Shakira, to reach 100\u00a0million followers.", "By June 2017, Ronaldo had 277\u00a0million followers across social media.", "His sponsors earned $936\u00a0million in media value across his social media accounts between June 2016 to June 2017."], ["Celebrity branding", "Companies can simply tag the username for the businesses Instagram page to allow other potential consumers to browse through that Instagram account in just one click.", "The culture of advertising on Instagram came naturally when businesses realized that celebrities have a direct means of communication to their target demographic.", "According to the Telegraph (2015), the ten most popular Instagram accounts are all celebrities who all have around 30 million followers.", "By partnering with one of these celebrities, businesses are already reaching an engaged and targeted audience of 30 million people.", "Many of America's top-earning celebrities Instagram accounts are continually promoting products such as health supplements, vitamins and detox teas.", "These aren't spontaneous proclamations, but rather posts paid for by brands to advertise products to the celebrities' sizable following.", "On Instagram alone a profile with three-to-seven million followers can charge as much as $75,000 per endorsement, even a profile with 50,000 to 500,000 followers might make $1000 for a post on Instagram.", "At the top end of the digital celebrity pay scale some posts can earn around $300,000, especially when Instagram pictures can be easily linked to other social media platforms such as Facebook or Twitter.", "One of the celebrities that is most well known for promoting brands on her Instagram page is Kim Kardashian."]], "gold": "As of September 2021, the most-followed individual on Instagram is Portuguese footballer Cristiano Ronaldo, or @cristiano, with over 340 million followers. However, with its own brand account, Instagram, or @instagram, is the most followed account overall with over 420 million followers.", "prediction 1": "Instagram is a photo-sharing platform, which means you can follow almost any profile you want on Instagram. There are several different Instagram profiles that have the most followers, some have more than 30 million followers, and some have less than 30 million followers. For example, Kim Kardashian has the most followers on Instagram, followed by a profile with 77 million followers, followed by the rapper Rihanna.", "prediction 2": "The Instagram profile with the most followers on Instagram is the one of Brazilian footballer Neymar, who has more than 260 million followers.", "prediction 3": "The Instagram profile with the most followers is the profile of footballer Cristiano Ronaldo, who has 277 million followers and has the most followers on Instagram. The profile of singer Beyonce, who has the most followers, has the most followers on Instagram.", "prediction 4": "The profile with the most followers on Instagram is the one belonging to Brazilian footballer Neymar, who has 277 million followers. The profile with the most followers on Instagram is the one belonging to American singer Justin Bieber, who has about 215 million followers.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 0, "end": 272}, {"error type": "Unverifiable", "start": 273, "end": 418}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 1, "sentence_id": [7]}], "corrected-prediction": "The profile with the most followers on Instagram is that of Cristiano Ronaldo, who had 277 million followers as of June 2017."}, "preference": [0, 2, 0, 2, 0, 1], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Cristiano Ronaldo\nS1. He topped the list for the second straight year with earnings of $93\u00a0million in 2016\u201317.\nS2. Ronaldo is one of the world's most marketable athletes: \"SportsPro\" rated him the fifth most marketable athlete in 2012, and eighth most marketable athlete in 2013, with Brazilian footballer Neymar topping both lists.\nS3. Sports market research company Repucom named Ronaldo the most marketable and most recognised football player in the world in May 2014.\nS4. He was additionally named in the 2014 Time 100, \"Time\"s annual list of the most influential people in the world.\nS5. ESPN named Ronaldo the world's most famous athlete in 2016, 2017 and 2018.\nS6. Ronaldo has established a strong online presence; the most popular sportsperson on social media, he counted 158\u00a0million total followers across Facebook, Twitter and Instagram by June 2015.\nS7. , he has the world's biggest Facebook fanbase with 103\u00a0million followers: he became the first sportsperson to reach 50\u00a0million followers in August 2010, and in October 2014, he became the first sportsperson, and the second person after Shakira, to reach 100\u00a0million followers.\nS8. By June 2017, Ronaldo had 277\u00a0million followers across social media.\nS9. His sponsors earned $936\u00a0million in media value across his social media accounts between June 2016 to June 2017.\n\nPassage 2: Title (S0) - Celebrity branding\nS1. Companies can simply tag the username for the businesses Instagram page to allow other potential consumers to browse through that Instagram account in just one click.\nS2. The culture of advertising on Instagram came naturally when businesses realized that celebrities have a direct means of communication to their target demographic.\nS3. According to the Telegraph (2015), the ten most popular Instagram accounts are all celebrities who all have around 30 million followers.\nS4. By partnering with one of these celebrities, businesses are already reaching an engaged and targeted audience of 30 million people.\nS5. Many of America's top-earning celebrities Instagram accounts are continually promoting products such as health supplements, vitamins and detox teas.\nS6. These aren't spontaneous proclamations, but rather posts paid for by brands to advertise products to the celebrities' sizable following.\nS7. On Instagram alone a profile with three-to-seven million followers can charge as much as $75,000 per endorsement, even a profile with 50,000 to 500,000 followers might make $1000 for a post on Instagram.\nS8. At the top end of the digital celebrity pay scale some posts can earn around $300,000, especially when Instagram pictures can be easily linked to other social media platforms such as Facebook or Twitter.\nS9. One of the celebrities that is most well known for promoting brands on her Instagram page is Kim Kardashian.\n    \nInput Question:\nWhat profile has the most followers on instagram?\n\nCorrect Response:\nAs of September 2021, the most-followed individual on Instagram is Portuguese footballer Cristiano Ronaldo, or @cristiano, with over 340 million followers. However, with its own brand account, Instagram, or @instagram, is the most followed account overall with over 420 million followers.\n\nModel Prediction:\nInstagram is a photo-sharing platform, which means you can follow almost any profile you want on Instagram. There are several different Instagram profiles that have the most followers, some have more than 30 million followers, and some have less than 30 million followers. For example, Kim Kardashian has the most followers on Instagram, followed by a profile with 77 million followers, followed by the rapper Rihanna.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "[Instagram is a photo-sharing platform, which means you can follow almost any profile you want on Instagram. There are several different Instagram profiles that have the most followers, some have more than 30 million followers, and some have less than 30 million followers.] For example, Kim Kardashian has the most followers on Instagram, followed by a profile with 77 million followers, followed by the rapper Rihanna.\n\nExplanation:\n1. The first two sentences in the model prediction are irrelevant as they do not provide a direct answer to the question nor do they provide crucial auxiliary information. They are general statements about Instagram that do not contribute to answering the question about which profile has the most followers on Instagram."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. Instagram is a photo-sharing platform, which means you can follow almost any profile you want on Instagram.\nS2. There are several different Instagram profiles that have the most followers, some have more than 30 million followers, and some have less than 30 million followers.\nS3. For example, Kim Kardashian has the most followers on Instagram, followed by a profile with 77 million followers, followed by the rapper Rihanna.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "1. S3\n\nExplanation:\n1. The claim that Kim Kardashian has the most followers on Instagram is inconsistent with the information provided in the passages. According to Passage 1, Sentence 7, Cristiano Ronaldo has the most followers on Instagram."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 7 [Missing Answer]\n\nExplanation:\n1. The model prediction is missing the correct answer to the question, which is that Cristiano Ronaldo has the most followers on Instagram. This information can be found in Passage 1, Sentence 7."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The profile with the most followers on Instagram is that of Cristiano Ronaldo, who had 277 million followers as of June 2017."}], "feedback_human": {"errors": [{"error type": "Unverifiable", "explanation": "", "start": 0, "end": 107}, {"error type": "Unverifiable", "explanation": "", "start": 273, "end": 418}, {"error type": "Irrelevant", "explanation": "", "start": 108, "end": 272}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 1, "sentence_id": [6]}], "corrected-prediction": "Ronaldo has established a strong online presence; the most popular sportsperson on social media, he counted 158 million total followers across Facebook, Twitter and Instagram by June 2015."}}, {"question": "When was the last time mount cameroon erupted?", "passages": [["Mount Cameroon", "Mount Cameroon\n\nMount Cameroon is an active volcano in Cameroon near the Gulf of Guinea.", "Mount Cameroon is also known as Cameroon Mountain or Fako (the name of the higher of its two peaks) or by its native name Mongo ma Ndemi (\"Mountain of Greatness\").", "It is the highest point in sub-Saharan western and central Africa, the fourth-most prominent peak in Africa, and the 31st-most prominent in the world.", "The mountain is part of the area of volcanic activity known as the Cameroon Volcanic Line, which also includes Lake Nyos, the site of a disaster in 1986.", "The most recent eruption occurred on February 3, 2012.", "Mount Cameroon is one of Africa's largest volcanoes, rising to above the coast of west Cameroon.", "It rises from the coast through tropical rainforest to a bare summit, which is cold, windy, and occasionally dusted with snow.", "The massive steep-sided volcano of dominantly basaltic-to-trachybasaltic composition forms a volcanic horst constructed above a basement of Precambrian metamorphic rocks covered with Cretaceous to Quaternary sediments.", "More than 100 small cinder cones, often fissure-controlled parallel to the long axis of the massive volcano, occur on the flanks and surrounding lowlands."]], "gold": "Mount Cameroon is an active volcano in the South West region of Cameroon next to the city of Buea near the Gulf of Guinea. It is the highest point in sub-Saharan western and central Africa, the fourth-most prominent peak in Africa, and the 31st-most prominent in the world. The mountain is part of the area of volcanic activity known as the Cameroon Volcanic Line, which also includes Lake Nyos, the site of a disaster in 1986. The most recent eruption occurred on February 3, 2012.  ", "prediction 1": "Mount Cameroon is an active volcano in Cameroon near the Gulf of Guinea, Africa. The most recent eruption occurred on February 3, 2012.", "prediction 2": "Mount Cameroon is an active volcano in Cameroon near the Gulf of Guinea. The most recent eruption occurred on February 3, 2012, the last time it erupted was on March 6, 2012.", "prediction 3": "Mount Cameroon is an active volcano in Cameroon near the Gulf of Guinea. The last time Mount Cameroon erupted was on February 3, 2012.", "prediction 4": "Mount Cameroon is an active volcano in Cameroon near the Gulf of Guinea, which is also known as Cameroon Mountain or Fako, which is the name of the higher of its two peaks, or by its native name Mongo ma Ndemi (\"Mountain of Greatness\"). The last time Mount Cameroon erupted was on February 3, 2012.", "feedback": {"errors": [], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [3]}], "corrected-prediction": "Mount Cameroon is an active volcano in Cameroon near the Gulf of Guinea, Africa. It is the highest point in sub-Saharan western and central Africa, the fourth-most prominent peak in Africa, and the 31st-most prominent in the world. The mountain is part of the area of volcanic activity known as the Cameroon Volcanic Line, which also includes Lake Nyos, the site of a disaster in 1986. The most recent eruption occurred on February 3, 2012."}, "preference": [0, 0, 1, 0, 1, 1], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Mount Cameroon\nS1. Mount Cameroon  Mount Cameroon is an active volcano in Cameroon near the Gulf of Guinea.\nS2. Mount Cameroon is also known as Cameroon Mountain or Fako (the name of the higher of its two peaks) or by its native name Mongo ma Ndemi (\"Mountain of Greatness\").\nS3. It is the highest point in sub-Saharan western and central Africa, the fourth-most prominent peak in Africa, and the 31st-most prominent in the world.\nS4. The mountain is part of the area of volcanic activity known as the Cameroon Volcanic Line, which also includes Lake Nyos, the site of a disaster in 1986.\nS5. The most recent eruption occurred on February 3, 2012.\nS6. Mount Cameroon is one of Africa's largest volcanoes, rising to above the coast of west Cameroon.\nS7. It rises from the coast through tropical rainforest to a bare summit, which is cold, windy, and occasionally dusted with snow.\nS8. The massive steep-sided volcano of dominantly basaltic-to-trachybasaltic composition forms a volcanic horst constructed above a basement of Precambrian metamorphic rocks covered with Cretaceous to Quaternary sediments.\nS9. More than 100 small cinder cones, often fissure-controlled parallel to the long axis of the massive volcano, occur on the flanks and surrounding lowlands.\n    \nInput Question:\nWhen was the last time mount cameroon erupted?\n\nCorrect Response:\nMount Cameroon is an active volcano in the South West region of Cameroon next to the city of Buea near the Gulf of Guinea. It is the highest point in sub-Saharan western and central Africa, the fourth-most prominent peak in Africa, and the 31st-most prominent in the world. The mountain is part of the area of volcanic activity known as the Cameroon Volcanic Line, which also includes Lake Nyos, the site of a disaster in 1986. The most recent eruption occurred on February 3, 2012.  \n\nModel Prediction:\nMount Cameroon is an active volcano in Cameroon near the Gulf of Guinea, Africa. The most recent eruption occurred on February 3, 2012.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "Mount Cameroon is an active volcano in Cameroon near the Gulf of Guinea, Africa. The most recent eruption occurred on February 3, 2012.\n\nExplanation: There are no irrelevant, incoherent, or repetitive spans in the model prediction. The information provided is relevant to the question, coherent, and not repetitive."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. Mount Cameroon is an active volcano in Cameroon near the Gulf of Guinea, Africa.\nS2. The most recent eruption occurred on February 3, 2012.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation: All the facts in the model prediction are consistent with the information provided in the passages. There are no unverifiable or inconsistent facts."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 3 [Missing Major Auxiliary Information]\n2. Passage 1, sentence 4 [Missing Major Auxiliary Information]\n\nExplanation:\n1. The model prediction misses the information about Mount Cameroon being the highest point in sub-Saharan western and central Africa, the fourth-most prominent peak in Africa, and the 31st-most prominent in the world. This information, found in Passage 1, sentence 3, is crucial for understanding the significance of Mount Cameroon and is included in the reference response.\n2. The model prediction also misses the information that Mount Cameroon is part of the area of volcanic activity known as the Cameroon Volcanic Line, which also includes Lake Nyos, the site of a disaster in 1986. This information, found in Passage 1, sentence 4, provides important context about the volcanic activity in the region and is included in the reference response."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "Mount Cameroon is an active volcano in Cameroon near the Gulf of Guinea, Africa. It is the highest point in sub-Saharan western and central Africa, the fourth-most prominent peak in Africa, and the 31st-most prominent in the world. The mountain is part of the area of volcanic activity known as the Cameroon Volcanic Line, which also includes Lake Nyos, the site of a disaster in 1986. The most recent eruption occurred on February 3, 2012."}], "feedback_human": {"errors": [], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [3]}, {"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [4]}], "corrected-prediction": "Mount Cameroon is an active volcano in Cameroon near the Gulf of Guinea, Africa. It is the highest point in sub-Saharan western and central Africa, the fourth-most prominent peak in Africa, and the 31st-most prominent in the world. The mountain is part of the area of volcanic activity known as the Cameroon Volcanic Line, which also includes Lake Nyos, the site of a disaster in 1986. The most recent eruption occurred on February 3, 2012."}}, {"question": "Who is the current managing director of nnpc?", "passages": [["Nigerian National Petroleum Corporation", "Nigerian National Petroleum Corporation\n\nThe Nigerian National Petroleum Corporation (NNPC) is the oil corporation through which the federal government of Nigeria regulates and participates in the country's petroleum industry.", "NNPC was established on 1 April 1977 as a merger of the Nigerian National Oil Corporation and the Federal Ministry of Mines and Steel.", "NNPC by law manages the joint venture between the Nigerian federal government and a number of foreign multinational corporations, which include Royal Dutch Shell, Agip, ExxonMobil, Total S.A, Chevron, and Texaco (now merged with Chevron).", "Through collaboration with these companies, the Nigerian government conducts petroleum exploration and production.", "In 2007, the head of the Nigerian wing of Transparency International said salaries for NNPC workers were too low to prevent graft.", "The NNPC Towers in Abuja is the headquarters of NNPC.", "Consisting of four identical towers, the complex is located on Herbert Macaulay Way, Central Business District Abuja.", "NNPC also has zonal offices in Lagos, Kaduna, Port Harcourt and Warri.", "It has an international office located in London, United Kingdom.", "Dr. Maikanti Baru is the current Group managing director."], ["Emmanuel Ibe Kachikwu", "Emmanuel Ibe Kachikwu\n\nEmmanuel Ibe Kachikwu (born December 18, 1956) is the Minister of State, Petroleum Resources and the immediate past Group Managing Director, Nigerian National Petroleum Corporation married to Elizabeth Kachikwu.", "Kachikwu is a graduate of Law from the University of Nigeria, Nsukka and Nigerian Law School.", "He thereafter obtained a Masters and Doctorate Degree in Law from Harvard University, with distinctions.", "He also has a Higher Diploma .T.L", "(H.DIP.T.L) from Georgetown University, USA.", "Kachikwu is married to Elizabeth Kachikwu.", "He was appointed as the Nigerian National Petroleum Corporation Chief Executive to wide public acclaim in August, 2015 under the presidency of Muhammadu Buhari.", "On November 11, 2015, Kachikwu was named the Minister of State, Petroleum Resources by the President.", "He was named as the Chairman of the Board of the Nigerian National Petroleum Corporation, as provided for under Section 1(2) of the Nigerian National Petroleum Corporation Act of 1997, as amended on 4th of July, 2016.", "He was removed as the GMD of the NNPC by President Muhammadu Buhari and replaced with Dr. Maikanti K. Baru on 4th of July, 2016."]], "gold": "The Nigerian National Petroleum Corporation is the oil corporation through which the federal government of Nigeria regulates and participates in the country's petroleum industry. Joseph Thlama Dawha was appointed as the managing director of Nigerian National Petroleum Corporation by president Goodluck Jonathan serving from August 2014 to 1 August 2015. This made him the 16th managing director. The 17th managing director, politician and engineer,  Dr. Emmanuel Ibe Kachikwu was appointed as in August 2015 under the presidency of Muhammadu Buhari. The 18th group manager was Maikanti Kachalla Baru who served from July 2016 to July 2019.", "prediction 1": "The Nigerian National Petroleum Corporation is the oil corporation through which the federal government of Nigeria regulates and participates in the country's petroleum industry. Dr. Maikanti Baru is the current Group managing director of NNPC. Emmanuel Ibe Kachikwu, who was the immediate past GMD, was removed as the GMD by President Muhammadu Buhari and replaced by Dr. Maikanti K. Baru on 4th of July, 2016.", "prediction 2": "The Nigerian National Petroleum Corporation (NNPC) is the oil corporation through which the federal government of Nigeria regulates and participates in the country's petroleum industry. Emmanuel Ibe Kachikwu is the Minister of State, Petroleum Resources and the immediate past Group Managing Director, Nigerian National Petroleum Corporation married to Elizabeth Kachikwu. Dr. Maikanti Baru is the current Group managing director.", "prediction 3": "The Nigerian National Petroleum Corporation (NNPC) is the oil corporation through which the Federal Government of Nigeria regulates and participates in the country's petroleum industry. Emmanuel Ibe Kachikwu is the Minister of State, Petroleum Resources and the immediate past Group Managing Director of the Nigerian National Petroleum Corporation. Dr. Maikanti Baru is the current Group managing director of the NNPC.", "prediction 4": "The Nigerian National Petroleum Corporation (NNPC) is the oil corporation through which the federal government of Nigeria regulates and participates in the country's petroleum industry. Dr. Maikanti Baru is the current Group managing director of the NNPC. Before Baru, Emmanuel Ibe Kachikwu was the GMD of the NNPC.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 245, "end": 411}], "missing-info": [], "corrected-prediction": "The Nigerian National Petroleum Corporation is the oil corporation through which the federal government of Nigeria regulates and participates in the country's petroleum industry. Dr. Maikanti Baru is the current Group managing director of NNPC."}, "preference": [1, 0, 0, 2, 2, 1], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Nigerian National Petroleum Corporation\nS1. Nigerian National Petroleum Corporation  The Nigerian National Petroleum Corporation (NNPC) is the oil corporation through which the federal government of Nigeria regulates and participates in the country's petroleum industry.\nS2. NNPC was established on 1 April 1977 as a merger of the Nigerian National Oil Corporation and the Federal Ministry of Mines and Steel.\nS3. NNPC by law manages the joint venture between the Nigerian federal government and a number of foreign multinational corporations, which include Royal Dutch Shell, Agip, ExxonMobil, Total S.A, Chevron, and Texaco (now merged with Chevron).\nS4. Through collaboration with these companies, the Nigerian government conducts petroleum exploration and production.\nS5. In 2007, the head of the Nigerian wing of Transparency International said salaries for NNPC workers were too low to prevent graft.\nS6. The NNPC Towers in Abuja is the headquarters of NNPC.\nS7. Consisting of four identical towers, the complex is located on Herbert Macaulay Way, Central Business District Abuja.\nS8. NNPC also has zonal offices in Lagos, Kaduna, Port Harcourt and Warri.\nS9. It has an international office located in London, United Kingdom.\nS10. Dr. Maikanti Baru is the current Group managing director.\n\nPassage 2: Title (S0) - Emmanuel Ibe Kachikwu\nS1. Emmanuel Ibe Kachikwu  Emmanuel Ibe Kachikwu (born December 18, 1956) is the Minister of State, Petroleum Resources and the immediate past Group Managing Director, Nigerian National Petroleum Corporation married to Elizabeth Kachikwu.\nS2. Kachikwu is a graduate of Law from the University of Nigeria, Nsukka and Nigerian Law School.\nS3. He thereafter obtained a Masters and Doctorate Degree in Law from Harvard University, with distinctions.\nS4. He also has a Higher Diploma .T.L\nS5. (H.DIP.T.L) from Georgetown University, USA.\nS6. Kachikwu is married to Elizabeth Kachikwu.\nS7. He was appointed as the Nigerian National Petroleum Corporation Chief Executive to wide public acclaim in August, 2015 under the presidency of Muhammadu Buhari.\nS8. On November 11, 2015, Kachikwu was named the Minister of State, Petroleum Resources by the President.\nS9. He was named as the Chairman of the Board of the Nigerian National Petroleum Corporation, as provided for under Section 1(2) of the Nigerian National Petroleum Corporation Act of 1997, as amended on 4th of July, 2016.\nS10. He was removed as the GMD of the NNPC by President Muhammadu Buhari and replaced with Dr. Maikanti K. Baru on 4th of July, 2016.\n    \nInput Question:\nWho is the current managing director of nnpc?\n\nCorrect Response:\nThe Nigerian National Petroleum Corporation is the oil corporation through which the federal government of Nigeria regulates and participates in the country's petroleum industry. Joseph Thlama Dawha was appointed as the managing director of Nigerian National Petroleum Corporation by president Goodluck Jonathan serving from August 2014 to 1 August 2015. This made him the 16th managing director. The 17th managing director, politician and engineer,  Dr. Emmanuel Ibe Kachikwu was appointed as in August 2015 under the presidency of Muhammadu Buhari. The 18th group manager was Maikanti Kachalla Baru who served from July 2016 to July 2019.\n\nModel Prediction:\nThe Nigerian National Petroleum Corporation is the oil corporation through which the federal government of Nigeria regulates and participates in the country's petroleum industry. Dr. Maikanti Baru is the current Group managing director of NNPC. Emmanuel Ibe Kachikwu, who was the immediate past GMD, was removed as the GMD by President Muhammadu Buhari and replaced by Dr. Maikanti K. Baru on 4th of July, 2016.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "The Nigerian National Petroleum Corporation is the oil corporation through which the federal government of Nigeria regulates and participates in the country's petroleum industry. Dr. Maikanti Baru is the current Group managing director of NNPC. [Emmanuel Ibe Kachikwu, who was the immediate past GMD, was removed as the GMD by President Muhammadu Buhari and replaced by Dr. Maikanti K. Baru on 4th of July, 2016.]\n\nExplanation:\nThe last sentence in the model prediction is repetitive as it repeats the information that Dr. Maikanti Baru is the current Group managing director of NNPC, which was already mentioned in the previous sentence. Therefore, it should be marked as \"Repetitive\". Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains a factual or coherence issue. However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The Nigerian National Petroleum Corporation is the oil corporation through which the federal government of Nigeria regulates and participates in the country's petroleum industry.\nS2. Dr. Maikanti Baru is the current Group managing director of NNPC.\nS3. Emmanuel Ibe Kachikwu, who was the immediate past GMD, was removed as the GMD by President Muhammadu Buhari and replaced by Dr. Maikanti K. Baru on 4th of July, 2016.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation:\nAll the facts in the model prediction are consistent with and verifiable by the provided passages."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "None\n\nExplanation:\nThe model prediction includes all the necessary information from the passages to answer the question. It correctly identifies the current managing director of NNPC and provides some context about his predecessor. There is no missing information in the model prediction."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The Nigerian National Petroleum Corporation is the oil corporation through which the federal government of Nigeria regulates and participates in the country's petroleum industry. Dr. Maikanti Baru is the current Group managing director of NNPC."}], "feedback_human": {"errors": [], "missing-info": [], "corrected-prediction": "The Nigerian National Petroleum Corporation is the oil corporation through which the federal government of Nigeria regulates and participates in the country's petroleum industry. Dr. Maikanti Baru is the current Group managing director of NNPC. Emmanuel Ibe Kachikwu, who was the immediate past GMD, was removed as the GMD by President Muhammadu Buhari and replaced by Dr. Maikanti K. Baru on 4th of July, 2016."}}, {"question": "Where did you find the red pandas in india?", "passages": [["Red panda", "The red panda is endemic to the temperate forests of the Himalayas, and ranges from the foothills of western Nepal to China in the east.", "Its easternmost limit is the Qinling Mountains of the Shaanxi Province in China.", "Its range includes southern Tibet, Sikkim and Assam in India, Bhutan, the northern mountains of Burma, and in south-western China, in the Hengduan Mountains of Sichuan and the Gongshan Mountains in Yunnan.", "It may also live in south-west Tibet and northern Arunachal Pradesh, but this has not been documented.", "Locations with the highest density of red pandas include an area in the Himalayas that has been proposed as having been a refuge for a variety of endemic species in the Pleistocene.", "The distribution range of the red panda should be considered disjunct, rather than continuous.", "A disjunct population inhabits the Meghalaya Plateau of north-eastern India.", "During a survey in the 1970s, signs of red pandas were found in Nepal's Dhorpatan Hunting Reserve.", "Their presence was confirmed in spring 2007 when four red pandas were sighted at elevations ranging from .", "The species' westernmost limit is in Rara National Park located farther west of the Dhorpatan Hunting Reserve.", "Their presence was confirmed in 2008.", "The red panda lives between altitude, inhabiting areas of moderate temperature between with little annual change."]], "gold": "In India, the red panda's ranges are from southern Tibet, Sikkim and Assam, with a disjunct population that inhabits the Meghalaya Plateau of north-eastern India.", "prediction 1": "The red panda is endemic to the temperate forests of the Himalayas, and ranges from the foothills of western Nepal to China in the east. Its range includes southern Tibet, Sikkim and Assam in India, Bhutan, the northern mountains of Burma, and in south-western China, in the Hengduan Mountains of Sichuan and the Gongshan Mountains in Yunnan. During a survey in the 1970s, signs of red pandas were found in Nepal's Dhorpatan Hunting Reserve. Their presence was confirmed in spring 2007 when four red pandas were sighted at elevations ranging from.\n", "prediction 2": "During a survey in the 1970s, signs of red pandas were found in Nepal's Dhorpatan Hunting Reserve. Their presence was confirmed in spring 2007 when four red pandas were sighted at elevations ranging from 6,000 to 14,500 feet.", "prediction 3": "Red pandas are found in India in vague numbers. During a survey in the 1970s, signs of red pandas were found in Nepal's Dhorpatan Hunting Reserve. Their presence was confirmed in spring 2007 when four red pandas were sighted at elevations ranging from 0400 m to 2,850 m.", "prediction 4": "When people search for red pandas they find many different ones. In India, the red panda is endemic to the temperate forests of the Himalayas, and ranges from the foothills of western Nepal to China in the east. Their range includes southern Tibet, Sikkim and Assam in India, Bhutan, the northern mountains of Burma, and in south-western China, in the Hengduan Mountains of Sichuan and the Gongshan Mountains in Yunnan and in north-ea.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 343, "end": 547}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 1, "sentence_id": [7]}], "corrected-prediction": "The red panda is endemic to the temperate forests of the Himalayas, and ranges from the foothills of western Nepal to China in the east. Its range includes southern Tibet, Sikkim and Assam in India, Bhutan, the northern mountains of Burma, and in south-western China, in the Hengduan Mountains of Sichuan and the Gongshan Mountains in Yunnan. Additionally, a disjunct population inhabits the Meghalaya Plateau of north-eastern India."}, "preference": [1, 1, 1, 1, 2, 2], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Red panda\nS1. The red panda is endemic to the temperate forests of the Himalayas, and ranges from the foothills of western Nepal to China in the east.\nS2. Its easternmost limit is the Qinling Mountains of the Shaanxi Province in China.\nS3. Its range includes southern Tibet, Sikkim and Assam in India, Bhutan, the northern mountains of Burma, and in south-western China, in the Hengduan Mountains of Sichuan and the Gongshan Mountains in Yunnan.\nS4. It may also live in south-west Tibet and northern Arunachal Pradesh, but this has not been documented.\nS5. Locations with the highest density of red pandas include an area in the Himalayas that has been proposed as having been a refuge for a variety of endemic species in the Pleistocene.\nS6. The distribution range of the red panda should be considered disjunct, rather than continuous.\nS7. A disjunct population inhabits the Meghalaya Plateau of north-eastern India.\nS8. During a survey in the 1970s, signs of red pandas were found in Nepal's Dhorpatan Hunting Reserve.\nS9. Their presence was confirmed in spring 2007 when four red pandas were sighted at elevations ranging from .\nS10. The species' westernmost limit is in Rara National Park located farther west of the Dhorpatan Hunting Reserve.\nS11. Their presence was confirmed in 2008.\nS12. The red panda lives between altitude, inhabiting areas of moderate temperature between with little annual change.\n    \nInput Question:\nWhere did you find the red pandas in india?\n\nCorrect Response:\nIn India, the red panda's ranges are from southern Tibet, Sikkim and Assam, with a disjunct population that inhabits the Meghalaya Plateau of north-eastern India.\n\nModel Prediction:\nThe red panda is endemic to the temperate forests of the Himalayas, and ranges from the foothills of western Nepal to China in the east. Its range includes southern Tibet, Sikkim and Assam in India, Bhutan, the northern mountains of Burma, and in south-western China, in the Hengduan Mountains of Sichuan and the Gongshan Mountains in Yunnan. During a survey in the 1970s, signs of red pandas were found in Nepal's Dhorpatan Hunting Reserve. Their presence was confirmed in spring 2007 when four red pandas were sighted at elevations ranging from.\n\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "The red panda is endemic to the temperate forests of the Himalayas, and ranges from the foothills of western Nepal to China in the east. Its range includes southern Tibet, Sikkim and Assam in India, Bhutan, the northern mountains of Burma, and in south-western China, in the Hengduan Mountains of Sichuan and the Gongshan Mountains in Yunnan. [During a survey in the 1970s, signs of red pandas were found in Nepal's Dhorpatan Hunting Reserve. Their presence was confirmed in spring 2007 when four red pandas were sighted at elevations ranging from.]\n\nExplanation:\nThe last two sentences in the model prediction are irrelevant to the question asked. The question asks about the location of red pandas in India, but these sentences provide information about the presence of red pandas in Nepal. Thus, they should be marked as \"Irrelevant\"."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The red panda is endemic to the temperate forests of the Himalayas, and ranges from the foothills of western Nepal to China in the east.\nS2. Its range includes southern Tibet, Sikkim and Assam in India, Bhutan, the northern mountains of Burma, and in south-western China, in the Hengduan Mountains of Sichuan and the Gongshan Mountains in Yunnan.\nS3. During a survey in the 1970s, signs of red pandas were found in Nepal's Dhorpatan Hunting Reserve.\nS4. Their presence was confirmed in spring 2007 when four red pandas were sighted at elevations ranging from.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation:\nAll the facts presented in the model prediction are consistent with the provided passages and can be verified. Therefore, there are no spans that contain inconsistent or unverifiable facts."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 7 [Missing Answer]\n\nExplanation:\n1. The model prediction does not mention the presence of a disjunct population of red pandas in the Meghalaya Plateau of north-eastern India, which is a crucial piece of information in answering the question about where red pandas can be found in India. Therefore, this information is labeled as \"Missing Answer\"."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The red panda is endemic to the temperate forests of the Himalayas, and ranges from the foothills of western Nepal to China in the east. Its range includes southern Tibet, Sikkim and Assam in India, Bhutan, the northern mountains of Burma, and in south-western China, in the Hengduan Mountains of Sichuan and the Gongshan Mountains in Yunnan. Additionally, a disjunct population inhabits the Meghalaya Plateau of north-eastern India."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 0, "end": 136}, {"error type": "Irrelevant", "explanation": "", "start": 199, "end": 342}, {"error type": "Irrelevant", "explanation": "", "start": 343, "end": 441}, {"error type": "Irrelevant", "explanation": "", "start": 442, "end": 548}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 1, "sentence_id": [7]}], "corrected-prediction": " Its range includes southern Tibet, Sikkim and Assam in India, with a disjunct population inhabits the Meghalaya Plateau of north-eastern India.\n"}}, {"question": "All 5 layers of the earth's atmosphere?", "passages": [["Atmosphere of Earth", "It extends from the exobase, which is located at the top of the thermosphere at an altitude of about 700\u00a0km above sea level, to about 10,000\u00a0km (6,200\u00a0mi; 33,000,000\u00a0ft) where it merges into the solar wind.", "This layer is mainly composed of extremely low densities of hydrogen, helium and several heavier molecules including nitrogen, oxygen and carbon dioxide closer to the exobase.", "The atoms and molecules are so far apart that they can travel hundreds of kilometers without colliding with one another.", "Thus, the exosphere no longer behaves like a gas, and the particles constantly escape into space.", "These free-moving particles follow ballistic trajectories and may migrate in and out of the magnetosphere or the solar wind.", "The exosphere is located too far above Earth for any meteorological phenomena to be possible.", "However, the aurora borealis and aurora australis sometimes occur in the lower part of the exosphere, where they overlap into the thermosphere.", "The exosphere contains most of the satellites orbiting Earth.", "The thermosphere is the second-highest layer of Earth's atmosphere.", "It extends from the mesopause (which separates it from the mesosphere) at an altitude of about up to the thermopause at an altitude range of ."], ["Atmosphere of Earth", "Atmosphere of Earth\n\nThe atmosphere of Earth is the layer of gases, commonly known as air, that surrounds the planet Earth and is retained by Earth's gravity.", "The atmosphere of Earth protects life on Earth by creating pressure allowing for liquid water to exist on the Earth's surface, absorbing ultraviolet solar radiation, warming the surface through heat retention (greenhouse effect), and reducing temperature extremes between day and night (the diurnal temperature variation).", "By volume, dry air contains 78.09% nitrogen, 20.95% oxygen, 0.93% argon, 0.04% carbon dioxide, and small amounts of other gases.", "Air also contains a variable amount of water vapor, on average around 1% at sea level, and 0.4% over the entire atmosphere.", "Air content and atmospheric pressure vary at different layers, and air suitable for use in photosynthesis by terrestrial plants and breathing of terrestrial animals is found only in Earth's troposphere and in artificial atmospheres.", "The atmosphere has a mass of about 5.15\u00a0kg, three quarters of which is within about of the surface.", "The atmosphere becomes thinner and thinner with increasing altitude, with no definite boundary between the atmosphere and outer space.", "The K\u00e1rm\u00e1n line, at , or 1.57% of Earth's radius, is often used as the border between the atmosphere and outer space."], ["Atmosphere of Earth", "Various industrial pollutants also may be present as gases or aerosols, such as chlorine (elemental or in compounds), fluorine compounds and elemental mercury vapor.", "Sulfur compounds such as hydrogen sulfide and sulfur dioxide (SO) may be derived from natural sources or from industrial air pollution.", "The relative concentration of gases remains constant until about .", "In general, air pressure and density decrease with altitude in the atmosphere.", "However, temperature has a more complicated profile with altitude, and may remain relatively constant or even increase with altitude in some regions (see the temperature section, below).", "Because the general pattern of the temperature/altitude profile is constant and measurable by means of instrumented balloon soundings, the temperature behavior provides a useful metric to distinguish atmospheric layers.", "In this way, Earth's atmosphere can be divided (called atmospheric stratification) into five main layers.", "Excluding the exosphere, the atmosphere has four primary layers, which are the troposphere, stratosphere, mesosphere, and thermosphere.", "From highest to lowest, the five main layers are:\n\n", "The exosphere is the outermost layer of Earth's atmosphere (i.e. the upper limit of the atmosphere)."]], "gold": "The atmosphere of Earth, commonly known as air, is the layer of gases retained by Earth's gravity that surrounds the planet and forms its planetary atmosphere. Earth's atmosphere can be divided into 5 layers according to their altitude: Troposhere, 0-7 miles; Stratosphere, 7-31 miles; Mesosphere, 31-50 miles; Thermosphere, 50-440 miles; and Exosphere, 440-6200 miles. The atmosphere of Earth protects life on Earth by creating pressure allowing for liquid water to exist on the Earth's surface, absorbing ultraviolet solar radiation, warming the surface through heat retention, and reducing temperature extremes between day and night.", "prediction 1": "The atmosphere of Earth is the layer of gases, commonly known as air, that surrounds the planet Earth and is retained by Earth's gravity. Excluding the exosphere, the atmosphere is divided into five main layers. From highest to lowest, the five main layers are: The troposphere, stratosphere, mesosphere, and thermosphere.", "prediction 2": "The atmosphere of Earth is the layer of gases, commonly known as air, that surrounds the planet Earth and is retained by Earth's gravity. The Earth's atmosphere protects life on Earth by creating pressure allowing for liquid water to exist on the Earth's surface, absorbing ultraviolet solar radiation, warming the surface through heat retention (greenhouse effect), and reducing temperature extremes between day and night (the diurnal temperature variation). The exosphere is the outermost layer of Earth's atmosphere, located at a height of about 700 km above sea level, and is located at a height of about 600 a height of about a height of about 700 kilometres above sea level, at an altitude of about 700 kilometer above the mesopause, at an altitude of about 700 km above the thermopause at an altitude range of. The thermosphere is located in the second-highest layer of Earth", "prediction 3": "The atmosphere of Earth is the layer of gases, commonly known as air, that surrounds the planet Earth and is retained by Earth's gravity. The five main layers of the atmosphere are: The troposphere, stratosphere, mesosphere, and thermosphere.", "prediction 4": "The atmosphere of Earth is the layer of gases, commonly known as air, that surrounds the planet Earth and is retained by Earth's gravity. The exosphere is the outermost layer of Earth's atmosphere. The thermosphere is the second highest layer of Earth's atmosphere. It extends from the mesopause (which separates it from the mesosphere) at an altitude of about up to the thermopause at an altitude range of.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 138, "end": 162}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 3, "sentence_id": [10]}], "corrected-prediction": "The atmosphere of Earth is the layer of gases, commonly known as air, that surrounds the planet Earth and is retained by Earth's gravity. The atmosphere is divided into five main layers. From highest to lowest, the five main layers are: The exosphere, thermosphere, mesosphere, stratosphere, and troposphere."}, "preference": [2, 1, 2, 1, 1, 2], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Atmosphere of Earth\nS1. It extends from the exobase, which is located at the top of the thermosphere at an altitude of about 700\u00a0km above sea level, to about 10,000\u00a0km (6,200\u00a0mi; 33,000,000\u00a0ft) where it merges into the solar wind.\nS2. This layer is mainly composed of extremely low densities of hydrogen, helium and several heavier molecules including nitrogen, oxygen and carbon dioxide closer to the exobase.\nS3. The atoms and molecules are so far apart that they can travel hundreds of kilometers without colliding with one another.\nS4. Thus, the exosphere no longer behaves like a gas, and the particles constantly escape into space.\nS5. These free-moving particles follow ballistic trajectories and may migrate in and out of the magnetosphere or the solar wind.\nS6. The exosphere is located too far above Earth for any meteorological phenomena to be possible.\nS7. However, the aurora borealis and aurora australis sometimes occur in the lower part of the exosphere, where they overlap into the thermosphere.\nS8. The exosphere contains most of the satellites orbiting Earth.\nS9. The thermosphere is the second-highest layer of Earth's atmosphere.\nS10. It extends from the mesopause (which separates it from the mesosphere) at an altitude of about up to the thermopause at an altitude range of .\n\nPassage 2: Title (S0) - Atmosphere of Earth\nS1. Atmosphere of Earth  The atmosphere of Earth is the layer of gases, commonly known as air, that surrounds the planet Earth and is retained by Earth's gravity.\nS2. The atmosphere of Earth protects life on Earth by creating pressure allowing for liquid water to exist on the Earth's surface, absorbing ultraviolet solar radiation, warming the surface through heat retention (greenhouse effect), and reducing temperature extremes between day and night (the diurnal temperature variation).\nS3. By volume, dry air contains 78.09% nitrogen, 20.95% oxygen, 0.93% argon, 0.04% carbon dioxide, and small amounts of other gases.\nS4. Air also contains a variable amount of water vapor, on average around 1% at sea level, and 0.4% over the entire atmosphere.\nS5. Air content and atmospheric pressure vary at different layers, and air suitable for use in photosynthesis by terrestrial plants and breathing of terrestrial animals is found only in Earth's troposphere and in artificial atmospheres.\nS6. The atmosphere has a mass of about 5.15\u00a0kg, three quarters of which is within about of the surface.\nS7. The atmosphere becomes thinner and thinner with increasing altitude, with no definite boundary between the atmosphere and outer space.\nS8. The K\u00e1rm\u00e1n line, at , or 1.57% of Earth's radius, is often used as the border between the atmosphere and outer space.\n\nPassage 3: Title (S0) - Atmosphere of Earth\nS1. Various industrial pollutants also may be present as gases or aerosols, such as chlorine (elemental or in compounds), fluorine compounds and elemental mercury vapor.\nS2. Sulfur compounds such as hydrogen sulfide and sulfur dioxide (SO) may be derived from natural sources or from industrial air pollution.\nS3. The relative concentration of gases remains constant until about .\nS4. In general, air pressure and density decrease with altitude in the atmosphere.\nS5. However, temperature has a more complicated profile with altitude, and may remain relatively constant or even increase with altitude in some regions (see the temperature section, below).\nS6. Because the general pattern of the temperature/altitude profile is constant and measurable by means of instrumented balloon soundings, the temperature behavior provides a useful metric to distinguish atmospheric layers.\nS7. In this way, Earth's atmosphere can be divided (called atmospheric stratification) into five main layers.\nS8. Excluding the exosphere, the atmosphere has four primary layers, which are the troposphere, stratosphere, mesosphere, and thermosphere.\nS9. From highest to lowest, the five main layers are:  \nS10. The exosphere is the outermost layer of Earth's atmosphere (i.e. the upper limit of the atmosphere).\n    \nInput Question:\nAll 5 layers of the earth's atmosphere?\n\nCorrect Response:\nThe atmosphere of Earth, commonly known as air, is the layer of gases retained by Earth's gravity that surrounds the planet and forms its planetary atmosphere. Earth's atmosphere can be divided into 5 layers according to their altitude: Troposhere, 0-7 miles; Stratosphere, 7-31 miles; Mesosphere, 31-50 miles; Thermosphere, 50-440 miles; and Exosphere, 440-6200 miles. The atmosphere of Earth protects life on Earth by creating pressure allowing for liquid water to exist on the Earth's surface, absorbing ultraviolet solar radiation, warming the surface through heat retention, and reducing temperature extremes between day and night.\n\nModel Prediction:\nThe atmosphere of Earth is the layer of gases, commonly known as air, that surrounds the planet Earth and is retained by Earth's gravity. Excluding the exosphere, the atmosphere is divided into five main layers. From highest to lowest, the five main layers are: The troposphere, stratosphere, mesosphere, and thermosphere.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "The atmosphere of Earth is the layer of gases, commonly known as air, that surrounds the planet Earth and is retained by Earth's gravity. [Excluding the exosphere,] the atmosphere is divided into five main layers. From highest to lowest, the five main layers are: The troposphere, stratosphere, mesosphere, and thermosphere.\n\nExplanation:\n1. The phrase \"Excluding the exosphere,\" is irrelevant because the question asks for all five layers of the Earth's atmosphere, which includes the exosphere."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The atmosphere of Earth is the layer of gases, commonly known as air, that surrounds the planet Earth and is retained by Earth's gravity.\nS2. Excluding the exosphere, the atmosphere is divided into five main layers.\nS3. From highest to lowest, the five main layers are: The troposphere, stratosphere, mesosphere, and thermosphere.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "S3\n\nExplanation:\n1. Sentence 3 is inconsistent with the passages. The model prediction lists only four layers of the Earth's atmosphere, while the passages clearly state that there are five main layers, including the exosphere."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 3, sentence 10 [Missing Answer]\n\nExplanation:\n1. The model prediction is missing the exosphere, which is the fifth layer of the Earth's atmosphere as stated in Passage 3, sentence 10."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The atmosphere of Earth is the layer of gases, commonly known as air, that surrounds the planet Earth and is retained by Earth's gravity. The atmosphere is divided into five main layers. From highest to lowest, the five main layers are: The exosphere, thermosphere, mesosphere, stratosphere, and troposphere."}], "feedback_human": {"errors": [], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 2, "sentence_id": [2]}], "corrected-prediction": "The atmosphere of Earth is the layer of gases, commonly known as air, that surrounds the planet Earth and is retained by Earth's gravity. Excluding the exosphere, the atmosphere is divided into five main layers. From highest to lowest, the five main layers are: The troposphere, stratosphere, mesosphere, and thermosphere and Exosphere. The atmosphere of Earth protects life on Earth by creating pressure allowing for liquid water to exist on the Earth's surface, absorbing ultraviolet solar radiation, warming the surface through heat retention, and reducing temperature extremes between day and night."}}, {"question": "What type of game is assassin's creed?", "passages": [["Assassin's Creed (video game)", "Assassin's Creed (video game)\n\nAssassin's Creed is an action-adventure video game developed by Ubisoft Montreal and published by Ubisoft.", "It is the first installment in the \"Assassin's Creed\" series.", "The game was released for PlayStation 3 and Xbox 360 in November 2007 and was made available on Microsoft Windows in April 2008.", "Also, the game can be played on Xbox One consoles via backward compatibility.", "The plot is set in a fictional history of real-world events and follows the centuries-old struggle between the Assassins, who fight for peace with free will, and the Templars, who desire peace through control.", "The game primarily takes place during the Third Crusade in the Holy Land in 1191, with the plot revolving around the Secret Order of Assassins, based upon the Hashshashin sect.", "The player is, in reality, playing as a modern-day man named Desmond Miles, who, through the use of a machine named the \"Animus\", is allowed the viewing and controlling of the protagonist's genetic memories of his ancestors, in this case, Alta\u00efr Ibn-La'Ahad, a member of the Assassins.", "Through this plot device, details emerge of a struggle between two factions: the Knights Templar and the Assassins, over an artifact known as the \"Apple of Eden\", an ancient artifact used to control minds."], ["Assassin's Creed (video game)", "The game received generally positive reviews, with critics praising its storytelling, visuals, art design, and originality, although the game was also criticized for the repetitive nature of its gameplay.", "\"Assassin's Creed\" won several awards at E3 in 2006, as well as several end-year awards after its release.", "The game spawned a sequel, \"Assassin's Creed II\", which was released in November 2009.", "Since the release and success of \"Assassin's Creed II\", subsequent games have been released, with various other Assassins and time periods.", "\"Assassin's Creed\" is an action-adventure game set in an open world environment and played from a third-person perspective in which the player primarily assumes the role of Alta\u00efr, as experienced by protagonist Desmond Miles.", "The primary goal of the game is to carry out a series of assassinations ordered by Al Mualim, the leader of the Assassins.", "To achieve this goal, the player must travel from the Brotherhood's headquarters in Masyaf, across the terrain of the Holy Land known as the Kingdom to one of three cities\u2014Jerusalem, Acre, or Damascus\u2014to find the Brotherhood agent in that city.", "There, the agent, in addition to providing a safe house, gives the player minimal knowledge about the target and requires them to perform additional reconnaissance missions before attempting the assassination."], ["Assassin's Creed Unity", "Assassin's Creed Unity\n\nAssassin's Creed Unity is an action-adventure video game developed by Ubisoft Montreal and published by Ubisoft.", "It was released in November 2014 for Microsoft Windows, PlayStation 4 and Xbox One.", "It is the eighth major installment in the \"Assassin's Creed\" series, and the successor to 2013's \"\".", "It also has ties to \"Assassin's Creed Rogue\" which was released for the previous generation consoles, the PlayStation 3 and Xbox 360 on the same date.", "The plot is set in a fictional history of real world events and follows the centuries-old struggle between the Assassins, who fight for peace with free will, and the Templars, who desire peace through control.", "The story is set in Paris during the French Revolution; the single-player story follows Arno Victor Dorian in his efforts to expose the true powers behind the Revolution.", "The game retains the series' third-person open world exploration as well as introducing a revamped combat, parkour and stealth system.", "The game also introduces cooperative multiplayer to the \"Assassin's Creed\" series, letting up to four players engage in narrative-driven missions and explore the open world map.", "\"Assassin's Creed Unity\" received mixed reviews upon its release."]], "gold": "Assassin's Creed is a single-player action-adventure video game developed by Ubisoft Montreal and published by Ubisoft. It is the first installment in the Assassin's Creed series. The game was released for PlayStation 3 and Xbox 360 in November 2007 and was made available on Microsoft Windows in April 2008. It is set in an open world environment and played from a third-person perspective.", "prediction 1": "Assassin's Creed is an action-adventure video game developed by Ubisoft Montreal and published by Ubisoft. It is the first installment in the Assassin's Creed series. Assassin's Creed is also known as Assassin's Creed Unity, an action-adventure video game developed by Ubisoft and released by Ubisoft in November 2014 for Microsoft Windows, PlayStation 4, and Xbox One.", "prediction 2": "Assassin's Creed is an action-adventure video game that was developed by Ubisoft Montreal and published by Ubisoft. It is the first installment in the Assassin's Creed series and was released for PlayStation 3 and Xbox 360 in November 2007 and made available on Microsoft Windows in April 2008. Assassin's Creed Unity is an action-adventure video game that was released in November 2014 for Microsoft Windows, PlayStation 4 and Xbox One. It is the eighth major installment in the Assassin's Creed series, the successor to 2013's \"Assassin's Creed Unity\" which was released in November 2014 for Microsoft Windows, PlayStation 4, PlayStation 4 and Xbox One.", "prediction 3": "Assassin's Creed is an action-adventure video game developed by Ubisoft Montreal and published by Ubisoft. It is the first installment in the Assassin's Creed series. Assassin's Creed: Unity is an action-adventure video game developed by Ubisoft and released by Ubisoft. The game is set in an open world environment and played from a third-person perspective in which the player primarily assumes the role of Altar, Assassin's Creed: Origins: Origin is a free to kill the Assassins.", "prediction 4": "Assassin's Creed is an action-adventure video game developed by Ubisoft Montreal and published by Ubisoft. It is the first installment in the Assassin's Creed series. Assassin's Creed Unity is an action-adventure video game developed by Ubisoft Montreal and published by Ubisoft. It was released in November 2014 for Microsoft Windows, PlayStation 4 and Xbox One.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 167, "end": 369}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [3]}], "corrected-prediction": "Assassin's Creed is an action-adventure video game developed by Ubisoft Montreal and published by Ubisoft. It is the first installment in the Assassin's Creed series. The game was released for PlayStation 3 and Xbox 360 in November 2007 and was made available on Microsoft Windows in April 2008. It is set in an open world environment and played from a third-person perspective."}, "preference": [1, 1, 0, 2, 2, 2], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Assassin's Creed (video game)\nS1. Assassin's Creed (video game)  Assassin's Creed is an action-adventure video game developed by Ubisoft Montreal and published by Ubisoft.\nS2. It is the first installment in the \"Assassin's Creed\" series.\nS3. The game was released for PlayStation 3 and Xbox 360 in November 2007 and was made available on Microsoft Windows in April 2008.\nS4. Also, the game can be played on Xbox One consoles via backward compatibility.\nS5. The plot is set in a fictional history of real-world events and follows the centuries-old struggle between the Assassins, who fight for peace with free will, and the Templars, who desire peace through control.\nS6. The game primarily takes place during the Third Crusade in the Holy Land in 1191, with the plot revolving around the Secret Order of Assassins, based upon the Hashshashin sect.\nS7. The player is, in reality, playing as a modern-day man named Desmond Miles, who, through the use of a machine named the \"Animus\", is allowed the viewing and controlling of the protagonist's genetic memories of his ancestors, in this case, Alta\u00efr Ibn-La'Ahad, a member of the Assassins.\nS8. Through this plot device, details emerge of a struggle between two factions: the Knights Templar and the Assassins, over an artifact known as the \"Apple of Eden\", an ancient artifact used to control minds.\n\nPassage 2: Title (S0) - Assassin's Creed (video game)\nS1. The game received generally positive reviews, with critics praising its storytelling, visuals, art design, and originality, although the game was also criticized for the repetitive nature of its gameplay.\nS2. \"Assassin's Creed\" won several awards at E3 in 2006, as well as several end-year awards after its release.\nS3. The game spawned a sequel, \"Assassin's Creed II\", which was released in November 2009.\nS4. Since the release and success of \"Assassin's Creed II\", subsequent games have been released, with various other Assassins and time periods.\nS5. \"Assassin's Creed\" is an action-adventure game set in an open world environment and played from a third-person perspective in which the player primarily assumes the role of Alta\u00efr, as experienced by protagonist Desmond Miles.\nS6. The primary goal of the game is to carry out a series of assassinations ordered by Al Mualim, the leader of the Assassins.\nS7. To achieve this goal, the player must travel from the Brotherhood's headquarters in Masyaf, across the terrain of the Holy Land known as the Kingdom to one of three cities\u2014Jerusalem, Acre, or Damascus\u2014to find the Brotherhood agent in that city.\nS8. There, the agent, in addition to providing a safe house, gives the player minimal knowledge about the target and requires them to perform additional reconnaissance missions before attempting the assassination.\n\nPassage 3: Title (S0) - Assassin's Creed Unity\nS1. Assassin's Creed Unity  Assassin's Creed Unity is an action-adventure video game developed by Ubisoft Montreal and published by Ubisoft.\nS2. It was released in November 2014 for Microsoft Windows, PlayStation 4 and Xbox One.\nS3. It is the eighth major installment in the \"Assassin's Creed\" series, and the successor to 2013's \"\".\nS4. It also has ties to \"Assassin's Creed Rogue\" which was released for the previous generation consoles, the PlayStation 3 and Xbox 360 on the same date.\nS5. The plot is set in a fictional history of real world events and follows the centuries-old struggle between the Assassins, who fight for peace with free will, and the Templars, who desire peace through control.\nS6. The story is set in Paris during the French Revolution; the single-player story follows Arno Victor Dorian in his efforts to expose the true powers behind the Revolution.\nS7. The game retains the series' third-person open world exploration as well as introducing a revamped combat, parkour and stealth system.\nS8. The game also introduces cooperative multiplayer to the \"Assassin's Creed\" series, letting up to four players engage in narrative-driven missions and explore the open world map.\nS9. \"Assassin's Creed Unity\" received mixed reviews upon its release.\n    \nInput Question:\nWhat type of game is assassin's creed?\n\nCorrect Response:\nAssassin's Creed is a single-player action-adventure video game developed by Ubisoft Montreal and published by Ubisoft. It is the first installment in the Assassin's Creed series. The game was released for PlayStation 3 and Xbox 360 in November 2007 and was made available on Microsoft Windows in April 2008. It is set in an open world environment and played from a third-person perspective.\n\nModel Prediction:\nAssassin's Creed is an action-adventure video game developed by Ubisoft Montreal and published by Ubisoft. It is the first installment in the Assassin's Creed series. Assassin's Creed is also known as Assassin's Creed Unity, an action-adventure video game developed by Ubisoft and released by Ubisoft in November 2014 for Microsoft Windows, PlayStation 4, and Xbox One.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "Assassin's Creed is an action-adventure video game developed by Ubisoft Montreal and published by Ubisoft. It is the first installment in the Assassin's Creed series. [Assassin's Creed is also known as Assassin's Creed Unity, an action-adventure video game developed by Ubisoft and released by Ubisoft in November 2014 for Microsoft Windows, PlayStation 4, and Xbox One.]\n\nExplanation:\nThe last sentence is irrelevant because it incorrectly states that Assassin's Creed is also known as Assassin's Creed Unity, which is a different installment in the series. This information is not pertinent to the question asked."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. Assassin's Creed is an action-adventure video game developed by Ubisoft Montreal and published by Ubisoft.\nS2. It is the first installment in the Assassin's Creed series.\nS3. Assassin's Creed is also known as Assassin's Creed Unity, an action-adventure video game developed by Ubisoft and released by Ubisoft in November 2014 for Microsoft Windows, PlayStation 4, and Xbox One.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "S3\n\nExplanation:\nSentence 3 is factually inconsistent with the passages. Assassin's Creed and Assassin's Creed Unity are different installments in the Assassin's Creed series, as stated in Passage 1, sentence 2 and Passage 3, sentence 1. Therefore, it is incorrect to say that Assassin's Creed is also known as Assassin's Creed Unity."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 3 [Missing Major Auxiliary Information]\n2. Passage 2, sentence 5 [Missing Major Auxiliary Information]\n\nExplanation:\n1. The model prediction does not mention that the game was released for PlayStation 3 and Xbox 360 in November 2007 and was made available on Microsoft Windows in April 2008, as stated in Passage 1, sentence 3. This information provides important context about the game's release and availability.\n2. The model prediction also omits the information that the game is set in an open world environment and played from a third-person perspective, as stated in Passage 2, sentence 5. This is crucial information that describes the gameplay of Assassin's Creed."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "Assassin's Creed is an action-adventure video game developed by Ubisoft Montreal and published by Ubisoft. It is the first installment in the Assassin's Creed series. The game was released for PlayStation 3 and Xbox 360 in November 2007 and was made available on Microsoft Windows in April 2008. It is set in an open world environment and played from a third-person perspective."}], "feedback_human": {"errors": [{"error type": "Redundant", "explanation": "Assassin's Creed is an action-adventure video game developed by Ubisoft ", "start": 167, "end": 300}, {"error type": "Irrelevant", "explanation": "", "start": 301, "end": 369}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [3]}, {"error type": "Missing-Minor-Auxiliary", "passage_id": 2, "sentence_id": [5]}], "corrected-prediction": "Assassin's Creed is an action-adventure video game developed by Ubisoft Montreal and published by Ubisoft. It is the first installment in the Assassin's Creed series. The game was released for PlayStation 3 and Xbox 360 in November 2007 and was made available on Microsoft Windows in April 2008. It is set in an open world environment and played from a third-person perspective."}}, {"question": "When did they change the speed limit to 55?", "passages": [["Speed limits in the United States by jurisdiction", "Missouri concluded a two-year experiment with variable speed limits along I-270 around St. Louis.", "Digital signs had been erected along the freeway as well as additional signs alerting drivers about the use of variable speed limits.", "The limits will vary between 40 and 60\u00a0miles per hour, depending on traffic conditions, and could change by up to 5\u00a0mph every 5\u00a0minutes.", "These speed limits, as of January 2012, are now posted as \"Advisory Speed Limits\".", "During the closure and major rebuild of I-64 in St. Louis, an additional lane was added to I-44 and I-70, and the speed limit was thus reduced to 55\u00a0mph on those roads within the St. Louis County and City.", "The I-64 construction has been completed, and the extra lanes were removed in 2010.", "In October 2010, the speed limit was restored to 60\u00a0mph on both I-44 and I-70.", "Most two-lane roads with shoulders have a 60\u00a0mph speed limit in Missouri.", "Two-lane roads without shoulders are usually, but not always, limited to 55\u00a0mph.", "However, the following two-lane highways have a 65\u00a0mph speed limit when bypassing or outside of incorporated areas.", "Most rural expressways have a 65\u00a0mph speed limit, but the following have a 70\u00a0mph speed limit."], ["Speed limits in the United States by jurisdiction", "The speed limit on urban freeways ranges from a low of 40\u00a0mph in downtown Pittsburgh and Philadelphia to a high of 70\u00a0mph in some suburban areas.", "In 1940, when the Pennsylvania Turnpike was opened between Irwin and Carlisle, the entire 160\u00a0mile limited-access toll road did not have a speed limit, similar to that of the German Autobahns.", "In 1941, a speed limit of 70\u00a0mph (113\u00a0km/h) was established, only to be reduced to 35\u00a0mph (56\u00a0km/h) during the war years (1942\u201345).", "After WWII, the limit was raised to 70\u00a0mph on the four-lane sections, with the two-lane tunnels having 50\u00a0mph (80\u00a0km/h) for cars and 40\u00a0mph (64\u00a0km/h) for trucks.", "Prior to the 1974 federal speed limit law, all Interstates and the Turnpike had a 65\u00a0mph (105\u00a0km/h) speed limit on rural stretches and 60\u00a0mph (97\u00a0km/h) speed limit in urban areas.", "In 1995, the state raised the speed limit on rural stretches of Interstate Highways and the Pennsylvania Turnpike system to 65\u00a0mph (105\u00a0km/h), with urban areas having a 55\u00a0mph (89\u00a0km/h) limit.", "In 1997, PennDOT raised the speed limit to some rural non-Interstate Highway bypasses to 65\u00a0mph (105\u00a0km/h)."], ["Speed limits in the United States by jurisdiction", "Only two State Secondary Road freeways in the state that has a 60\u00a0mph speed limit are the Wade Avenue Extension as of February 2012 and Aviation Parkway (from south of Globe Rd to Airport Blvd) as of July 2014, which are both in Raleigh.", "60\u00a0mph speed limits along non-freeway segments are growing in popularity and have replaced 55\u00a0mph limits on several boulevard and expressway segments throughout the state.", "The boulevard speed limit changes go against the NCDOT rationale behind signing 60\u00a0mph speed limits along only freeway and expressway segments.", "As of June 1, 2008, some examples of the affected boulevards are US 17 north of Elizabeth City, US 74 east of Wadesboro and NC 11 in Pitt County.", "60\u00a0mph speed limits along Expressways are US 1 in northeastern Moore County, US 17 on bypass routes in Brunswick County, US 74 east of I-95, US 117 in Wayne County & Duplin County, US 220 in Rockingham County only along bypass segments and on NC 16 in Lincoln and Catawba counties (as of October 2012).", "Previously, the entire US 220 alignment from NC 68 to the Virginia state line was 60\u00a0mph but went back to 55\u00a0mph between NC 68 and NC 704."]], "gold": "The National Maximum Speed Limit (NMSL) was a provision of the federal government of the United States 1974 Emergency Highway Energy Conservation Act that effectively prohibited speed limits higher than 55 miles per hour (89 km/h). The Emergency Highway Energy Conservation Act was a bill in the U.S. Congress that included the National Maximum Speed Limit. States had to agree to the limit if they desired to receive federal funding for highway repair. The uniform speed limit was signed into law by Nixon on January 2, 1974, and became effective 60 days later. During the rebuild of I-64 an additional lane was added to I-44 and I-70 which had a 55 mph limit. Upon completion the limit was restored to 60 mph. In New Mexico the in November 2005, the stretch between NM-4 and Pojoaque became a safety corridor. In 2007, the speed limit on the San Ildefonso-Pojoaque stretch was lowered to 55 mph. US 84/285 speed limit was changed to 55 mph in 2005.  In the 2000s, the major cities of Memphis, Knoxville and Chattanooga Tennessee petitioned TDOT to enact environmental speed limits in their respective counties after failing to meet EPA air quality standards, reducing speed limits from 70 mph to 65 mph and 55 mph for trucks.", "prediction 1": "In 1950, the speed limit on the Pennsylvania Turnpike was 70 mph (113 km/h), but by 1941, the limit was reduced to 35 mph (56 km/h) for cars and 40 mph (64 km/h) for trucks. In 1995, the state raised the speed limit on rural stretches of Interstate Highways and the Pennsylvania Turnpike system to 65 mph (105 km/h), with urban areas having a 55 mph (89 km/h) limit. In 1997, PennDOT raised the speed limit to some rural non-Interstate Highway bypasses to 65 mph (105 km/h), with urban areas having a 55 mph (89 km/h) limit.", "prediction 2": "In the United States, speed limits are generally set at 55 mph. However, in Missouri, during the closure and major rebuild of I-64 in St. Louis, an additional lane was added to I-44 and I-70, and the speed limit was thus reduced to 55 mph on those roads within the St. Louis County and City. In 1995, the state raised the speed limit on rural stretches of Interstate Highways and the Pennsylvania Turnpike system to 65 mph (105 km/h), with urban areas having a 55 mph limit. In 1997, PennDOT raised the speed limit to some rural non-Interstate Highway bypasses to 65 mph (105 km/h).", "prediction 3": "In 1995, the state raised the speed limit on rural stretches of Interstate Highways and the Pennsylvania Turnpike system to 65 mph (105 km/h), with urban areas having a 55 mph (89 km/h) limit. In 1997, PennDOT raised the speed limit to some rural non-Interstate Highway bypasses to 65 mph (105 km/h). The speed limit at intersections on I-465 and I-24 between Harrisburg and Philadelphia was 55 mph (89 km/h).", "prediction 4": "In the United States, most two-lane roads with shoulders have a 60 mph speed limit. However, the following two-lane highways have a 65 mph speed limit when bypassing or outside incorporated areas; most rural expressways have a 65 mph speed limit, but the following have a 70 mph speed limit. In the United States, in 1995, the state raised the speed limit on rural stretches of Interstate Highways and the Pennsylvania Turnpike system to 65 mph (105 km/h), with urban areas having a 55 mph limit; in 1997, the speed limit to some rural non-Interstate Highway bypasses to 65 mph (89 km/h) limit; however, the 55 mph limit was restored to 55 mph limits on several boulevard and expressway segments throughout the state. The speed limit was restored to 55 mph limits on several boulevards and expressway segments", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 0, "end": 173}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 1, "sentence_id": [5]}], "corrected-prediction": "During the rebuild of I-64 in St. Louis, an additional lane was added to I-44 and I-70, and the speed limit was thus reduced to 55 mph on those roads within the St. Louis County and City. In October 2010, the speed limit was restored to 60 mph on both I-44 and I-70."}, "preference": [1, 1, 1, 1, 1, 2], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Speed limits in the United States by jurisdiction\nS1. Missouri concluded a two-year experiment with variable speed limits along I-270 around St. Louis.\nS2. Digital signs had been erected along the freeway as well as additional signs alerting drivers about the use of variable speed limits.\nS3. The limits will vary between 40 and 60\u00a0miles per hour, depending on traffic conditions, and could change by up to 5\u00a0mph every 5\u00a0minutes.\nS4. These speed limits, as of January 2012, are now posted as \"Advisory Speed Limits\".\nS5. During the closure and major rebuild of I-64 in St. Louis, an additional lane was added to I-44 and I-70, and the speed limit was thus reduced to 55\u00a0mph on those roads within the St. Louis County and City.\nS6. The I-64 construction has been completed, and the extra lanes were removed in 2010.\nS7. In October 2010, the speed limit was restored to 60\u00a0mph on both I-44 and I-70.\nS8. Most two-lane roads with shoulders have a 60\u00a0mph speed limit in Missouri.\nS9. Two-lane roads without shoulders are usually, but not always, limited to 55\u00a0mph.\nS10. However, the following two-lane highways have a 65\u00a0mph speed limit when bypassing or outside of incorporated areas.\nS11. Most rural expressways have a 65\u00a0mph speed limit, but the following have a 70\u00a0mph speed limit.\n\nPassage 2: Title (S0) - Speed limits in the United States by jurisdiction\nS1. The speed limit on urban freeways ranges from a low of 40\u00a0mph in downtown Pittsburgh and Philadelphia to a high of 70\u00a0mph in some suburban areas.\nS2. In 1940, when the Pennsylvania Turnpike was opened between Irwin and Carlisle, the entire 160\u00a0mile limited-access toll road did not have a speed limit, similar to that of the German Autobahns.\nS3. In 1941, a speed limit of 70\u00a0mph (113\u00a0km/h) was established, only to be reduced to 35\u00a0mph (56\u00a0km/h) during the war years (1942\u201345).\nS4. After WWII, the limit was raised to 70\u00a0mph on the four-lane sections, with the two-lane tunnels having 50\u00a0mph (80\u00a0km/h) for cars and 40\u00a0mph (64\u00a0km/h) for trucks.\nS5. Prior to the 1974 federal speed limit law, all Interstates and the Turnpike had a 65\u00a0mph (105\u00a0km/h) speed limit on rural stretches and 60\u00a0mph (97\u00a0km/h) speed limit in urban areas.\nS6. In 1995, the state raised the speed limit on rural stretches of Interstate Highways and the Pennsylvania Turnpike system to 65\u00a0mph (105\u00a0km/h), with urban areas having a 55\u00a0mph (89\u00a0km/h) limit.\nS7. In 1997, PennDOT raised the speed limit to some rural non-Interstate Highway bypasses to 65\u00a0mph (105\u00a0km/h).\n\nPassage 3: Title (S0) - Speed limits in the United States by jurisdiction\nS1. Only two State Secondary Road freeways in the state that has a 60\u00a0mph speed limit are the Wade Avenue Extension as of February 2012 and Aviation Parkway (from south of Globe Rd to Airport Blvd) as of July 2014, which are both in Raleigh.\nS2. 60\u00a0mph speed limits along non-freeway segments are growing in popularity and have replaced 55\u00a0mph limits on several boulevard and expressway segments throughout the state.\nS3. The boulevard speed limit changes go against the NCDOT rationale behind signing 60\u00a0mph speed limits along only freeway and expressway segments.\nS4. As of June 1, 2008, some examples of the affected boulevards are US 17 north of Elizabeth City, US 74 east of Wadesboro and NC 11 in Pitt County.\nS5. 60\u00a0mph speed limits along Expressways are US 1 in northeastern Moore County, US 17 on bypass routes in Brunswick County, US 74 east of I-95, US 117 in Wayne County & Duplin County, US 220 in Rockingham County only along bypass segments and on NC 16 in Lincoln and Catawba counties (as of October 2012).\nS6. Previously, the entire US 220 alignment from NC 68 to the Virginia state line was 60\u00a0mph but went back to 55\u00a0mph between NC 68 and NC 704.\n    \nInput Question:\nWhen did they change the speed limit to 55?\n\nCorrect Response:\nThe National Maximum Speed Limit (NMSL) was a provision of the federal government of the United States 1974 Emergency Highway Energy Conservation Act that effectively prohibited speed limits higher than 55 miles per hour (89 km/h). The Emergency Highway Energy Conservation Act was a bill in the U.S. Congress that included the National Maximum Speed Limit. States had to agree to the limit if they desired to receive federal funding for highway repair. The uniform speed limit was signed into law by Nixon on January 2, 1974, and became effective 60 days later. During the rebuild of I-64 an additional lane was added to I-44 and I-70 which had a 55 mph limit. Upon completion the limit was restored to 60 mph. In New Mexico the in November 2005, the stretch between NM-4 and Pojoaque became a safety corridor. In 2007, the speed limit on the San Ildefonso-Pojoaque stretch was lowered to 55 mph. US 84/285 speed limit was changed to 55 mph in 2005.  In the 2000s, the major cities of Memphis, Knoxville and Chattanooga Tennessee petitioned TDOT to enact environmental speed limits in their respective counties after failing to meet EPA air quality standards, reducing speed limits from 70 mph to 65 mph and 55 mph for trucks.\n\nModel Prediction:\nIn 1950, the speed limit on the Pennsylvania Turnpike was 70 mph (113 km/h), but by 1941, the limit was reduced to 35 mph (56 km/h) for cars and 40 mph (64 km/h) for trucks. In 1995, the state raised the speed limit on rural stretches of Interstate Highways and the Pennsylvania Turnpike system to 65 mph (105 km/h), with urban areas having a 55 mph (89 km/h) limit. In 1997, PennDOT raised the speed limit to some rural non-Interstate Highway bypasses to 65 mph (105 km/h), with urban areas having a 55 mph (89 km/h) limit.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "[In 1950, the speed limit on the Pennsylvania Turnpike was 70 mph (113 km/h), but by 1941, the limit was reduced to 35 mph (56 km/h) for cars and 40 mph (64 km/h) for trucks.] In 1995, the state raised the speed limit on rural stretches of Interstate Highways and the Pennsylvania Turnpike system to 65 mph (105 km/h), with urban areas having a 55 mph (89 km/h) limit. In 1997, PennDOT raised the speed limit to some rural non-Interstate Highway bypasses to 65 mph (105 km/h), with urban areas having a 55 mph (89 km/h) limit.\n\nExplanation:\n1. The first sentence in the model prediction is irrelevant because it does not provide any information about when the speed limit was changed to 55 mph, which is the question asked. It talks about the speed limit being reduced to 35 mph and 40 mph, which is not related to the question."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. In 1950, the speed limit on the Pennsylvania Turnpike was 70 mph (113 km/h), but by 1941, the limit was reduced to 35 mph (56 km/h) for cars and 40 mph (64 km/h) for trucks.\nS2. In 1995, the state raised the speed limit on rural stretches of Interstate Highways and the Pennsylvania Turnpike system to 65 mph (105 km/h), with urban areas having a 55 mph (89 km/h) limit.\nS3. In 1997, PennDOT raised the speed limit to some rural non-Interstate Highway bypasses to 65 mph (105 km/h), with urban areas having a 55 mph (89 km/h) limit.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "Inconsistent or Unverifiable Sentences:\n1. S1\n2. S2\n3. S3\n\nExplanation:\n1. The first sentence is factually inconsistent with the passages. The passages do not provide any information about the speed limit being 70 mph in 1950 and then being reduced to 35 mph for cars and 40 mph for trucks by 1941.\n2. The second sentence is unverifiable as the passages do not mention that in 1995, the state raised the speed limit on rural stretches of Interstate Highways and the Pennsylvania Turnpike system to 65 mph, with urban areas having a 55 mph limit.\n3. The third sentence is also unverifiable as the passages do not mention that in 1997, PennDOT raised the speed limit to some rural non-Interstate Highway bypasses to 65 mph, with urban areas having a 55 mph limit."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 5 [Missing Answer]\n2. Passage 1, sentence 7 [Missing Answer]\n\nExplanation:\n1. The model prediction does not mention that during the rebuild of I-64 in St. Louis, an additional lane was added to I-44 and I-70, and the speed limit was thus reduced to 55 mph on those roads within the St. Louis County and City. This is a missing answer as it directly responds to the question.\n2. The model prediction also misses the information that in October 2010, the speed limit was restored to 60 mph on both I-44 and I-70. This is another missing answer as it provides additional context to the change in speed limit to 55 mph."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "During the rebuild of I-64 in St. Louis, an additional lane was added to I-44 and I-70, and the speed limit was thus reduced to 55 mph on those roads within the St. Louis County and City. In October 2010, the speed limit was restored to 60 mph on both I-44 and I-70."}], "feedback_human": {"errors": [{"error type": "Wrong-Grounding", "explanation": "{\"passage_id\":2,\"sentence_id\":[3]}", "start": 3, "end": 8}, {"error type": "Wrong-Grounding", "explanation": "{\"passage_id\":2,\"sentence_id\":[4]}", "start": 84, "end": 89}, {"error type": "Wrong-Grounding", "explanation": "{\"passage_id\":2,\"sentence_id\":[4]}", "start": 115, "end": 117}, {"error type": "Irrelevant", "explanation": "", "start": 219, "end": 316}, {"error type": "Irrelevant", "explanation": "", "start": 367, "end": 474}, {"error type": "Redundant", "explanation": "In 1995, the state raised the speed limit on rural stretches of Interstate Highways and the Pennsylvania Turnpike system to 65 mph (105 km/h), with urban areas having a 55 mph (89 km/h) limit. ", "start": 475, "end": 524}, {"error type": "Irrelevant", "explanation": "", "start": 141, "end": 173}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [5]}, {"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [7]}], "corrected-prediction": "In 1941, the speed limit on the Pennsylvania Turnpike was 70 mph (113 km/h), but after WWII, the two-lane limit was reduced to 50 mph (56 km/h) for cars. In 1995, the state raised the speed limit on urban areas to a 55 mph (89 km/h) limit. During the closure and major rebuild of I-64 in St. Louis, an additional lane was added to I-44 and I-70, and the speed limit was thus reduced to 55 mph on those roads. In October 2010, the speed limit was restored to 60 mph on both I-44 and I-70."}}, {"question": "Who played guitar on goodbye yellow brick road?", "passages": [["Bryan Forbes", "In 1972, Forbes started work on the documentary, \"Elton John and Bernie Taupin Say Goodbye Norma Jean and Other Things\" (1973), which chronicled the life of the young Elton John and Bernie Taupin.", "The project took Forbes a full year to complete, and provided a behind-the-scenes look at the writing and recording of \"Goodbye Yellow Brick Road\", including interviews with John, Taupin and band members, including Nigel Olsson and Dee Murray, as well as John's mother, Sheila, DJM label head Dick James and son Stephen, and footage of John's Hollywood Bowl concert in 1973.", "(Some of the footage was licensed for the Eagle Vision Classic Albums series \"Goodbye Yellow Brick Road\" documentary.)", "During the filming, Forbes formed a close friendship with John and Taupin, which led him to do other work with them, including photography on the \"Don't Shoot Me I'm Only the Piano Player\" and \"Goodbye Yellow Brick Road\" album sleeves.", "ITV broadcast the documentary in the UK on 4 December 1973 (in the US, ABC screened it) shortly after completion, and was later briefly issued on VHS.", "Forbes returned to Hollywood to direct \"The Stepford Wives\" (1975), based on Ira Levin's novel of the same name.", "The horror classic again featured Newman and was to become his best-known film."], ["This Train Don't Stop There Anymore", "This Train Don't Stop There Anymore\n\n\"This Train Don't Stop There Anymore\" is a 2001 song performed by Elton John.", "The song was written by Elton John and Bernie Taupin.", "The music video was directed by David LaChapelle, and with Pierre Rouger as cinematographer, and presents a younger John played by Justin Timberlake dressed in outfits typical of John in the 1970s; the video also features Paul Reubens of Pee-Wee Herman fame as John Reid, John's manager of 25 years.", "The song's lyrics detail John's coming to terms with getting older.", "It appears on the album \"Songs from the West Coast\".", "It was released as a single and reached #24 in the UK Singles chart and was a Top 10 Adult Contemporary chart hit in the US.", "Gary Barlow provided backing vocals for the track.", "The arrangement was simple, a throwback to John's early piano-bass-drums combination prior to the arrival of Davey Johnstone.", "On the track, John plays piano, Paul Bushnell provides bass and backing vocals, and Matt Chamberlain plays drums.", "Country music artists Rosanne Cash and Emmylou Harris covered the song for the 2018 tribute album \"\"."]], "gold": "\"Goodbye Yellow Brick Road\" is a ballad performed by musician Elton John and the title track on his 1973 album of the same name. On the song and album Davey Johnstone played the acoustic, electric, slide, and leslie guitars.  Dee Murray played bass guitar on the album.", "prediction 1": "On the 1973 song \"Goodbye Yellow Brick Road\", Elton John plays piano, Paul Bushnell provides bass and backing vocals, and Matt Chamberlain plays drums.", "prediction 2": "In the 1973 album Goodbye Yellow Brick Road, guitarist Elton John plays the guitar and bass while bassist Paul Bushnell and drummer Matt Chamberlain play the drums. Gary Barlow provided the backing vocals for the 2001 song This Train Don't Stop There Anymore.", "prediction 3": "Gary Barlow provided backing vocals on the song \"Goodbye Yellow Brick Road\" and played guitar on the documentary \"Elton John and Bernie Taupin Say Goodbye Norma Jean and Other Things\" released in 1973. On the track, John plays piano, Paul Bushnell provides bass and backing vocals, and Matt Chamberlain plays drums.", "prediction 4": "Elton John and Bernie Taupin played guitar on their 1972 song \"Goodbye Yellow Brick Road\". In the 1973 documentary \"Elton John and Bernie Taupin Say Goodbye Norma Jean and Other Things\", Bryan Forbes provided a behind-the-scenes look at the writing and recording of the song. Gary Barlow provided back-up vocals for the song \"This Train Don't Stop There Anymore\", a 2001 song performed by Elton John.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 0, "end": 151}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 1, "sentence_id": [2]}], "corrected-prediction": "The guitar on the song \"Goodbye Yellow Brick Road\" was played by band members, including Nigel Olsson and Dee Murray."}, "preference": [0, 1, 1, 1, 1, 1], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Bryan Forbes\nS1. In 1972, Forbes started work on the documentary, \"Elton John and Bernie Taupin Say Goodbye Norma Jean and Other Things\" (1973), which chronicled the life of the young Elton John and Bernie Taupin.\nS2. The project took Forbes a full year to complete, and provided a behind-the-scenes look at the writing and recording of \"Goodbye Yellow Brick Road\", including interviews with John, Taupin and band members, including Nigel Olsson and Dee Murray, as well as John's mother, Sheila, DJM label head Dick James and son Stephen, and footage of John's Hollywood Bowl concert in 1973.\nS3. (Some of the footage was licensed for the Eagle Vision Classic Albums series \"Goodbye Yellow Brick Road\" documentary.)\nS4. During the filming, Forbes formed a close friendship with John and Taupin, which led him to do other work with them, including photography on the \"Don't Shoot Me I'm Only the Piano Player\" and \"Goodbye Yellow Brick Road\" album sleeves.\nS5. ITV broadcast the documentary in the UK on 4 December 1973 (in the US, ABC screened it) shortly after completion, and was later briefly issued on VHS.\nS6. Forbes returned to Hollywood to direct \"The Stepford Wives\" (1975), based on Ira Levin's novel of the same name.\nS7. The horror classic again featured Newman and was to become his best-known film.\n\nPassage 2: Title (S0) - This Train Don't Stop There Anymore\nS1. This Train Don't Stop There Anymore  \"This Train Don't Stop There Anymore\" is a 2001 song performed by Elton John.\nS2. The song was written by Elton John and Bernie Taupin.\nS3. The music video was directed by David LaChapelle, and with Pierre Rouger as cinematographer, and presents a younger John played by Justin Timberlake dressed in outfits typical of John in the 1970s; the video also features Paul Reubens of Pee-Wee Herman fame as John Reid, John's manager of 25 years.\nS4. The song's lyrics detail John's coming to terms with getting older.\nS5. It appears on the album \"Songs from the West Coast\".\nS6. It was released as a single and reached #24 in the UK Singles chart and was a Top 10 Adult Contemporary chart hit in the US.\nS7. Gary Barlow provided backing vocals for the track.\nS8. The arrangement was simple, a throwback to John's early piano-bass-drums combination prior to the arrival of Davey Johnstone.\nS9. On the track, John plays piano, Paul Bushnell provides bass and backing vocals, and Matt Chamberlain plays drums.\nS10. Country music artists Rosanne Cash and Emmylou Harris covered the song for the 2018 tribute album \"\".\n    \nInput Question:\nWho played guitar on goodbye yellow brick road?\n\nCorrect Response:\n\"Goodbye Yellow Brick Road\" is a ballad performed by musician Elton John and the title track on his 1973 album of the same name. On the song and album Davey Johnstone played the acoustic, electric, slide, and leslie guitars.  Dee Murray played bass guitar on the album.\n\nModel Prediction:\nOn the 1973 song \"Goodbye Yellow Brick Road\", Elton John plays piano, Paul Bushnell provides bass and backing vocals, and Matt Chamberlain plays drums.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "[On the 1973 song \"Goodbye Yellow Brick Road\", Elton John plays piano, Paul Bushnell provides bass and backing vocals, and Matt Chamberlain plays drums.]\n\nExplanation:\nThe entire model prediction is irrelevant because it does not answer the question about who played the guitar on \"Goodbye Yellow Brick Road\". Instead, it provides information about who played the piano, bass, and drums, which is not asked in the question. Therefore, the entire prediction is marked as irrelevant."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. On the 1973 song \"Goodbye Yellow Brick Road\", Elton John plays piano, Paul Bushnell provides bass and backing vocals, and Matt Chamberlain plays drums.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "S1\n\nExplanation:\nThe information in sentence S1 is inconsistent with the passages. The passages do not mention Paul Bushnell and Matt Chamberlain playing bass and drums, respectively, on the song \"Goodbye Yellow Brick Road\". Therefore, this information is marked as an \"Inconsistent Fact\"."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 2 [Missing Answer]\n\nExplanation:\n1. The model prediction is missing the answer to the question, which is who played the guitar on \"Goodbye Yellow Brick Road\". According to Passage 1, sentence 2, the guitar was played by band members, including Nigel Olsson and Dee Murray. This information is missing in the model prediction."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The guitar on the song \"Goodbye Yellow Brick Road\" was played by band members, including Nigel Olsson and Dee Murray."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 57, "end": 151}, {"error type": "Unverifiable", "explanation": "", "start": 7, "end": 11}], "missing-info": [], "corrected-prediction": "The song \"Goodbye Yellow Brick Road\" is performed by Elton John."}}, {"question": "When was the first drunk driving law passed?", "passages": [["Impaired driving in Canada", "At the time, the courts interpreted intoxication to mean substantial inebriation, and more than just being under the influence of alcohol.", "The minimum penalty for the first offence was seven days in jail.", "The minimum penalty for the second offence was one month in jail.", "The minimum penalty for a third offence was three months in jail.", "In 1925, Parliament amended the \"Criminal Code\" to include a new offence of driving while intoxicated by a narcotic.", "The offences were also amended to include \"care or control\" of a motor vehicle, not just driving.", "(See below.)", "In 1930, Parliament changed the offence to a hybrid offence, giving the Crown the option to proceed with the more serious indictable offence procedure.", "Difficulties arose regarding how to prove someone was in care or control of a motor vehicle, and what the test should be.", "In 1947, Parliament amended the \"Criminal Code\" again, adding a presumption of care or control when a person was found sitting in the driver's seat of a motor vehicle.", "This did not answer all of the problems regarding the test (i.e. when a person is not found in the driver's seat of a motor vehicle).", "Many of the court's answers to those questions remain in conflict today."], ["Drunk driving in the United States", "Drunk driving in the United States\n\nDrunk driving is the act of operating a motor vehicle with the operator's ability to do so impaired as a result of alcohol consumption, or with a blood alcohol level in excess of the legal limit.", "For drivers 21 years or older, driving with a blood alcohol concentration (BAC) of 0.08% or higher is illegal.", "For drivers under 21 years old, the legal limit is lower, with state limits ranging from 0.00 to 0.02.", "Lower BAC limits apply when operating boats, airplanes, or commercial vehicles.", "Among other names, the criminal offense of drunk driving may be called driving under the influence (DUI), driving while intoxicated or impaired (DWI), or operating while impaired (OWI).", "According to the Bureau of Justice Statistics, approximately 1.5 million drunk driving arrests were made nationwide in 1996.", "In 2012, 29.1 million people admitted to driving under the influence of alcohol.", "In 1997 an estimated 513,200 DUI offenders were under correctional supervision, down from 593,000 in 1990 and up from 270,100 in 1986."], ["Drunk driving in the United States", "If anyone involved in the accident (even a passenger) has a BAC of 0.01% of greater, then the NTHSA classifies the accident as alcohol-related.", "Alcohol-related injuries were estimated at 275,000 in 2003.", "For the most part, DUI or DWI are synonymous terms that represent the criminal offense of operating (or in some jurisdictions merely being in physical control of) a motor vehicle while being under the influence of alcohol or drugs or a combination of both.", "The key inquiry focuses on whether the driver's faculties were impaired by the substance that was consumed.", "The detection and successful prosecution of drivers impaired by prescription medication or illegal drugs can therefore be difficult.", "Breathalyzers have been developed for the purpose of administering roadside or laboratory tests that can detect the actual level of a controlled substance in an individual's body.", "New Jersey enacted the first law that specifically criminalized driving an automobile while intoxicated, in 1906.", "The New Jersey statute provided that \"[n]o intoxicated person shall drive a motor vehicle.\"", "Violation of this provision was punishable by a fine of up to $500, or a term of up to 60 days in county jail.", "Early laws, such as that enacted in New Jersey, required proof of a state of intoxication with no specific definition of what level of inebriation qualified."]], "gold": "Drunk driving is the act of operating a motor vehicle with the operator's ability to do so impaired as a result of alcohol consumption, or with a blood alcohol level in excess of the legal limit. In the United States, the first law that specifically criminalized driving an automobile while intoxicated was established in New Jersey in 1906, with the violation of this provision being punishable by a fine of up to $500, or a term of up to 60 days in county jail. In Canada, parliament first created a summary conviction offence for drinking and driving in 1921, called \"driving while intoxicated,\" which at the time, the courts interpreted to mean substantial inebriation, and more than just being under the influence of alcohol. The minimum penalty for the first offence was seven days in jail, with the second offence being one month in jail, and a third offence was three months in jail.", "prediction 1": "In 1921, Parliament amended the Criminal Code to include a new offence of driving while intoxicated by a narcotic. The offences were also amended to include \"care or control\" of a motor vehicle, not just driving. In 1916, the first law that specifically criminalized driving an automobile while intoxicated was passed in New Jersey. In 1947, Parliament amended the Criminal Code again, adding a presumption of care or control when a person was found sitting in the driver's seat of a motor vehicle.", "prediction 2": "Drunk driving is the act of operating a motor vehicle with the operator's ability to do so impaired as a result of alcohol consumption, or with a blood alcohol level in excess of the legal limit. In New Jersey, the first state to pass a law to criminalize driving while intoxicated was in 1906. In the United States, the first law to criminalize driving while intoxicated was in 1925.", "prediction 3": "Drunk driving is the act of operating a motor vehicle with the operator's ability to do so impaired as a result of alcohol consumption, or with a blood alcohol level in excess of the legal limit. New Jersey enacted the first law that specifically criminalized driving an automobile while intoxicated, in 1906. The law provides that \"[n]o intoxicated person shall drive a motor vehicle.\" Violation of this provision was punishable by a fine of up to $500, or a term of up to 60 days in county jail. New Jersey enacted the first law that specifically criminalized driving an automobile while intoxicated, intoxicated, in 1906.", "prediction 4": "In Canada, the first drunk driving law was passed in 1912. In the United States, the first drunk driving law was passed in 1906 and in New Jersey the first was passed in 1906.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 115, "end": 212}, {"error type": "Irrelevant", "explanation": "", "start": 333, "end": 498}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 1, "sentence_id": [2]}], "corrected-prediction": "In 1906, the first law that specifically criminalized driving an automobile while intoxicated was passed in New Jersey. In Canada, Parliament first created a summary conviction offence for drinking and driving in 1921, called \"driving while intoxicated.\" The minimum penalty for the first offence was seven days in jail, for the second offence it was one month in jail, and for a third offence it was three months in jail."}, "preference": [2, 2, 2, 2, 1, 1], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Impaired driving in Canada\nS1. At the time, the courts interpreted intoxication to mean substantial inebriation, and more than just being under the influence of alcohol.\nS2. The minimum penalty for the first offence was seven days in jail.\nS3. The minimum penalty for the second offence was one month in jail.\nS4. The minimum penalty for a third offence was three months in jail.\nS5. In 1925, Parliament amended the \"Criminal Code\" to include a new offence of driving while intoxicated by a narcotic.\nS6. The offences were also amended to include \"care or control\" of a motor vehicle, not just driving.\nS7. (See below.)\nS8. In 1930, Parliament changed the offence to a hybrid offence, giving the Crown the option to proceed with the more serious indictable offence procedure.\nS9. Difficulties arose regarding how to prove someone was in care or control of a motor vehicle, and what the test should be.\nS10. In 1947, Parliament amended the \"Criminal Code\" again, adding a presumption of care or control when a person was found sitting in the driver's seat of a motor vehicle.\nS11. This did not answer all of the problems regarding the test (i.e. when a person is not found in the driver's seat of a motor vehicle).\nS12. Many of the court's answers to those questions remain in conflict today.\n\nPassage 2: Title (S0) - Drunk driving in the United States\nS1. Drunk driving in the United States  Drunk driving is the act of operating a motor vehicle with the operator's ability to do so impaired as a result of alcohol consumption, or with a blood alcohol level in excess of the legal limit.\nS2. For drivers 21 years or older, driving with a blood alcohol concentration (BAC) of 0.08% or higher is illegal.\nS3. For drivers under 21 years old, the legal limit is lower, with state limits ranging from 0.00 to 0.02.\nS4. Lower BAC limits apply when operating boats, airplanes, or commercial vehicles.\nS5. Among other names, the criminal offense of drunk driving may be called driving under the influence (DUI), driving while intoxicated or impaired (DWI), or operating while impaired (OWI).\nS6. According to the Bureau of Justice Statistics, approximately 1.5 million drunk driving arrests were made nationwide in 1996.\nS7. In 2012, 29.1 million people admitted to driving under the influence of alcohol.\nS8. In 1997 an estimated 513,200 DUI offenders were under correctional supervision, down from 593,000 in 1990 and up from 270,100 in 1986.\n\nPassage 3: Title (S0) - Drunk driving in the United States\nS1. If anyone involved in the accident (even a passenger) has a BAC of 0.01% of greater, then the NTHSA classifies the accident as alcohol-related.\nS2. Alcohol-related injuries were estimated at 275,000 in 2003.\nS3. For the most part, DUI or DWI are synonymous terms that represent the criminal offense of operating (or in some jurisdictions merely being in physical control of) a motor vehicle while being under the influence of alcohol or drugs or a combination of both.\nS4. The key inquiry focuses on whether the driver's faculties were impaired by the substance that was consumed.\nS5. The detection and successful prosecution of drivers impaired by prescription medication or illegal drugs can therefore be difficult.\nS6. Breathalyzers have been developed for the purpose of administering roadside or laboratory tests that can detect the actual level of a controlled substance in an individual's body.\nS7. New Jersey enacted the first law that specifically criminalized driving an automobile while intoxicated, in 1906.\nS8. The New Jersey statute provided that \"[n]o intoxicated person shall drive a motor vehicle.\"\nS9. Violation of this provision was punishable by a fine of up to $500, or a term of up to 60 days in county jail.\nS10. Early laws, such as that enacted in New Jersey, required proof of a state of intoxication with no specific definition of what level of inebriation qualified.\n    \nInput Question:\nWhen was the first drunk driving law passed?\n\nCorrect Response:\nDrunk driving is the act of operating a motor vehicle with the operator's ability to do so impaired as a result of alcohol consumption, or with a blood alcohol level in excess of the legal limit. In the United States, the first law that specifically criminalized driving an automobile while intoxicated was established in New Jersey in 1906, with the violation of this provision being punishable by a fine of up to $500, or a term of up to 60 days in county jail. In Canada, parliament first created a summary conviction offence for drinking and driving in 1921, called \"driving while intoxicated,\" which at the time, the courts interpreted to mean substantial inebriation, and more than just being under the influence of alcohol. The minimum penalty for the first offence was seven days in jail, with the second offence being one month in jail, and a third offence was three months in jail.\n\nModel Prediction:\nIn 1921, Parliament amended the Criminal Code to include a new offence of driving while intoxicated by a narcotic. The offences were also amended to include \"care or control\" of a motor vehicle, not just driving. In 1916, the first law that specifically criminalized driving an automobile while intoxicated was passed in New Jersey. In 1947, Parliament amended the Criminal Code again, adding a presumption of care or control when a person was found sitting in the driver's seat of a motor vehicle.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "In 1921, Parliament amended the Criminal Code to include a new offence of driving while intoxicated by a narcotic. [The offences were also amended to include \"care or control\" of a motor vehicle, not just driving.] In 1916, the first law that specifically criminalized driving an automobile while intoxicated was passed in New Jersey. [In 1947, Parliament amended the Criminal Code again, adding a presumption of care or control when a person was found sitting in the driver's seat of a motor vehicle.]\n\nExplanation:\n1. The information about the offences being amended to include \"care or control\" of a motor vehicle is irrelevant to the question about when the first drunk driving law was passed.\n2. The information about the 1947 amendment to the Criminal Code is also irrelevant to the question. The question is asking about the first law, not subsequent amendments."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. In 1921, Parliament amended the Criminal Code to include a new offence of driving while intoxicated by a narcotic.\nS2. The offences were also amended to include \"care or control\" of a motor vehicle, not just driving.\nS3. In 1916, the first law that specifically criminalized driving an automobile while intoxicated was passed in New Jersey.\nS4. In 1947, Parliament amended the Criminal Code again, adding a presumption of care or control when a person was found sitting in the driver's seat of a motor vehicle.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "S3\n\nExplanation:\n1. The third sentence is factually inconsistent with the passages. According to Passage 3, Sentence 7, the first law that specifically criminalized driving an automobile while intoxicated was enacted in New Jersey in 1906, not 1916."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 2 [Missing Answer]\n2. Passage 1, sentence 3 [Missing Answer]\n3. Passage 1, sentence 4 [Missing Answer]\n4. Passage 3, sentence 9 [Missing Major Auxiliary Information]\n\nExplanation:\n1. The model prediction does not mention the minimum penalties for the first, second, and third offences of drunk driving in Canada, which are included in the reference response and can be found in Passage 1, sentences 2, 3, and 4.\n2. The model prediction also does not include the information about the punishment for violating the first drunk driving law in New Jersey, which is included in the reference response and can be found in Passage 3, sentence 9. This is considered major auxiliary information as it provides context to the severity of the first drunk driving law."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "In 1906, the first law that specifically criminalized driving an automobile while intoxicated was passed in New Jersey. In Canada, Parliament first created a summary conviction offence for drinking and driving in 1921, called \"driving while intoxicated.\" The minimum penalty for the first offence was seven days in jail, for the second offence it was one month in jail, and for a third offence it was three months in jail."}], "feedback_human": {"errors": [{"error type": "Wrong-Grounding", "explanation": "{\"passage_id\":3,\"sentence_id\":[7]}", "start": 216, "end": 221}, {"error type": "Irrelevant", "explanation": "", "start": 0, "end": 114}, {"error type": "Irrelevant", "explanation": "", "start": 115, "end": 212}, {"error type": "Unverifiable", "explanation": "", "start": 333, "end": 498}], "missing-info": [{"error type": "Missing-Minor-Auxiliary", "passage_id": 2, "sentence_id": [1]}, {"error type": "Missing-Minor-Auxiliary", "passage_id": 3, "sentence_id": [9]}, {"error type": "Missing-Minor-Auxiliary", "passage_id": 1, "sentence_id": [1]}, {"error type": "Missing-Minor-Auxiliary", "passage_id": 1, "sentence_id": [2]}, {"error type": "Missing-Minor-Auxiliary", "passage_id": 1, "sentence_id": [3]}, {"error type": "Missing-Minor-Auxiliary", "passage_id": 1, "sentence_id": [4]}], "corrected-prediction": "Drunk driving in the United States is the act of operating a motor vehicle with the operator's ability to do so impaired as a result of alcohol consumption, or with a blood alcohol level in excess of the legal limit. In 1906, the first law that specifically criminalized driving an automobile while intoxicated was passed in New Jersey. Violation of this provision was punishable by a fine of up to $500, or a term of up to 60 days in county jail. In Canada  the courts interpreted intoxication to mean substantial inebriation, and more than just being under the influence of alcohol.  The minimum penalty for the first offence was seven days in jail. The minimum penalty for the second offence was one month in jail and the minimum penalty for a third offence was three months in jail."}}, {"question": "When was the star wars theme song composed?", "passages": [["Star Wars (Main Title)", "Star Wars (Main Title)\n\n\"Star Wars (Main Title)\" is a 1977 instrumental hit single composed and conducted by John Williams.", "It is the main musical theme of \"Star Wars\".", "It was performed by the London Symphony Orchestra.", "The track became a hit in the United States (#10) and Canada (#13) during the fall of that year.", "The composition draws influence from Erich Wolfgang Korngold's score for the 1942 film \u201cKings Row\".", "The B side featured the original movie score of Cantina Band.", "\"Star Wars (Main Title)\" was the lesser of two hits featuring music from \"Star Wars\".", "Meco's disco version of \"Star Wars Theme/Cantina Band\" reached number one concurrently with the chart run of Williams' original movie score version.", "The Star Wars main title theme was covered by Patrick Gleeson a month after the release of the London Symphony Orchestra performance.", "His version was released in France."]], "gold": "Star Wars (Main Title) is a musical theme composed and conducted by John Williams. It is the main musical theme of Star Wars and is also considered the primary leitmotif for Luke Skywalker, the protagonist of the original Star Wars trilogy. The original July 1977 recording was performed by the London Symphony Orchestra. The song Star Wars Theme/Cantina Band was also released in 1977.", "prediction 1": "\"Star Wars (Main Title)\" is a 1977 instrumental hit single composed and conducted by John Williams. It is the main musical theme of \"Star Wars\". It was performed by the London Symphony Orchestra.", "prediction 2": "The star wars theme song Star Wars (Main Title) was composed and conducted by John Williams in 1977. It was performed by the London Symphony Orchestra. The score draws influence from Erich Wolfgang Korngold's score for the 1942 film King's Row.", "prediction 3": "\"Star Wars (Main Title)\" is a 1977 instrumental hit single composed and conducted by John Williams. It is the main musical theme of \"Star Wars.\" It was performed by the London Symphony Orchestra.", "prediction 4": "The star wars theme song \"Star Wars (Main Title)\" was composed in 1977 and was conducted by John Williams. The track was performed by the London Symphony Orchestra. It became a hit in the United States (#10) and Canada (#13) during the fall of that year.", "feedback": {"errors": [], "missing-info": [], "corrected-prediction": "\"Star Wars (Main Title)\" is a 1977 instrumental hit single composed and conducted by John Williams. It is the main musical theme of \"Star Wars\". It was performed by the London Symphony Orchestra."}, "preference": [1, 0, 1, 2, 1, 1], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Star Wars (Main Title)\nS1. Star Wars (Main Title)  \"Star Wars (Main Title)\" is a 1977 instrumental hit single composed and conducted by John Williams.\nS2. It is the main musical theme of \"Star Wars\".\nS3. It was performed by the London Symphony Orchestra.\nS4. The track became a hit in the United States (#10) and Canada (#13) during the fall of that year.\nS5. The composition draws influence from Erich Wolfgang Korngold's score for the 1942 film \u201cKings Row\".\nS6. The B side featured the original movie score of Cantina Band.\nS7. \"Star Wars (Main Title)\" was the lesser of two hits featuring music from \"Star Wars\".\nS8. Meco's disco version of \"Star Wars Theme/Cantina Band\" reached number one concurrently with the chart run of Williams' original movie score version.\nS9. The Star Wars main title theme was covered by Patrick Gleeson a month after the release of the London Symphony Orchestra performance.\nS10. His version was released in France.\n    \nInput Question:\nWhen was the star wars theme song composed?\n\nCorrect Response:\nStar Wars (Main Title) is a musical theme composed and conducted by John Williams. It is the main musical theme of Star Wars and is also considered the primary leitmotif for Luke Skywalker, the protagonist of the original Star Wars trilogy. The original July 1977 recording was performed by the London Symphony Orchestra. The song Star Wars Theme/Cantina Band was also released in 1977.\n\nModel Prediction:\n\"Star Wars (Main Title)\" is a 1977 instrumental hit single composed and conducted by John Williams. It is the main musical theme of \"Star Wars\". It was performed by the London Symphony Orchestra.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "\"Star Wars (Main Title)\" is a 1977 instrumental hit single composed and conducted by John Williams. It is the main musical theme of \"Star Wars\". It was performed by the London Symphony Orchestra.\n\nExplanation: There are no irrelevant, incoherent, or repetitive spans in the model prediction. The information provided is relevant to the question, coherent, and not repetitive."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. \"Star Wars (Main Title)\" is a 1977 instrumental hit single composed and conducted by John Williams.\nS2. It is the main musical theme of \"Star Wars\".\nS3. It was performed by the London Symphony Orchestra.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation: All the facts in the model prediction are consistent with the passages and can be verified from the passages."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "None\n\nExplanation: The model prediction does not miss any crucial information from the passages. It correctly answers the question about when the Star Wars theme song was composed."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "\"Star Wars (Main Title)\" is a 1977 instrumental hit single composed and conducted by John Williams. It is the main musical theme of \"Star Wars\". It was performed by the London Symphony Orchestra."}], "feedback_human": {"errors": [], "missing-info": [], "corrected-prediction": "\"Star Wars (Main Title)\" is a 1977 instrumental hit single composed and conducted by John Williams. It is the main musical theme of \"Star Wars\". It was performed by the London Symphony Orchestra."}}, {"question": "This is gonna be the best day of my life singer?", "passages": [["Believer (American Authors song)", "Believer (American Authors song)\n\n\"Believer\" is the debut single by American indie rock band American Authors.", "The song was written by band members Zac Barnett, Dave Rublin, Matt Sanchez, and James Adam Shelley, along with producers Aaron Accetta and Shep Goodman.", "\"Believer\" first appeared on their 2013 \"American Authors\" EP and was released as the band's debut single on March 19, 2013; it was later included on their debut studio album, \"Oh, What a Life\" (2014).", "\"Believer\" initially garnered airplay on United States modern rock radio in early 2013, and was later re-released to modern rock, triple A, hot adult contemporary and mainstream radio following the success of the band's second single \"Best Day of My Life\".", "A remix of the song by Dutch DJ Ti\u00ebsto was issued as a digital single on July 22, 2014.", "There is an accompanying music video that shows two boys working together to build a time machine\n\n\n\nAdapted from \"Oh, What a Life\" liner notes."], ["Zac Brown Band", "Zac Brown Band\n\nZac Brown Band is an American country band based in Atlanta, Georgia.", "The lineup consists of Zachary Alexander \"Zac\" Brown (born July 31, 1978) (lead vocals, guitar), Jimmy De Martini (born August 3, 1976) (fiddle, vocals), John Driskell Hopkins (born May 3, 1971) (bass guitar, guitar, baritone guitar, banjo, ukulele, upright bass, vocals), Coy Bowles (born February 20, 1979) (guitar, keyboards), Chris Fryar (born November 22, 1970) (drums), Clay Cook (born April 20, 1978) (guitar, keyboards, mandolin, steel guitar, vocals), Matt Mangano (born May 12, 1976) (bass guitar), and Daniel de los Reyes (born July 18, 1962) (percussion).", "The band has released six studio albums along with two live albums, one greatest-hits album, and two extended plays."]], "gold": "Released in 2013, Best Day of My Life is a song by pop rock band American Authors with Zac Barnett as the lead singer.", "prediction 1": "American indie rock band American Authors released the song \"Believer\" as their debut single on March 19, 2013. The song was later included on their debut studio album, Oh, What a Life. The song was covered by American country band Zac Brown Band and Dutch DJ Tisto.\n", "prediction 2": "Singers Bob Dylan, James Taylor and Zac Brown have all been known to sing \"There Goes My Life\". American indie rock band American Authors released the song Believer as their debut single on March 19, 2013. Other songs released during the year include The Band's 2012 album Maybe That's The Day, 2014's What a Wonderful World, and 2013's Say Anything.", "prediction 3": "The song \"When I wake up everyday is gonna be the best day of my life\" was released as the debut single by American indie rock band American Authors on March 19, 2013. The band also released an equally successful single as a single on July 20, 2014, entitled \"What a Life\".", "prediction 4": "The song \"This is gonna be the best day of my life\" by American indie rock band American Authors was released on March 19, 2013. A remix of the song by Dutch DJ Tisto was issued as a digital single on July 22, 2014.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 186, "end": 266}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 1, "sentence_id": [4]}], "corrected-prediction": "The song \"Best Day of My Life\" is by the American indie rock band American Authors. The band released it following their debut single \"Believer\". Zac Barnett is the lead singer of the band."}, "preference": [1, 1, 2, 2, 2, 2], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Believer (American Authors song)\nS1. Believer (American Authors song)  \"Believer\" is the debut single by American indie rock band American Authors.\nS2. The song was written by band members Zac Barnett, Dave Rublin, Matt Sanchez, and James Adam Shelley, along with producers Aaron Accetta and Shep Goodman.\nS3. \"Believer\" first appeared on their 2013 \"American Authors\" EP and was released as the band's debut single on March 19, 2013; it was later included on their debut studio album, \"Oh, What a Life\" (2014).\nS4. \"Believer\" initially garnered airplay on United States modern rock radio in early 2013, and was later re-released to modern rock, triple A, hot adult contemporary and mainstream radio following the success of the band's second single \"Best Day of My Life\".\nS5. A remix of the song by Dutch DJ Ti\u00ebsto was issued as a digital single on July 22, 2014.\nS6. There is an accompanying music video that shows two boys working together to build a time machine    Adapted from \"Oh, What a Life\" liner notes.\n\nPassage 2: Title (S0) - Zac Brown Band\nS1. Zac Brown Band  Zac Brown Band is an American country band based in Atlanta, Georgia.\nS2. The lineup consists of Zachary Alexander \"Zac\" Brown (born July 31, 1978) (lead vocals, guitar), Jimmy De Martini (born August 3, 1976) (fiddle, vocals), John Driskell Hopkins (born May 3, 1971) (bass guitar, guitar, baritone guitar, banjo, ukulele, upright bass, vocals), Coy Bowles (born February 20, 1979) (guitar, keyboards), Chris Fryar (born November 22, 1970) (drums), Clay Cook (born April 20, 1978) (guitar, keyboards, mandolin, steel guitar, vocals), Matt Mangano (born May 12, 1976) (bass guitar), and Daniel de los Reyes (born July 18, 1962) (percussion).\nS3. The band has released six studio albums along with two live albums, one greatest-hits album, and two extended plays.\n    \nInput Question:\nThis is gonna be the best day of my life singer?\n\nCorrect Response:\nReleased in 2013, Best Day of My Life is a song by pop rock band American Authors with Zac Barnett as the lead singer.\n\nModel Prediction:\nAmerican indie rock band American Authors released the song \"Believer\" as their debut single on March 19, 2013. The song was later included on their debut studio album, Oh, What a Life. The song was covered by American country band Zac Brown Band and Dutch DJ Tisto.\n\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "American indie rock band American Authors released the song \"Believer\" as their debut single on March 19, 2013. The song was later included on their debut studio album, Oh, What a Life. [The song was covered by American country band Zac Brown Band and Dutch DJ Tisto.]\n\nExplanation:\nThe information about the song \"Believer\" being covered by the Zac Brown Band and Dutch DJ Tisto is irrelevant to the question, which asks about the singer of \"Best Day of My Life\". Thus, it should be marked as \"Irrelevant\"."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. American indie rock band American Authors released the song \"Believer\" as their debut single on March 19, 2013.\nS2. The song was later included on their debut studio album, Oh, What a Life.\nS3. The song was covered by American country band Zac Brown Band and Dutch DJ Tisto.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "S3\n\nExplanation:\nThe third sentence of the model prediction states that the song \"Believer\" was covered by the Zac Brown Band and Dutch DJ Tisto. This fact is not mentioned in any of the provided passages, making it an \"Unverifiable Fact\"."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 4 [Missing Answer]\n\nExplanation:\nThe model prediction does not mention that the song \"Best Day of My Life\" is by the American Authors, which is the answer to the question. This information is missing from the model prediction."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The song \"Best Day of My Life\" is by the American indie rock band American Authors. The band released it following their debut single \"Believer\". Zac Barnett is the lead singer of the band."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 186, "end": 267}, {"error type": "Irrelevant", "explanation": "", "start": 112, "end": 185}, {"error type": "Irrelevant", "explanation": "", "start": 42, "end": 111}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [4]}], "corrected-prediction": "American indie rock band American Authors released the song \"Best Day of My Life\" as their second single.\n"}}, {"question": "Who made the song i need a hero?", "passages": [["Holding Out for a Hero", "Holding Out for a Hero\n\n\"Holding Out for a Hero\" is a song recorded by Welsh singer Bonnie Tyler for the soundtrack to the 1984 film \"Footloose\", and later included on her 1986 album \"Secret Dreams and Forbidden Fire\".", "It was written by Jim Steinman and Dean Pitchford.", "Initially, the song only just reached the Top 100 in the UK Singles Chart, but made it to number 2 the following year, and re-entered the charts again at number 69 in 1991.", "The song reached No. 1 on the Irish Singles Chart on 28 September 1985.", "It reached the top 40 in the United States and Canada.", "The song's instrumental break was reused from an earlier song by Jim Steinman called \"Stark Raving Love\", which featured on Steinman's 1981 album \"Bad for Good\".", "Jim Steinman had been recruited to work on the \"Footloose\" soundtrack, for which he wrote \"Holding Out for a Hero\" with Dean Pitchford.", "Steinman suggested Tyler's name when he was approached about finding a singer to record the song.", "Tyler recorded the song at the Paramount Studios, and was shown the scene of the film where the song would feature.", "Around the world, \"Holding Out for a Hero\" has become considered a torch song."]], "gold": "The song Holding Out For A Hero was written by Jim Steinman and Dean Pitchford, produced by Jim Steinman, and sang by Bonnie Tyler.", "prediction 1": "\"Holding Out for a Hero\" is a song recorded by Welsh singer Bonnie Tyler for the soundtrack to the 1984 film Footloose, and later included on her 1986 album Secret Dreams and Forbidden Fire. It was written by Jim Steinman and Dean Pitchford. Initially, the song only just reached the Top 100 in the UK Singles Chart, but made it to number 2 the following year, and re-entered the charts again at number 69 in 1991. The song reached No. 1 on the Irish Singles Chart on 28 September 1985. It reached No. 1 on the Irish Singles Chart on 28 September 1985. It reached the top 40 in the United States and Canada.", "prediction 2": "\"Holding Out for a Hero\" is a song recorded by Welsh singer Bonnie Tyler for the soundtrack to the 1984 film FOOTLESSE. It was written by Jim Steinman and Dean Pitchford. Around the world, \"Holding Out for a Hero\" has become considered a torch song.", "prediction 3": "\"Holding Out for a Hero\" is a song recorded by Welsh singer Bonnie Tyler for the soundtrack to the 1984 film \"Footloose\". It was written by Jim Steinman and Dean Pitchford. Around the world, \"Holding Out for a Hero\" has become considered a torch song.", "prediction 4": "\"Holding Out for a Hero\" is a song recorded by Welsh singer Bonnie Tyler for the 1984 film \"Footloose\". It was written by Jim Steinman and Dean Pitchford. Around the world, \"Holding Out for a Hero\" has become considered a torch song.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 242, "end": 486}, {"error type": "Irrelevant", "explanation": "", "start": 487, "end": 552}, {"error type": "Irrelevant", "explanation": "", "start": 553, "end": 607}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [7]}], "corrected-prediction": "\"Holding Out for a Hero\" is a song recorded by Welsh singer Bonnie Tyler for the soundtrack to the 1984 film Footloose, and later included on her 1986 album Secret Dreams and Forbidden Fire. It was written and produced by Jim Steinman and Dean Pitchford."}, "preference": [2, 2, 2, 0, 1, 1], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Holding Out for a Hero\nS1. Holding Out for a Hero  \"Holding Out for a Hero\" is a song recorded by Welsh singer Bonnie Tyler for the soundtrack to the 1984 film \"Footloose\", and later included on her 1986 album \"Secret Dreams and Forbidden Fire\".\nS2. It was written by Jim Steinman and Dean Pitchford.\nS3. Initially, the song only just reached the Top 100 in the UK Singles Chart, but made it to number 2 the following year, and re-entered the charts again at number 69 in 1991.\nS4. The song reached No. 1 on the Irish Singles Chart on 28 September 1985.\nS5. It reached the top 40 in the United States and Canada.\nS6. The song's instrumental break was reused from an earlier song by Jim Steinman called \"Stark Raving Love\", which featured on Steinman's 1981 album \"Bad for Good\".\nS7. Jim Steinman had been recruited to work on the \"Footloose\" soundtrack, for which he wrote \"Holding Out for a Hero\" with Dean Pitchford.\nS8. Steinman suggested Tyler's name when he was approached about finding a singer to record the song.\nS9. Tyler recorded the song at the Paramount Studios, and was shown the scene of the film where the song would feature.\nS10. Around the world, \"Holding Out for a Hero\" has become considered a torch song.\n    \nInput Question:\nWho made the song i need a hero?\n\nCorrect Response:\nThe song Holding Out For A Hero was written by Jim Steinman and Dean Pitchford, produced by Jim Steinman, and sang by Bonnie Tyler.\n\nModel Prediction:\n\"Holding Out for a Hero\" is a song recorded by Welsh singer Bonnie Tyler for the soundtrack to the 1984 film Footloose, and later included on her 1986 album Secret Dreams and Forbidden Fire. It was written by Jim Steinman and Dean Pitchford. Initially, the song only just reached the Top 100 in the UK Singles Chart, but made it to number 2 the following year, and re-entered the charts again at number 69 in 1991. The song reached No. 1 on the Irish Singles Chart on 28 September 1985. It reached No. 1 on the Irish Singles Chart on 28 September 1985. It reached the top 40 in the United States and Canada.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "\"Holding Out for a Hero\" is a song recorded by Welsh singer Bonnie Tyler for the soundtrack to the 1984 film Footloose, and later included on her 1986 album Secret Dreams and Forbidden Fire. It was written by Jim Steinman and Dean Pitchford. [Initially, the song only just reached the Top 100 in the UK Singles Chart, but made it to number 2 the following year, and re-entered the charts again at number 69 in 1991. The song reached No. 1 on the Irish Singles Chart on 28 September 1985.] [It reached No. 1 on the Irish Singles Chart on 28 September 1985.] [It reached the top 40 in the United States and Canada.]\n\nExplanation:\n1. The information about the song's chart performance is irrelevant to the question, which is asking about who made the song.\n2. The sentence \"It reached No. 1 on the Irish Singles Chart on 28 September 1985.\" is repeated and thus marked as repetitive.\n3. The sentence \"It reached the top 40 in the United States and Canada.\" is also irrelevant to the question."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. \"Holding Out for a Hero\" is a song recorded by Welsh singer Bonnie Tyler for the soundtrack to the 1984 film Footloose, and later included on her 1986 album Secret Dreams and Forbidden Fire.\nS2. It was written by Jim Steinman and Dean Pitchford.\nS3. Initially, the song only just reached the Top 100 in the UK Singles Chart, but made it to number 2 the following year, and re-entered the charts again at number 69 in 1991.\nS4. The song reached No.\nS5. 1 on the Irish Singles Chart on 28 September 1985.\nS6. It reached No.\nS7. 1 on the Irish Singles Chart on 28 September 1985.\nS8. It reached the top 40 in the United States and Canada.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation:\nAll the facts presented in the model prediction are consistent with the provided passages and can be verified. However, some of the information is irrelevant to the question, as noted in the previous step."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 7 [Missing Major Auxiliary Information]\n\nExplanation:\n1. The model prediction does not mention that Jim Steinman also produced the song, which is a crucial piece of information about who made the song. This information can be inferred from Passage 1, sentence 7, where it is mentioned that Steinman was recruited to work on the Footloose soundtrack and wrote the song."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "\"Holding Out for a Hero\" is a song recorded by Welsh singer Bonnie Tyler for the soundtrack to the 1984 film Footloose, and later included on her 1986 album Secret Dreams and Forbidden Fire. It was written and produced by Jim Steinman and Dean Pitchford."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 73, "end": 190}, {"error type": "Irrelevant", "explanation": "", "start": 242, "end": 414}, {"error type": "Irrelevant", "explanation": "", "start": 415, "end": 486}, {"error type": "Irrelevant", "explanation": "", "start": 487, "end": 552}, {"error type": "Irrelevant", "explanation": "", "start": 553, "end": 607}], "missing-info": [], "corrected-prediction": "\"Holding Out for a Hero\" is a song recorded by Welsh singer Bonnie Tyler. It was written by Jim Steinman and Dean Pitchford. "}}, {"question": "Who sings the song raise a little hell?", "passages": [["Raise a Little Hell", "Raise a Little Hell\n\n\"Raise a Little Hell\" is a song by Canadian rock band Trooper.", "The song is the 10th and final track on the band's 1978 album \"Thick as Thieves\".", "It is the band's only US Hot 100 hit and is regularly played in sports stadiums across Canada and the United States.", "The song peaked at #27 on the Canadian Hot 100 and #59 on the Billboard Hot 100, the group's only hit on the latter chart.", "The song appeared in the television series \"Call Me Fitz\" and \"Stranger Things\"; and the films \"Gutterball (2008) and \"Drive Angry\" (2011).", "\"Raise a Little Hell\" has become both a staple of classic rock radio stations around the world, and a popular sports anthem in Canada and the United States, most notably at National Hockey League and Major League Baseball games.", "Rolling Stone placed the song at #7 on their list of the \"Top 10 Sports Anthems of All Time\", while CKKQ-FM \"the Q\" ranked the song at #10 on their list of \"The 150 Best Canadian Songs\".", "The song as covered by Canadian punk band GrimSkunk and appears on \"\" which the soundtrack to the film \"FUBAR\"."]], "gold": "\"Raise a Little Hell\" is a song by Canadian rock band Trooper, who released it as the 10th and final track on the band's 1978 album \"Thick as Thieves\". The song was Trooper's only US Hot 100 hit and was later covered by Canadian punk band GrimSkunk for the soundtrack of the film \"FUBAR\".", "prediction 1": "\"Raise a Little Hell\" is a song by Canadian rock band Trooper. The song is the 10th and final track on the band's 1978 album \"Thick as Thieves\". It is the band's only US Hot 100 hit and is regularly played in sports stadiums across Canada and the United States. It is also a popular sports anthem in the National Hockey League and Major League Baseball games.", "prediction 2": "\"Raise a Little Hell\" is a song by Canadian rock band Trooper that was released on their 1978 album Thieves. It is the band's only US Hot 100 hit and is regularly played in sports stadiums across Canada and the United States. The song appeared in the television series Call Me Fitz and Stranger Things; and the films Gutterball (2008) and Drive Angry (2011). The song as covered by Canadian punk band GrimSkunk and appears on the soundtrack to the film FUBAR.", "prediction 3": "\"Raise a Little Hell\" is a song by Canadian rock band Trooper. The song is the 10th and final track on the band's 1978 album \"Thick as Thieves\". It is the band's only US Hot 100 hit and is regularly played in sports stadiums across Canada and the United States. The song has become both a staple of classic rock radio stations around the world, and a popular sports anthem in Canada and the United States, most notably at National Hockey League and Major League Baseball games.", "prediction 4": "\"Raise a Little Hell\" is a song by Canadian rock band Trooper. It is the 10th and final track on the band's 1978 album Thieves. The song is the band's only US Hot 100 hit and is regularly played in sports stadiums across Canada and the United States. The song appeared in the television series Call Me Fitz and Stranger Things; and the films Gutterball (2008) and Drive Angry (2011). The song has become both a staple of classic rock radio stations around the world, and a popular sports anthem in Canada and the United States, most notably at National Hockey League Baseball games. It has been covered by Canadian punk band GrimSkunk, and appears on the soundtrack to the film FUBAR.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 262, "end": 359}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [8]}], "corrected-prediction": "\"Raise a Little Hell\" is a song by Canadian rock band Trooper. The song is the 10th and final track on the band's 1978 album \"Thick as Thieves\". It is the band's only US Hot 100 hit and is regularly played in sports stadiums across Canada and the United States. The song was also covered by Canadian punk band GrimSkunk for the soundtrack of the film \"FUBAR\"."}, "preference": [2, 1, 1, 1, 1, 1], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Raise a Little Hell\nS1. Raise a Little Hell  \"Raise a Little Hell\" is a song by Canadian rock band Trooper.\nS2. The song is the 10th and final track on the band's 1978 album \"Thick as Thieves\".\nS3. It is the band's only US Hot 100 hit and is regularly played in sports stadiums across Canada and the United States.\nS4. The song peaked at #27 on the Canadian Hot 100 and #59 on the Billboard Hot 100, the group's only hit on the latter chart.\nS5. The song appeared in the television series \"Call Me Fitz\" and \"Stranger Things\"; and the films \"Gutterball (2008) and \"Drive Angry\" (2011).\nS6. \"Raise a Little Hell\" has become both a staple of classic rock radio stations around the world, and a popular sports anthem in Canada and the United States, most notably at National Hockey League and Major League Baseball games.\nS7. Rolling Stone placed the song at #7 on their list of the \"Top 10 Sports Anthems of All Time\", while CKKQ-FM \"the Q\" ranked the song at #10 on their list of \"The 150 Best Canadian Songs\".\nS8. The song as covered by Canadian punk band GrimSkunk and appears on \"\" which the soundtrack to the film \"FUBAR\".\n    \nInput Question:\nWho sings the song raise a little hell?\n\nCorrect Response:\n\"Raise a Little Hell\" is a song by Canadian rock band Trooper, who released it as the 10th and final track on the band's 1978 album \"Thick as Thieves\". The song was Trooper's only US Hot 100 hit and was later covered by Canadian punk band GrimSkunk for the soundtrack of the film \"FUBAR\".\n\nModel Prediction:\n\"Raise a Little Hell\" is a song by Canadian rock band Trooper. The song is the 10th and final track on the band's 1978 album \"Thick as Thieves\". It is the band's only US Hot 100 hit and is regularly played in sports stadiums across Canada and the United States. It is also a popular sports anthem in the National Hockey League and Major League Baseball games.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "\"Raise a Little Hell\" is a song by Canadian rock band Trooper. The song is the 10th and final track on the band's 1978 album \"Thick as Thieves\". It is the band's only US Hot 100 hit and is regularly played in sports stadiums across Canada and the United States. [It is also a popular sports anthem in the National Hockey League and Major League Baseball games.]\n\nExplanation:\n1. The last sentence in the model prediction is repetitive as it repeats the information that the song is regularly played in sports stadiums, which is already mentioned in the previous sentence. Therefore, it should be marked as \"Repetitive\"."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. \"Raise a Little Hell\" is a song by Canadian rock band Trooper.\nS2. The song is the 10th and final track on the band's 1978 album \"Thick as Thieves\".\nS3. It is the band's only US Hot 100 hit and is regularly played in sports stadiums across Canada and the United States.\nS4. It is also a popular sports anthem in the National Hockey League and Major League Baseball games.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation:\nThere are no factual inconsistencies or unverifiable facts in the model prediction. All the information provided in the model prediction is consistent with the passages."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 8 [Missing Major Auxiliary Information]\n\nExplanation:\n1. The model prediction misses the information that the song \"Raise a Little Hell\" was covered by Canadian punk band GrimSkunk for the soundtrack of the film \"FUBAR\". This information is found in Passage 1, sentence 8 and is also included in the reference response, making it a missing major auxiliary information."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "\"Raise a Little Hell\" is a song by Canadian rock band Trooper. The song is the 10th and final track on the band's 1978 album \"Thick as Thieves\". It is the band's only US Hot 100 hit and is regularly played in sports stadiums across Canada and the United States. The song was also covered by Canadian punk band GrimSkunk for the soundtrack of the film \"FUBAR\"."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 182, "end": 261}, {"error type": "Irrelevant", "explanation": "", "start": 262, "end": 359}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 1, "sentence_id": [8]}], "corrected-prediction": "\"Raise a Little Hell\" is a song by Canadian rock band Trooper. The song is the 10th and final track on the band's 1978 album \"Thick as Thieves\". It is the band's only US Hot 100 hit. The song was covered by Canadian punk band GrimSkunk and appears on \"\" which the soundtrack to the film \"FUBAR\"."}}, {"question": "Who does the voice of max from a goofy movie?", "passages": [["A Goofy Movie", "A Goofy Movie\n\nA Goofy Movie is a 1995 animated musical comedy drama film, produced by Disney MovieToons and Walt Disney Television Animation and distributed by Walt Disney Pictures.", "The animated directorial debut of Kevin Lima, the film is based on The Disney Afternoon television series \"Goof Troop\" created by Mike Peraza, and acts as a follow-up to the show.", "Taking place several years after the events of \"Goof Troop\", \"A Goofy Movie\" follows Goofy and his son, Max, who is now in high school, and revolves around the father-son relationship between the two as Goofy takes Max on a fishing trip out of fear that Max is drifting away from him, unintentionally interfering with Max's social life, particularly his relationship with Roxanne, his high school crush.", "It features the voices of Jason Marsden, Bill Farmer, Jim Cummings, Kellie Martin, Pauly Shore, Jenna von O\u00ff, and Wallace Shawn, and prominently features the singing voice of Tevin Campbell as Powerline, a fictional pop star.", "The film was also dedicated to Pat Buttram, who died during the film's production.", "\"A Goofy Movie\" was released theatrically on April 7, 1995, by Walt Disney Pictures to mixed reviews from critics and moderate box office success.", "It has since gained a cult following among millennials."], ["Max Goof", "\"A Goofy Movie\" features Max as a teenage high school student, finishing the school year before going on summer break.", "In this movie, Max has grown to find his father's goofy antics embarrassing, and is likewise viewed by his peers as a geek and a goof himself; a view he seeks to change at the school assembly when he dresses up like the popular rock star Powerline and interrupts the assembly to perform Powerline's hit song \"Stand Out\" before the entire student body.", "Additionally, Max seeks to gain the attention of his crush, a popular girl named Roxanne, whom Max is convinced only ever '[looks] right through [him]' and believes the laugh he inherited from his father (\"ah-hyuck\") is to her disliking.", "Though Max ends up in detention for hijacking the assembly, he succeeds in not only impressing the other students but also winning the affections of Roxanne, who shyly yet delightedly agrees to go with him to a party that is to be held the next Saturday.", "However, the principal informs Max's father, Goofy, about Max's behavior and, fearful that his son is becoming a delinquent, Goofy decides to take Max on a cross-country fishing trip for some 'father-son bonding', much to Max's chagrin."]], "gold": "A Goofy Movie is a 1995 American animated musical comedy film that revolves around the father-son relationship between Goofy and his 14-year-old son Max as they embark on a misguided mission to bond together in the middle of a cross-country fishing trip. Different people voiced the character of Max during the production of the movie. Jason Marsden, who was in high-school at the time, was the primary voice actor, while Aaron Lohr worked on his singing voice.", "prediction 1": "A Goofy Movie is a 1995 musical comedy drama animated film. The film features the voices of Jason Marsden, Bill Farmer, Jim Cummings, Kellie Martin, Pauly Shore, Jenna von O, and Wallace Shawn, and prominently features the singing voice of Tevin Campbell as Powerline, a fictional pop star.", "prediction 2": "Max Goof is the voice of Max in the 1995 animated musical comedy drama film A Goofy Movie. The film was the animated directorial debut of Kevin Lima, and is based on the television series Goof Troop created by Mike Peraza. Jason Marsden, Bill Farmer, Jim Cummings, Kellie Martin, Pauly Shore, Jenna von O, and Wallace Shawn do the voices of Max and Powerline. Tevin Campbell does the voice of Powerline.", "prediction 3": "Max Goof is a fictional character in the 1995 animated musical comedy drama film, A Goofy Movie, and the film's director is Kevin Lima, with voices by Jason Marsden, Bill Farmer, Jim Cummings, Kellie Martin, Pauly Shore, Wallace Shawn, and Wallace Shawn, and prominently features the singing voice of Tevin Campbell as the pop star Powerline.", "prediction 4": "The voice of Max Goof in A Goofy Movie is done by Jason Marsden. He is the son of Goofy and Max, who is now in high school and has grown to find his dad's goofy antics embarrassing. He also finds his peers' opinion of him as a geek and a goof.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 92, "end": 290}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 1, "sentence_id": [4]}], "corrected-prediction": "In \"A Goofy Movie\", the character Max is voiced by Jason Marsden."}, "preference": [2, 2, 1, 0, 1, 1], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - A Goofy Movie\nS1. A Goofy Movie  A Goofy Movie is a 1995 animated musical comedy drama film, produced by Disney MovieToons and Walt Disney Television Animation and distributed by Walt Disney Pictures.\nS2. The animated directorial debut of Kevin Lima, the film is based on The Disney Afternoon television series \"Goof Troop\" created by Mike Peraza, and acts as a follow-up to the show.\nS3. Taking place several years after the events of \"Goof Troop\", \"A Goofy Movie\" follows Goofy and his son, Max, who is now in high school, and revolves around the father-son relationship between the two as Goofy takes Max on a fishing trip out of fear that Max is drifting away from him, unintentionally interfering with Max's social life, particularly his relationship with Roxanne, his high school crush.\nS4. It features the voices of Jason Marsden, Bill Farmer, Jim Cummings, Kellie Martin, Pauly Shore, Jenna von O\u00ff, and Wallace Shawn, and prominently features the singing voice of Tevin Campbell as Powerline, a fictional pop star.\nS5. The film was also dedicated to Pat Buttram, who died during the film's production.\nS6. \"A Goofy Movie\" was released theatrically on April 7, 1995, by Walt Disney Pictures to mixed reviews from critics and moderate box office success.\nS7. It has since gained a cult following among millennials.\n\nPassage 2: Title (S0) - Max Goof\nS1. \"A Goofy Movie\" features Max as a teenage high school student, finishing the school year before going on summer break.\nS2. In this movie, Max has grown to find his father's goofy antics embarrassing, and is likewise viewed by his peers as a geek and a goof himself; a view he seeks to change at the school assembly when he dresses up like the popular rock star Powerline and interrupts the assembly to perform Powerline's hit song \"Stand Out\" before the entire student body.\nS3. Additionally, Max seeks to gain the attention of his crush, a popular girl named Roxanne, whom Max is convinced only ever '[looks] right through [him]' and believes the laugh he inherited from his father (\"ah-hyuck\") is to her disliking.\nS4. Though Max ends up in detention for hijacking the assembly, he succeeds in not only impressing the other students but also winning the affections of Roxanne, who shyly yet delightedly agrees to go with him to a party that is to be held the next Saturday.\nS5. However, the principal informs Max's father, Goofy, about Max's behavior and, fearful that his son is becoming a delinquent, Goofy decides to take Max on a cross-country fishing trip for some 'father-son bonding', much to Max's chagrin.\n    \nInput Question:\nWho does the voice of max from a goofy movie?\n\nCorrect Response:\nA Goofy Movie is a 1995 American animated musical comedy film that revolves around the father-son relationship between Goofy and his 14-year-old son Max as they embark on a misguided mission to bond together in the middle of a cross-country fishing trip. Different people voiced the character of Max during the production of the movie. Jason Marsden, who was in high-school at the time, was the primary voice actor, while Aaron Lohr worked on his singing voice.\n\nModel Prediction:\nA Goofy Movie is a 1995 musical comedy drama animated film. The film features the voices of Jason Marsden, Bill Farmer, Jim Cummings, Kellie Martin, Pauly Shore, Jenna von O, and Wallace Shawn, and prominently features the singing voice of Tevin Campbell as Powerline, a fictional pop star.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "A Goofy Movie is a 1995 musical comedy drama animated film. The film features the voices of [Jason Marsden, Bill Farmer, Jim Cummings, Kellie Martin, Pauly Shore, Jenna von O, and Wallace Shawn, and prominently features the singing voice of Tevin Campbell as Powerline, a fictional pop star.]\n\nExplanation:\nThe model prediction includes a list of all the voice actors in the film, which is irrelevant to the question. The question specifically asks for the voice actor of Max, so the other names are not needed. The information about Tevin Campbell voicing Powerline is also irrelevant."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. A Goofy Movie is a 1995 musical comedy drama animated film.\nS2. The film features the voices of Jason Marsden, Bill Farmer, Jim Cummings, Kellie Martin, Pauly Shore, Jenna von O, and Wallace Shawn, and prominently features the singing voice of Tevin Campbell as Powerline, a fictional pop star.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation:\nAll the facts in the model prediction are consistent with the provided passages and there are no unverifiable facts. The problem with the model prediction is not about factual inaccuracy, but about relevance to the question."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 4 [Missing Answer]\n\nExplanation:\n1. The model prediction does not directly answer the question about who voiced the character Max in \"A Goofy Movie\". The information that Jason Marsden voiced Max is found in Passage 1, sentence 4. This is a missing answer in the model prediction."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "In \"A Goofy Movie\", the character Max is voiced by Jason Marsden."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 60, "end": 290}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [3]}], "corrected-prediction": "A Goofy Movie is a 1995 musical comedy drama animated film. It revolves around the father-son relationship between the two as Goofy takes Max on a fishing trip out of fear that Max is drifting away from him. "}}, {"question": "Who holds the record of scoring the maximum number of runs in test cricket?", "passages": [["Australia national cricket team", "The team was led by Bill Woodfull on his final tour and was notably dominated by Ponsford and Bradman, who twice put on partnerships of over 380 runs, with Bradman once again scoring a triple-century at Leeds.", "The bowling was dominated by the spin pair of Bill O'Reilly and Clarrie Grimmett, who took 53 wickets between them, with O'Reilly twice taking seven-wicket hauls.", "Sir Donald Bradman is widely considered the greatest batsman of all time.", "He dominated the sport from 1930 until his retirement in 1948, setting new records for the highest score in a Test innings (334 vs England at Headingley in 1930), the most number of runs (6996), the most number of centuries (29), the most number of double centuries and the highest Test and first-class batting averages.", "His record for the highest Test batting average \u2013 99.94 \u2013 has never been beaten.", "It is almost 40 runs per innings above the next highest average.", "He would have finished with an average of over 100 runs per innings if he had not been dismissed for a duck in his last Test.", "He was knighted in 1949 for services to cricket.", "He is generally considered one of Australia's greatest sporting heroes."], ["Sachin Tendulkar", "South Africa toured in March and April 2008 for a three-Test series.", "Tendulkar scored a five-ball duck in his only innings of the series; he sustained a groin strain in the match and as a result was forced not only to miss the second and third Tests, but also the tri-series involving Bangladesh, the 2008 Asia Cup, and the first half of the inaugural season of the IPL.", "Before the Indian cricket team's tour of Sri Lanka in July 2008, Tendulkar needed 177 runs to go past Brian Lara's record of Test 11,953 runs.", "However, he failed in all six innings, scoring a total of 95 runs.", "India lost the series and his average of 15.83 was his worst in a Test series with at least three matches.", "In the following ODI series against Sri Lanka, Tendulkar was sidelined due to injury.", "However, during the following Australia tour of India, he returned to fitness and form, scoring 13 and 49 in the first Test before making 88 in the first innings of the second Test, breaking the record for most number of Test runs held by Brian Lara.", "He also reached the 12,000 run mark when he was on 61.", "He described the achievement as the biggest in 19 years of his career on the day he achieved the record."], ["Graham Gooch", "His aggregate of 456 for the match remains a world record for a Test match, as does his aggregate of 753 for the 3-match series.", "Both series were won, and in 1990 Gooch was awarded Professional Cricketers' Association Player of the Year.", "The winter tour of Australia did not, however, go according to plan, England losing 3\u20130 despite holding first-innings leads in the first two tests (both of which were lost), although Gooch scored a marvellous hundred chasing an improbable total in the drawn 4th test.", "Gooch had a public falling-out with David Gower, the England batsman, particularly after Gower hired a vintage aircraft and 'buzzed' the ground where England was playing during the unsuccessful tour of Australia in 1990/91.", "Gooch contributed to the decision to omit Gower from England's tour of India in 1993, which proved so controversial that an extraordinary vote of no confidence in the selectors was passed at the MCC.", "Gower never played another Test, lending an ironic edge to Gooch's surpassing him as England's leading run scorer in the 1993 Ashes series."]], "gold": "Sachin Tendulkar holds the record for most runs scored in test cricket in a career with 11,953. Graham Gooch hold the record for most runs scored in a match in test cricket with 456. Donald Bradman has the record for most runs in a series with 974. Mohammad Yousuf has the record for most runs in a calendar year with 1788 in 2006.", "prediction 1": "Sir Donald Bradman is widely considered the greatest batsman of all time. He dominated the sport from 1930 until his retirement in 1948, setting new records for the highest score in a Test innings (334 vs England at Headingley in 1930), the most number of runs (6996), the most number of centuries (29), the most number of double centuries and the highest Test and first-class batting averages. Sachin Tendulkar holds the record for scoring the most number of Test runs in a Test innings, scoring a total of 12,5162 runs. His aggregate of 456 for the match remains a world record for a Test match, as does his aggregate of 753 for the 3-match series.", "prediction 2": "Sir Donald Bradman is widely considered the greatest batsman of all time. He dominated the sport from 1930 until his retirement in 1948, setting new records for the highest score in a Test innings (334 vs England at Headingley in 1930), the most number of runs (6996), the most number of centuries (29), the most number of double centuries and the highest Test and first-class batting averages. However, before the Indian cricket team's tour of Sri Lanka in July 2008, Sachin Tendulkar needed 177 runs to go past Brian Lara's record for most number of Test 11,953 runs. However, he failed in all six innings, scoring a total of 95 runs. He also reached the 12,000 run mark when he was on 61. Gooch broke the record for most number of Test runs held by David Gower.", "prediction 3": "The record for scoring the maximum number of runs in Test cricket is held by Sir Donald Bradman, who is widely considered to be the greatest batsman of all time. Brian Lara holds the record for the most number of Test runs scored in a single innings in Test cricket, with his total of 11,953 runs in one Test. However, Graham Gooch holds the record for scoring the maximum number of runs in a single innings in Test cricket.", "prediction 4": "Sir Donald Bradman is widely considered to be the greatest batsman of all time. He dominated the sport from 1930 until his retirement in 1948, setting new records for the highest score in a Test innings (334 vs England at Headingley in 1930), the most number of runs (6996), the most number of centuries (29), the most number of double centuries and the highest Test and first-class batting averages. His record for the highest Test batting average \u2013 99.94 \u2013 has never been beaten. It is almost 40 runs per innings above the next highest average. His record for the highest Test batting average \u2013 99.94 \u2013 has never been beaten. It is almost 40 runs per innings above the next highest average. It is almost 40 runs per innings above the next highest average. It is almost 40 runs per innings above the next highest average. It is almost 40 runs per innings above the next highest", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 395, "end": 521}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 2, "sentence_id": [7]}], "corrected-prediction": "Sir Donald Bradman is widely considered the greatest batsman of all time. He dominated the sport from 1930 until his retirement in 1948, setting new records for the highest score in a Test innings (334 vs England at Headingley in 1930), the most number of runs (6996), the most number of centuries (29), the most number of double centuries and the highest Test and first-class batting averages. Sachin Tendulkar holds the record for scoring the most number of Test runs in a career, scoring a total of 11,953 runs. His aggregate of 456 for the match remains a world record for a Test match, as does his aggregate of 753 for the 3-match series."}, "preference": [1, 1, 1, 1, 1, 2], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Australia national cricket team\nS1. The team was led by Bill Woodfull on his final tour and was notably dominated by Ponsford and Bradman, who twice put on partnerships of over 380 runs, with Bradman once again scoring a triple-century at Leeds.\nS2. The bowling was dominated by the spin pair of Bill O'Reilly and Clarrie Grimmett, who took 53 wickets between them, with O'Reilly twice taking seven-wicket hauls.\nS3. Sir Donald Bradman is widely considered the greatest batsman of all time.\nS4. He dominated the sport from 1930 until his retirement in 1948, setting new records for the highest score in a Test innings (334 vs England at Headingley in 1930), the most number of runs (6996), the most number of centuries (29), the most number of double centuries and the highest Test and first-class batting averages.\nS5. His record for the highest Test batting average \u2013 99.94 \u2013 has never been beaten.\nS6. It is almost 40 runs per innings above the next highest average.\nS7. He would have finished with an average of over 100 runs per innings if he had not been dismissed for a duck in his last Test.\nS8. He was knighted in 1949 for services to cricket.\nS9. He is generally considered one of Australia's greatest sporting heroes.\n\nPassage 2: Title (S0) - Sachin Tendulkar\nS1. South Africa toured in March and April 2008 for a three-Test series.\nS2. Tendulkar scored a five-ball duck in his only innings of the series; he sustained a groin strain in the match and as a result was forced not only to miss the second and third Tests, but also the tri-series involving Bangladesh, the 2008 Asia Cup, and the first half of the inaugural season of the IPL.\nS3. Before the Indian cricket team's tour of Sri Lanka in July 2008, Tendulkar needed 177 runs to go past Brian Lara's record of Test 11,953 runs.\nS4. However, he failed in all six innings, scoring a total of 95 runs.\nS5. India lost the series and his average of 15.83 was his worst in a Test series with at least three matches.\nS6. In the following ODI series against Sri Lanka, Tendulkar was sidelined due to injury.\nS7. However, during the following Australia tour of India, he returned to fitness and form, scoring 13 and 49 in the first Test before making 88 in the first innings of the second Test, breaking the record for most number of Test runs held by Brian Lara.\nS8. He also reached the 12,000 run mark when he was on 61.\nS9. He described the achievement as the biggest in 19 years of his career on the day he achieved the record.\n\nPassage 3: Title (S0) - Graham Gooch\nS1. His aggregate of 456 for the match remains a world record for a Test match, as does his aggregate of 753 for the 3-match series.\nS2. Both series were won, and in 1990 Gooch was awarded Professional Cricketers' Association Player of the Year.\nS3. The winter tour of Australia did not, however, go according to plan, England losing 3\u20130 despite holding first-innings leads in the first two tests (both of which were lost), although Gooch scored a marvellous hundred chasing an improbable total in the drawn 4th test.\nS4. Gooch had a public falling-out with David Gower, the England batsman, particularly after Gower hired a vintage aircraft and 'buzzed' the ground where England was playing during the unsuccessful tour of Australia in 1990/91.\nS5. Gooch contributed to the decision to omit Gower from England's tour of India in 1993, which proved so controversial that an extraordinary vote of no confidence in the selectors was passed at the MCC.\nS6. Gower never played another Test, lending an ironic edge to Gooch's surpassing him as England's leading run scorer in the 1993 Ashes series.\n    \nInput Question:\nWho holds the record of scoring the maximum number of runs in test cricket?\n\nCorrect Response:\nSachin Tendulkar holds the record for most runs scored in test cricket in a career with 11,953. Graham Gooch hold the record for most runs scored in a match in test cricket with 456. Donald Bradman has the record for most runs in a series with 974. Mohammad Yousuf has the record for most runs in a calendar year with 1788 in 2006.\n\nModel Prediction:\nSir Donald Bradman is widely considered the greatest batsman of all time. He dominated the sport from 1930 until his retirement in 1948, setting new records for the highest score in a Test innings (334 vs England at Headingley in 1930), the most number of runs (6996), the most number of centuries (29), the most number of double centuries and the highest Test and first-class batting averages. Sachin Tendulkar holds the record for scoring the most number of Test runs in a Test innings, scoring a total of 12,5162 runs. His aggregate of 456 for the match remains a world record for a Test match, as does his aggregate of 753 for the 3-match series.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "Sir Donald Bradman is widely considered the greatest batsman of all time. He dominated the sport from 1930 until his retirement in 1948, setting new records for the highest score in a Test innings (334 vs England at Headingley in 1930), the most number of runs (6996), the most number of centuries (29), the most number of double centuries and the highest Test and first-class batting averages. [Sachin Tendulkar holds the record for scoring the most number of Test runs in a Test innings, scoring a total of 12,5162 runs.] His aggregate of 456 for the match remains a world record for a Test match, as does his aggregate of 753 for the 3-match series.\n\nExplanation:\n1. The span \"Sachin Tendulkar holds the record for scoring the most number of Test runs in a Test innings, scoring a total of 12,5162 runs.\" is incorrect and irrelevant. Sachin Tendulkar holds the record for most runs scored in test cricket in a career, not in a Test innings. The number 12,5162 is also incorrect and does not make sense."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. Sir Donald Bradman is widely considered the greatest batsman of all time.\nS2. He dominated the sport from 1930 until his retirement in 1948, setting new records for the highest score in a Test innings (334 vs England at Headingley in 1930), the most number of runs (6996), the most number of centuries (29), the most number of double centuries and the highest Test and first-class batting averages.\nS3. Sachin Tendulkar holds the record for scoring the most number of Test runs in a Test innings, scoring a total of 12,5162 runs.\nS4. His aggregate of 456 for the match remains a world record for a Test match, as does his aggregate of 753 for the 3-match series.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "Inconsistent or Unverifiable Sentences:\n1. S3\n\nExplanation:\n1. The statement \"Sachin Tendulkar holds the record for scoring the most number of Test runs in a Test innings, scoring a total of 12,5162 runs.\" is factually incorrect and inconsistent with the passages. The passages do not provide any information to verify this claim."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 2, sentence 7 [Missing Answer]\n\nExplanation:\n1. The model prediction does not mention that Sachin Tendulkar holds the record for most runs scored in test cricket in a career with 11,953, which is a direct answer to the question and is mentioned in Passage 2, sentence 7."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "Sir Donald Bradman is widely considered the greatest batsman of all time. He dominated the sport from 1930 until his retirement in 1948, setting new records for the highest score in a Test innings (334 vs England at Headingley in 1930), the most number of runs (6996), the most number of centuries (29), the most number of double centuries and the highest Test and first-class batting averages. Sachin Tendulkar holds the record for scoring the most number of Test runs in a career, scoring a total of 11,953 runs. His aggregate of 456 for the match remains a world record for a Test match, as does his aggregate of 753 for the 3-match series."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 19, "end": 73}, {"error type": "Irrelevant", "explanation": "", "start": 74, "end": 236}, {"error type": "Irrelevant", "explanation": "", "start": 269, "end": 394}, {"error type": "Irrelevant", "explanation": "", "start": 522, "end": 650}, {"error type": "Unverifiable", "explanation": "", "start": 470, "end": 521}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 1, "sentence_id": [1]}], "corrected-prediction": "Sir Donald Bradman has the most number of runs 6996 in a Test innings. Sachin Tendulkar holds the record for scoring the most number of Test runs.  Graham Gooch's aggregate of 456 for the match remains a world record for a Test match, as does his aggregate of 753 for the 3-match series."}}, {"question": "When did the smoking ban came into the uk?", "passages": [["Smoking in the United Kingdom", "Until 31 August 2008, the minimum age to purchase and consume tobacco products in public was 16 years of age.", "From 1 September 2008 the Children and Young Persons (Sale of Tobacco etc.)", "Regulations (Northern Ireland) 2008 became effective, raising the minimum purchase, consumption and possession age to 18 years of age.", "Smoking in workplaces and enclosed public spaces has been illegal since 26 March 2006 in Scotland, 2 April 2007 in Wales, 30 April 2007 in Northern Ireland and 1 July 2007 in England, \n\nOn 6 April 2012, the display of tobacco products was banned in retailers larger than 280 square metres in England.", "With the ban coming into effect in small retailers three years later on 6 April 2015.", "In March 2011, the Conservative-Lib Dem coalition government committed itself to holding a public consultation on the introduction of plain tobacco packaging.", "Influenced by the introduction of plain packaging in Australia, the House of Commons voted 367\u2013113 in March 2015 to pass the Children and Families Act 2014 which would give the government the power to require plain packaging for tobacco products.", "This came into force on 20 May 2016, but tobacco companies were given one year to sell off remaining stock; in which afterwards, all tobacco products sold in the UK must follow plain packaging laws.", "On October 1, 2015 a law was passed which banned smoking in vehicles with anyone under eighteen years of age present."], ["Smoking ban in England", "Smoking ban in England\n\nA smoking ban in England, making it illegal to smoke in all enclosed work places in England, came into force on 1 July 2007 as a consequence of the Health Act 2006.", "Similar bans had already been introduced by the rest of the United Kingdom: in Scotland on 26 March 2006, Wales on 2 April 2007 and Northern Ireland on 30 April 2007.", "Before the ban many businesses voluntarily introduced bans on smoking mainly as a result of public feedback.", "The pub chain Wetherspoons was the first major chain to introduce a complete ban on indoor smoking, doing so in May 2006.", "Tobacco advertising had been banned in England gradually starting with a ban on Television Advertising of cigarettes in 1965 to a complete ban on all Tobacco Advertising in 2005.", "On 16 November 2004 a Public Health white paper proposed a smoking ban in almost all public places in England and Wales.", "Smoking restrictions would be phased in, with a ban on smoking in NHS and government buildings by 2006, in enclosed public places by 2007, and pubs, bars and restaurants (except pubs not serving food) by the end of 2008.", "On 26 October 2005, after external challenge and debates within the Cabinet, the government announced that it would continue with its plans."], ["Smoking in the United Kingdom", "The law does not apply to e-cigarettes, if the driver is seventeen years of age and alone in the vehicle or in a convertible with the roof completely down.", "Despite the name, 'e-cigarette,' these devices contain no tobacco and produce no smoke, and therefore any reference to them, should be under e-cigarettes and not smoking.", "Exceptions to this might be their role as an alternative to smoking, or as devices where it increasingly looks like they are helping young people avoid smoking.", "On 2 April 2014 the Welsh Government published a public health white paper in which it proposed a ban on the use of e-cigarettes in public spaces.", "The Bill was subsequently defeated.", "The annual Smokefree GB survey, published in May 2017, concluded that 52% of the 2.9 million British e-cigarette users are now ex-smokers.", "26% of respondents thought e-cigarettes were as harmful as real cigarettes.", "In March 2017, it was reported by The Telegraph UK's e-cigarette boom is on a decline, with the number of people using e-cigarettes in Britain decreasing for the first time since their launch."]], "gold": "A smoking ban in England, making it illegal to smoke in all enclosed public space and workplaces, came into force on 1 July 2007 as a consequence of the Health Act 2006. Similar bans had already been introduced by the rest of the United Kingdom: in Scotland on 26 March 2006, Wales on 2 April 2007 and Northern Ireland on 30 April 2007. On 1 October 2015, a law was passed which banned smoking in vehicles with anyone under eighteen years of age present. The law does not apply to e-cigarettes, if the driver is seventeen years of age and alone in the vehicle, or in a convertible with the roof completely down.", "prediction 1": "The smoking ban in the United Kingdom, making it illegal to smoke in all enclosed work places in England, came into force on 1 July 2007. Smoking in workplaces and enclosed public spaces has been illegal since 26 March 2006 in Scotland, 2 April 2007 in Wales, 30 April 2007 in Northern Ireland and 1 July 2007 in England. On 6 April 2012, the display of tobacco products was banned in retailers larger than 280 square metres in England. With the ban coming into effect in small retailers three years later on 6 April 2015. On October 1, 2015 a law was passed which banned smoking in vehicles with anyone under 18 years of age present.", "prediction 2": "A smoking ban in England, making it illegal to smoke in all enclosed work places in England, came into force on 1 July 2007 as a consequence of the Health Act 2006. Similar bans had already been introduced by the rest of the United Kingdom: in Scotland on 26 March 2006, 2 April 2007 in Wales, 30 April 2007 in Northern Ireland and 1 July 2007 in England. On 6 April 2012, the display of tobacco products was banned in retailers larger than 280 square metres in England. With the ban coming into effect in small retailers three years later on 6 April 2015, a law was passed which banned smoking in vehicles with anyone under eighteen years of age present.", "prediction 3": "The smoking ban in England, making it illegal to smoke in all enclosed work places in England, came into force on 1 July 2007 as a consequence of the Health Act 2006. Similar bans have already been introduced in Scotland and Wales, and in Northern Ireland, as well. On 16 November 2004 a Public Health white paper proposed a smoking ban in almost all public places in England and Wales. The smoking restrictions would be phased in, with a ban on smoking in NHS and government buildings by 2006, in enclosed public places by 2007 and pubs, bars and restaurants, by the end of 2014.", "prediction 4": "The smoking ban came into force on 1 July 2007 in England. The law made it illegal to smoke in all enclosed work places in England.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 322, "end": 522}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 3, "sentence_id": [1]}], "corrected-prediction": "The smoking ban in the United Kingdom, making it illegal to smoke in all enclosed work places in England, came into force on 1 July 2007. Smoking in workplaces and enclosed public spaces has been illegal since 26 March 2006 in Scotland, 2 April 2007 in Wales, 30 April 2007 in Northern Ireland and 1 July 2007 in England. On October 1, 2015 a law was passed which banned smoking in vehicles with anyone under 18 years of age present. However, this law does not apply to e-cigarettes if the driver is seventeen years of age and alone in the vehicle, or in a convertible with the roof completely down."}, "preference": [0, 1, 1, 1, 1, 1], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Smoking in the United Kingdom\nS1. Until 31 August 2008, the minimum age to purchase and consume tobacco products in public was 16 years of age.\nS2. From 1 September 2008 the Children and Young Persons (Sale of Tobacco etc.)\nS3. Regulations (Northern Ireland) 2008 became effective, raising the minimum purchase, consumption and possession age to 18 years of age.\nS4. Smoking in workplaces and enclosed public spaces has been illegal since 26 March 2006 in Scotland, 2 April 2007 in Wales, 30 April 2007 in Northern Ireland and 1 July 2007 in England,   On 6 April 2012, the display of tobacco products was banned in retailers larger than 280 square metres in England.\nS5. With the ban coming into effect in small retailers three years later on 6 April 2015.\nS6. In March 2011, the Conservative-Lib Dem coalition government committed itself to holding a public consultation on the introduction of plain tobacco packaging.\nS7. Influenced by the introduction of plain packaging in Australia, the House of Commons voted 367\u2013113 in March 2015 to pass the Children and Families Act 2014 which would give the government the power to require plain packaging for tobacco products.\nS8. This came into force on 20 May 2016, but tobacco companies were given one year to sell off remaining stock; in which afterwards, all tobacco products sold in the UK must follow plain packaging laws.\nS9. On October 1, 2015 a law was passed which banned smoking in vehicles with anyone under eighteen years of age present.\n\nPassage 2: Title (S0) - Smoking ban in England\nS1. Smoking ban in England  A smoking ban in England, making it illegal to smoke in all enclosed work places in England, came into force on 1 July 2007 as a consequence of the Health Act 2006.\nS2. Similar bans had already been introduced by the rest of the United Kingdom: in Scotland on 26 March 2006, Wales on 2 April 2007 and Northern Ireland on 30 April 2007.\nS3. Before the ban many businesses voluntarily introduced bans on smoking mainly as a result of public feedback.\nS4. The pub chain Wetherspoons was the first major chain to introduce a complete ban on indoor smoking, doing so in May 2006.\nS5. Tobacco advertising had been banned in England gradually starting with a ban on Television Advertising of cigarettes in 1965 to a complete ban on all Tobacco Advertising in 2005.\nS6. On 16 November 2004 a Public Health white paper proposed a smoking ban in almost all public places in England and Wales.\nS7. Smoking restrictions would be phased in, with a ban on smoking in NHS and government buildings by 2006, in enclosed public places by 2007, and pubs, bars and restaurants (except pubs not serving food) by the end of 2008.\nS8. On 26 October 2005, after external challenge and debates within the Cabinet, the government announced that it would continue with its plans.\n\nPassage 3: Title (S0) - Smoking in the United Kingdom\nS1. The law does not apply to e-cigarettes, if the driver is seventeen years of age and alone in the vehicle or in a convertible with the roof completely down.\nS2. Despite the name, 'e-cigarette,' these devices contain no tobacco and produce no smoke, and therefore any reference to them, should be under e-cigarettes and not smoking.\nS3. Exceptions to this might be their role as an alternative to smoking, or as devices where it increasingly looks like they are helping young people avoid smoking.\nS4. On 2 April 2014 the Welsh Government published a public health white paper in which it proposed a ban on the use of e-cigarettes in public spaces.\nS5. The Bill was subsequently defeated.\nS6. The annual Smokefree GB survey, published in May 2017, concluded that 52% of the 2.9 million British e-cigarette users are now ex-smokers.\nS7. 26% of respondents thought e-cigarettes were as harmful as real cigarettes.\nS8. In March 2017, it was reported by The Telegraph UK's e-cigarette boom is on a decline, with the number of people using e-cigarettes in Britain decreasing for the first time since their launch.\n    \nInput Question:\nWhen did the smoking ban came into the uk?\n\nCorrect Response:\nA smoking ban in England, making it illegal to smoke in all enclosed public space and workplaces, came into force on 1 July 2007 as a consequence of the Health Act 2006. Similar bans had already been introduced by the rest of the United Kingdom: in Scotland on 26 March 2006, Wales on 2 April 2007 and Northern Ireland on 30 April 2007. On 1 October 2015, a law was passed which banned smoking in vehicles with anyone under eighteen years of age present. The law does not apply to e-cigarettes, if the driver is seventeen years of age and alone in the vehicle, or in a convertible with the roof completely down.\n\nModel Prediction:\nThe smoking ban in the United Kingdom, making it illegal to smoke in all enclosed work places in England, came into force on 1 July 2007. Smoking in workplaces and enclosed public spaces has been illegal since 26 March 2006 in Scotland, 2 April 2007 in Wales, 30 April 2007 in Northern Ireland and 1 July 2007 in England. On 6 April 2012, the display of tobacco products was banned in retailers larger than 280 square metres in England. With the ban coming into effect in small retailers three years later on 6 April 2015. On October 1, 2015 a law was passed which banned smoking in vehicles with anyone under 18 years of age present.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "The smoking ban in the United Kingdom, making it illegal to smoke in all enclosed work places in England, came into force on 1 July 2007. Smoking in workplaces and enclosed public spaces has been illegal since 26 March 2006 in Scotland, 2 April 2007 in Wales, 30 April 2007 in Northern Ireland and 1 July 2007 in England. [On 6 April 2012, the display of tobacco products was banned in retailers larger than 280 square metres in England. With the ban coming into effect in small retailers three years later on 6 April 2015.] On October 1, 2015 a law was passed which banned smoking in vehicles with anyone under 18 years of age present.\n\nExplanation:\nThe information about the ban on the display of tobacco products in retailers is irrelevant to the question about when the smoking ban came into effect in the UK. Therefore, it should be marked as \"Irrelevant\"."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The smoking ban in the United Kingdom, making it illegal to smoke in all enclosed work places in England, came into force on 1 July 2007.\nS2. Smoking in workplaces and enclosed public spaces has been illegal since 26 March 2006 in Scotland, 2 April 2007 in Wales, 30 April 2007 in Northern Ireland and 1 July 2007 in England.\nS3. On 6 April 2012, the display of tobacco products was banned in retailers larger than 280 square metres in England.\nS4. With the ban coming into effect in small retailers three years later on 6 April 2015.\nS5. On October 1, 2015 a law was passed which banned smoking in vehicles with anyone under 18 years of age present.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation:\nAll the facts presented in the model prediction are consistent with the information provided in the passages."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 3, sentence 1 [Missing Major Auxiliary Information]\n\nExplanation:\n1. The model prediction does not mention the exception to the law that it does not apply to e-cigarettes if the driver is seventeen years of age and alone in the vehicle, or in a convertible with the roof completely down. This information is crucial for understanding the full scope of the smoking ban in the UK."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The smoking ban in the United Kingdom, making it illegal to smoke in all enclosed work places in England, came into force on 1 July 2007. Smoking in workplaces and enclosed public spaces has been illegal since 26 March 2006 in Scotland, 2 April 2007 in Wales, 30 April 2007 in Northern Ireland and 1 July 2007 in England. On October 1, 2015 a law was passed which banned smoking in vehicles with anyone under 18 years of age present. However, this law does not apply to e-cigarettes if the driver is seventeen years of age and alone in the vehicle, or in a convertible with the roof completely down."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 322, "end": 436}, {"error type": "Irrelevant", "explanation": "", "start": 437, "end": 522}], "missing-info": [{"error type": "Missing-Minor-Auxiliary", "passage_id": 2, "sentence_id": [1]}, {"error type": "Missing-Major-Auxiliary", "passage_id": 3, "sentence_id": [1]}], "corrected-prediction": "The smoking ban in the United Kingdom, making it illegal to smoke in all enclosed work places in England, came into force on 1 July 2007 as a consequence of the Health Act 2006. Smoking in workplaces and enclosed public spaces has been illegal since 26 March 2006 in Scotland, 2 April 2007 in Wales, 30 April 2007 in Northern Ireland and 1 July 2007 in England. On October 1, 2015 a law was passed which banned smoking in vehicles with anyone under 18 years of age present. The law does not apply to e-cigarettes, if the driver is seventeen years of age and alone in the vehicle or in a convertible with the roof completely down."}}, {"question": "When did the boston celtics win their first championship?", "passages": [["1956\u201357 NBA season", "1956\u201357 NBA season\n\nThe 1956\u201357 NBA season was the 11th season of the National Basketball Association.", "The season ended with the Boston Celtics winning the NBA Championship (which would be the first of their 17 NBA titles), beating the St. Louis Hawks 4 games to 3 in the NBA Finals.", "x \u2013 clinched playoff spot\n\nNote: Prior to the 1969\u201370 season, league leaders in points, rebounds, and assists were determined by totals rather than averages."], ["Boston Celtics", "Boston Celtics\n\nThe Boston Celtics are an American professional basketball team based in Boston, Massachusetts.", "The Celtics compete in the National Basketball Association (NBA) as a member of the league's Eastern Conference Atlantic Division.", "Founded in 1946 as one of the original eight NBA teams to survive the league's first decade, the team is owned by Boston Basketball Partners LLC.", "The Celtics play their home games at the TD Garden, which they share with the National Hockey League (NHL)'s Boston Bruins.", "The franchise has won the most championships in NBA history with 17, accounting for 23.9 percent of all NBA championships since the league's founding.", "The Celtics have a notable rivalry with the Los Angeles Lakers, and have played the Lakers a record 12 times in the NBA Finals (including their most recent appearances in 2008 and 2010), of which the Celtics have won nine.", "Four Celtics players (Bob Cousy, Bill Russell, Dave Cowens and Larry Bird) have won the NBA Most Valuable Player Award for an NBA record total of 10 MVP awards.", "Both the nickname \"Celtics\" and their mascot \"Lucky the Leprechaun\" are a nod to Boston's historically large Irish population."]], "gold": "The Boston Celtics are an American professional basketball team based in Boston, that compete in the National Basketball Association as a member of the league's Eastern Conference Atlantic Division. They were founded in 1946 as one of the league's original eight teams. The Boston Celtics won their first championship of their 17 NBA titles during the 1956\u201357 NBA season. In the championship game, on April 13 1957, they beat the St. Louis Hawks 4 games to 3 in the NBA Finals.", "prediction 1": "The Boston Celtics are an American professional basketball team based in Boston, Massachusetts. Founded in 1946 as one of the original eight NBA teams to survive the league's first decade, the team has won the most championships in NBA history with 17. The team has won the NBA Championship 17 times, accounting for 23.9 percent of all NBA championships since the league's founding.\n", "prediction 2": "The Boston Celtics are an American professional basketball team based in Boston, Massachusetts. Founded in 1946 as one of the original eight NBA teams to survive the league's first decade, the team competes in the NBA as a member of the league's Eastern Conference Atlantic Division. The 1956\u201357 NBA season was the 11th season of the National Basketball Association. The season ended with the Boston Celtics winning the NBA Championship (which would be the first of their 17 NBA titles), beating the St. Louis Hawks 4 games to 3 in the NBA Finals.", "prediction 3": "The Boston Celtics are an American professional basketball team based in Boston that compete in the National Basketball Association as a member of the Eastern Conference Atlantic Division. In the 1956\u201357 NBA season the team won their first championship, beating the St. Louis Hawks 4 games to 3 in the NBA Finals.", "prediction 4": "The Boston Celtics are an American professional basketball team based in Boston that competes in the National Basketball Association as a member of the league's Eastern Conference Atlantic Division. The 1956-57 NBA season ended with the Boston Celtics winning the NBA Championship, which would be the first of their 17 NBA titles, defeating the St. Louis Hawks 4 games to 3 in the NBA Finals.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 253, "end": 382}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 1, "sentence_id": [2]}], "corrected-prediction": "The Boston Celtics are an American professional basketball team based in Boston, Massachusetts. Founded in 1946 as one of the original eight NBA teams to survive the league's first decade, the team has won the most championships in NBA history with 17. The Boston Celtics won their first championship during the 1956\u201357 NBA season."}, "preference": [2, 2, 2, 1, 1, 2], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - 1956\u201357 NBA season\nS1. 1956\u201357 NBA season  The 1956\u201357 NBA season was the 11th season of the National Basketball Association.\nS2. The season ended with the Boston Celtics winning the NBA Championship (which would be the first of their 17 NBA titles), beating the St. Louis Hawks 4 games to 3 in the NBA Finals.\nS3. x \u2013 clinched playoff spot  Note: Prior to the 1969\u201370 season, league leaders in points, rebounds, and assists were determined by totals rather than averages.\n\nPassage 2: Title (S0) - Boston Celtics\nS1. Boston Celtics  The Boston Celtics are an American professional basketball team based in Boston, Massachusetts.\nS2. The Celtics compete in the National Basketball Association (NBA) as a member of the league's Eastern Conference Atlantic Division.\nS3. Founded in 1946 as one of the original eight NBA teams to survive the league's first decade, the team is owned by Boston Basketball Partners LLC.\nS4. The Celtics play their home games at the TD Garden, which they share with the National Hockey League (NHL)'s Boston Bruins.\nS5. The franchise has won the most championships in NBA history with 17, accounting for 23.9 percent of all NBA championships since the league's founding.\nS6. The Celtics have a notable rivalry with the Los Angeles Lakers, and have played the Lakers a record 12 times in the NBA Finals (including their most recent appearances in 2008 and 2010), of which the Celtics have won nine.\nS7. Four Celtics players (Bob Cousy, Bill Russell, Dave Cowens and Larry Bird) have won the NBA Most Valuable Player Award for an NBA record total of 10 MVP awards.\nS8. Both the nickname \"Celtics\" and their mascot \"Lucky the Leprechaun\" are a nod to Boston's historically large Irish population.\n    \nInput Question:\nWhen did the boston celtics win their first championship?\n\nCorrect Response:\nThe Boston Celtics are an American professional basketball team based in Boston, that compete in the National Basketball Association as a member of the league's Eastern Conference Atlantic Division. They were founded in 1946 as one of the league's original eight teams. The Boston Celtics won their first championship of their 17 NBA titles during the 1956\u201357 NBA season. In the championship game, on April 13 1957, they beat the St. Louis Hawks 4 games to 3 in the NBA Finals.\n\nModel Prediction:\nThe Boston Celtics are an American professional basketball team based in Boston, Massachusetts. Founded in 1946 as one of the original eight NBA teams to survive the league's first decade, the team has won the most championships in NBA history with 17. The team has won the NBA Championship 17 times, accounting for 23.9 percent of all NBA championships since the league's founding.\n\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "The Boston Celtics are an American professional basketball team based in Boston, Massachusetts. Founded in 1946 as one of the original eight NBA teams to survive the league's first decade, the team has won the most championships in NBA history with 17. [The team has won the NBA Championship 17 times, accounting for 23.9 percent of all NBA championships since the league's founding.]\n\nExplanation:\nThe last sentence in the model prediction is repetitive as it repeats the information about the Celtics winning 17 championships, which is already mentioned in the previous sentence. Therefore, it should be marked as \"Repetitive\"."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The Boston Celtics are an American professional basketball team based in Boston, Massachusetts.\nS2. Founded in 1946 as one of the original eight NBA teams to survive the league's first decade, the team has won the most championships in NBA history with 17.\nS3. The team has won the NBA Championship 17 times, accounting for 23.9 percent of all NBA championships since the league's founding.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation:\nAll the facts in the model prediction are consistent with the passages and verifiable. There are no factual inconsistencies or unverifiable facts in the model prediction."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 2 [Missing Answer]\n\nExplanation:\n1. The model prediction does not include the information about when the Boston Celtics won their first championship. This information is present in Passage 1, sentence 2, which states that the Celtics won their first NBA Championship during the 1956\u201357 NBA season. This is a missing answer in the model prediction."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The Boston Celtics are an American professional basketball team based in Boston, Massachusetts. Founded in 1946 as one of the original eight NBA teams to survive the league's first decade, the team has won the most championships in NBA history with 17. The Boston Celtics won their first championship during the 1956\u201357 NBA season."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 81, "end": 95}, {"error type": "Irrelevant", "explanation": "", "start": 151, "end": 188}, {"error type": "Irrelevant", "explanation": "", "start": 189, "end": 252}, {"error type": "Irrelevant", "explanation": "", "start": 301, "end": 383}], "missing-info": [{"error type": "Missing-Minor-Auxiliary", "passage_id": 2, "sentence_id": [2]}, {"error type": "Missing-Answer", "passage_id": 1, "sentence_id": [1, 2]}], "corrected-prediction": "The Boston Celtics are an American professional basketball team based in Boston, that compete in the National Basketball Association as a member of the league's Eastern Conference Atlantic Division.  Founded in 1946 as one of the original eight NBA teams, they won the first of their 17 championships during the 1956\u201357 season, beating the St. Louis Hawks 4 games to 3 in the NBA Finals."}}, {"question": "How many seasons are there of knight rider?", "passages": [["Team Knight Rider", "Team Knight Rider\n\nTeam Knight Rider (TKR) is a syndicated television series that was adapted from the \"Knight Rider\" franchise and ran between 1997 and 1998.", "\"TKR\" was created by writer/producers Rick Copp and David A. Goodman, based on the original series created by Glen A. Larson, who was an executive producer.", "\"TKR\" was produced by Gil Wadsworth and Scott McAboy and was distributed by Universal Domestic Television and ran only a single season of 22 one-hour episodes before it was canceled due to poor ratings.", "The story is about a new team of high-tech crime fighters assembled by the Foundation for Law and Government (FLAG, formed by Wilton Knight) who follow in the tracks of the legendary Michael Knight and his supercar KITT.", "Instead of \"one man making a difference\", there are now five team members who each have a computerized talking vehicle counterpart.", "Like the original duo, \"TKR\" goes after notorious criminals who operate \"above the law\"\u00a0\u2013 from spies and assassins, to terrorists and drug dealers.", "The final episode of the season, and series, featured the reappearance of Michael Knight (seen only from behind and played by a stand-in) at the very end.", "Team Knight Rider use five different vehicles for their missions, each with its own computer AI system similar to the original Knight Industries 2000 vehicle."], ["Knight Rider (1982 TV series)", "Knight Rider (1982 TV series)\n\nKnight Rider is an American television series created and produced by Glen A. Larson.", "The series was originally broadcast on NBC from 1982 to 1986.", "The show stars David Hasselhoff as Michael Knight, a high-tech modern crime fighter assisted by KITT, an advanced artificially intelligent, self-aware and nearly indestructible car.", "This was the last series Larson devised at Universal Television before he moved to 20th Century Fox.", "Self-made billionaire Wilton Knight rescues police Detective Lieutenant Michael Arthur Long after a near fatal shot to the face, giving him a new identity (by plastic surgery) and a new name: Michael Knight.", "Wilton selects Michael to be the primary field agent in the pilot program of his public justice organization, the Foundation for Law and Government (FLAG).", "The other half of this pilot program is the Knight Industries Two Thousand (KITT), a heavily modified, technologically advanced Pontiac Firebird Trans Am with numerous features including an extremely durable shell and frame, controlled by a computer with artificial intelligence.", "Michael and KITT are brought in during situations where \"direct action might provide the only feasible solution\".", "Heading FLAG is Devon Miles, who provides Michael with directives and guidance."], ["Knight Rider", "These adventures were continued with the television films \"Knight Rider 2000\" and \"Knight Rider 2010\" and the short-lived \"Team Knight Rider\".", "One other television movie, \"Knight Rider\", served as a pilot for the 2008 television series \"Knight Rider\".", "In 1985, a spin-off series, \"Code of Vengeance\", also premiered.", "Three television series make up the bulk of the \"Knight Rider\" mythos: \"Knight Rider\" (1982\u20131986), \"Team Knight Rider\" (1997\u20131998), and \"Knight Rider\" (2008\u20132009).", "There also was a spin-off series, \"Code of Vengeance\", that ran for one season (1985\u20131986).", "In total, 133 \"Knight Rider\" episodes have been produced across the seven seasons of the four various TV series.", "The original \"Knight Rider\" series saw Michael Knight (David Hasselhoff), a crime fighter who uses a high tech, artificially intelligent automobile, the Knight Industries Two Thousand (KITT).", "This car is a virtually indestructible weapon that fights for justice, and is voiced by actor William Daniels.", "The show was created and produced by Glen A. Larson, and was originally broadcast on NBC from 1982 to 1986.", "The show has 90 episodes over four seasons, was highly popular with audiences."], ["Knight Rider (2008 TV series)", "The new series premiered on NBC on September 24, 2008 and led the network's Wednesday evening lineup, along with \"Deal or No Deal\" and \"Lipstick Jungle\".", "On October 21, 2008, NBC gave the show a full season order of 22 episodes.", "All of the episodes that aired on TV are also available on the PlayStation Network Video Store, Xbox Live Marketplace, Hulu Plus (available only for computer streaming, not TV or mobile streaming), and iTunes Store.", "The episodes are available in HD format and SD format.", "On November 10, 2008, NBC reformatted the show in an effort to more closely resemble the storyline of its predecessor.", "Yancey Arias, Bruce Davison, and Sydney Tamiia Poitier's characters were removed from the series after the end of their original thirteen episode commitment starting with a two-part episode scheduled to air in January 2009.", "The show continued with a more character-driven focus on Michael and KITT.", "On December 3, 2008, NBC reduced its season order to seventeen episodes.", "The series finale aired on March 4, 2009.", "When NBC's 2009-2010 schedule was announced on May 19, 2009, it did not include \"Knight Rider\", effectively signaling the cancellation of the series.", "For the series premiere, many new features in KITT were introduced in addition to those seen on the pilot movie."], ["Knight Rider (season 4)", "Knight Rider (season 4)\n\nThe fourth and final season of Knight Rider, an American television series, began September 20, 1985, and ended on April 4, 1986.", "It aired on NBC.", "The region 1 DVD was released on April 4, 2006.", "Interest in the show declined, leading to its cancellation by the end of the season.", "Hasselhoff, knowing the show was coming to an end, attempted to make a \"series finale\" and helped conceive the story \"The Scent of Roses\" with his wife at the time Catherine Hickland, who played Michael's love interest Stephanie \"Stevie\" Mason in past episodes.", "The network instead aired \"Voodoo Knight\" as the final episode.", "A new street-smart mechanic, played by Peter Parros, was added to the cast in addition to Bonnie.", "Of all KITT's features added in fourth season, the most important of them is \"Super Pursuit Mode\".", "KITT could also convert into an open convertible.", "<onlyinclude></onlyinclude>"]], "gold": "The 1982 action crime drama TV series Knight Rider ran for 4 seasons and 90 episodes from 1982 to 1986. The franchise was later adapted to create 1997 series Team Knight Rider, which ran for 1 season of 22 episodes, and 2008 series Knight Rider, which ran for 1 season of 17 episodes.", "prediction 1": "Knight Rider is an American television series created and produced by Glen A. Larson, which ran on NBC from 1982 to 1986. There were four seasons of the show, with 90 episodes each. The new series, Knight Rider, ran for seven seasons, with 22 episodes each.\n", "prediction 2": "Henrik Ibsen played Michael Knight in the original Knight Rider series, which was broadcast on NBC from 1982 to 1986, and the show was adapted for the syndicated television series network OK Go in 1997, while the new Knight Rider franchise, aired from August 2008 to September 2009, had 10 seasons and 132 episodes in total.", "prediction 3": "Knight Rider is an American television series created and produced by Glen A. Larson, that was originally broadcast on NBC from 1982 to 1986. There are three different TV series that make up the bulk of the Knight Rider mythos. The 1982-88 series saw David Hasselhoff as Michael Knight, a crime fighter who uses a high tech, artificially intelligent automobile, the Knight Industries Two Thousand (KITT), and a spin-off series, Code of Vengeance. The newer series, Knight Rider, was developed by William Daniels, and aired between 1998 and 2009, and run for four seasons.", "prediction 4": "There are several titles for the television series Knight Rider. The 1982 show was created and produced by Glen A. Larson and aired on NBC from 1982 to 1986. The 1997 version of the series, Team Knight Rider, ran between 1997 and 1998. There was also a 2008 version of the series which ran from 2009 to 2014 that had a total of 22 episodes and a house credit of 10 minutes.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 182, "end": 257}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 1, "sentence_id": [3]}], "corrected-prediction": "Knight Rider is an American television series created and produced by Glen A. Larson, which ran on NBC from 1982 to 1986. There were four seasons of the original show. The franchise was later adapted to create the 1997 series Team Knight Rider, which ran for one season, and the 2008 series Knight Rider, which also ran for one season."}, "preference": [1, 1, 2, 0, 2, 2], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Team Knight Rider\nS1. Team Knight Rider  Team Knight Rider (TKR) is a syndicated television series that was adapted from the \"Knight Rider\" franchise and ran between 1997 and 1998.\nS2. \"TKR\" was created by writer/producers Rick Copp and David A. Goodman, based on the original series created by Glen A. Larson, who was an executive producer.\nS3. \"TKR\" was produced by Gil Wadsworth and Scott McAboy and was distributed by Universal Domestic Television and ran only a single season of 22 one-hour episodes before it was canceled due to poor ratings.\nS4. The story is about a new team of high-tech crime fighters assembled by the Foundation for Law and Government (FLAG, formed by Wilton Knight) who follow in the tracks of the legendary Michael Knight and his supercar KITT.\nS5. Instead of \"one man making a difference\", there are now five team members who each have a computerized talking vehicle counterpart.\nS6. Like the original duo, \"TKR\" goes after notorious criminals who operate \"above the law\"\u00a0\u2013 from spies and assassins, to terrorists and drug dealers.\nS7. The final episode of the season, and series, featured the reappearance of Michael Knight (seen only from behind and played by a stand-in) at the very end.\nS8. Team Knight Rider use five different vehicles for their missions, each with its own computer AI system similar to the original Knight Industries 2000 vehicle.\n\nPassage 2: Title (S0) - Knight Rider (1982 TV series)\nS1. Knight Rider (1982 TV series)  Knight Rider is an American television series created and produced by Glen A. Larson.\nS2. The series was originally broadcast on NBC from 1982 to 1986.\nS3. The show stars David Hasselhoff as Michael Knight, a high-tech modern crime fighter assisted by KITT, an advanced artificially intelligent, self-aware and nearly indestructible car.\nS4. This was the last series Larson devised at Universal Television before he moved to 20th Century Fox.\nS5. Self-made billionaire Wilton Knight rescues police Detective Lieutenant Michael Arthur Long after a near fatal shot to the face, giving him a new identity (by plastic surgery) and a new name: Michael Knight.\nS6. Wilton selects Michael to be the primary field agent in the pilot program of his public justice organization, the Foundation for Law and Government (FLAG).\nS7. The other half of this pilot program is the Knight Industries Two Thousand (KITT), a heavily modified, technologically advanced Pontiac Firebird Trans Am with numerous features including an extremely durable shell and frame, controlled by a computer with artificial intelligence.\nS8. Michael and KITT are brought in during situations where \"direct action might provide the only feasible solution\".\nS9. Heading FLAG is Devon Miles, who provides Michael with directives and guidance.\n\nPassage 3: Title (S0) - Knight Rider\nS1. These adventures were continued with the television films \"Knight Rider 2000\" and \"Knight Rider 2010\" and the short-lived \"Team Knight Rider\".\nS2. One other television movie, \"Knight Rider\", served as a pilot for the 2008 television series \"Knight Rider\".\nS3. In 1985, a spin-off series, \"Code of Vengeance\", also premiered.\nS4. Three television series make up the bulk of the \"Knight Rider\" mythos: \"Knight Rider\" (1982\u20131986), \"Team Knight Rider\" (1997\u20131998), and \"Knight Rider\" (2008\u20132009).\nS5. There also was a spin-off series, \"Code of Vengeance\", that ran for one season (1985\u20131986).\nS6. In total, 133 \"Knight Rider\" episodes have been produced across the seven seasons of the four various TV series.\nS7. The original \"Knight Rider\" series saw Michael Knight (David Hasselhoff), a crime fighter who uses a high tech, artificially intelligent automobile, the Knight Industries Two Thousand (KITT).\nS8. This car is a virtually indestructible weapon that fights for justice, and is voiced by actor William Daniels.\nS9. The show was created and produced by Glen A. Larson, and was originally broadcast on NBC from 1982 to 1986.\nS10. The show has 90 episodes over four seasons, was highly popular with audiences.\n\nPassage 4: Title (S0) - Knight Rider (2008 TV series)\nS1. The new series premiered on NBC on September 24, 2008 and led the network's Wednesday evening lineup, along with \"Deal or No Deal\" and \"Lipstick Jungle\".\nS2. On October 21, 2008, NBC gave the show a full season order of 22 episodes.\nS3. All of the episodes that aired on TV are also available on the PlayStation Network Video Store, Xbox Live Marketplace, Hulu Plus (available only for computer streaming, not TV or mobile streaming), and iTunes Store.\nS4. The episodes are available in HD format and SD format.\nS5. On November 10, 2008, NBC reformatted the show in an effort to more closely resemble the storyline of its predecessor.\nS6. Yancey Arias, Bruce Davison, and Sydney Tamiia Poitier's characters were removed from the series after the end of their original thirteen episode commitment starting with a two-part episode scheduled to air in January 2009.\nS7. The show continued with a more character-driven focus on Michael and KITT.\nS8. On December 3, 2008, NBC reduced its season order to seventeen episodes.\nS9. The series finale aired on March 4, 2009.\nS10. When NBC's 2009-2010 schedule was announced on May 19, 2009, it did not include \"Knight Rider\", effectively signaling the cancellation of the series.\nS11. For the series premiere, many new features in KITT were introduced in addition to those seen on the pilot movie.\n\nPassage 5: Title (S0) - Knight Rider (season 4)\nS1. Knight Rider (season 4)  The fourth and final season of Knight Rider, an American television series, began September 20, 1985, and ended on April 4, 1986.\nS2. It aired on NBC.\nS3. The region 1 DVD was released on April 4, 2006.\nS4. Interest in the show declined, leading to its cancellation by the end of the season.\nS5. Hasselhoff, knowing the show was coming to an end, attempted to make a \"series finale\" and helped conceive the story \"The Scent of Roses\" with his wife at the time Catherine Hickland, who played Michael's love interest Stephanie \"Stevie\" Mason in past episodes.\nS6. The network instead aired \"Voodoo Knight\" as the final episode.\nS7. A new street-smart mechanic, played by Peter Parros, was added to the cast in addition to Bonnie.\nS8. Of all KITT's features added in fourth season, the most important of them is \"Super Pursuit Mode\".\nS9. KITT could also convert into an open convertible.\nS10. <onlyinclude></onlyinclude>\n    \nInput Question:\nHow many seasons are there of knight rider?\n\nCorrect Response:\nThe 1982 action crime drama TV series Knight Rider ran for 4 seasons and 90 episodes from 1982 to 1986. The franchise was later adapted to create 1997 series Team Knight Rider, which ran for 1 season of 22 episodes, and 2008 series Knight Rider, which ran for 1 season of 17 episodes.\n\nModel Prediction:\nKnight Rider is an American television series created and produced by Glen A. Larson, which ran on NBC from 1982 to 1986. There were four seasons of the show, with 90 episodes each. The new series, Knight Rider, ran for seven seasons, with 22 episodes each.\n\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "Knight Rider is an American television series created and produced by Glen A. Larson, which ran on NBC from 1982 to 1986. There were four seasons of the show, with 90 episodes each. [The new series, Knight Rider, ran for seven seasons, with 22 episodes each.]\n\nExplanation:\nThe last sentence in the model prediction is incorrect. The 2008 series Knight Rider only ran for one season, not seven. Therefore, it should be marked as \"Irrelevant\". You can ignore the factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. Knight Rider is an American television series created and produced by Glen A. Larson, which ran on NBC from 1982 to 1986.\nS2. There were four seasons of the show, with 90 episodes each.\nS3. The new series, Knight Rider, ran for seven seasons, with 22 episodes each.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "S3\n\nExplanation:\nThe third sentence of the model prediction is factually inconsistent with the passages. According to Passage 4, sentence 9, the 2008 series of Knight Rider only ran for one season, not seven."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 3 [Missing Answer]\n2. Passage 4, sentence 9 [Missing Answer]\n\nExplanation:\n1. The model prediction does not mention the series \"Team Knight Rider\" which ran for one season according to Passage 1, sentence 3. This is a missing answer.\n2. The model prediction incorrectly states that the 2008 series of Knight Rider ran for seven seasons, while it actually only ran for one season according to Passage 4, sentence 9. This is also a missing answer."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "Knight Rider is an American television series created and produced by Glen A. Larson, which ran on NBC from 1982 to 1986. There were four seasons of the original show. The franchise was later adapted to create the 1997 series Team Knight Rider, which ran for one season, and the 2008 series Knight Rider, which also ran for one season."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 46, "end": 85}, {"error type": "Irrelevant", "explanation": "", "start": 92, "end": 102}, {"error type": "Wrong-Grounding", "explanation": "{\"passage_id\":3,\"sentence_id\":[10]}", "start": 176, "end": 181}, {"error type": "Wrong-Grounding", "explanation": "{\"passage_id\":3,\"sentence_id\":[6]}", "start": 182, "end": 258}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 3, "sentence_id": [6]}, {"error type": "Missing-Answer", "passage_id": 1, "sentence_id": [3]}, {"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [1]}, {"error type": "Missing-Answer", "passage_id": 4, "sentence_id": [8]}], "corrected-prediction": "Knight Rider is an American television series which ran from 1982 to 1986. The show has 90 episodes over four seasons. It was later adapted to an 1997 series Team Knight Rider, which ran for 1 season of 22 episodes, and an 2008 series Knight Rider, which ran for 1 season of 17 episodes. In total, there are seven seasons of the four various Knight Rider TV series.\n"}}, {"question": "What is the value of the fourth power of ten?", "passages": [["Rondo in A minor (Mozart)", "a8 r8\n\n\\new Staff { \n\\set Staff.midiInstrument = #\"fortepiano\"\n\\set Staff.midiMaximumVolume = #0.3\nr8\nr8 <c' e'>8 <c' e'>8 r8 <cis' e'>8 <cis' e'>8 r8 <d' f'>8 <d' f'>8", "r8 <e' g'>8 <e' g'>8 r8 <f' a'>8 8 <c' a'>8 \na4.", "a a a \na a8 \n\n\\oneVoice\n\nr8 r8\ne'4 (d'8) c' r\n\\clef \"bass\" \ne4.", "a8\n\u00bb\n</score>\nWolff also addresses this sort of passage, saying \"trill chains must be smoothly connected, with no accent given to the new trill tone at its entrance.\"", "The basis for his advice is a piano exercise taught by Mozart to his pupil Johann Nepomuk Hummel and recalled later by Hummel in his own textbook.", "A number of the ornaments and variations are not notated with signs, but simply written out by Mozart in ordinary music notation."], ["Base (exponentiation)", "Base (exponentiation)\n\n", "In exponentiation, the base is the number b in an expression of the form b.", "The number n is called the exponent and the expression is known formally as exponentiation of b by n or the exponential of n with base b.", "It is more commonly expressed as \"the nth power of b\", \"b to the nth power\" or \"b to the power n\".", "For example, the fourth power of 10 is 10,000 because .", "The term \"power\" strictly refers to the entire expression, but is sometimes used to refer to the exponent.", "Radix is the traditional term for \"base\", but usually refers then to one of the common bases: decimal (10), binary (2), hexadecimal (16), or sexagesimal (60).", "When the concepts of variable and constant came to be distinguished, the process of exponentiation was seen to transcend the algebraic functions.", "In his 1748 \"Introductio in analysin infinitorum\", Leonhard Euler referred to \"base a = 10\" in an example.", "He referred to \"a\" as a \"constant number\" in an extensive consideration of the function F(\"z\") = \"a\"."], ["Decimal", "The Hungarian language also uses a straightforward decimal system.", "All numbers between 10 and 20 are formed regularly (e.g. 11 is expressed as \"tizenegy\" literally \"one on ten\"), as with those between 20 and 100 (23 as \"huszonh\u00e1rom\" = \"three on twenty\").", "A straightforward decimal rank system with a word for each order (10 , 100 , 1000 , 10,000 ), and in which 11 is expressed as \"ten-one\" and 23 as \"two-ten-three\", and 89,345 is expressed as 8 (ten thousands) 9 (thousand) 3 (hundred) 4 (tens) 5 is found in Chinese, and in Vietnamese with a few irregularities.", "Japanese, Korean, and Thai have imported the Chinese decimal system.", "Many other languages with a decimal system have special words for the numbers between 10 and 20, and decades.", "For example, in English 11 is \"eleven\" not \"ten-one\" or \"one-teen\".", "Incan languages such as Quechua and Aymara have an almost straightforward decimal system, in which 11 is expressed as \"ten with one\" and 23 as \"two-ten with three\".", "Some psychologists suggest irregularities of the English names of numerals may hinder children's counting ability.", "Some cultures do, or did, use other bases of numbers."]], "gold": "The value of the fourth power of ten is ten thousand. The value of the fourth power of ten in number form is 10,000, written as a one followed by four zeros. The value of the fourth power of ten in word form or spelled out consists of the word ten followed by the word thousand, written as t e n t h o u s a n d.  In E notation ten thousand is also written as 1 E+4 or as 1 E4.", "prediction 1": "In exponentiation, the base is the number b in an expression of the form b. The number n is called the exponent, so the expression is known formally as the exponentiation of b by n or the exponential of n with base b. For example, the fourth power of 10 is 10,000 because.", "prediction 2": "In exponentiation, the base is the number b in an expression of the form b. The number n is called the exponent and the expression is known formally as exponentiation of b by n or the exponential of n with base b. The fourth power of 10 is 10,000 because.", "prediction 3": "In exponentiation, the base is the number b in an expression of the form b. The number n is called the exponent and the expression is known formally as exponentiation of b by n or the exponential of n with base b. For example, the fourth power of 10 is 10,000.", "prediction 4": "In exponentiation, the base is the number b in an expression of the form b. The number n is called the exponent and the expression is known formally as exponentiation of b by n or the exponential of n with base b. For example, the fourth power of 10 is 10,000 because.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 0, "end": 217}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 2, "sentence_id": [5]}], "corrected-prediction": "The fourth power of 10 is 10,000. The value of the fourth power of ten in number form is 10,000, written as a one followed by four zeros. The value of the fourth power of ten in word form or spelled out consists of the word ten followed by the word thousand, written as t e n t h o u s a n d.  In E notation ten thousand is also written as 1 E+4 or as 1 E4."}, "preference": [0, 0, 0, 0, 0, 0], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Rondo in A minor (Mozart)\nS1. a8 r8  \\new Staff {  \\set Staff.midiInstrument = #\"fortepiano\" \\set Staff.midiMaximumVolume = #0.3 r8 r8 <c' e'>8 <c' e'>8 r8 <cis' e'>8 <cis' e'>8 r8 <d' f'>8 <d' f'>8\nS2. r8 <e' g'>8 <e' g'>8 r8 <f' a'>8 8 <c' a'>8  a4.\nS3. a a a  a a8   \\oneVoice  r8 r8 e'4 (d'8) c' r \\clef \"bass\"  e4.\nS4. a8 \u00bb </score> Wolff also addresses this sort of passage, saying \"trill chains must be smoothly connected, with no accent given to the new trill tone at its entrance.\"\nS5. The basis for his advice is a piano exercise taught by Mozart to his pupil Johann Nepomuk Hummel and recalled later by Hummel in his own textbook.\nS6. A number of the ornaments and variations are not notated with signs, but simply written out by Mozart in ordinary music notation.\n\nPassage 2: Title (S0) - Base (exponentiation)\nS1. Base (exponentiation)  \nS2. In exponentiation, the base is the number b in an expression of the form b.\nS3. The number n is called the exponent and the expression is known formally as exponentiation of b by n or the exponential of n with base b.\nS4. It is more commonly expressed as \"the nth power of b\", \"b to the nth power\" or \"b to the power n\".\nS5. For example, the fourth power of 10 is 10,000 because .\nS6. The term \"power\" strictly refers to the entire expression, but is sometimes used to refer to the exponent.\nS7. Radix is the traditional term for \"base\", but usually refers then to one of the common bases: decimal (10), binary (2), hexadecimal (16), or sexagesimal (60).\nS8. When the concepts of variable and constant came to be distinguished, the process of exponentiation was seen to transcend the algebraic functions.\nS9. In his 1748 \"Introductio in analysin infinitorum\", Leonhard Euler referred to \"base a = 10\" in an example.\nS10. He referred to \"a\" as a \"constant number\" in an extensive consideration of the function F(\"z\") = \"a\".\n\nPassage 3: Title (S0) - Decimal\nS1. The Hungarian language also uses a straightforward decimal system.\nS2. All numbers between 10 and 20 are formed regularly (e.g. 11 is expressed as \"tizenegy\" literally \"one on ten\"), as with those between 20 and 100 (23 as \"huszonh\u00e1rom\" = \"three on twenty\").\nS3. A straightforward decimal rank system with a word for each order (10 , 100 , 1000 , 10,000 ), and in which 11 is expressed as \"ten-one\" and 23 as \"two-ten-three\", and 89,345 is expressed as 8 (ten thousands) 9 (thousand) 3 (hundred) 4 (tens) 5 is found in Chinese, and in Vietnamese with a few irregularities.\nS4. Japanese, Korean, and Thai have imported the Chinese decimal system.\nS5. Many other languages with a decimal system have special words for the numbers between 10 and 20, and decades.\nS6. For example, in English 11 is \"eleven\" not \"ten-one\" or \"one-teen\".\nS7. Incan languages such as Quechua and Aymara have an almost straightforward decimal system, in which 11 is expressed as \"ten with one\" and 23 as \"two-ten with three\".\nS8. Some psychologists suggest irregularities of the English names of numerals may hinder children's counting ability.\nS9. Some cultures do, or did, use other bases of numbers.\n    \nInput Question:\nWhat is the value of the fourth power of ten?\n\nCorrect Response:\nThe value of the fourth power of ten is ten thousand. The value of the fourth power of ten in number form is 10,000, written as a one followed by four zeros. The value of the fourth power of ten in word form or spelled out consists of the word ten followed by the word thousand, written as t e n t h o u s a n d.  In E notation ten thousand is also written as 1 E+4 or as 1 E4.\n\nModel Prediction:\nIn exponentiation, the base is the number b in an expression of the form b. The number n is called the exponent, so the expression is known formally as the exponentiation of b by n or the exponential of n with base b. For example, the fourth power of 10 is 10,000 because.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "[In exponentiation, the base is the number b in an expression of the form b. The number n is called the exponent, so the expression is known formally as the exponentiation of b by n or the exponential of n with base b.] For example, the fourth power of 10 is 10,000 because.\n\nExplanation:\n1. The first two sentences in the model prediction are neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, they should be marked as \"Irrelevant\"."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. In exponentiation, the base is the number b in an expression of the form b.\nS2. The number n is called the exponent, so the expression is known formally as the exponentiation of b by n or the exponential of n with base b.\nS3. For example, the fourth power of 10 is 10,000 because.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation:\nThere are no factual inconsistencies or unverifiable facts in the model prediction. All the facts mentioned are consistent with the provided passages."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 2, sentence 5 [Missing Major Auxiliary Information]\n\nExplanation:\n1. The model prediction does not include the auxiliary information that the value of the fourth power of ten in number form is 10,000, written as a one followed by four zeros. The value of the fourth power of ten in word form or spelled out consists of the word ten followed by the word thousand, written as t e n t h o u s a n d.  In E notation ten thousand is also written as 1 E+4 or as 1 E4. This information is crucial for a better understanding of the answer."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The fourth power of 10 is 10,000. The value of the fourth power of ten in number form is 10,000, written as a one followed by four zeros. The value of the fourth power of ten in word form or spelled out consists of the word ten followed by the word thousand, written as t e n t h o u s a n d.  In E notation ten thousand is also written as 1 E+4 or as 1 E4."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 0, "end": 75}, {"error type": "Irrelevant", "explanation": "", "start": 76, "end": 217}, {"error type": "Incoherent", "explanation": "", "start": 264, "end": 272}, {"error type": "Incoherent", "explanation": "", "start": 218, "end": 230}], "missing-info": [], "corrected-prediction": "The value of the fourth power of 10 is 10,000."}}, {"question": "Who hit the last home run in municipal stadium?", "passages": [["Municipal Stadium (Kansas City, Missouri)", "Kansas City welcomed the new Royals, who were led by 1969 American League Rookie of the Year Lou Piniella.", "The expansion team drew nearly one million fans in their first season, despite a 69\u201393 record.", "In subsequent seasons, many future stars made their debuts for the Royals, who were building a highly competitive team, rising up to an 85-76 record in 1971.", "CF Amos Otis (1970), P Paul Splittorff (1970), SS Freddie Patek (1971), 1B John Mayberry (1972) and P Steve Busby (1972) were a core of young Royals who made their debuts at Municipal Stadium.", "Each went on to selection into the Royals Hall of Fame.", "After the 1972 baseball season, the Royals moved to what's now Kaufmann Stadium in the Truman Sports Complex.", "The Royals won the final game (and event) at Municipal Stadium, a 4\u20130 win over the Texas Rangers on October 4, 1972, in what was also the final Major League game managed by Hall of Famer Ted Williams.", "Amos Otis scored the final run in Municipal Stadium history and Ed Kirkpatrick had the final hit.", "Four days prior Gene Tenace of the Oakland A's hit the final home run, and John Mayberry hit the final Royals home run the night before."], ["Municipal Stadium (Kansas City, Missouri)", "Municipal Stadium (Kansas City, Missouri)\n\nKansas City Municipal Stadium was an American baseball and football stadium in the central United States, located in Kansas City, Missouri.", "It was located at the corner of Brooklyn Avenue and E. 22nd Street.", "Municipal Stadium hosted both the minor-league Kansas City Blues of the American Association and the Kansas City Monarchs of the Negro leagues from 1923 to 1954.", "The stadium was almost completely rebuilt prior to the 1955 baseball season when the Kansas City Athletics moved to Kansas City from Philadelphia.", "The A's played from 1955 to 1967, the Kansas City Royals from 1969 to 1972, the Kansas City Chiefs (American Football League and National Football League) from 1963 to 1971 and the Kansas City Spurs (North American Soccer League) from 1968\u20131969.", "The stadium hosted the All-Star Game in 1960 (first game).", "In the final football game ever played there, Municipal Stadium was the site of the longest NFL game in history, a playoff game between the Chiefs and the Miami Dolphins on Christmas Day 1971; the Chiefs moved to the new Arrowhead Stadium in 1972.", "Jackie Robinson played at the stadium for the Kansas City Monarchs in 1945 until he was signed by the Brooklyn Dodgers.", "The stadium opened in 1923 as Muehlebach Field."]], "gold": "Kansas City Municipal Stadium was an American baseball and football stadium in the central United States, located in Kansas City, Missouri. The Royals won the final game (and event) at Municipal Stadium, a 4\u20130 win over the Texas Rangers on October 4, 1972, in what was also the final Major League game managed by Hall of Famer Ted Williams. Four days prior Gene Tenace of the Oakland A's hit the final home run, and John Mayberry hit the final Royals home run the night before.", "prediction 1": "The Kansas City Municipal Stadium was an American baseball and football stadium in the central United States, located in Kansas City, Missouri. On October 4, 1972, the Kansas City Royals won the final game and event at the stadium, a 4\u20130 win over the Texas Rangers. Gene Tenace of the Oakland A's hit the final home run, and John Mayberry hit the final Royals home run the night before.", "prediction 2": "Amos Otis scored the final run in Municipal Stadium history and Ed Kirkpatrick had the final hit. Four days prior Gene Tenace of the Oakland A's hit the final home run, and John Mayberry hit the final Royals home run the night before.", "prediction 3": "Amos Otis scored the final run in Municipal Stadium history and Ed Kirkpatrick had the final hit. Four days prior Gene Tenace of the Oakland A's hit the final home run, and John Mayberry hit the final Royals home run the night before. The stadium hosted both the minor-league Kansas City Blues of the American Association and the Kansas City Monarchs of the Negro leagues from 1923 to 1954.", "prediction 4": "The Kansas City Municipal Stadium was an American baseball and football stadium in the central United States, located in Kansas City, Missouri. The stadium hosted both the minor-league Kansas City Blues of the American Association and the Kansas City Monarchs of the Negro leagues from 1923 to 1954. Gene Tenace of the Oakland A's hit the final home run in Municipal Stadium history, and John Mayberry hit the final Royals home run the night before.", "feedback": {"errors": [], "missing-info": [], "corrected-prediction": "The Kansas City Municipal Stadium was an American baseball and football stadium in the central United States, located in Kansas City, Missouri. On October 4, 1972, the Kansas City Royals won the final game and event at the stadium, a 4\u20130 win over the Texas Rangers. Gene Tenace of the Oakland A's hit the final home run, and John Mayberry hit the final Royals home run the night before."}, "preference": [1, 1, 0, 2, 2, 2], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Municipal Stadium (Kansas City, Missouri)\nS1. Kansas City welcomed the new Royals, who were led by 1969 American League Rookie of the Year Lou Piniella.\nS2. The expansion team drew nearly one million fans in their first season, despite a 69\u201393 record.\nS3. In subsequent seasons, many future stars made their debuts for the Royals, who were building a highly competitive team, rising up to an 85-76 record in 1971.\nS4. CF Amos Otis (1970), P Paul Splittorff (1970), SS Freddie Patek (1971), 1B John Mayberry (1972) and P Steve Busby (1972) were a core of young Royals who made their debuts at Municipal Stadium.\nS5. Each went on to selection into the Royals Hall of Fame.\nS6. After the 1972 baseball season, the Royals moved to what's now Kaufmann Stadium in the Truman Sports Complex.\nS7. The Royals won the final game (and event) at Municipal Stadium, a 4\u20130 win over the Texas Rangers on October 4, 1972, in what was also the final Major League game managed by Hall of Famer Ted Williams.\nS8. Amos Otis scored the final run in Municipal Stadium history and Ed Kirkpatrick had the final hit.\nS9. Four days prior Gene Tenace of the Oakland A's hit the final home run, and John Mayberry hit the final Royals home run the night before.\n\nPassage 2: Title (S0) - Municipal Stadium (Kansas City, Missouri)\nS1. Municipal Stadium (Kansas City, Missouri)  Kansas City Municipal Stadium was an American baseball and football stadium in the central United States, located in Kansas City, Missouri.\nS2. It was located at the corner of Brooklyn Avenue and E. 22nd Street.\nS3. Municipal Stadium hosted both the minor-league Kansas City Blues of the American Association and the Kansas City Monarchs of the Negro leagues from 1923 to 1954.\nS4. The stadium was almost completely rebuilt prior to the 1955 baseball season when the Kansas City Athletics moved to Kansas City from Philadelphia.\nS5. The A's played from 1955 to 1967, the Kansas City Royals from 1969 to 1972, the Kansas City Chiefs (American Football League and National Football League) from 1963 to 1971 and the Kansas City Spurs (North American Soccer League) from 1968\u20131969.\nS6. The stadium hosted the All-Star Game in 1960 (first game).\nS7. In the final football game ever played there, Municipal Stadium was the site of the longest NFL game in history, a playoff game between the Chiefs and the Miami Dolphins on Christmas Day 1971; the Chiefs moved to the new Arrowhead Stadium in 1972.\nS8. Jackie Robinson played at the stadium for the Kansas City Monarchs in 1945 until he was signed by the Brooklyn Dodgers.\nS9. The stadium opened in 1923 as Muehlebach Field.\n    \nInput Question:\nWho hit the last home run in municipal stadium?\n\nCorrect Response:\nKansas City Municipal Stadium was an American baseball and football stadium in the central United States, located in Kansas City, Missouri. The Royals won the final game (and event) at Municipal Stadium, a 4\u20130 win over the Texas Rangers on October 4, 1972, in what was also the final Major League game managed by Hall of Famer Ted Williams. Four days prior Gene Tenace of the Oakland A's hit the final home run, and John Mayberry hit the final Royals home run the night before.\n\nModel Prediction:\nThe Kansas City Municipal Stadium was an American baseball and football stadium in the central United States, located in Kansas City, Missouri. On October 4, 1972, the Kansas City Royals won the final game and event at the stadium, a 4\u20130 win over the Texas Rangers. Gene Tenace of the Oakland A's hit the final home run, and John Mayberry hit the final Royals home run the night before.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "The Kansas City Municipal Stadium was an American baseball and football stadium in the central United States, located in Kansas City, Missouri. On October 4, 1972, the Kansas City Royals won the final game and event at the stadium, a 4\u20130 win over the Texas Rangers. Gene Tenace of the Oakland A's hit the final home run, and John Mayberry hit the final Royals home run the night before.\n\nExplanation: There are no irrelevant, incoherent, or repetitive spans in the model prediction. The information provided is relevant to the question, coherent, and not repetitive."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The Kansas City Municipal Stadium was an American baseball and football stadium in the central United States, located in Kansas City, Missouri.\nS2. On October 4, 1972, the Kansas City Royals won the final game and event at the stadium, a 4\u20130 win over the Texas Rangers.\nS3. Gene Tenace of the Oakland A's hit the final home run, and John Mayberry hit the final Royals home run the night before.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation: All the facts in the model prediction are consistent with the information provided in the passages. There are no unverifiable or inconsistent facts."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "None\n\nExplanation: The model prediction includes all the necessary information to answer the question. It correctly identifies both Gene Tenace of the Oakland A's and John Mayberry of the Royals as the players who hit the last home runs in the Municipal Stadium. There is no missing information."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The Kansas City Municipal Stadium was an American baseball and football stadium in the central United States, located in Kansas City, Missouri. On October 4, 1972, the Kansas City Royals won the final game and event at the stadium, a 4\u20130 win over the Texas Rangers. Gene Tenace of the Oakland A's hit the final home run, and John Mayberry hit the final Royals home run the night before."}], "feedback_human": {"errors": [], "missing-info": [{"error type": "Missing-Minor-Auxiliary", "passage_id": 1, "sentence_id": [7]}], "corrected-prediction": "The Kansas City Municipal Stadium was an American baseball and football stadium in the central United States, located in Kansas City, Missouri. On October 4, 1972, the Kansas City Royals won the final game and event at the stadium, a 4\u20130 win over the Texas Rangers, in what was also the final Major League game managed by Hall of Famer Ted Williams. Gene Tenace of the Oakland A's hit the final home run, and John Mayberry hit the final Royals home run the night before."}}, {"question": "Who played prudence on nanny and the professor?", "passages": [["Nanny and the Professor", "Nanny and the Professor\n\nNanny and the Professor is an American sitcom created by AJ Carothers and Thomas L. Miller for 20th Century-Fox Television.", "During pre-production, the proposed title was \"Nanny Will Do\".", "Playing upon the popularity of \"Mary Poppins\" and other magical nannies of literature, this TV series posited another ostensibly magical British nanny taking care of a family in need of guidance.", "Unlike the candid \"magicality\" of its forebears, this Nanny's paranormal nature was less overt and only implied.", "The Nanny's young wards, as well as the audience, were left intentionally uncertain of the nature of Nanny's \"powers\", if any.", "The series starred Juliet Mills as Nanny Phoebe Figalilly, Richard Long as Professor Harold Everett, and in season 3 Elsa Lanchester in the recurring role of Aunt Henrietta.", "Figalilly was housekeeper for Professor Everett as well as nanny to his three children: Hal, the intellectual tinkerer, played by David Doremus; Butch, the middle child, played by Trent Lehman; and Prudence, the youngest, played by Kim Richards.", "Nanny was apparently psychic, and had regular flashes of what was often more than intuition (accented by a musical tinkling sound effect); she frequently knew who was at the door before the doorbell even rang."], ["Nanny and the Professor (film)", "Nanny and the Professor (film)\n\nNanny and the Professor is a 1972 American animated comedy TV Movie based on the sitcom by the same name.", "The series' original cast returned reprised their roles from the live action series.", "Unlike in the television series, Nanny openly performs magic, while in the TV series it was only implied."]], "gold": "Nanny and the Professor is an early 1970's American sitcom about a magical British nanny taking care of a family in need of guidance. In 1972, a TV movie was made based on the sitcom using the same name and original cast. Kim Richards played Prudence, the youngest child, in both versions.", "prediction 1": "On the 1972 American animated comedy TV Movie Nanny and the Professor, Prudence, the youngest of the three children, is played by Kim Richards.", "prediction 2": "On Nanny and the Professor, Prudence is played by Kim Richards. In the 1972 American animated comedy TV Movie based on the sitcom by the same name, Kim Richards played Prudence.", "prediction 3": "Nanny and the Professor is an American sitcom created by AJ Carothers and Thomas L. Miller for 20th Century Fox Television. During pre-production, the proposed title was \"Nanny Will Do\". Playing upon the popularity of \"Mary Poppins\" and other magical nannies of literature, this TV series posited another ostensibly magical British nanny taking care of a family in need of guidance.", "prediction 4": "Prudence is a character on Nanny and the Professor, an American sitcom created by AJ Carothers and Thomas L. Miller for 20th Century-Fox Television. Kim Richards played Prudence on the show. Prudence on Nanny and the Professor is also a character in the 1972 American animated comedy TV Movie based on the sitcom by the same name.", "feedback": {"errors": [], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [7]}], "corrected-prediction": "Kim Richards played the role of Prudence, the youngest of the three children, in both the original sitcom \"Nanny and the Professor\" and its 1972 American animated comedy TV Movie adaptation."}, "preference": [0, 1, 1, 1, 1, 1], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Nanny and the Professor\nS1. Nanny and the Professor  Nanny and the Professor is an American sitcom created by AJ Carothers and Thomas L. Miller for 20th Century-Fox Television.\nS2. During pre-production, the proposed title was \"Nanny Will Do\".\nS3. Playing upon the popularity of \"Mary Poppins\" and other magical nannies of literature, this TV series posited another ostensibly magical British nanny taking care of a family in need of guidance.\nS4. Unlike the candid \"magicality\" of its forebears, this Nanny's paranormal nature was less overt and only implied.\nS5. The Nanny's young wards, as well as the audience, were left intentionally uncertain of the nature of Nanny's \"powers\", if any.\nS6. The series starred Juliet Mills as Nanny Phoebe Figalilly, Richard Long as Professor Harold Everett, and in season 3 Elsa Lanchester in the recurring role of Aunt Henrietta.\nS7. Figalilly was housekeeper for Professor Everett as well as nanny to his three children: Hal, the intellectual tinkerer, played by David Doremus; Butch, the middle child, played by Trent Lehman; and Prudence, the youngest, played by Kim Richards.\nS8. Nanny was apparently psychic, and had regular flashes of what was often more than intuition (accented by a musical tinkling sound effect); she frequently knew who was at the door before the doorbell even rang.\n\nPassage 2: Title (S0) - Nanny and the Professor (film)\nS1. Nanny and the Professor (film)  Nanny and the Professor is a 1972 American animated comedy TV Movie based on the sitcom by the same name.\nS2. The series' original cast returned reprised their roles from the live action series.\nS3. Unlike in the television series, Nanny openly performs magic, while in the TV series it was only implied.\n    \nInput Question:\nWho played prudence on nanny and the professor?\n\nCorrect Response:\nNanny and the Professor is an early 1970's American sitcom about a magical British nanny taking care of a family in need of guidance. In 1972, a TV movie was made based on the sitcom using the same name and original cast. Kim Richards played Prudence, the youngest child, in both versions.\n\nModel Prediction:\nOn the 1972 American animated comedy TV Movie Nanny and the Professor, Prudence, the youngest of the three children, is played by Kim Richards.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "On the 1972 American animated comedy TV Movie Nanny and the Professor, Prudence, the youngest of the three children, is played by Kim Richards.\n\nExplanation: There are no irrelevant, incoherent or repetitive spans in the model prediction. The information provided is relevant to the question, coherent, and not repetitive."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. On the 1972 American animated comedy TV Movie Nanny and the Professor, Prudence, the youngest of the three children, is played by Kim Richards.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation: There are no inconsistent or unverifiable facts in the model prediction. The information provided is consistent with the passages and can be verified from the passages."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 7 [Missing Major Auxiliary Information]\n\nExplanation:\n1. The model prediction is missing the information that Kim Richards also played Prudence in the original sitcom \"Nanny and the Professor\", not just in the 1972 movie. This information is found in Passage 1, sentence 7 and is crucial for a complete understanding of the answer."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "Kim Richards played the role of Prudence, the youngest of the three children, in both the original sitcom \"Nanny and the Professor\" and its 1972 American animated comedy TV Movie adaptation."}], "feedback_human": {"errors": [], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [1]}, {"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [3]}], "corrected-prediction": "Nanny and the Professor is an early 1970's American sitcom about a magical British nanny taking care of a family in need of guidance. In 1972, a TV movie was made based on the sitcom using the same name and original cast. Prudence, the youngest of the three children, is played by Kim Richards."}}, {"question": "Who wrote we're going to be friends?", "passages": [["Suzy Lee (song)", "Suzy Lee (song)\n\n\"Suzy Lee\" is a love song by the American rock band The White Stripes from their 1999 self-titled album.", "The name Suzy Lee appears in the song as well as other instances throughout the White Stripes' discography, most notably from their 2001 album \"White Blood Cells\", in the song \"We're Going to Be Friends\", and the dedication of \"Get Behind Me Satan\" in which Jack White dedicated the album to Suzy Lee, \"Wherever she may be...\"", "It is rumored that Suzy Lee was a childhood friend/crush of his.", "Unlike most of the White Stripes' alternative rock and folk rock songs, \"Suzy Lee\" draws a large influence from blues music, most obviously with the use of a slide guitar throughout the song, played by Johnny Walker of the Soledad Brothers.", "Although it is different from many of their other songs, a characteristically simple and heavy drum beat, played by Meg White, largely drives the song\u2019s melody.", "\"Suzy Lee\" is one of many songs where the White Stripes are compared to the hard rock/blues rock band Led Zeppelin."], ["The White Stripes", "The White Stripes performed live for the first time since September 2007 on the final episode of \"Late Night with Conan O'Brien\" on February 20, 2009, where they performed an alternate version of \"We're Going to Be Friends\".", "This proved to be their final live performance as a band.", "In 2009 he reported that the White Stripes were working on their seventh album.", "In an article dated May 6, 2009 with MusicRadar.com, Jack mentioned recording songs with Meg before the Conan gig had taken place, saying, \"We had recorded a couple of songs at the new studio.\"", "About a new White Stripes album, Jack said, \"It won't be too far off.", "Maybe next year.\"", "Jack also explained Meg's acute anxiety during the Stripes' last tour, saying, \"I just came from a Raconteurs tour and went right into that, so I was already full-speed.", "Meg had come from a dead-halt for a year and went right back into that madness.", "Meg is a very shy girl, a very quiet and shy person.", "To go full-speed from a dead-halt is overwhelming, and we had to take a break.\"", "A concert film, \"Under Great White Northern Lights\" premiered at the Toronto International Film Festival on September 18, 2009."], ["Jack White", "Jack White\n\nJohn Anthony \"Jack\" White (; born July 9, 1975) is an American singer, songwriter, multi-instrumentalist and producer.", "He is best known as the lead singer and guitarist of the duo The White Stripes, but has also had success in other bands and as a solo artist.", "White has enjoyed consistent critical and popular success and is widely credited as one of the key artists in the garage rock revival of the 2000s.", "He has won twelve Grammy Awards, and all three of his solo albums have reached number one on the \"Billboard\" charts.", "\"Rolling Stone\" ranked him number 70 on its 2010 list of \"The 100 Greatest Guitarists of All Time\".", "David Fricke's 2011 list ranked him at number 17.", "After moonlighting in several underground Detroit bands as a drummer, White founded The White Stripes with fellow Detroit native and then-wife Meg White in 1997.", "Their 2001 breakthrough album, \"White Blood Cells\", brought them international fame with the hit single and accompanying music video \"Fell in Love with a Girl\".", "This recognition provided White opportunities to collaborate with famous artists, including Loretta Lynn and Bob Dylan.", "In 2006, White founded The Raconteurs with Brendan Benson, and in 2009 founded The Dead Weather with Alison Mosshart of The Kills."]], "gold": "\"We're Going to Be Friends\" is a song by the American alternative rock band White Stripes from their album White Blood Cells. It was released in late 2002, and tells the story of meeting a new friend at the beginning of a school year. The song was written by singer, songwriter, instrumentalist and producer, Jack White, who is the lead singer and guitarist of the White Stripes, but has also had success in other bands and as a solo artist. White also wrote a book in 2017 based off the song that shares the title.", "prediction 1": "The song \"We're Going to Be Friends\" is a love song by the American rock band The White Stripes. American singer, songwriter, multi-instrumentalist and producer John Anthony \"Jack\" White wrote the song.", "prediction 2": "\"We're Going to Be Friends\" is a love song by the American rock band The White Stripes, which was released in 1999. It is rumored that Suzy Lee was a childhood friend/crush of Jack White. It is also one of many songs where the White Stripes are compared to the hard rock/blues rock band Led Zeppelin. In 2001, the lead singer and guitarist of the duo, Jack White, wrote the song.", "prediction 3": "The song \"We're Going to Be Friends\" is a love song by the American rock band The White Stripes, which was written by lead singer and guitarist Jack White. John Anthony \"Jack\" White wrote the song, and Meg White wrote the lyrics.", "prediction 4": "The love song \"We're Going to Be Friends\" comes from American rock band The White Stripes' 1999 self-titled album. American singer-songwriter, multi-instrumentalist, producer, and guitarist Jack White wrote the song. Jack White is best known as the lead singer and guitarist of the duo The White Stripes, but has also had success in other bands and as a solo artist.", "feedback": {"errors": [], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [2]}], "corrected-prediction": "The song \"We're Going to Be Friends\" is from the American rock band The White Stripes' 2001 album \"White Blood Cells\". The song was written by American singer, songwriter, multi-instrumentalist and producer John Anthony \"Jack\" White, who is best known as the lead singer and guitarist of The White Stripes, but has also had success in other bands and as a solo artist."}, "preference": [2, 0, 2, 1, 0, 2], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Suzy Lee (song)\nS1. Suzy Lee (song)  \"Suzy Lee\" is a love song by the American rock band The White Stripes from their 1999 self-titled album.\nS2. The name Suzy Lee appears in the song as well as other instances throughout the White Stripes' discography, most notably from their 2001 album \"White Blood Cells\", in the song \"We're Going to Be Friends\", and the dedication of \"Get Behind Me Satan\" in which Jack White dedicated the album to Suzy Lee, \"Wherever she may be...\"\nS3. It is rumored that Suzy Lee was a childhood friend/crush of his.\nS4. Unlike most of the White Stripes' alternative rock and folk rock songs, \"Suzy Lee\" draws a large influence from blues music, most obviously with the use of a slide guitar throughout the song, played by Johnny Walker of the Soledad Brothers.\nS5. Although it is different from many of their other songs, a characteristically simple and heavy drum beat, played by Meg White, largely drives the song\u2019s melody.\nS6. \"Suzy Lee\" is one of many songs where the White Stripes are compared to the hard rock/blues rock band Led Zeppelin.\n\nPassage 2: Title (S0) - The White Stripes\nS1. The White Stripes performed live for the first time since September 2007 on the final episode of \"Late Night with Conan O'Brien\" on February 20, 2009, where they performed an alternate version of \"We're Going to Be Friends\".\nS2. This proved to be their final live performance as a band.\nS3. In 2009 he reported that the White Stripes were working on their seventh album.\nS4. In an article dated May 6, 2009 with MusicRadar.com, Jack mentioned recording songs with Meg before the Conan gig had taken place, saying, \"We had recorded a couple of songs at the new studio.\"\nS5. About a new White Stripes album, Jack said, \"It won't be too far off.\nS6. Maybe next year.\"\nS7. Jack also explained Meg's acute anxiety during the Stripes' last tour, saying, \"I just came from a Raconteurs tour and went right into that, so I was already full-speed.\nS8. Meg had come from a dead-halt for a year and went right back into that madness.\nS9. Meg is a very shy girl, a very quiet and shy person.\nS10. To go full-speed from a dead-halt is overwhelming, and we had to take a break.\"\nS11. A concert film, \"Under Great White Northern Lights\" premiered at the Toronto International Film Festival on September 18, 2009.\n\nPassage 3: Title (S0) - Jack White\nS1. Jack White  John Anthony \"Jack\" White (; born July 9, 1975) is an American singer, songwriter, multi-instrumentalist and producer.\nS2. He is best known as the lead singer and guitarist of the duo The White Stripes, but has also had success in other bands and as a solo artist.\nS3. White has enjoyed consistent critical and popular success and is widely credited as one of the key artists in the garage rock revival of the 2000s.\nS4. He has won twelve Grammy Awards, and all three of his solo albums have reached number one on the \"Billboard\" charts.\nS5. \"Rolling Stone\" ranked him number 70 on its 2010 list of \"The 100 Greatest Guitarists of All Time\".\nS6. David Fricke's 2011 list ranked him at number 17.\nS7. After moonlighting in several underground Detroit bands as a drummer, White founded The White Stripes with fellow Detroit native and then-wife Meg White in 1997.\nS8. Their 2001 breakthrough album, \"White Blood Cells\", brought them international fame with the hit single and accompanying music video \"Fell in Love with a Girl\".\nS9. This recognition provided White opportunities to collaborate with famous artists, including Loretta Lynn and Bob Dylan.\nS10. In 2006, White founded The Raconteurs with Brendan Benson, and in 2009 founded The Dead Weather with Alison Mosshart of The Kills.\n    \nInput Question:\nWho wrote we're going to be friends?\n\nCorrect Response:\n\"We're Going to Be Friends\" is a song by the American alternative rock band White Stripes from their album White Blood Cells. It was released in late 2002, and tells the story of meeting a new friend at the beginning of a school year. The song was written by singer, songwriter, instrumentalist and producer, Jack White, who is the lead singer and guitarist of the White Stripes, but has also had success in other bands and as a solo artist. White also wrote a book in 2017 based off the song that shares the title.\n\nModel Prediction:\nThe song \"We're Going to Be Friends\" is a love song by the American rock band The White Stripes. American singer, songwriter, multi-instrumentalist and producer John Anthony \"Jack\" White wrote the song.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "The song \"We're Going to Be Friends\" is a love song by the American rock band The White Stripes. American singer, songwriter, multi-instrumentalist and producer John Anthony \"Jack\" White wrote the song.\n\nExplanation: There are no irrelevant, incoherent, or repetitive spans in the model prediction. The information provided is relevant to the question, coherent, and not repetitive."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The song \"We're Going to Be Friends\" is a love song by the American rock band The White Stripes.\nS2. American singer, songwriter, multi-instrumentalist and producer John Anthony \"Jack\" White wrote the song.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation: There are no inconsistent or unverifiable facts in the model prediction. The information provided is consistent with the passages and can be verified from them."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 2 [Missing Major Auxiliary Information]\n2. Passage 3, sentence 2 [Missing Major Auxiliary Information]\n\nExplanation:\n1. The model prediction does not mention that the song \"We're Going to Be Friends\" is from the White Stripes' 2001 album \"White Blood Cells\", which is a crucial piece of information that provides context about the song.\n2. The model prediction also does not mention that Jack White is not only associated with the White Stripes but has also had success in other bands and as a solo artist. This is important auxiliary information that gives a fuller picture of Jack White's career and his role in creating the song."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The song \"We're Going to Be Friends\" is from the American rock band The White Stripes' 2001 album \"White Blood Cells\". The song was written by American singer, songwriter, multi-instrumentalist and producer John Anthony \"Jack\" White, who is best known as the lead singer and guitarist of The White Stripes, but has also had success in other bands and as a solo artist."}], "feedback_human": {"errors": [], "missing-info": [{"error type": "Missing-Minor-Auxiliary", "passage_id": 1, "sentence_id": [2]}, {"error type": "Missing-Major-Auxiliary", "passage_id": 3, "sentence_id": [2]}], "corrected-prediction": "The song \"We're Going to Be Friends\" is a love song by the American rock band The White Stripes from their 2001 album \"White Blood Cells\". American singer, songwriter, multi-instrumentalist and producer John Anthony \"Jack\" White wrote the song. He is best known as the lead singer and guitarist of the duo The White Stripes, but has also had success in other bands and as a solo artist."}}, {"question": "Who invented the process to remove impurities by blasts of cold air blown through heated iron?", "passages": [["Bessemer process", "The Bessemer process was so fast (10\u201320 minutes for a heat) that it allowed little time for chemical analysis or adjustment of the alloying elements in the steel.", "Bessemer converters did not remove phosphorus efficiently from the molten steel; as low-phosphorus ores became more expensive, conversion costs increased.", "The process permitted only limited amount of scrap steel to be charged, further increasing costs, especially when scrap was inexpensive.", "Use of electric arc furnace technology competed favourably with the Bessemer process resulting in its obsolescence.", "Basic oxygen steelmaking is essentially an improved version of the Bessemer process (decarburization by blowing oxygen as gas into the heat rather than burning the excess carbon away by adding oxygen carrying substances into the heat).", "The advantages of pure oxygen blast over air blast was known to Henry Bessemer, but the 19th-century technology was not advanced enough to allow for the production of the large quantities of pure oxygen to make it economically feasible for use."], ["Bessemer process", "Bessemer process\n\nThe Bessemer process was the first inexpensive industrial process for the mass production of steel from molten pig iron before the development of the open hearth furnace.", "The key principle is removal of impurities from the iron by oxidation with air being blown through the molten iron.", "The oxidation also raises the temperature of the iron mass and keeps it molten.", "Related decarburizing with air processes had been used outside Europe for hundreds of years, but not on an industrial scale.", "One such process has existed since the 11th century in East Asia, where the scholar Shen Kuo of that era described its use in the Chinese iron and steel industry.", "In the 17th century, accounts by European travelers detailed its possible use by the Japanese.", "The modern process is named after its inventor, the Englishman Henry Bessemer, who took out a patent on the process in 1856.", "The process was said to be independently discovered in 1851 by the American inventor William Kelly, though there is little to back up this claim.", "The process using a basic refractory lining is known as the \"basic Bessemer process\" or Gilchrist\u2013Thomas process after the English discoverers Percy Gilchrist and Sidney Gilchrist Thomas.", "A system akin to the Bessemer process has existed since the 11th century in East Asia."]], "gold": "The Bessemer process was the first inexpensive industrial process for the mass production of steel from molten pig iron before the development of the open hearth furnace. The key principle is removal of impurities from the iron by oxidation with air being blown through the molten iron. It is named after its inventor, Englishman, Henry Bessemer who took out a patent on the process in 1856. The process was said to be independently discovered in 1851 by the American inventor, William Kelly, though the claim is controversial.", "prediction 1": "The Bessemer process is the first inexpensive industrial process for the mass production of steel from molten pig iron before the development of the open hearth furnace. The modern process is named after its inventor, the Englishman Henry Bessemer, who took out a patent on the process in 1856. The process was said to be independently discovered in 1851 by the American inventor William Kelly, though there is little to back up this claim.", "prediction 2": "The Bessemer process to remove impurities by blasts of cold air blown through heated iron is said to be independently discovered in 1851 by the American inventor William Kelly. The process was named after its inventor, the Englishman Henry Bessemer, who took out a patent on the process in 1856. The process was said to be independently discovered in 1851 by the American inventor William Kelly, though there is little to back up this claim.", "prediction 3": "The process to remove impurities by blasts of cold air blown through heated iron was invented by the Englishman Henry Bessemer in 1856. It was said to be independently discovered in 1851 by the American inventor William Kelly, though there is little to back up this claim.", "prediction 4": "The modern process is named after its inventor, the Englishman Henry Bessemer, who took out a patent on the process in 1856. The process was said to be independently discovered in 1851 by the American inventor William Kelly, though there is little to back this claim. The modern process is named after its inventor, the Englishman Henry Bessemer, who took out a patent on the process in 1856 and subsequently held a patent expiring in 1861 for the process.", "feedback": {"errors": [], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 2, "sentence_id": [2]}], "corrected-prediction": "The Bessemer process is the first inexpensive industrial process for the mass production of steel from molten pig iron before the development of the open hearth furnace. The key principle of this process is the removal of impurities from the iron by oxidation with air being blown through the molten iron. The modern process is named after its inventor, the Englishman Henry Bessemer, who took out a patent on the process in 1856. The process was said to be independently discovered in 1851 by the American inventor William Kelly, though there is little to back up this claim."}, "preference": [0, 1, 1, 1, 1, 2], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Bessemer process\nS1. The Bessemer process was so fast (10\u201320 minutes for a heat) that it allowed little time for chemical analysis or adjustment of the alloying elements in the steel.\nS2. Bessemer converters did not remove phosphorus efficiently from the molten steel; as low-phosphorus ores became more expensive, conversion costs increased.\nS3. The process permitted only limited amount of scrap steel to be charged, further increasing costs, especially when scrap was inexpensive.\nS4. Use of electric arc furnace technology competed favourably with the Bessemer process resulting in its obsolescence.\nS5. Basic oxygen steelmaking is essentially an improved version of the Bessemer process (decarburization by blowing oxygen as gas into the heat rather than burning the excess carbon away by adding oxygen carrying substances into the heat).\nS6. The advantages of pure oxygen blast over air blast was known to Henry Bessemer, but the 19th-century technology was not advanced enough to allow for the production of the large quantities of pure oxygen to make it economically feasible for use.\n\nPassage 2: Title (S0) - Bessemer process\nS1. Bessemer process  The Bessemer process was the first inexpensive industrial process for the mass production of steel from molten pig iron before the development of the open hearth furnace.\nS2. The key principle is removal of impurities from the iron by oxidation with air being blown through the molten iron.\nS3. The oxidation also raises the temperature of the iron mass and keeps it molten.\nS4. Related decarburizing with air processes had been used outside Europe for hundreds of years, but not on an industrial scale.\nS5. One such process has existed since the 11th century in East Asia, where the scholar Shen Kuo of that era described its use in the Chinese iron and steel industry.\nS6. In the 17th century, accounts by European travelers detailed its possible use by the Japanese.\nS7. The modern process is named after its inventor, the Englishman Henry Bessemer, who took out a patent on the process in 1856.\nS8. The process was said to be independently discovered in 1851 by the American inventor William Kelly, though there is little to back up this claim.\nS9. The process using a basic refractory lining is known as the \"basic Bessemer process\" or Gilchrist\u2013Thomas process after the English discoverers Percy Gilchrist and Sidney Gilchrist Thomas.\nS10. A system akin to the Bessemer process has existed since the 11th century in East Asia.\n    \nInput Question:\nWho invented the process to remove impurities by blasts of cold air blown through heated iron?\n\nCorrect Response:\nThe Bessemer process was the first inexpensive industrial process for the mass production of steel from molten pig iron before the development of the open hearth furnace. The key principle is removal of impurities from the iron by oxidation with air being blown through the molten iron. It is named after its inventor, Englishman, Henry Bessemer who took out a patent on the process in 1856. The process was said to be independently discovered in 1851 by the American inventor, William Kelly, though the claim is controversial.\n\nModel Prediction:\nThe Bessemer process is the first inexpensive industrial process for the mass production of steel from molten pig iron before the development of the open hearth furnace. The modern process is named after its inventor, the Englishman Henry Bessemer, who took out a patent on the process in 1856. The process was said to be independently discovered in 1851 by the American inventor William Kelly, though there is little to back up this claim.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "The Bessemer process is the first inexpensive industrial process for the mass production of steel from molten pig iron before the development of the open hearth furnace. The modern process is named after its inventor, the Englishman Henry Bessemer, who took out a patent on the process in 1856. The process was said to be independently discovered in 1851 by the American inventor William Kelly, though there is little to back up this claim.\n\nExplanation: There are no irrelevant, incoherent, or repetitive spans in the model prediction. All the information provided is relevant to the question, coherent with the context, and not repetitive."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The Bessemer process is the first inexpensive industrial process for the mass production of steel from molten pig iron before the development of the open hearth furnace.\nS2. The modern process is named after its inventor, the Englishman Henry Bessemer, who took out a patent on the process in 1856.\nS3. The process was said to be independently discovered in 1851 by the American inventor William Kelly, though there is little to back up this claim.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation: All the facts in the model prediction are consistent with the provided passages and can be verified. Therefore, there are no spans that contain inconsistent or unverifiable facts."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 2, sentence 2 [Missing Major Auxiliary Information]\n\nExplanation:\n1. The model prediction does not mention the key principle of the Bessemer process, which is the removal of impurities from the iron by oxidation with air being blown through the molten iron. This is a major piece of auxiliary information that helps to understand the answer better."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The Bessemer process is the first inexpensive industrial process for the mass production of steel from molten pig iron before the development of the open hearth furnace. The key principle of this process is the removal of impurities from the iron by oxidation with air being blown through the molten iron. The modern process is named after its inventor, the Englishman Henry Bessemer, who took out a patent on the process in 1856. The process was said to be independently discovered in 1851 by the American inventor William Kelly, though there is little to back up this claim."}], "feedback_human": {"errors": [], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 2, "sentence_id": [2]}], "corrected-prediction": "The Bessemer process is the first inexpensive industrial process for the mass production of steel from molten pig iron before the development of the open hearth furnace.  The key principle is removal of impurities from the iron by oxidation with air being blown through the molten iron. The modern process is named after its inventor, the Englishman Henry Bessemer, who took out a patent on the process in 1856. The process was said to be independently discovered in 1851 by the American inventor William Kelly, though there is little to back up this claim."}}, {"question": "What did the sea dogs have that led to their defeat of the spanish armada?", "passages": [["Sea Dogs", "A favorite of the queen, he received a title that allowed him to claim any land he discovered in the name of England.", "During an expedition to the New World, he founded the colony of Roanoke.", "This colony however ended up disappearing mysteriously.", "Raleigh became infatuated with the idea of a \u201ccity of gold\u201d hidden somewhere in South America and set out on an expedition to find it.", "On his second expedition to find \u201cEl Dorado\u201d he ended up in a bit of a predicament after men under his subordinate Lawrence Keymis looted a Spanish Outpost.", "After this outrage Raleigh went back to England and the Spanish were not very happy with what Raleigh's men did in violation of the extant peace treaties.", "In order to make things right to the Spaniards, Raleigh was executed in the reign of King James I. King Phillip II of Spain had a very large and powerful navy that he claimed to be \u201cinvincible\u201d.", "However, after years of picking off and looting by English Sea Dogs he decided he had had enough.", "Phillip took his whole armada of 130 ships into the English Channel and decided to attempt to end English Piracy for good.", "The Spanish ships were bigger and more heavily armed but the English ships were smaller, faster, and more maneuverable.", "Concurrently, there was a huge storm that came in while the Spaniards were on their way and the Spanish suffered terrible losses."], ["Sea Dogs", "Sea Dogs\n\nThe Sea Dogs were a group of sea-raiders, (privateers, \"Elizabethan Pirates\"), who were authorised by Queen Elizabeth I of England, and also engaged in slave trading.", "The Sea Dogs were essentially a military branch that were authorised by the Queen to attack the Spanish fleet and loot their ships in order to bring back riches and treasure.", "They carried \"Letters of Marque\" which made their plundering of Spanish ships legal under English Law despite not being at war.", "The Sea Dogs were started in 1560 as a way to bridge the gap between the Spanish Navy and the English Navy.", "By having a small fleet of ships that would sail around and pick off Spanish ships, risking their lives and own ships in the process, they were able to reduce the funds and size of the Spanish navy significantly.", "The Sea Dogs continued carrying out raids against the Spanish until 1604 when England and Spain made peace.", "After that, many of the Sea Dogs continued as pirates employed by the Barbary States, in what would become the Anglo-Turkish piracy in the Caribbean.", "Sir Francis Drake, El Draque (The Dragon), was one of the most profitable and successful sea dogs of all time.", "The captain of \"Golden Hind\", he served in the English Navy from 1563\u20131596 and achieved the rank of Vice Admiral."]], "gold": "The Sea Dogs were a group of sea-raiders and privateers who were authorized by Elizabeth I of England and active from 1560-1605. They also engaged in slave trading, and committed piracy in the Caribbean, Spanish colonies as well as in European waters. After years of picking off and looting by English Sea Dogs, Philip II of Spain decided that he had had enough and mobilized an armada of 130 ships to sail into the English Channel and decided to attempt to end English sea-raiding for good. The sea dogs were able to defeat the Spanish armada in a huge storm because their ships were smaller, faster, and more man\u0153uvrable.   ", "prediction 1": "The Sea Dogs were a group of sea-raiders, (privateers, \"Elizabethan Pirates\"), who were authorised by Queen Elizabeth I of England, and also engaged in slave trading. They carried \"Letters of Marque\" which made their plundering of Spanish ships legal under English Law despite not being at war.\n", "prediction 2": "The Sea Dogs were a group of sea-raiders, (privateers, Elizabethan Pirates), who were authorised by Queen Elizabeth I of England, who were also engaged in slave trading. They carried Letters of Marque which made their plundering of Spanish ships legal under English Law despite not being at war.", "prediction 3": "The Sea Dogs were a group of sea-raiders who were authorised by Queen Elizabeth I of England and also engaged in slave trading. They had a small fleet of ships that would sail around and pick off Spanish ships, risking their lives and own ships in the process, they were able to reduce the funds and size of the Spanish navy significantly.", "prediction 4": "The Sea Dogs were a group of sea-raiders, who were authorised by Queen Elizabeth I of England, who also engaged in slave trading. They were started in 1560 as a way to bridge the gap between the Spanish Navy and the English Navy. By having a small fleet of ships that would sail around and pick off Spanish ships, risking their lives and own ships in the process, they were able to reduce the funds and size of the Spanish navy significantly. They defeated the Spanish armada in a huge storm that came in while the Spanish suffered terrible losses.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 167, "end": 294}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 1, "sentence_id": [10]}], "corrected-prediction": "The Sea Dogs were a group of sea-raiders, (privateers, \"Elizabethan Pirates\"), who were authorised by Queen Elizabeth I of England, and also engaged in slave trading. The Sea Dogs were able to defeat the Spanish Armada because their ships were smaller, faster, and more maneuverable. Additionally, a huge storm played a significant role in their victory."}, "preference": [0, 1, 1, 1, 1, 2], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Sea Dogs\nS1. A favorite of the queen, he received a title that allowed him to claim any land he discovered in the name of England.\nS2. During an expedition to the New World, he founded the colony of Roanoke.\nS3. This colony however ended up disappearing mysteriously.\nS4. Raleigh became infatuated with the idea of a \u201ccity of gold\u201d hidden somewhere in South America and set out on an expedition to find it.\nS5. On his second expedition to find \u201cEl Dorado\u201d he ended up in a bit of a predicament after men under his subordinate Lawrence Keymis looted a Spanish Outpost.\nS6. After this outrage Raleigh went back to England and the Spanish were not very happy with what Raleigh's men did in violation of the extant peace treaties.\nS7. In order to make things right to the Spaniards, Raleigh was executed in the reign of King James I. King Phillip II of Spain had a very large and powerful navy that he claimed to be \u201cinvincible\u201d.\nS8. However, after years of picking off and looting by English Sea Dogs he decided he had had enough.\nS9. Phillip took his whole armada of 130 ships into the English Channel and decided to attempt to end English Piracy for good.\nS10. The Spanish ships were bigger and more heavily armed but the English ships were smaller, faster, and more maneuverable.\nS11. Concurrently, there was a huge storm that came in while the Spaniards were on their way and the Spanish suffered terrible losses.\n\nPassage 2: Title (S0) - Sea Dogs\nS1. Sea Dogs  The Sea Dogs were a group of sea-raiders, (privateers, \"Elizabethan Pirates\"), who were authorised by Queen Elizabeth I of England, and also engaged in slave trading.\nS2. The Sea Dogs were essentially a military branch that were authorised by the Queen to attack the Spanish fleet and loot their ships in order to bring back riches and treasure.\nS3. They carried \"Letters of Marque\" which made their plundering of Spanish ships legal under English Law despite not being at war.\nS4. The Sea Dogs were started in 1560 as a way to bridge the gap between the Spanish Navy and the English Navy.\nS5. By having a small fleet of ships that would sail around and pick off Spanish ships, risking their lives and own ships in the process, they were able to reduce the funds and size of the Spanish navy significantly.\nS6. The Sea Dogs continued carrying out raids against the Spanish until 1604 when England and Spain made peace.\nS7. After that, many of the Sea Dogs continued as pirates employed by the Barbary States, in what would become the Anglo-Turkish piracy in the Caribbean.\nS8. Sir Francis Drake, El Draque (The Dragon), was one of the most profitable and successful sea dogs of all time.\nS9. The captain of \"Golden Hind\", he served in the English Navy from 1563\u20131596 and achieved the rank of Vice Admiral.\n    \nInput Question:\nWhat did the sea dogs have that led to their defeat of the spanish armada?\n\nCorrect Response:\nThe Sea Dogs were a group of sea-raiders and privateers who were authorized by Elizabeth I of England and active from 1560-1605. They also engaged in slave trading, and committed piracy in the Caribbean, Spanish colonies as well as in European waters. After years of picking off and looting by English Sea Dogs, Philip II of Spain decided that he had had enough and mobilized an armada of 130 ships to sail into the English Channel and decided to attempt to end English sea-raiding for good. The sea dogs were able to defeat the Spanish armada in a huge storm because their ships were smaller, faster, and more man\u0153uvrable.   \n\nModel Prediction:\nThe Sea Dogs were a group of sea-raiders, (privateers, \"Elizabethan Pirates\"), who were authorised by Queen Elizabeth I of England, and also engaged in slave trading. They carried \"Letters of Marque\" which made their plundering of Spanish ships legal under English Law despite not being at war.\n\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "The Sea Dogs were a group of sea-raiders, (privateers, \"Elizabethan Pirates\"), who were authorised by Queen Elizabeth I of England, and also engaged in slave trading. [They carried \"Letters of Marque\" which made their plundering of Spanish ships legal under English Law despite not being at war.]\n\nExplanation:\nThe information about the \"Letters of Marque\" is irrelevant to the question asked. The question is about what led to the defeat of the Spanish Armada by the Sea Dogs, not about the legality of their actions. Therefore, this information is marked as irrelevant."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The Sea Dogs were a group of sea-raiders, (privateers, \"Elizabethan Pirates\"), who were authorised by Queen Elizabeth I of England, and also engaged in slave trading.\nS2. They carried \"Letters of Marque\" which made their plundering of Spanish ships legal under English Law despite not being at war.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation:\nThere are no factual inconsistencies or unverifiable facts in the model prediction. All the information provided in the model prediction is consistent with the passages."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 10 [Missing Answer]\n2. Passage 1, sentence 11 [Missing Answer]\n\nExplanation:\n1. The model prediction does not mention that the Sea Dogs' ships were smaller, faster, and more maneuverable, which is a key factor in their defeat of the Spanish Armada. This information is found in Passage 1, Sentence 10.\n2. The model prediction also omits the fact that a huge storm played a role in the Sea Dogs' victory over the Spanish Armada. This information is found in Passage 1, Sentence 11."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The Sea Dogs were a group of sea-raiders, (privateers, \"Elizabethan Pirates\"), who were authorised by Queen Elizabeth I of England, and also engaged in slave trading. The Sea Dogs were able to defeat the Spanish Armada because their ships were smaller, faster, and more maneuverable. Additionally, a huge storm played a significant role in their victory."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 55, "end": 78}, {"error type": "Irrelevant", "explanation": "", "start": 167, "end": 295}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [8, 9]}, {"error type": "Missing-Answer", "passage_id": 1, "sentence_id": [10]}, {"error type": "Missing-Answer", "passage_id": 1, "sentence_id": [11]}], "corrected-prediction": "The Sea Dogs were a group of sea-raiders and privateers who were authorized by Queen Elizabeth I of England. They also engaged in slave trading. After years of picking off and looting by English Sea Dogs, Philip II of Spain decided that he had had enough and mobilized an armada of 130 ships to sail into the English Channel and decided to attempt to end English sea-raiding for good. However, the English ships were smaller, faster, and more maneuverable. Concurrently, there was a huge storm that came in while the Spaniards were on their way causing them to suffer terrible losses.\n"}}, {"question": "Which two plates meet along the west coast of the usa?", "passages": [["San Andreas Fault", "The Elkhorn Scarp defines the fault trace along much of its length within the plain.", "The southern segment, which stretches from Parkfield in Monterey County all the way to the Salton Sea, is capable of an 8.1-magnitude earthquake.", "At its closest, this fault passes about to the northeast of Los Angeles.", "Such a large earthquake on this southern segment would kill thousands of people in Los Angeles, San Bernardino, Riverside, and surrounding areas, and cause hundreds of billions of dollars in damage.", "The Pacific Plate, to the west of the fault, is moving in a northwest direction while the North American Plate to the east is moving toward the southwest, but relatively southeast under the influence of plate tectonics.", "The rate of slippage averages about a year across California.", "The southwestward motion of the North American Plate towards the Pacific is creating compressional forces along the eastern side of the fault.", "The effect is expressed as the Coast Ranges.", "The northwest movement of the Pacific Plate is also creating significant compressional forces which are especially pronounced where the North American Plate has forced the San Andreas to jog westward.", "This has led to the formation of the Transverse Ranges in Southern California, and to a lesser but still significant extent, the Santa Cruz Mountains (the location of the Loma Prieta earthquake in 1989)."], ["San Andreas Fault", "San Andreas Fault\n\nThe San Andreas Fault is a continental transform fault that extends roughly through California.", "It forms the tectonic boundary between the Pacific Plate and the North American Plate, and its motion is right-lateral strike-slip (horizontal).", "The fault divides into three segments, each with different characteristics and a different degree of earthquake risk.", "The slip rate along the fault ranges from /yr.", "The fault was identified in 1895 by Professor Andrew Lawson of UC Berkeley, who discovered the northern zone.", "It is often described as having been named after San Andreas Lake, a small body of water that was formed in a valley between the two plates.", "However, according to some of his reports from 1895 and 1908, Lawson actually named it after the surrounding San Andreas Valley.", "Following the 1906 San Francisco earthquake, Lawson concluded that the fault extended all the way into southern California.", "In 1953, geologist Thomas Dibblee concluded that hundreds of miles of lateral movement could occur along the fault.", "A project called the San Andreas Fault Observatory at Depth (SAFOD) near Parkfield, Monterey County, was drilled through the fault during 2004 - 2007 to collect material and make physical and chemical observations to better understand fault behavior ."], ["1906 San Francisco earthquake", "1906 San Francisco earthquake\n\nThe 1906 San Francisco earthquake struck the coast of Northern California at 5:12\u00a0a.m. on Wednesday, April\u00a018 with an estimated moment magnitude of 7.9 and a maximum Mercalli intensity of XI (\"Extreme\").", "High intensity shaking was felt from Eureka on the North Coast to the Salinas Valley, an agricultural region to the south of the San Francisco Bay Area.", "Devastating fires soon broke out in the city and lasted for several days.", "Thousands of homes were dismantled.", "As a result, up to 3,000 people died and over 80% of the city of San Francisco was destroyed.", "The events are remembered as one of the worst and deadliest earthquakes in the history of the United States.", "The death toll remains the greatest loss of life from a natural disaster in California's history and high in the lists of American disasters.", "The San Andreas Fault is a continental transform fault that forms part of the tectonic boundary between the Pacific Plate and the North American Plate.", "The strike-slip fault is characterized by mainly lateral motion in a dextral sense, where the western (Pacific) plate moves northward relative to the eastern (North American) plate.", "This fault runs the length of California from the Salton Sea in the south to Cape Mendocino in the north, a distance of about ."]], "gold": "The Pacific Plate and the North American Plate are the two plates that meet along the West Coast of the United States. The San Andraes Fault forms the tectonic boundary between these two plates. The Pacific Plate is to the west of the San Andraes Fault, while the North American Plate is to the east of the San Andraes Fault. The San Andreas Fault is an active transform boundary; therefore, the Pacific Plate, carrying the city of Los Angeles, is moving northwards with respect to the North American Plate.", "prediction 1": "The Pacific Plate and the North American Plate meet roughly along the west coast of the United States. The San Andreas Fault is part of the tectonic boundary between the two plates. It forms the right-lateral strike-slip fault, where the western (Pacific) plate moves northward relative to the eastern (North American) plate. The San Andreas Fault runs roughly through California, and is part of the tectonic boundary between the two plates.", "prediction 2": "The San Andreas Fault is a continental transform fault that forms the tectonic boundary between the Pacific Plate and the North American Plate, and its motion is right-lateral strike-slip. The Pacific Plate, to the west of the fault, is moving in a northwest direction while the North American Plate to the east is moving towards the southwest, but relatively southeast under the influence of plate tectonics. The 1906 San Francisco earthquake struck the coast of Northern California at 5:12 a.m. on Wednesday, April 1885, and is remembered as one of the worst and deadliest earthquake in the history of the history of the history of the United States.", "prediction 3": "The San Andreas Fault is a continental transform fault that forms part of the tectonic boundary between the Pacific Plate and the North American Plate. The Pacific Plate, to the west of the fault, is moving in a northwest direction while the North American Plate to the east is moving toward the southwest, but relatively southeast under the influence of plate tectonics. The 1906 San Francisco earthquake struck the coast of Northern California at 5:12 a.m. on Wednesday, April 18 with an estimated moment magnitude of 7.9 and a maximum Mercalli intensity of XI (\"Extreme\").", "prediction 4": "The San Andreas Fault is a continental transform fault that forms the tectonic boundary between the Pacific Plate and the North American Plate. The western plate of the two plates, known as the Pacific Plate, moves northward relative to the eastern plate, known as the North American Plate.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 326, "end": 441}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [5]}], "corrected-prediction": "The Pacific Plate and the North American Plate meet roughly along the west coast of the United States. The San Andreas Fault is part of the tectonic boundary between the two plates. It forms the right-lateral strike-slip fault, where the western (Pacific) plate moves northward relative to the eastern (North American) plate. The Pacific Plate, to the west of the fault, is moving in a northwest direction while the North American Plate to the east is moving toward the southwest. The southwestward motion of the North American Plate towards the Pacific is creating compressional forces along the eastern side of the fault."}, "preference": [1, 1, 1, 1, 1, 1], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - San Andreas Fault\nS1. The Elkhorn Scarp defines the fault trace along much of its length within the plain.\nS2. The southern segment, which stretches from Parkfield in Monterey County all the way to the Salton Sea, is capable of an 8.1-magnitude earthquake.\nS3. At its closest, this fault passes about to the northeast of Los Angeles.\nS4. Such a large earthquake on this southern segment would kill thousands of people in Los Angeles, San Bernardino, Riverside, and surrounding areas, and cause hundreds of billions of dollars in damage.\nS5. The Pacific Plate, to the west of the fault, is moving in a northwest direction while the North American Plate to the east is moving toward the southwest, but relatively southeast under the influence of plate tectonics.\nS6. The rate of slippage averages about a year across California.\nS7. The southwestward motion of the North American Plate towards the Pacific is creating compressional forces along the eastern side of the fault.\nS8. The effect is expressed as the Coast Ranges.\nS9. The northwest movement of the Pacific Plate is also creating significant compressional forces which are especially pronounced where the North American Plate has forced the San Andreas to jog westward.\nS10. This has led to the formation of the Transverse Ranges in Southern California, and to a lesser but still significant extent, the Santa Cruz Mountains (the location of the Loma Prieta earthquake in 1989).\n\nPassage 2: Title (S0) - San Andreas Fault\nS1. San Andreas Fault  The San Andreas Fault is a continental transform fault that extends roughly through California.\nS2. It forms the tectonic boundary between the Pacific Plate and the North American Plate, and its motion is right-lateral strike-slip (horizontal).\nS3. The fault divides into three segments, each with different characteristics and a different degree of earthquake risk.\nS4. The slip rate along the fault ranges from /yr.\nS5. The fault was identified in 1895 by Professor Andrew Lawson of UC Berkeley, who discovered the northern zone.\nS6. It is often described as having been named after San Andreas Lake, a small body of water that was formed in a valley between the two plates.\nS7. However, according to some of his reports from 1895 and 1908, Lawson actually named it after the surrounding San Andreas Valley.\nS8. Following the 1906 San Francisco earthquake, Lawson concluded that the fault extended all the way into southern California.\nS9. In 1953, geologist Thomas Dibblee concluded that hundreds of miles of lateral movement could occur along the fault.\nS10. A project called the San Andreas Fault Observatory at Depth (SAFOD) near Parkfield, Monterey County, was drilled through the fault during 2004 - 2007 to collect material and make physical and chemical observations to better understand fault behavior .\n\nPassage 3: Title (S0) - 1906 San Francisco earthquake\nS1. 1906 San Francisco earthquake  The 1906 San Francisco earthquake struck the coast of Northern California at 5:12\u00a0a.m. on Wednesday, April\u00a018 with an estimated moment magnitude of 7.9 and a maximum Mercalli intensity of XI (\"Extreme\").\nS2. High intensity shaking was felt from Eureka on the North Coast to the Salinas Valley, an agricultural region to the south of the San Francisco Bay Area.\nS3. Devastating fires soon broke out in the city and lasted for several days.\nS4. Thousands of homes were dismantled.\nS5. As a result, up to 3,000 people died and over 80% of the city of San Francisco was destroyed.\nS6. The events are remembered as one of the worst and deadliest earthquakes in the history of the United States.\nS7. The death toll remains the greatest loss of life from a natural disaster in California's history and high in the lists of American disasters.\nS8. The San Andreas Fault is a continental transform fault that forms part of the tectonic boundary between the Pacific Plate and the North American Plate.\nS9. The strike-slip fault is characterized by mainly lateral motion in a dextral sense, where the western (Pacific) plate moves northward relative to the eastern (North American) plate.\nS10. This fault runs the length of California from the Salton Sea in the south to Cape Mendocino in the north, a distance of about .\n    \nInput Question:\nWhich two plates meet along the west coast of the usa?\n\nCorrect Response:\nThe Pacific Plate and the North American Plate are the two plates that meet along the West Coast of the United States. The San Andraes Fault forms the tectonic boundary between these two plates. The Pacific Plate is to the west of the San Andraes Fault, while the North American Plate is to the east of the San Andraes Fault. The San Andreas Fault is an active transform boundary; therefore, the Pacific Plate, carrying the city of Los Angeles, is moving northwards with respect to the North American Plate.\n\nModel Prediction:\nThe Pacific Plate and the North American Plate meet roughly along the west coast of the United States. The San Andreas Fault is part of the tectonic boundary between the two plates. It forms the right-lateral strike-slip fault, where the western (Pacific) plate moves northward relative to the eastern (North American) plate. The San Andreas Fault runs roughly through California, and is part of the tectonic boundary between the two plates.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "The Pacific Plate and the North American Plate meet roughly along the west coast of the United States. The San Andreas Fault is part of the tectonic boundary between the two plates. It forms the right-lateral strike-slip fault, where the western (Pacific) plate moves northward relative to the eastern (North American) plate. [The San Andreas Fault runs roughly through California, and is part of the tectonic boundary between the two plates.]\n\nExplanation:\nThe last sentence in the model prediction is repetitive as it restates the information about the San Andreas Fault being the tectonic boundary between the Pacific and North American Plates, which was already mentioned in the second sentence. Therefore, it should be marked as \"Repetitive\"."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The Pacific Plate and the North American Plate meet roughly along the west coast of the United States.\nS2. The San Andreas Fault is part of the tectonic boundary between the two plates.\nS3. It forms the right-lateral strike-slip fault, where the western (Pacific) plate moves northward relative to the eastern (North American) plate.\nS4. The San Andreas Fault runs roughly through California, and is part of the tectonic boundary between the two plates.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation:\nAll the facts presented in the model prediction are consistent with the information provided in the passages. There are no inconsistencies or unverifiable facts."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 5 [Missing Major Auxiliary Information]\n2. Passage 1, sentence 7 [Missing Major Auxiliary Information]\n\nExplanation:\n1. The model prediction does not mention the specific directions in which the Pacific Plate and the North American Plate are moving, which is crucial information for understanding the dynamics of the San Andreas Fault. This information is present in sentence 5 of Passage 1.\n2. The model prediction also omits the information about the compressional forces being created along the eastern side of the fault due to the southwestward motion of the North American Plate towards the Pacific. This information is present in sentence 7 of Passage 1 and is important for understanding the geological activity along the fault."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The Pacific Plate and the North American Plate meet roughly along the west coast of the United States. The San Andreas Fault is part of the tectonic boundary between the two plates. It forms the right-lateral strike-slip fault, where the western (Pacific) plate moves northward relative to the eastern (North American) plate. The Pacific Plate, to the west of the fault, is moving in a northwest direction while the North American Plate to the east is moving toward the southwest. The southwestward motion of the North American Plate towards the Pacific is creating compressional forces along the eastern side of the fault."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 182, "end": 325}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [5]}], "corrected-prediction": "The Pacific Plate and the North American Plate meet roughly along the west coast of the United States. The San Andreas Fault is part of the tectonic boundary between the two plates. The Pacific Plate, to the west of the fault, is moving in a northwest direction while the North American Plate to the east is moving toward the southwest, but relatively southeast under the influence of plate tectonics."}}, {"question": "When do doug and carol get married in er?", "passages": [["Doug Ross", "When Ross leaves, he and Hathaway are on poor terms until she discovers that she's pregnant with his twin girls.", "Her clinic is later re-opened, but she has to report to her former assistant there.", "Ross was written out of the series because Clooney wished to focus on his expanding film career.", "He also said that there wasn't any strong story in place for his character after Season 5.", "He appeared at the end of the penultimate episode of season 6, when Carol leaves Cook County to reunite with Ross in Seattle.", "He was reportedly asked to return briefly in season 8, to make an appearance in Anthony Edwards's last episode during Greene's funeral, but Clooney declined because he did not want his cameo appearance to overshadow the departure of a beloved character on the show.", "Clooney returned to \"ER\" for its 15th and final season in 2009 in a story arc beginning with Episode 328, titled \"Old Times\", with Julianna Margulies also returning as Hathaway.", "George Clooney did not receive a casting call for the television series.", "He received a draft of the script from a friend; he read it and became interested in the part.", "He said: \"I like the flaws in this guy.", "I can play him.\""], ["ER (season 1)", "ER (season 1)\n\nThe first season of the American fictional drama television series \"ER\" aired from 1994\u20131995 with 25 episodes.", "The 2-hour pilot episode aired on September 19, 1994 and was followed by 24 other episodes, including the season finale that aired on May 18, 1995.", "In \"ER\"'s first season, the core cast consisted of Chief Resident Dr. Mark Greene, pediatric resident Dr. Doug Ross, second-year resident Dr. Susan Lewis, medical student John Carter, head nurse Carol Hathaway, and second-year surgical resident Dr. Peter Benton.", "The series premiere \"24 Hours\" sees Dr. Greene considering a move into private practice at the request of his wife, Jen.", "The episode also sees an attempted suicide from staff nurse Carol Hathaway, who had previously been in a long-term relationship with Doug Ross, and the first day for medical student John Carter.", "Originally, Carol Hathaway died by suicide, but her death in the pilot was never shown or referred to by other characters, leaving her open for a return.", "Audiences responded so well to her character that producers decided to offer Julianna Margulies a permanent spot in the cast.", "Over the course of the season, Dr. Greene's marriage begins to disintegrate."]], "gold": "In the American drama TV series ER, characters Doug Ross and Carol Hathaway first appear as a married couple in episode 328, airing on March 12, 2009 during the show's 15th and final season. ", "prediction 1": "In the first season of the American medical drama television series ER, the 2-hour pilot episode aired on September 19, 1994. The next 24 episodes followed, including the season finale on May 18, 1995. The wedding takes place in the episode 24 Hours, the final episode of the first season. The wedding takes place in the episode 328, Old Times.", "prediction 2": "In the first season of the American fictional drama television series ER, the couple Doug Ross and Carol Hathaway marry in the episode 24 Hours.", "prediction 3": "In the American television series ER, Doug Ross and Carol Hathaway marry in the first season. The episode 24, \"24 Hours\" is the first episode of the series.", "prediction 4": "In the American medical drama television series ER, Doug Ross and Carol Hathaway get married in Season 1 episode 25, \"The Wedding.\" The wedding takes place during the series finale, which aired on May 18, 1995.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 0, "end": 201}, {"error type": "Irrelevant", "explanation": "", "start": 202, "end": 289}, {"error type": "Unverifiable", "start": 202, "end": 289}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [7]}], "corrected-prediction": "Doug Ross and Carol Hathaway first appear as a married couple in episode 328, titled \"Old Times\", during the 15th and final season of the American medical drama television series ER."}, "preference": [2, 2, 1, 0, 1, 1], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Doug Ross\nS1. When Ross leaves, he and Hathaway are on poor terms until she discovers that she's pregnant with his twin girls.\nS2. Her clinic is later re-opened, but she has to report to her former assistant there.\nS3. Ross was written out of the series because Clooney wished to focus on his expanding film career.\nS4. He also said that there wasn't any strong story in place for his character after Season 5.\nS5. He appeared at the end of the penultimate episode of season 6, when Carol leaves Cook County to reunite with Ross in Seattle.\nS6. He was reportedly asked to return briefly in season 8, to make an appearance in Anthony Edwards's last episode during Greene's funeral, but Clooney declined because he did not want his cameo appearance to overshadow the departure of a beloved character on the show.\nS7. Clooney returned to \"ER\" for its 15th and final season in 2009 in a story arc beginning with Episode 328, titled \"Old Times\", with Julianna Margulies also returning as Hathaway.\nS8. George Clooney did not receive a casting call for the television series.\nS9. He received a draft of the script from a friend; he read it and became interested in the part.\nS10. He said: \"I like the flaws in this guy.\nS11. I can play him.\"\n\nPassage 2: Title (S0) - ER (season 1)\nS1. ER (season 1)  The first season of the American fictional drama television series \"ER\" aired from 1994\u20131995 with 25 episodes.\nS2. The 2-hour pilot episode aired on September 19, 1994 and was followed by 24 other episodes, including the season finale that aired on May 18, 1995.\nS3. In \"ER\"'s first season, the core cast consisted of Chief Resident Dr. Mark Greene, pediatric resident Dr. Doug Ross, second-year resident Dr. Susan Lewis, medical student John Carter, head nurse Carol Hathaway, and second-year surgical resident Dr. Peter Benton.\nS4. The series premiere \"24 Hours\" sees Dr. Greene considering a move into private practice at the request of his wife, Jen.\nS5. The episode also sees an attempted suicide from staff nurse Carol Hathaway, who had previously been in a long-term relationship with Doug Ross, and the first day for medical student John Carter.\nS6. Originally, Carol Hathaway died by suicide, but her death in the pilot was never shown or referred to by other characters, leaving her open for a return.\nS7. Audiences responded so well to her character that producers decided to offer Julianna Margulies a permanent spot in the cast.\nS8. Over the course of the season, Dr. Greene's marriage begins to disintegrate.\n    \nInput Question:\nWhen do doug and carol get married in er?\n\nCorrect Response:\nIn the American drama TV series ER, characters Doug Ross and Carol Hathaway first appear as a married couple in episode 328, airing on March 12, 2009 during the show's 15th and final season. \n\nModel Prediction:\nIn the first season of the American medical drama television series ER, the 2-hour pilot episode aired on September 19, 1994. The next 24 episodes followed, including the season finale on May 18, 1995. The wedding takes place in the episode 24 Hours, the final episode of the first season. The wedding takes place in the episode 328, Old Times.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "[In the first season of the American medical drama television series ER, the 2-hour pilot episode aired on September 19, 1994. The next 24 episodes followed, including the season finale on May 18, 1995.] The wedding takes place in the episode 24 Hours, the final episode of the first season. [The wedding takes place in the episode 24 Hours, the final episode of the first season.] The wedding takes place in the episode 328, Old Times.\n\nExplanation:\n1. The first two sentences in the model prediction are irrelevant as they do not provide any information about when Doug and Carol get married in ER.\n2. The third sentence is repetitive as it repeats the information that the wedding takes place in the episode 24 Hours, the final episode of the first season."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. In the first season of the American medical drama television series ER, the 2-hour pilot episode aired on September 19, 1994.\nS2. The next 24 episodes followed, including the season finale on May 18, 1995.\nS3. The wedding takes place in the episode 24 Hours, the final episode of the first season.\nS4. The wedding takes place in the episode 328, Old Times.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "1. S3\n2. S4\n\nExplanation:\n1. The claim in sentence 3 that the wedding takes place in the episode \"24 Hours\", the final episode of the first season, is not supported by the passages. This is an \"Unverifiable Fact\".\n2. Sentence 4 is factually inconsistent with the passages. According to Passage 1, Sentence 7, Doug Ross and Carol Hathaway first appear as a married couple in episode 328, not that the wedding takes place in this episode. This is an \"Inconsistent Fact\"."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 7 [Missing Major Auxiliary Information]\n\nExplanation:\n1. The model prediction does not mention that Doug Ross and Carol Hathaway first appear as a married couple in episode 328, which is a crucial piece of information for understanding when they got married in the series. This is a \"Missing Major Auxiliary Information\"."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "Doug Ross and Carol Hathaway first appear as a married couple in episode 328, titled \"Old Times\", during the 15th and final season of the American medical drama television series ER."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 126, "end": 201}, {"error type": "Unverifiable", "explanation": "", "start": 202, "end": 289}, {"error type": "Unverifiable", "explanation": "", "start": 290, "end": 344}, {"error type": "Irrelevant", "explanation": "", "start": 0, "end": 125}], "missing-info": [], "corrected-prediction": ""}}, {"question": "Leader who declared war on russia to support austria hungary?", "passages": [["Wilhelm II, German Emperor", "Wilhelm II, German Emperor\n\nWilhelm II (Friedrich Wilhelm Viktor Albert; 27 January 18594 June 1941) was the last German Emperor (\"Kaiser\") and King of Prussia, reigning from 15 June 1888 until his abdication on 9 November 1918.", "He was the eldest grandchild of Queen Victoria of the United Kingdom and related to many monarchs and princes of Europe, most notably, King George V of the United Kingdom and Emperor Nicholas II of Russia.", "Acceding to the throne in 1888, he dismissed the chancellor, Otto von Bismarck, in 1890.", "He also launched Germany on a bellicose \"New Course\" in foreign affairs that culminated in his support for Austria-Hungary in the crisis of July 1914 that led in a matter of days to the First World War.", "Bombastic and impetuous, he sometimes made tactless pronouncements on sensitive topics without consulting his ministers, behavior which culminated in a disastrous \"Daily Telegraph\" interview in 1908 that cost him most of his influence.", "His leading generals, Paul von Hindenburg and Erich Ludendorff, dictated policy during the First World War with little regard for the civilian government.", "An ineffective war-time leader, he lost the support of the army, abdicated on 9 November 1918, and fled to exile in the Netherlands."], ["German entry into World War I", "As the war started, Germany stood behind its ally Austria-Hungary in a confrontation with Serbia, but Serbia was under the protection of Russia, which was allied to France.", "Germany was the leader of the Central Powers, which included Austria-Hungary, the Ottoman Empire, and later Bulgaria; arrayed against them were the Allies, consisting chiefly of Russia, France, Britain, and in 1915 Italy.", "There were several main causes of World War I, which broke out unexpectedly in June-August 1914, including the conflicts and hostility of the previous four decades.", "Militarism, alliances, imperialism, and ethnic nationalism played major roles.", "However the immediate origins of the war lay in the decisions taken by statesmen and generals during the Crisis of 1914, which was sparked by the assassination of Archduke Franz Ferdinand (heir to the throne of Austria Hungary) by a Serbian secret organization, the Black Hand.", "Since the 1870s or 1880s all the major powers had been preparing for a large-scale war, although none expected one.", "Britain focused on building up its Royal Navy, already stronger than the next two navies combined.", "Germany, France, Austria, Italy and Russia, and some smaller countries, set up conscription systems whereby young men would serve from 1 to 3 years in the army, then spend the next 20 years or so in the reserves with annual summer training.", "Men of higher social status became officers."], ["Wilhelm II, German Emperor", "Wilhelm offered to support Austria-Hungary in crushing the Black Hand, the secret organization that had plotted the killing, and even sanctioned the use of force by Austria against the perceived source of the movement\u2014Serbia (this is often called \"the blank cheque\").", "He wanted to remain in Berlin until the crisis was resolved, but his courtiers persuaded him instead to go on his annual cruise of the North Sea on 6 July 1914.", "Wilhelm made erratic attempts to stay on top of the crisis via telegram, and when the Austro-Hungarian ultimatum was delivered to Serbia, he hurried back to Berlin.", "He reached Berlin on 28 July, read a copy of the Serbian reply, and wrote on it:\n\nUnknown to the Emperor, Austro-Hungarian ministers and generals had already convinced the 83-year-old Franz Joseph I of Austria to sign a declaration of war against Serbia.", "As a direct consequence, Russia began a general mobilization to attack Austria in defense of Serbia.", "On the night of 30 July, when handed a document stating that Russia would not cancel its mobilization, Wilhelm wrote a lengthy commentary containing these observations:\n\nMore recent British authors state that Wilhelm II really declared, \"Ruthlessness and weakness will start the most terrifying war of the world, whose purpose is to destroy Germany."]], "gold": "Wilhelm II  anglicised as William II, was the last German Emperor (Kaiser) and King of Prussia, reigning from June 15, 1888 until his abdication on November 9, 1918. Wilhelm was a friend of Archduke Franz Ferdinand of Austria, and he was deeply shocked by his assassination on June 28, 1914. Wilhelm offered to support Austria-Hungary in crushing the Black Hand, the secret organisation that had plotted the killing, and even sanctioned the use of force by Austria against the perceived source of the movement,Serbia, but Serbia was under the protection of Russia, which was allied to France. Wilhelm left virtually all decision-making regarding strategy and organisation of the war effort to the German Army's Great General Staff. German Chief of Staff Moltke sent an emotional telegram to the Austrian Chief of Staff Conrad on July 30: \"Austria-Hungary must be preserved, mobilise at once against Russia. Germany will mobilise.\" Vienna officials decided that Moltke was really in chargeand refused mediation and mobilized against Russia.", "prediction 1": "The German Empire declared war on Russia in 1914 to support Austria-Hungary. The German leader who declared war on Russian was the Emperor Friedrich Wilhelm II.", "prediction 2": "In 1917, Wilhelm II announced a military mobilization against Russia to support Austria-Hungary, which resulted in the Russians attacking Austria in defense of Serbia. The Emperor of Austria was Franz Joseph II, who had been Emperor since 1888 and was the last German Emperor and King of Prussia. However, as the leader of the Central Powers, Wilhelm declared war on Russia to support Austria-Hungary during the Crisis of 1914, which led in a matter of days to the First World War.", "prediction 3": "The German emperor Friedrich Wilhelm II declared war on Russia in July 1914 in support of his ally Austria-Hungary. He did so as the last German Emperor and King of Prussia, reigning from 15 June 1888 until his abdication on 9 November 1918. The Austrian-Hungarian crisis of July 1914 led to a series of events that led to the First World War.", "prediction 4": "There were several German leaders who declared war on Russia in the First World War. The German Emperor Friedrich Wilhelm Viktor Albert declared war on Russia to support Austria-Hungary in the crisis of July 1914 that led in a matter of days to the First World War. The Austro-Hungarian government was led by Franz Joseph I, 83, and their ministers had already convinced Joseph to sign a declaration of war against Serbia.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 139, "end": 148}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [1]}], "corrected-prediction": "Wilhelm II, the last German Emperor (\"Kaiser\") and King of Prussia, reigning from 15 June 1888 until his abdication on 9 November 1918, declared war on Russia in 1914 to support Austria-Hungary. He launched Germany on a bellicose \"New Course\" in foreign affairs that culminated in his support for Austria-Hungary in the crisis of July 1914 that led in a matter of days to the First World War. Wilhelm II offered to support Austria-Hungary in crushing the Black Hand, the secret organization that had plotted the killing, and even sanctioned the use of force by Austria against the perceived source of the movement\u2014Serbia."}, "preference": [2, 2, 2, 2, 1, 1], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Wilhelm II, German Emperor\nS1. Wilhelm II, German Emperor  Wilhelm II (Friedrich Wilhelm Viktor Albert; 27 January 18594 June 1941) was the last German Emperor (\"Kaiser\") and King of Prussia, reigning from 15 June 1888 until his abdication on 9 November 1918.\nS2. He was the eldest grandchild of Queen Victoria of the United Kingdom and related to many monarchs and princes of Europe, most notably, King George V of the United Kingdom and Emperor Nicholas II of Russia.\nS3. Acceding to the throne in 1888, he dismissed the chancellor, Otto von Bismarck, in 1890.\nS4. He also launched Germany on a bellicose \"New Course\" in foreign affairs that culminated in his support for Austria-Hungary in the crisis of July 1914 that led in a matter of days to the First World War.\nS5. Bombastic and impetuous, he sometimes made tactless pronouncements on sensitive topics without consulting his ministers, behavior which culminated in a disastrous \"Daily Telegraph\" interview in 1908 that cost him most of his influence.\nS6. His leading generals, Paul von Hindenburg and Erich Ludendorff, dictated policy during the First World War with little regard for the civilian government.\nS7. An ineffective war-time leader, he lost the support of the army, abdicated on 9 November 1918, and fled to exile in the Netherlands.\n\nPassage 2: Title (S0) - German entry into World War I\nS1. As the war started, Germany stood behind its ally Austria-Hungary in a confrontation with Serbia, but Serbia was under the protection of Russia, which was allied to France.\nS2. Germany was the leader of the Central Powers, which included Austria-Hungary, the Ottoman Empire, and later Bulgaria; arrayed against them were the Allies, consisting chiefly of Russia, France, Britain, and in 1915 Italy.\nS3. There were several main causes of World War I, which broke out unexpectedly in June-August 1914, including the conflicts and hostility of the previous four decades.\nS4. Militarism, alliances, imperialism, and ethnic nationalism played major roles.\nS5. However the immediate origins of the war lay in the decisions taken by statesmen and generals during the Crisis of 1914, which was sparked by the assassination of Archduke Franz Ferdinand (heir to the throne of Austria Hungary) by a Serbian secret organization, the Black Hand.\nS6. Since the 1870s or 1880s all the major powers had been preparing for a large-scale war, although none expected one.\nS7. Britain focused on building up its Royal Navy, already stronger than the next two navies combined.\nS8. Germany, France, Austria, Italy and Russia, and some smaller countries, set up conscription systems whereby young men would serve from 1 to 3 years in the army, then spend the next 20 years or so in the reserves with annual summer training.\nS9. Men of higher social status became officers.\n\nPassage 3: Title (S0) - Wilhelm II, German Emperor\nS1. Wilhelm offered to support Austria-Hungary in crushing the Black Hand, the secret organization that had plotted the killing, and even sanctioned the use of force by Austria against the perceived source of the movement\u2014Serbia (this is often called \"the blank cheque\").\nS2. He wanted to remain in Berlin until the crisis was resolved, but his courtiers persuaded him instead to go on his annual cruise of the North Sea on 6 July 1914.\nS3. Wilhelm made erratic attempts to stay on top of the crisis via telegram, and when the Austro-Hungarian ultimatum was delivered to Serbia, he hurried back to Berlin.\nS4. He reached Berlin on 28 July, read a copy of the Serbian reply, and wrote on it:  Unknown to the Emperor, Austro-Hungarian ministers and generals had already convinced the 83-year-old Franz Joseph I of Austria to sign a declaration of war against Serbia.\nS5. As a direct consequence, Russia began a general mobilization to attack Austria in defense of Serbia.\nS6. On the night of 30 July, when handed a document stating that Russia would not cancel its mobilization, Wilhelm wrote a lengthy commentary containing these observations:  More recent British authors state that Wilhelm II really declared, \"Ruthlessness and weakness will start the most terrifying war of the world, whose purpose is to destroy Germany.\n    \nInput Question:\nLeader who declared war on russia to support austria hungary?\n\nCorrect Response:\nWilhelm II  anglicised as William II, was the last German Emperor (Kaiser) and King of Prussia, reigning from June 15, 1888 until his abdication on November 9, 1918. Wilhelm was a friend of Archduke Franz Ferdinand of Austria, and he was deeply shocked by his assassination on June 28, 1914. Wilhelm offered to support Austria-Hungary in crushing the Black Hand, the secret organisation that had plotted the killing, and even sanctioned the use of force by Austria against the perceived source of the movement,Serbia, but Serbia was under the protection of Russia, which was allied to France. Wilhelm left virtually all decision-making regarding strategy and organisation of the war effort to the German Army's Great General Staff. German Chief of Staff Moltke sent an emotional telegram to the Austrian Chief of Staff Conrad on July 30: \"Austria-Hungary must be preserved, mobilise at once against Russia. Germany will mobilise.\" Vienna officials decided that Moltke was really in chargeand refused mediation and mobilized against Russia.\n\nModel Prediction:\nThe German Empire declared war on Russia in 1914 to support Austria-Hungary. The German leader who declared war on Russian was the Emperor Friedrich Wilhelm II.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "The German Empire declared war on Russia in 1914 to support Austria-Hungary. The German leader who declared war on Russian was the Emperor [Friedrich] Wilhelm II.\n\nExplanation:\n1. The name \"Friedrich\" in the model prediction is irrelevant because the German Emperor who declared war on Russia to support Austria-Hungary was Wilhelm II, not Friedrich Wilhelm II. The name \"Friedrich\" is not found in the passages or the reference response."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The German Empire declared war on Russia in 1914 to support Austria-Hungary.\nS2. The German leader who declared war on Russian was the Emperor Friedrich Wilhelm II.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "S2\n\nExplanation:\n1. The name \"Friedrich Wilhelm II\" in sentence 2 is inconsistent with the passages. The German Emperor who declared war on Russia to support Austria-Hungary was Wilhelm II, not Friedrich Wilhelm II. The name \"Friedrich\" is not found in the passages or the reference response."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 1 [Missing Major Auxiliary Information]\n2. Passage 1, sentence 4 [Missing Major Auxiliary Information]\n3. Passage 3, sentence 1 [Missing Major Auxiliary Information]\n\nExplanation:\n1. The model prediction misses the information that Wilhelm II was the last German Emperor (\"Kaiser\") and King of Prussia, reigning from 15 June 1888 until his abdication on 9 November 1918. This is crucial auxiliary information that provides context to Wilhelm II's role and reign.\n2. The model prediction does not mention Wilhelm II's \"New Course\" in foreign affairs that culminated in his support for Austria-Hungary in the crisis of July 1914 that led in a matter of days to the First World War. This is crucial auxiliary information that provides context to Wilhelm II's actions leading up to the war.\n3. The model prediction does not mention Wilhelm II's offer to support Austria-Hungary in crushing the Black Hand, the secret organization that had plotted the killing, and even sanctioned the use of force by Austria against the perceived source of the movement\u2014Serbia (this is often called \"the blank cheque\"). This is crucial auxiliary information that provides context to Wilhelm II's motivations and actions in declaring war on Russia."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "Wilhelm II, the last German Emperor (\"Kaiser\") and King of Prussia, reigning from 15 June 1888 until his abdication on 9 November 1918, declared war on Russia in 1914 to support Austria-Hungary. He launched Germany on a bellicose \"New Course\" in foreign affairs that culminated in his support for Austria-Hungary in the crisis of July 1914 that led in a matter of days to the First World War. Wilhelm II offered to support Austria-Hungary in crushing the Black Hand, the secret organization that had plotted the killing, and even sanctioned the use of force by Austria against the perceived source of the movement\u2014Serbia."}], "feedback_human": {"errors": [{"error type": "Wrong-Grounding", "explanation": "{\"passage_id\":3,\"sentence_id\":[1]}", "start": 0, "end": 76}, {"error type": "Redundant", "explanation": "The German Empire declared war on Russia ", "start": 77, "end": 160}], "missing-info": [{"error type": "Missing-Minor-Auxiliary", "passage_id": 1, "sentence_id": [1]}, {"error type": "Missing-Major-Auxiliary", "passage_id": 2, "sentence_id": [1]}, {"error type": "Missing-Major-Auxiliary", "passage_id": 2, "sentence_id": [5]}], "corrected-prediction": " German Emperor Wilhelm II was the last German Emperor (\"Kaiser\") and King of Prussia, reigning from 15 June 1888 until his abdication on 9 November 1918. Sparked by the 1914 assassination of Archduke Franz Ferdinand (heir to the throne of Austria Hungary), Wilhelm offered to support Austria-Hungary in crushing the Black Hand, the secret organization that had plotted the killing, and even sanctioned the use of force by Austria against the perceived source of the movement\u2014Serbia, but Serbia was under the protection of Russia, which was allied to France."}}, {"question": "When was the first government formed in the world?", "passages": [["Political history of the world", "Political history of the world\n\nThe political history of the world is the history of the various political entities created by the human race throughout their existence and the way these states define their borders.", "Throughout history, political entities have expanded from basic systems of self-governance and monarchy to the complex democratic and totalitarian systems that exist today.", "In parallel, political systems have expanded from vaguely defined frontier-type boundaries, to the national definite boundaries existing today.", "In ancient history, civilizations did not have definite boundaries as states have today, and their borders could be more accurately described as frontiers.", "Early dynastic Sumer, and early dynastic Egypt were the first civilizations to define their borders.", "Moreover, for the past 200,000 years and up to the twentieth century, many people have lived in non-state societies.", "These range from relatively egalitarian bands and tribes to complex and highly stratified chiefdoms.", "The first states of sorts were those of early dynastic Sumer and early dynastic Egypt, which arose from the Uruk period and Predynastic Egypt respectively at approximately 3000BCE.", "Early dynastic Egypt was based around the Nile River in the north-east of Africa, the kingdom's boundaries being based around the Nile and stretching to areas where oases existed."], ["Government", "Government\n\nA government is the system or group of people governing an organized community, often a state.", "In the case of its broad associative definition, government normally consists of legislature, executive, and judiciary.", "Government is a means by which organizational policies are enforced, as well as a mechanism for determining policy.", "Each government has a kind of constitution, a statement of its governing principles and philosophy.", "Typically the philosophy chosen is some balance between the principle of individual freedom and the idea of absolute state authority (tyranny).", "While all types of organizations have governance, the word \"government\" is often used more specifically to refer to the approximately 200 independent national governments on Earth, as well as subsidiary organizations.", "Historically prevalent forms of government include monarchy, aristocracy, timocracy, oligarchy, democracy, theocracy and tyranny.", "The main aspect of any philosophy of government is how political power is obtained, with the two main forms being electoral contest and hereditary succession.", "A government is the system to govern a state or community.", "The word \"government\" derives, ultimately, from the Greek verb \u03ba\u03c5\u03b2\u03b5\u03c1\u03bd\u03ac\u03c9", "[\"kubern\u00e1o\"] (meaning \"to steer\" with gubernaculum (rudder), the metaphorical sense being attested in Plato's Ship of State)."]], "gold": "A government is the system, or group of people, governing an organized community, which is generally a state. The first government in the world was formed in approximately 3000BCE. The communities that are considered to have been the first states with governments are early dynastic Sumer, which arose from the Uruk period, and early dynastic Egypt, which arose from Predynastic Egypt period.", "prediction 1": "The first government formed in the world was the state of Sumer in the early dynastic period, or Early dynastic Egypt, formed during the Uruk period and Predynastic Egypt at approximately 3000 BCE.", "prediction 2": "The first government formed in the world was the government of early dynastic Sumer, which arose from the Uruk period and Predynastic Egypt respectively at approximately 3000BCE.", "prediction 3": "The first government formed in the world is the system or group of people governing an organized community, often a state. The first states of sorts were those of early dynastic Sumer and early dynastic Egypt, which arose from the Uruk period and Predynastic Egypt respectively at approximately 3000BCE.", "prediction 4": "The first government in the world was formed in approximately 3000 BCE. The political history of the world is the history of the various political entities created by the human race throughout their existence and the way these states define their borders. In parallel, political systems have expanded from vaguely defined frontier-type boundaries, to the national definite boundaries existing today. In ancient history, civilizations did not have definite boundaries as states have today, and their borders could be more accurately described as frontiers. Nevertheless, for the past 200,000 years and up to the twentieth century, many people have lived in non-state societies.", "feedback": {"errors": [], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 2, "sentence_id": [1]}], "corrected-prediction": "A government, which is the system or group of people governing an organized community, was first formed in the world by the state of Sumer in the early dynastic period, or Early dynastic Egypt, during the Uruk period and Predynastic Egypt at approximately 3000 BCE."}, "preference": [0, 0, 1, 0, 1, 1], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Political history of the world\nS1. Political history of the world  The political history of the world is the history of the various political entities created by the human race throughout their existence and the way these states define their borders.\nS2. Throughout history, political entities have expanded from basic systems of self-governance and monarchy to the complex democratic and totalitarian systems that exist today.\nS3. In parallel, political systems have expanded from vaguely defined frontier-type boundaries, to the national definite boundaries existing today.\nS4. In ancient history, civilizations did not have definite boundaries as states have today, and their borders could be more accurately described as frontiers.\nS5. Early dynastic Sumer, and early dynastic Egypt were the first civilizations to define their borders.\nS6. Moreover, for the past 200,000 years and up to the twentieth century, many people have lived in non-state societies.\nS7. These range from relatively egalitarian bands and tribes to complex and highly stratified chiefdoms.\nS8. The first states of sorts were those of early dynastic Sumer and early dynastic Egypt, which arose from the Uruk period and Predynastic Egypt respectively at approximately 3000BCE.\nS9. Early dynastic Egypt was based around the Nile River in the north-east of Africa, the kingdom's boundaries being based around the Nile and stretching to areas where oases existed.\n\nPassage 2: Title (S0) - Government\nS1. Government  A government is the system or group of people governing an organized community, often a state.\nS2. In the case of its broad associative definition, government normally consists of legislature, executive, and judiciary.\nS3. Government is a means by which organizational policies are enforced, as well as a mechanism for determining policy.\nS4. Each government has a kind of constitution, a statement of its governing principles and philosophy.\nS5. Typically the philosophy chosen is some balance between the principle of individual freedom and the idea of absolute state authority (tyranny).\nS6. While all types of organizations have governance, the word \"government\" is often used more specifically to refer to the approximately 200 independent national governments on Earth, as well as subsidiary organizations.\nS7. Historically prevalent forms of government include monarchy, aristocracy, timocracy, oligarchy, democracy, theocracy and tyranny.\nS8. The main aspect of any philosophy of government is how political power is obtained, with the two main forms being electoral contest and hereditary succession.\nS9. A government is the system to govern a state or community.\nS10. The word \"government\" derives, ultimately, from the Greek verb \u03ba\u03c5\u03b2\u03b5\u03c1\u03bd\u03ac\u03c9\nS11. [\"kubern\u00e1o\"] (meaning \"to steer\" with gubernaculum (rudder), the metaphorical sense being attested in Plato's Ship of State).\n    \nInput Question:\nWhen was the first government formed in the world?\n\nCorrect Response:\nA government is the system, or group of people, governing an organized community, which is generally a state. The first government in the world was formed in approximately 3000BCE. The communities that are considered to have been the first states with governments are early dynastic Sumer, which arose from the Uruk period, and early dynastic Egypt, which arose from Predynastic Egypt period.\n\nModel Prediction:\nThe first government formed in the world was the state of Sumer in the early dynastic period, or Early dynastic Egypt, formed during the Uruk period and Predynastic Egypt at approximately 3000 BCE.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "The first government formed in the world was the state of Sumer in the early dynastic period, or Early dynastic Egypt, formed during the Uruk period and Predynastic Egypt at approximately 3000 BCE.\n\nExplanation: The model prediction does not contain any irrelevant, incoherent or repetitive spans. All the information provided is relevant to the question, coherent with the context, and not repetitive."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The first government formed in the world was the state of Sumer in the early dynastic period, or Early dynastic Egypt, formed during the Uruk period and Predynastic Egypt at approximately 3000 BCE.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation: The model prediction does not contain any inconsistent or unverifiable facts. The information provided is consistent with the passages and can be verified from the passages."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 2, sentence 1 [Missing Major Auxiliary Information]\n\nExplanation:\n1. The model prediction does not include the definition of a government, which is a major auxiliary information that helps in understanding the context of the answer. This information can be found in Passage 2, sentence 1."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "A government, which is the system or group of people governing an organized community, was first formed in the world by the state of Sumer in the early dynastic period, or Early dynastic Egypt, during the Uruk period and Predynastic Egypt at approximately 3000 BCE."}], "feedback_human": {"errors": [], "missing-info": [{"error type": "Missing-Minor-Auxiliary", "passage_id": 2, "sentence_id": [1]}], "corrected-prediction": "A government is the system or group of people governing an organized community, often a state. The first government formed in the world was the state of Sumer in the early dynastic period, or Early dynastic Egypt, formed during the Uruk period and Predynastic Egypt at approximately 3000 BCE."}}, {"question": "When was the song stacy's mom released?", "passages": [["Stacy's Mom", "Stacy's Mom\n\n\"Stacy's Mom\" is a pop rock song recorded by the American rock band Fountains of Wayne for their third studio album, \"Welcome Interstate Managers\".", "\"Stacy's Mom\" was released to radio on May 20, 2003.", "The song was released as the lead single from \"Welcome Interstate Managers\" on September 29, 2003 through S-Curve Records and Virgin Records.", "\"Stacy's Mom\" was written by bassist Adam Schlesinger and vocalist Chris Collingwood, both of whom produced the song alongside Mike Denneen.", "Its subject matter was inspired by a friend of Schlesinger's when he was young who had a crush on his grandmother.", "A power pop song, the group hoped to emulate the sound of The Cars with the track.", "\"Stacy's Mom\" reached number 21 on the \"Billboard\" Hot 100, becoming the band's highest-charting hit in the United States.", "Additionally, the song peaked within the top 10 in Ireland, and the top 20 in the United Kingdom, Canada, and Australia.", "The single was certified gold by the Recording Industry Association of America for sales of over 500,000 copies.", "It was nominated for a Grammy Award for Best Vocal Pop Performance.", "The song was accompanied with a music video in which model Rachel Hunter plays the titular role."], ["Stacy's Mom", "The Cars' frontman Ric Ocasek thought that the intro was a sample from \"Just What I Needed\" but the band says they performed it in the studio and just \"got it right.\"", "\"Stacy's Mom\" debuted on the \"Billboard\" Hot 100 the week of October 11, 2003 at number 59, making this their first song to appear on that chart.", "It entered the top 40 the week after by moving twenty-one spots to number 38 and moved nine spots to number 31 on the week of October 25, 2003.", "It peaked at number 21 the week of November 21, 2003 and stayed there for two weeks.", "It stayed on the chart for seventeen weeks.", "It was one of the first songs to reach the No. 1 spot on the \"Most Downloaded Songs\" list of the iTunes Music Store.", "It reached No. 11 in the UK Singles Chart.", "It was nominated for a Grammy Award for Best Vocal Pop Performance at the 2004 awards.", "The single's sales were last estimated at 888,000, according to Nielsen SoundScan, in 2011.", "Richard Harrington of \"The Washington Post\" dubbed it \"nicely naughty.\"", "Ben Greenman, writing for \"The New Yorker\", considered it the \"second-catchiest song ever written about a girlfriend's parent,\" after \"Mrs. Robinson\".", "The song ranks No."], ["Stacy's Mom", "In multiple interviews, Bowling for Soup bandleader Jaret Reddick has said that he regularly encountered fans at their concerts who mistakenly thought \"Stacy's Mom\" was a Bowling for Soup song.", "In 2011, they recorded and released a cover version of the song.", "Reddick said that by finally releasing their own version of the song, \"I\u2019ve basically just taken care of a large part of the population that\u2019s been wrong for years, and I\u2019ve made them right.\"", "Alluding to the mistaken identity issue, the cover art for the song release reads: \"Finally you can say this is your favorite song by BFS and not look like an idiot!\"", "Bowling for Soup has since made the song part of their live set list.", "The song was included on the setlist for \"\" as a guest act.", "It also appeared in the 4th episode of the 1st season of the television series \"Psych, Woman Seeking Dead Husband, Smokers Ok, No Pets\".", "The song was parodied on \"The Howard Stern Show\" to mock Wack Pack character Hanzi (Imran Kahn).", "It has also been performed by \"Postmodern Jukebox\" ft.", "Casey Abrams.", "A cover of the song by the Northeastern University pep band has become an unofficial theme song for the Northeastern Huskies men's ice hockey team."]], "gold": "\"Stacy's Mom\" is a pop rock song by American rock band Fountains of Wayne. It was first released on radio on May 20, 2003 and then as the lead single of the album \"Welcome Interstate Managers\" on September 29, 2003. The song also became available for digital download on September 29, 2003 in the US and on October 7, 2003 in the UK, followed by its commercialization in the 7\" format on March 8, 2004. Years later, the American rock band Bowling for Soup covered the song and released their version on October 10, 2011.", "prediction 1": "Stacy's Mom is a pop rock song recorded by the American rock band Fountains of Wayne for their third studio album, Welcome Interstate Managers. The song was released to radio on May 20, 2003. It was released as the lead single from the album on September 29, 2003 through S-Curve Records and Virgin Records. Bowling for Soup also recorded and released a cover of the song in 2011, which they released in their entirety on February 12, 2014.", "prediction 2": "The pop rock song Stacy's Mom was released to radio on May 20, 2003. The song was released as the lead single from Fountains of Wayne's third studio album, Welcome Interstate Managers, on September 29, 2003 through S-Curve Records and Virgin Records. In 2011, Bowling for Soup released a cover of the song.", "prediction 3": "Stacy's Mom is a pop rock song recorded by the American rock band Fountains of Wayne for their third studio album, Welcome Interstate Managers. The song was released to radio on May 20, 2003. It was released as the lead single from the album on September 29, 2003. In 2011, Bowling for Soup released a cover version of the song.", "prediction 4": "In 2003, the pop rock song Stacy's Mom was released to radio on May 20, 2003. Stacy's Mom was released as the lead single from Fountains of Wayne's third studio album, Welcome Interstate Managers on September 29, 2003 through S-Curve Records and Virgin Records. In 2011, Bowling for Soup recorded and released a cover version of the song.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 381, "end": 440}], "missing-info": [{"error type": "Missing-Minor-Auxiliary", "passage_id": 3, "sentence_id": [2]}], "corrected-prediction": "Stacy's Mom is a pop rock song recorded by the American rock band Fountains of Wayne for their third studio album, Welcome Interstate Managers. The song was released to radio on May 20, 2003. It was released as the lead single from the album on September 29, 2003 through S-Curve Records and Virgin Records. Bowling for Soup also recorded a cover of the song and released it in 2011."}, "preference": [2, 2, 2, 0, 0, 0], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Stacy's Mom\nS1. Stacy's Mom  \"Stacy's Mom\" is a pop rock song recorded by the American rock band Fountains of Wayne for their third studio album, \"Welcome Interstate Managers\".\nS2. \"Stacy's Mom\" was released to radio on May 20, 2003.\nS3. The song was released as the lead single from \"Welcome Interstate Managers\" on September 29, 2003 through S-Curve Records and Virgin Records.\nS4. \"Stacy's Mom\" was written by bassist Adam Schlesinger and vocalist Chris Collingwood, both of whom produced the song alongside Mike Denneen.\nS5. Its subject matter was inspired by a friend of Schlesinger's when he was young who had a crush on his grandmother.\nS6. A power pop song, the group hoped to emulate the sound of The Cars with the track.\nS7. \"Stacy's Mom\" reached number 21 on the \"Billboard\" Hot 100, becoming the band's highest-charting hit in the United States.\nS8. Additionally, the song peaked within the top 10 in Ireland, and the top 20 in the United Kingdom, Canada, and Australia.\nS9. The single was certified gold by the Recording Industry Association of America for sales of over 500,000 copies.\nS10. It was nominated for a Grammy Award for Best Vocal Pop Performance.\nS11. The song was accompanied with a music video in which model Rachel Hunter plays the titular role.\n\nPassage 2: Title (S0) - Stacy's Mom\nS1. The Cars' frontman Ric Ocasek thought that the intro was a sample from \"Just What I Needed\" but the band says they performed it in the studio and just \"got it right.\"\nS2. \"Stacy's Mom\" debuted on the \"Billboard\" Hot 100 the week of October 11, 2003 at number 59, making this their first song to appear on that chart.\nS3. It entered the top 40 the week after by moving twenty-one spots to number 38 and moved nine spots to number 31 on the week of October 25, 2003.\nS4. It peaked at number 21 the week of November 21, 2003 and stayed there for two weeks.\nS5. It stayed on the chart for seventeen weeks.\nS6. It was one of the first songs to reach the No. 1 spot on the \"Most Downloaded Songs\" list of the iTunes Music Store.\nS7. It reached No. 11 in the UK Singles Chart.\nS8. It was nominated for a Grammy Award for Best Vocal Pop Performance at the 2004 awards.\nS9. The single's sales were last estimated at 888,000, according to Nielsen SoundScan, in 2011.\nS10. Richard Harrington of \"The Washington Post\" dubbed it \"nicely naughty.\"\nS11. Ben Greenman, writing for \"The New Yorker\", considered it the \"second-catchiest song ever written about a girlfriend's parent,\" after \"Mrs. Robinson\".\nS12. The song ranks No.\n\nPassage 3: Title (S0) - Stacy's Mom\nS1. In multiple interviews, Bowling for Soup bandleader Jaret Reddick has said that he regularly encountered fans at their concerts who mistakenly thought \"Stacy's Mom\" was a Bowling for Soup song.\nS2. In 2011, they recorded and released a cover version of the song.\nS3. Reddick said that by finally releasing their own version of the song, \"I\u2019ve basically just taken care of a large part of the population that\u2019s been wrong for years, and I\u2019ve made them right.\"\nS4. Alluding to the mistaken identity issue, the cover art for the song release reads: \"Finally you can say this is your favorite song by BFS and not look like an idiot!\"\nS5. Bowling for Soup has since made the song part of their live set list.\nS6. The song was included on the setlist for \"\" as a guest act.\nS7. It also appeared in the 4th episode of the 1st season of the television series \"Psych, Woman Seeking Dead Husband, Smokers Ok, No Pets\".\nS8. The song was parodied on \"The Howard Stern Show\" to mock Wack Pack character Hanzi (Imran Kahn).\nS9. It has also been performed by \"Postmodern Jukebox\" ft.\nS10. Casey Abrams.\nS11. A cover of the song by the Northeastern University pep band has become an unofficial theme song for the Northeastern Huskies men's ice hockey team.\n    \nInput Question:\nWhen was the song stacy's mom released?\n\nCorrect Response:\n\"Stacy's Mom\" is a pop rock song by American rock band Fountains of Wayne. It was first released on radio on May 20, 2003 and then as the lead single of the album \"Welcome Interstate Managers\" on September 29, 2003. The song also became available for digital download on September 29, 2003 in the US and on October 7, 2003 in the UK, followed by its commercialization in the 7\" format on March 8, 2004. Years later, the American rock band Bowling for Soup covered the song and released their version on October 10, 2011.\n\nModel Prediction:\nStacy's Mom is a pop rock song recorded by the American rock band Fountains of Wayne for their third studio album, Welcome Interstate Managers. The song was released to radio on May 20, 2003. It was released as the lead single from the album on September 29, 2003 through S-Curve Records and Virgin Records. Bowling for Soup also recorded and released a cover of the song in 2011, which they released in their entirety on February 12, 2014.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "Stacy's Mom is a pop rock song recorded by the American rock band Fountains of Wayne for their third studio album, Welcome Interstate Managers. The song was released to radio on May 20, 2003. It was released as the lead single from the album on September 29, 2003 through S-Curve Records and Virgin Records. Bowling for Soup also recorded and released a cover of the song in 2011, [which they released in their entirety on February 12, 2014.]\n\nExplanation:\nThe last part of the sentence \"which they released in their entirety on February 12, 2014\" is irrelevant as it does not provide any necessary information about the release date of the song \"Stacy's Mom\". It also seems to be factually incorrect as there is no mention of this date in the provided passages."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. Stacy's Mom is a pop rock song recorded by the American rock band Fountains of Wayne for their third studio album, Welcome Interstate Managers.\nS2. The song was released to radio on May 20, 2003.\nS3. It was released as the lead single from the album on September 29, 2003 through S-Curve Records and Virgin Records.\nS4. Bowling for Soup also recorded and released a cover of the song in 2011, which they released in their entirety on February 12, 2014.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "S4\n\nExplanation:\nThe claim that Bowling for Soup released their cover of \"Stacy's Mom\" in its entirety on February 12, 2014 is unverifiable as there is no mention of this date in the provided passages."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 3, sentence 2 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. The model prediction mentions that Bowling for Soup covered the song \"Stacy's Mom\" in 2011, but it does not mention that they released their cover version of the song in the same year, as stated in Passage 3, sentence 2. This is a minor auxiliary information as it provides additional context to the release of the cover version."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "Stacy's Mom is a pop rock song recorded by the American rock band Fountains of Wayne for their third studio album, Welcome Interstate Managers. The song was released to radio on May 20, 2003. It was released as the lead single from the album on September 29, 2003 through S-Curve Records and Virgin Records. Bowling for Soup also recorded a cover of the song and released it in 2011."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 264, "end": 307}, {"error type": "Unverifiable", "explanation": "", "start": 381, "end": 440}], "missing-info": [], "corrected-prediction": "Stacy's Mom is a pop rock song recorded by the American rock band Fountains of Wayne for their third studio album, Welcome Interstate Managers. The song was released to radio on May 20, 2003. It was released as the lead single from the album on September 29, 2003 through S-Curve Records and Virgin Records. Bowling for Soup also recorded and released a cover of the song in 2011."}}, {"question": "Who has a grammy oscar tony and emmy?", "passages": [["Triple Crown of Acting", "Triple Crown of Acting\n\nThe Triple Crown of Acting is a term used in the American entertainment industry to describe actors who have won a competitive Academy Award, Emmy Award, and Tony Award in the acting categories.", "As of June 2018, twenty-four people have achieved the triple crown of acting (15 women, 9 men).", "Helen Hayes's Emmy Award win on February 5, 1953, made her the first person to achieve the triple crown.", "Thomas Mitchell became the first man to achieve the triple crown with his Tony Award win later the same year on March 29, 1953.", "Hayes and Rita Moreno are the only triple crown winners in competitive acting categories who have also won a Grammy Award to complete the EGOT.", "American actress Helen Hayes (1900\u20131993) was the first performer to achieve the triple crown of acting.", "She completed the triple crown in 1953.", "Hayes was a 9-time Emmy (1), 3-time Tony (2), and 2-time Oscar (2) nominee, for a total of 14 TC nominations.", "She won two Oscars, two Tonys and an Emmy for a total of five competitive triple crown awards.", "She also won a Grammy in 1977 for Best Spoken Word Recording to complete the EGOT, for competitive Emmy, Grammy, Oscar and Tony wins.", "Hayes is one of only two Triple Crown winners (along with Rita Moreno) to have achieved the EGOT."]], "gold": "A small group of people have won awards for their work in television, recording, movie, and theatre, for which they received four different awards. They each received an Emmy, a Grammy, an Oscar, and a Tony Award. The people who have won all four awards, all in competitive categories, are Richard Rodgers, Helen Hayes, Rita Moreno, John Gielgud, Audrey Hepburn, Marvin Hamlisch, Jonathan Tunick, Mel Brooks, Mike Nichols, Whoopi Goldberg, Scott Rudin, Robert Lopez, John Legend, Andrew Lloyd Webber, Tim Rice. The people who won all four awards, which includes non-competitive categories, are Barbra Streisand, Liza Minelli, James Earl Jones, Alan Menken, Harry Belafonte, Quincy Jones.", "prediction 1": "The Triple Crown of Acting is a term used in the American entertainment industry to describe actors who have won a competitive Oscar, Emmy Award, and Tony Award in the acting categories. As of June 2018, twenty-four people have achieved the triple crown of acting (15 women, 9 men). Helen Hayes' Emmy Award win on February 5, 1953, made her the first person to achieve the triple crown. Thomas Mitchell became the first man to achieve the triple crown with his Tony Award win later the same year on March 29, 1953. Rita Moreno are the only triple crown winners in competitive acting categories who have also won a Grammy Award to complete the EGOT.", "prediction 2": "The Triple Crown of Acting is a term used in the American entertainment industry to describe actors who have won a competitive Emmy Award, Tony Award, and Oscar Award in the acting categories. Helen Hayes and Rita Moreno are the only triple crown winners in competitive acting categories who have also won a Grammy Award to complete the EGOT, for competitive triple crown awards. Thomas Mitchell became the first man to achieve the triple crown with his Tony Award win later the same year on March 29, 1953.", "prediction 3": "The Triple Crown of Acting is a term used in the American entertainment industry to describe actors who have won a competitive Academy Award, Emmy Award, and Tony Award in the acting categories. Helen Hayes was the first performer to achieve the triple crown, completing the triple crown in 1953. Rita Moreno was the only triple crown winner in competitive acting categories who also won a Grammy Award to complete the EGOT. Hayes and Rita Moreno are the only triple crown winners in competitive acting categories who have also won a Grammy Award to complete the EGOT, for competitive triple crown wins.", "prediction 4": "The Triple Crown of Acting is a term used in the American entertainment industry to describe actors who have won a competitive Oscar, Emmy, and Tony Award in the acting categories. Helen Hayes completed the triple crown in 1953 and was the first performer to achieve the triple crown and also won a Grammy Award. Rita Moreno is the only triple crown winner in the competitive acting categories who has also won a Grammy Award to complete the EGOT, for competitive Emmy, Grammy, Oscar and Tony wins.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 0, "end": 514}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 1, "sentence_id": [10]}], "corrected-prediction": "Helen Hayes and Rita Moreno are the only triple crown winners in competitive acting categories who have also won a Grammy Award to complete the EGOT."}, "preference": [1, 1, 1, 2, 2, 1], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Triple Crown of Acting\nS1. Triple Crown of Acting  The Triple Crown of Acting is a term used in the American entertainment industry to describe actors who have won a competitive Academy Award, Emmy Award, and Tony Award in the acting categories.\nS2. As of June 2018, twenty-four people have achieved the triple crown of acting (15 women, 9 men).\nS3. Helen Hayes's Emmy Award win on February 5, 1953, made her the first person to achieve the triple crown.\nS4. Thomas Mitchell became the first man to achieve the triple crown with his Tony Award win later the same year on March 29, 1953.\nS5. Hayes and Rita Moreno are the only triple crown winners in competitive acting categories who have also won a Grammy Award to complete the EGOT.\nS6. American actress Helen Hayes (1900\u20131993) was the first performer to achieve the triple crown of acting.\nS7. She completed the triple crown in 1953.\nS8. Hayes was a 9-time Emmy (1), 3-time Tony (2), and 2-time Oscar (2) nominee, for a total of 14 TC nominations.\nS9. She won two Oscars, two Tonys and an Emmy for a total of five competitive triple crown awards.\nS10. She also won a Grammy in 1977 for Best Spoken Word Recording to complete the EGOT, for competitive Emmy, Grammy, Oscar and Tony wins.\nS11. Hayes is one of only two Triple Crown winners (along with Rita Moreno) to have achieved the EGOT.\n    \nInput Question:\nWho has a grammy oscar tony and emmy?\n\nCorrect Response:\nA small group of people have won awards for their work in television, recording, movie, and theatre, for which they received four different awards. They each received an Emmy, a Grammy, an Oscar, and a Tony Award. The people who have won all four awards, all in competitive categories, are Richard Rodgers, Helen Hayes, Rita Moreno, John Gielgud, Audrey Hepburn, Marvin Hamlisch, Jonathan Tunick, Mel Brooks, Mike Nichols, Whoopi Goldberg, Scott Rudin, Robert Lopez, John Legend, Andrew Lloyd Webber, Tim Rice. The people who won all four awards, which includes non-competitive categories, are Barbra Streisand, Liza Minelli, James Earl Jones, Alan Menken, Harry Belafonte, Quincy Jones.\n\nModel Prediction:\nThe Triple Crown of Acting is a term used in the American entertainment industry to describe actors who have won a competitive Oscar, Emmy Award, and Tony Award in the acting categories. As of June 2018, twenty-four people have achieved the triple crown of acting (15 women, 9 men). Helen Hayes' Emmy Award win on February 5, 1953, made her the first person to achieve the triple crown. Thomas Mitchell became the first man to achieve the triple crown with his Tony Award win later the same year on March 29, 1953. Rita Moreno are the only triple crown winners in competitive acting categories who have also won a Grammy Award to complete the EGOT.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "[The Triple Crown of Acting is a term used in the American entertainment industry to describe actors who have won a competitive Oscar, Emmy Award, and Tony Award in the acting categories. As of June 2018, twenty-four people have achieved the triple crown of acting (15 women, 9 men). Helen Hayes' Emmy Award win on February 5, 1953, made her the first person to achieve the triple crown. Thomas Mitchell became the first man to achieve the triple crown with his Tony Award win later the same year on March 29, 1953.] Rita Moreno are the only triple crown winners in competitive acting categories who have also won a Grammy Award to complete the EGOT.\n\nExplanation:\n1. The first four sentences in the model prediction are irrelevant to the question. The question is asking about individuals who have won a Grammy, Oscar, Tony, and Emmy, not about the Triple Crown of Acting. Therefore, these sentences should be marked as \"Irrelevant\"."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The Triple Crown of Acting is a term used in the American entertainment industry to describe actors who have won a competitive Oscar, Emmy Award, and Tony Award in the acting categories.\nS2. As of June 2018, twenty-four people have achieved the triple crown of acting (15 women, 9 men).\nS3. Helen Hayes' Emmy Award win on February 5, 1953, made her the first person to achieve the triple crown.\nS4. Thomas Mitchell became the first man to achieve the triple crown with his Tony Award win later the same year on March 29, 1953.\nS5. Rita Moreno are the only triple crown winners in competitive acting categories who have also won a Grammy Award to complete the EGOT.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "S5\n\nExplanation:\n1. Sentence 5 states that Rita Moreno is the only triple crown winner who has also won a Grammy Award to complete the EGOT. However, this is factually inconsistent with the passages, as Passage 1, Sentence 5 mentions that both Helen Hayes and Rita Moreno have achieved this."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 10 [Missing Answer]\n2. Passage 1, sentence 11 [Missing Answer]\n\nExplanation:\n1. The model prediction fails to mention that Helen Hayes also won a Grammy, Oscar, Tony, and Emmy, which is a direct answer to the question and can be found in Passage 1, Sentence 10.\n2. The model prediction does not include the information that there are only two Triple Crown winners who have also achieved the EGOT, which is another direct answer to the question and can be found in Passage 1, Sentence 11."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "Helen Hayes and Rita Moreno are the only triple crown winners in competitive acting categories who have also won a Grammy Award to complete the EGOT."}], "feedback_human": {"errors": [], "missing-info": [], "corrected-prediction": "The Triple Crown of Acting is a term used in the American entertainment industry to describe actors who have won a competitive Oscar, Emmy Award, and Tony Award in the acting categories. As of June 2018, twenty-four people have achieved the triple crown of acting (15 women, 9 men). Helen Hayes' Emmy Award win on February 5, 1953, made her the first person to achieve the triple crown. Thomas Mitchell became the first man to achieve the triple crown with his Tony Award win later the same year on March 29, 1953. Rita Moreno are the only triple crown winners in competitive acting categories who have also won a Grammy Award to complete the EGOT."}}, {"question": "When was the first road to key west built?", "passages": [["Key West", "The southernmost location that the public can visit is the beach at Fort Zachary Taylor park.", "The actual southernmost point of the contiguous United States is Ballast Key, a privately owned island just south and west of Key West.", "The claim \"90 Miles to Cuba\" on the monument is close to correct; Cuba at its closest point has been measured at from Key West.", "Several U.S. presidents have visited Key West with the first being Ulysses S. Grant in 1880, followed by Grover Cleveland in 1889, and William Howard Taft in 1912.", "Taft was the first president to use the first officer's quarters that would later be known as the Little White House.", "Franklin D. Roosevelt visited the Florida Keys many times, beginning in 1917.", "Harry S. Truman visited Key West for a total of 175 days on 11 visits during his presidency and visited five times after he left office.", "His first visit was in 1946.", "The Little White House and Truman Annex take their names from his frequent and well-documented visits.", "The residence is also known as the Winter White House as Truman stayed there mostly in the winter months, and used it for official business such as the Truman Doctrine.", "Dwight D. Eisenhower stayed at the Little White House following a heart attack in 1955.", "John F. Kennedy visited Key West in March 1961, and in November 1962, a month after the resolution of the Cuban Missile Crisis."], ["Overseas Railroad", "Overseas Railroad\n\nThe Overseas Railroad (also known as Florida Overseas Railroad, the Overseas Extension, and Flagler's Folly) was an extension of the Florida East Coast Railway to Key West, a city located 128 miles (204.8\u00a0km) beyond the end of the Florida peninsula.", "Work on the line started in 1905 and it operated from 1912 to 1935, when it was partially destroyed by the Labor Day Hurricane.", "Henry Flagler (1830\u20131913) was a principal in Rockefeller, Andrews & Flagler and later a founder of Standard Oil during the Gilded Age in the United States.", "The wealthy man took an interest in Florida while seeking a warmer climate for his ailing first wife in the late 1870s.", "Returning to Florida in 1881, he became the builder and developer of resort hotels and railroads along the east coast of Florida.", "Beginning with St. Augustine, he moved progressively south.", "Flagler helped develop Ormond Beach, Daytona Beach, and Palm Beach, and became known as the Father of Miami, Florida.", "Flagler's rail network became known as the Florida East Coast Railway (FEC).", "By 1904, the FEC had reached Homestead, south of Miami.", "After the United States announced in 1905 the construction of the Panama Canal, Flagler became particularly interested in linking Key West to the mainland."]], "gold": "The first road to key west started being built in 1905, and was finished in 1912.", "prediction 1": "The first road to Key West was built in 1905. The Overseas Railroad was an extension of the Florida East Coast Railway. It was built from 1912 to 1935.", "prediction 2": "The first road to Key West was the Overseas Railroad, a link to the Florida East Coast Railway. Work on the line started in 1905 and it operated from 1912 to 1935, when it was partially destroyed by the Labor Day Hurricane.", "prediction 3": "The first road to Key West was built in 1905. The Overseas Railroad was an extension of the Florida East Coast Railway to Key West, a city located 128 miles (204.8 km) beyond the end of the Florida peninsula. Work on the line started in 1905 and it operated from 1912 to 1935, when it was partially destroyed by the Labor Day Hurricane.", "prediction 4": "The first road to Key West was built in 1905. The Overseas Railroad was an extension of the Florida East Coast Railway to Key West, a city located 128 miles (204.8 km) beyond the end of the Florida peninsula. Work on the line started in 1905 and it operated from 1912 to 1935, when it was partially destroyed by the Labor Day Hurricane. The railroad was named for its designer, Henry Flagler, who designed the railroad system and the buildings on the line.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 120, "end": 151}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 2, "sentence_id": [2]}], "corrected-prediction": "The first road to Key West, known as the Overseas Railroad, was an extension of the Florida East Coast Railway. Construction started in 1905 and was completed in 1912."}, "preference": [1, 1, 1, 1, 1, 1], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Key West\nS1. The southernmost location that the public can visit is the beach at Fort Zachary Taylor park.\nS2. The actual southernmost point of the contiguous United States is Ballast Key, a privately owned island just south and west of Key West.\nS3. The claim \"90 Miles to Cuba\" on the monument is close to correct; Cuba at its closest point has been measured at from Key West.\nS4. Several U.S. presidents have visited Key West with the first being Ulysses S. Grant in 1880, followed by Grover Cleveland in 1889, and William Howard Taft in 1912.\nS5. Taft was the first president to use the first officer's quarters that would later be known as the Little White House.\nS6. Franklin D. Roosevelt visited the Florida Keys many times, beginning in 1917.\nS7. Harry S. Truman visited Key West for a total of 175 days on 11 visits during his presidency and visited five times after he left office.\nS8. His first visit was in 1946.\nS9. The Little White House and Truman Annex take their names from his frequent and well-documented visits.\nS10. The residence is also known as the Winter White House as Truman stayed there mostly in the winter months, and used it for official business such as the Truman Doctrine.\nS11. Dwight D. Eisenhower stayed at the Little White House following a heart attack in 1955.\nS12. John F. Kennedy visited Key West in March 1961, and in November 1962, a month after the resolution of the Cuban Missile Crisis.\n\nPassage 2: Title (S0) - Overseas Railroad\nS1. Overseas Railroad  The Overseas Railroad (also known as Florida Overseas Railroad, the Overseas Extension, and Flagler's Folly) was an extension of the Florida East Coast Railway to Key West, a city located 128 miles (204.8\u00a0km) beyond the end of the Florida peninsula.\nS2. Work on the line started in 1905 and it operated from 1912 to 1935, when it was partially destroyed by the Labor Day Hurricane.\nS3. Henry Flagler (1830\u20131913) was a principal in Rockefeller, Andrews & Flagler and later a founder of Standard Oil during the Gilded Age in the United States.\nS4. The wealthy man took an interest in Florida while seeking a warmer climate for his ailing first wife in the late 1870s.\nS5. Returning to Florida in 1881, he became the builder and developer of resort hotels and railroads along the east coast of Florida.\nS6. Beginning with St. Augustine, he moved progressively south.\nS7. Flagler helped develop Ormond Beach, Daytona Beach, and Palm Beach, and became known as the Father of Miami, Florida.\nS8. Flagler's rail network became known as the Florida East Coast Railway (FEC).\nS9. By 1904, the FEC had reached Homestead, south of Miami.\nS10. After the United States announced in 1905 the construction of the Panama Canal, Flagler became particularly interested in linking Key West to the mainland.\n    \nInput Question:\nWhen was the first road to key west built?\n\nCorrect Response:\nThe first road to key west started being built in 1905, and was finished in 1912.\n\nModel Prediction:\nThe first road to Key West was built in 1905. The Overseas Railroad was an extension of the Florida East Coast Railway. It was built from 1912 to 1935.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "The first road to Key West was built in 1905. The Overseas Railroad was an extension of the Florida East Coast Railway. [It was built from 1912 to 1935.]\n\nExplanation:\nThe phrase \"It was built from 1912 to 1935\" is incorrect and irrelevant. The road was built from 1905 and finished in 1912. The model seems to have confused the construction period with the operational period of the railway. The railway was in operation from 1912 to 1935, not built during this period. Thus, this phrase should be marked as \"Irrelevant\"."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The first road to Key West was built in 1905.\nS2. The Overseas Railroad was an extension of the Florida East Coast Railway.\nS3. It was built from 1912 to 1935.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "S3\n\nExplanation:\nThe phrase \"It was built from 1912 to 1935\" in sentence 3 is factually inconsistent with the passages. According to Passage 2, Sentence 2, the Overseas Railroad was built from 1905 and finished in 1912, not from 1912 to 1935. Thus, this sentence is marked as \"Inconsistent Fact\"."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 2, sentence 2 [Missing Answer]\n\nExplanation:\nThe model prediction does not mention the year the road to Key West was finished, which is 1912 according to Passage 2, sentence 2. This is a crucial part of the answer to the question, so it is marked as \"Missing Answer\"."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The first road to Key West, known as the Overseas Railroad, was an extension of the Florida East Coast Railway. Construction started in 1905 and was completed in 1912."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 46, "end": 119}, {"error type": "Wrong-Grounding", "explanation": "{\"passage_id\":2,\"sentence_id\":[2]}", "start": 127, "end": 132}], "missing-info": [], "corrected-prediction": "The first road to Key West was built in 1905 and it operated from 1912 to 1935."}}, {"question": "When does better call saul come out on netflix?", "passages": [["Better Call Saul", "AMC announced that \"Talking Saul\" would air after the second season \"Better Call Saul\" premiere on February 15, 2016, and again after the second-season finale on April 18, 2016.", "It returned following the season 3 premiere and finale.", "These episodes discuss season two of \"Better Call Saul\".", "These episodes discuss season three of \"Better Call Saul\".", "In December 2013, Netflix announced that the entire first season would be available for streaming in the U.S. after the airing of the first-season finale, and in Latin America and Europe each episode would be available a few days after the episode airs in the U.S. However, the first season was not released on Netflix in the U.S. until February 1, 2016.", "Netflix is the exclusive video-on-demand provider for the series and makes the content available in all its territories, except for Australia and New Zealand.", "In Australia, \"Better Call Saul\" premiered on the streaming service Stan on February 9, 2015, acting as the service's flagship program.", "In New Zealand, the show is exclusive to the New Zealand-based subscription video-on-demand service, Lightbox.", "The episodes were available for viewing within three days of broadcast in the U.S."], ["Better Call Saul", "In the United Kingdom and Ireland, the series was acquired by Netflix on December 16, 2013, and the first episode premiered on February 9, 2015, with the second episode released the following day.", "Every subsequent episode was released each week thereafter.", "In India, the series is broadcast on Colors Infinity within 24 hours of the U.S. broadcast.", "The series premiere drew in 4.4 million and 4 million in the 18\u201349 and 25\u201354 demographics, respectively, and received an overall viewership of 6.9 million.", "This was the record for the highest-rated scripted series premiere in basic cable history, until it was surpassed later the same year by another AMC series, \"Fear the Walking Dead\".", "\"Better Call Saul\" has received widespread critical acclaim.", "The first season of \"Better Call Saul\" received critical acclaim, particularly for its acting, writing, and directing with many critics calling it a worthy successor to \"Breaking Bad\".", "On Rotten Tomatoes, the first season has a rating of 98%, based on 62 reviews, with an average rating of 8.17/10.", "The site's critical consensus reads, \"\"Better Call Saul\" is a quirky, dark character study that manages to stand on its own without being overshadowed by the series that spawned it.\""], ["Better Call Saul (season 1)", "Better Call Saul (season 1)\n\n", "The first season of the American television drama series \"Better Call Saul\" premiered on February 8, 2015, and concluded on April 6, 2015.", "The ten-episode season was broadcast on Monday nights in the United States on AMC, excluding the pilot episode which aired on a Sunday.", "\"Better Call Saul\" is a spin-off of \"Breaking Bad\" created by Vince Gilligan and Peter Gould who also worked on \"Breaking Bad\".", "The first season mainly takes place in 2002, and features Bob Odenkirk reprising his role from \"Breaking Bad\" as James Morgan \"Jimmy\" McGill, a lawyer who later becomes known as Saul Goodman from the fourth season onwards.", "Jonathan Banks also reprises his role as Mike Ehrmantraut, a former Philadelphia police officer who works independently as a parking lot attendant, and later on a private investigator and \"cleaner\".", "By July 2013, the series had yet to be green-lighted.", "Netflix was one of many interested distributors, but ultimately a deal was made between AMC and \"Breaking Bad\" production company Sony Pictures Television.", "Gilligan and Gould serve as co-showrunners and Gilligan directed the pilot."]], "gold": "Better Call Saul is an American crime drama television series created by Vince Gilligan and Peter Gould. In December 2013, Netflix announced that the entire first season would be available for streaming in the U.S. after the airing of the first-season finale, and in Latin America and Europe each episode would be available a few days after the episode airs in the U.S. In the United Kingdom and Ireland, the first episode premiered on February 9, 2015, with the second episode released the following day. The first season was not released on Netflix in the U.S. until February 1, 2016.", "prediction 1": "Better Call Saul, an American television drama series created by Vince Gilligan and Peter Gould who also worked on Breaking Bad, first came out on Netflix on February 1, 2015. The first season premiered on February 8, 2015, and concluded on April 6, 2015. The second season was released the following day, with the final episode coming out on February 1, 2016.", "prediction 2": "Better Call Saul, an American television drama series, is a spin-off of the Breaking Bad television series and is based on the character Saul Goodman. The first season came out on Netflix in the United States on February 1, 2016, but was not released on Netflix in the United Kingdom and Ireland until February 1, 2016.", "prediction 3": "Better Call Saul, an American television drama series, is a spin-off of the television series Breaking Bad. The first season premiered on February 8, 2015, with the second episode released the following day. The third and final season premiered on April 6, 2015.", "prediction 4": "Better Call Saul is an American television series that is a spin-off of the popular television series Breaking Bad created by Vince Gilligan and Peter Gould, as well as a spin-off of the crime show Breaking Bad. The first season premiered on February 8, 2015, with the second episode released the following day. The second season was released on Netflix in the United States on February 1, 2016.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 256, "end": 360}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 1, "sentence_id": [5]}], "corrected-prediction": "Better Call Saul, an American television drama series created by Vince Gilligan and Peter Gould who also worked on Breaking Bad, first came out on Netflix in the United Kingdom and Ireland on February 9, 2015. The first season premiered on February 8, 2015, and concluded on April 6, 2015. The first season was not released on Netflix in the U.S. until February 1, 2016."}, "preference": [0, 1, 0, 1, 0, 2], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Better Call Saul\nS1. AMC announced that \"Talking Saul\" would air after the second season \"Better Call Saul\" premiere on February 15, 2016, and again after the second-season finale on April 18, 2016.\nS2. It returned following the season 3 premiere and finale.\nS3. These episodes discuss season two of \"Better Call Saul\".\nS4. These episodes discuss season three of \"Better Call Saul\".\nS5. In December 2013, Netflix announced that the entire first season would be available for streaming in the U.S. after the airing of the first-season finale, and in Latin America and Europe each episode would be available a few days after the episode airs in the U.S. However, the first season was not released on Netflix in the U.S. until February 1, 2016.\nS6. Netflix is the exclusive video-on-demand provider for the series and makes the content available in all its territories, except for Australia and New Zealand.\nS7. In Australia, \"Better Call Saul\" premiered on the streaming service Stan on February 9, 2015, acting as the service's flagship program.\nS8. In New Zealand, the show is exclusive to the New Zealand-based subscription video-on-demand service, Lightbox.\nS9. The episodes were available for viewing within three days of broadcast in the U.S.\n\nPassage 2: Title (S0) - Better Call Saul\nS1. In the United Kingdom and Ireland, the series was acquired by Netflix on December 16, 2013, and the first episode premiered on February 9, 2015, with the second episode released the following day.\nS2. Every subsequent episode was released each week thereafter.\nS3. In India, the series is broadcast on Colors Infinity within 24 hours of the U.S. broadcast.\nS4. The series premiere drew in 4.4 million and 4 million in the 18\u201349 and 25\u201354 demographics, respectively, and received an overall viewership of 6.9 million.\nS5. This was the record for the highest-rated scripted series premiere in basic cable history, until it was surpassed later the same year by another AMC series, \"Fear the Walking Dead\".\nS6. \"Better Call Saul\" has received widespread critical acclaim.\nS7. The first season of \"Better Call Saul\" received critical acclaim, particularly for its acting, writing, and directing with many critics calling it a worthy successor to \"Breaking Bad\".\nS8. On Rotten Tomatoes, the first season has a rating of 98%, based on 62 reviews, with an average rating of 8.17/10.\nS9. The site's critical consensus reads, \"\"Better Call Saul\" is a quirky, dark character study that manages to stand on its own without being overshadowed by the series that spawned it.\"\n\nPassage 3: Title (S0) - Better Call Saul (season 1)\nS1. Better Call Saul (season 1)  \nS2. The first season of the American television drama series \"Better Call Saul\" premiered on February 8, 2015, and concluded on April 6, 2015.\nS3. The ten-episode season was broadcast on Monday nights in the United States on AMC, excluding the pilot episode which aired on a Sunday.\nS4. \"Better Call Saul\" is a spin-off of \"Breaking Bad\" created by Vince Gilligan and Peter Gould who also worked on \"Breaking Bad\".\nS5. The first season mainly takes place in 2002, and features Bob Odenkirk reprising his role from \"Breaking Bad\" as James Morgan \"Jimmy\" McGill, a lawyer who later becomes known as Saul Goodman from the fourth season onwards.\nS6. Jonathan Banks also reprises his role as Mike Ehrmantraut, a former Philadelphia police officer who works independently as a parking lot attendant, and later on a private investigator and \"cleaner\".\nS7. By July 2013, the series had yet to be green-lighted.\nS8. Netflix was one of many interested distributors, but ultimately a deal was made between AMC and \"Breaking Bad\" production company Sony Pictures Television.\nS9. Gilligan and Gould serve as co-showrunners and Gilligan directed the pilot.\n    \nInput Question:\nWhen does better call saul come out on netflix?\n\nCorrect Response:\nBetter Call Saul is an American crime drama television series created by Vince Gilligan and Peter Gould. In December 2013, Netflix announced that the entire first season would be available for streaming in the U.S. after the airing of the first-season finale, and in Latin America and Europe each episode would be available a few days after the episode airs in the U.S. In the United Kingdom and Ireland, the first episode premiered on February 9, 2015, with the second episode released the following day. The first season was not released on Netflix in the U.S. until February 1, 2016.\n\nModel Prediction:\nBetter Call Saul, an American television drama series created by Vince Gilligan and Peter Gould who also worked on Breaking Bad, first came out on Netflix on February 1, 2015. The first season premiered on February 8, 2015, and concluded on April 6, 2015. The second season was released the following day, with the final episode coming out on February 1, 2016.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "Better Call Saul, an American television drama series created by Vince Gilligan and Peter Gould who also worked on Breaking Bad, first came out on Netflix on February 1, 2015. The first season premiered on February 8, 2015, and concluded on April 6, 2015. [The second season was released the following day, with the final episode coming out on February 1, 2016.]\n\nExplanation:\nThe information about the second season being released the following day and the final episode coming out on February 1, 2016 is irrelevant as it does not directly answer the question nor is it crucial auxiliary information. It is also not factually consistent with the passages."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. Better Call Saul, an American television drama series created by Vince Gilligan and Peter Gould who also worked on Breaking Bad, first came out on Netflix on February 1, 2015.\nS2. The first season premiered on February 8, 2015, and concluded on April 6, 2015.\nS3. The second season was released the following day, with the final episode coming out on February 1, 2016.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "Inconsistent or Unverifiable Sentences:\n1. S1\n2. S3\n\nExplanation:\n1. The first sentence is factually inconsistent with the passages. According to Passage 1, Sentence 5, the first season was not released on Netflix in the U.S. until February 1, 2016, not 2015 as stated in the model prediction.\n2. The third sentence is unverifiable as there is no information in the passages about the release date of the second season on Netflix."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 5 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Answer]\n\nExplanation:\n1. The model prediction is missing the information that the first season of Better Call Saul was not released on Netflix in the U.S. until February 1, 2016, which is found in Passage 1, Sentence 5.\n2. The model prediction also omits the information that in the United Kingdom and Ireland, the first episode premiered on Netflix on February 9, 2015, with the second episode released the following day. This information is found in Passage 2, Sentence 1."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "Better Call Saul, an American television drama series created by Vince Gilligan and Peter Gould who also worked on Breaking Bad, first came out on Netflix in the United Kingdom and Ireland on February 9, 2015. The first season premiered on February 8, 2015, and concluded on April 6, 2015. The first season was not released on Netflix in the U.S. until February 1, 2016."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 96, "end": 128}, {"error type": "Wrong-Grounding", "explanation": "{\"passage_id\":2,\"sentence_id\":[1]}", "start": 158, "end": 175}, {"error type": "Irrelevant", "explanation": "", "start": 176, "end": 255}, {"error type": "Irrelevant", "explanation": "", "start": 256, "end": 360}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 1, "sentence_id": [5]}], "corrected-prediction": "Better Call Saul, an American television drama series created by Vince Gilligan and Peter Gould, first came out on Netflix, in the United Kingdom and Ireland, on February 9, 2015, with the second episode released the following day.  In December 2013, Netflix announced that the entire first season would be available for streaming in the U.S. after the airing of the first-season finale, and in Latin America and Europe each episode would be available a few days after the episode airs in the U.S. However, the first season was not released on Netflix in the U.S. until February 1, 2016."}}, {"question": "When did twenty one pilots start the hiatus?", "passages": [["Twenty One Pilots", "The duo performed at several small venues they first played as a local band including The Basement, Newport Music Hall, and Express Live!, before ending their tour cycle with arena shows at Nationwide Arena and Value City Arena.", "In an interview with \"Alternative Press\" in November 2016, Twenty One Pilots stated that after their last show, they will be \"going dark\" to focus on new music.", "Joseph stated that he would like to focus on lyrical content of the music, and bring the music back to the \"authenticity, lyrics, delivery, and fearlessness of songwriting\" similar to that of the self-titled album.", "The band's last activity came in July 2017 in the form of posts on social media depicting an eye closing over lyrics from several of their songs.", "In March 2018, their song \"Hometown\" received a Gold certification from the RIAA, making \"Blurryface\" the first full-length album to have every track achieve at least gold status.", "In April 2018, a cryptic message was uncovered on the band's web store, which revealed a website.", "Fans began using the clues and found other sections of this site, hinting at the possibility of the band's return.", "There were multiple images uploaded to the website, including letters from a character named \"Clancy\"."], ["Twenty One Pilots", "In July 2018, Twenty One Pilots broke their year-long silence, first sending a cryptic email to fans and later posting a video to all social media platforms and updating their logo and branding.", "Tyler Joseph made his first media appearance in over a year for an interview with Zane Lowe of Beats 1 from his own home studio in Columbus, Ohio, in which he spoke about the band's year long hiatus, creating the new album, and battling against personal demons and insecurities.", "On July 11, 2018, the band released two new songs, \"Jumpsuit\" and \"Nico and the Niners\", as well as the music video for \"Jumpsuit\".", "They also made the announcement of their fifth studio album, \"Trench\", scheduled to be released on October 5, 2018, and a new world tour, titled \"The Bandito Tour\", starting October 16.", "Later, on July 26, 2018, the music video for \"Nico and the Niners\" was released.", "The song \"Levitate\" was subsequently released as the album's third single via Zane Lowe's Beats 1 show as the day's \"World Record\".", "The music video was also released, concluding the trilogy series."]], "gold": "Twenty One Pilots announced their hiatus in November 2016 during an interview with Alternative Press, stating that they will be \"going dark\" to focus on new music. The official beginning of the hiatus was in July 2017, when the band published posts on social media depicting an eye closing over lyrics from several of their songs. In July 2018, the band broke their year-long silence, first send a cryptic email to fans and later posting a video to all social media platforms and updating their logo and branding.", "prediction 1": "Twenty One Pilots started a yearlong hiatus on July 1, 2017 and officially began a new hiatus on July 3, 2018.", "prediction 2": "Twenty One Pilots started a year-long hiatus on August 1, 2017. The band's last activity came in July 2017 in the form of posts on social media depicting an eye closing over lyrics from several of their songs. In July 2018, the band broke their year-long silence, first sending a cryptic email to fans and later posting a video to all social media platforms and updating their logo and branding.", "prediction 3": "Twenty One Pilots started the hiatus in July 2018. The band first sent cryptic messages to fans in April 2018 and posted a video to all social media platforms in July 2018. During the hiatus, the band also made the announcement of their fifth studio album Trench, scheduled to be released on October 5, 2018.", "prediction 4": "Twenty One Pilots started their year-long hiatus on June 13, 2017 and ended it on July 11, 2018. On July 26, 2018, the band released their music video for \"Nico and the Niners\", and on July 11, 2018, they sent a cryptic email to fans and then posted a video to all social media platforms and updated their logo and branding. In November 2016, Twenty One Pilots stated that after their last show, they will be \"going dark\" to focus on new music.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 0, "end": 110}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 1, "sentence_id": [2]}], "corrected-prediction": "Twenty One Pilots announced their hiatus in November 2016, stating that they will be \"going dark\" to focus on new music. The band's last activity before the hiatus was in July 2017, when they published posts on social media depicting an eye closing over lyrics from several of their songs. They broke their year-long silence in July 2018, first sending a cryptic email to fans and later posting a video to all social media platforms and updating their logo and branding."}, "preference": [2, 0, 0, 1, 1, 0], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Twenty One Pilots\nS1. The duo performed at several small venues they first played as a local band including The Basement, Newport Music Hall, and Express Live!, before ending their tour cycle with arena shows at Nationwide Arena and Value City Arena.\nS2. In an interview with \"Alternative Press\" in November 2016, Twenty One Pilots stated that after their last show, they will be \"going dark\" to focus on new music.\nS3. Joseph stated that he would like to focus on lyrical content of the music, and bring the music back to the \"authenticity, lyrics, delivery, and fearlessness of songwriting\" similar to that of the self-titled album.\nS4. The band's last activity came in July 2017 in the form of posts on social media depicting an eye closing over lyrics from several of their songs.\nS5. In March 2018, their song \"Hometown\" received a Gold certification from the RIAA, making \"Blurryface\" the first full-length album to have every track achieve at least gold status.\nS6. In April 2018, a cryptic message was uncovered on the band's web store, which revealed a website.\nS7. Fans began using the clues and found other sections of this site, hinting at the possibility of the band's return.\nS8. There were multiple images uploaded to the website, including letters from a character named \"Clancy\".\n\nPassage 2: Title (S0) - Twenty One Pilots\nS1. In July 2018, Twenty One Pilots broke their year-long silence, first sending a cryptic email to fans and later posting a video to all social media platforms and updating their logo and branding.\nS2. Tyler Joseph made his first media appearance in over a year for an interview with Zane Lowe of Beats 1 from his own home studio in Columbus, Ohio, in which he spoke about the band's year long hiatus, creating the new album, and battling against personal demons and insecurities.\nS3. On July 11, 2018, the band released two new songs, \"Jumpsuit\" and \"Nico and the Niners\", as well as the music video for \"Jumpsuit\".\nS4. They also made the announcement of their fifth studio album, \"Trench\", scheduled to be released on October 5, 2018, and a new world tour, titled \"The Bandito Tour\", starting October 16.\nS5. Later, on July 26, 2018, the music video for \"Nico and the Niners\" was released.\nS6. The song \"Levitate\" was subsequently released as the album's third single via Zane Lowe's Beats 1 show as the day's \"World Record\".\nS7. The music video was also released, concluding the trilogy series.\n    \nInput Question:\nWhen did twenty one pilots start the hiatus?\n\nCorrect Response:\nTwenty One Pilots announced their hiatus in November 2016 during an interview with Alternative Press, stating that they will be \"going dark\" to focus on new music. The official beginning of the hiatus was in July 2017, when the band published posts on social media depicting an eye closing over lyrics from several of their songs. In July 2018, the band broke their year-long silence, first send a cryptic email to fans and later posting a video to all social media platforms and updating their logo and branding.\n\nModel Prediction:\nTwenty One Pilots started a yearlong hiatus on July 1, 2017 and officially began a new hiatus on July 3, 2018.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "[Twenty One Pilots started a yearlong hiatus on July 1, 2017 and officially began a new hiatus on July 3, 2018.]\n\nExplanation:\nThe entire model prediction is irrelevant because it does not provide the correct information about when Twenty One Pilots started their hiatus. The band announced their hiatus in November 2016 and officially began it in July 2017. There is no mention of a new hiatus starting on July 3, 2018 in the provided passages. Therefore, the entire model prediction is marked as irrelevant."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. Twenty One Pilots started a yearlong hiatus on July 1, 2017 and officially began a new hiatus on July 3, 2018.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "S1\n\nExplanation:\nThe model prediction states that Twenty One Pilots started a yearlong hiatus on July 1, 2017 and officially began a new hiatus on July 3, 2018. However, this information is not consistent with the passages. According to Passage 1, sentence 2, Twenty One Pilots announced their hiatus in November 2016. The band's last activity before the hiatus was in July 2017, as stated in Passage 1, sentence 4. There is no mention of a new hiatus beginning on July 3, 2018 in the provided passages. Therefore, the entire sentence is marked as \"Inconsistent Fact\"."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 2 [Missing Answer]\n2. Passage 1, sentence 4 [Missing Answer]\n3. Passage 2, sentence 1 [Missing Major Auxiliary Information]\n\nExplanation:\n1. The model prediction does not mention that Twenty One Pilots announced their hiatus in November 2016, which is a direct answer to the question and can be found in Passage 1, sentence 2.\n2. The model prediction also does not mention that the band's last activity before the hiatus was in July 2017, which is another direct answer to the question and can be found in Passage 1, sentence 4.\n3. The model prediction does not include the information that the band broke their year-long silence in July 2018, which is a major auxiliary information that helps to understand the timeline of the hiatus. This information can be found in Passage 2, sentence 1."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "Twenty One Pilots announced their hiatus in November 2016, stating that they will be \"going dark\" to focus on new music. The band's last activity before the hiatus was in July 2017, when they published posts on social media depicting an eye closing over lyrics from several of their songs. They broke their year-long silence in July 2018, first sending a cryptic email to fans and later posting a video to all social media platforms and updating their logo and branding."}], "feedback_human": {"errors": [{"error type": "Wrong-Grounding", "explanation": "{\"passage_id\":2,\"sentence_id\":[1]}", "start": 64, "end": 104}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 1, "sentence_id": [2]}, {"error type": "Missing-Minor-Auxiliary", "passage_id": 1, "sentence_id": [4]}], "corrected-prediction": "In an interview with \"Alternative Press\" in November 2016, Twenty One Pilots stated that after their last show, they will be \"going dark\" to focus on new music. Twenty One Pilots started a yearlong hiatus on July 1, 2017 with posts on social media depicting an eye closing over lyrics from several of their songs. They broke their year-long silence, first sending a cryptic email to fans and later posting a video to all social media platforms and updating their logo and branding, in July 2018."}}, {"question": "Who plays the main girl in phantom of the opera?", "passages": [["The Phantom of the Opera", "In Paris in the 1880s, the Palais Garnier opera house is believed to be haunted by an entity known as the Phantom of the Opera, or simply the Opera Ghost.", "A stagehand named Joseph Buquet is found hanged and the rope around his neck goes missing.", "At a gala performance for the retirement of the opera house's two managers, a young little-known Swedish soprano, Christine Daa\u00e9, is called upon to sing in the place of the Opera's leading soprano, Carlotta, who is ill, and her performance is an astonishing success.", "The Vicomte Raoul de Chagny, who was present at the performance, recognizes her as his childhood playmate and recalls his love for her.", "He attempts to visit her backstage, where he hears a man complimenting her from inside her dressing room.", "He investigates the room once Christine leaves, only to find it empty.", "At Perros-Guirec, Christine meets with Raoul, who confronts her about the voice he heard in her room.", "Christine tells him she has been tutored by the Angel of Music, whom her father used to tell them about.", "When Raoul suggests that she might be the victim of a prank, she storms off.", "Christine visits her father's grave one night, where a mysterious figure appears and plays the violin for her.", "Raoul attempts to confront it but is attacked and knocked out in the process."]], "gold": "Christine Daa\u00e9, a young, little-known Swedish soprano in Phantom of the Opera, has been played by multiple actresses. In the original West End Cast, she was played by: Sarah Brightman, Claire Moore. In the original Broadway Cast, she was played by: Sarah Brightman, Patti Cohenour. In the original US Tour Cast, she was played by: Dale Kristien, Mary D'Arcy.", "prediction 1": "The Phantom of the Opera, sometimes called the Opera Ghost, is believed to be haunted by an entity known as Carlotta. Swedish soprano Christine Daa\u00e9 plays the main girl in Phantom of the Opera.", "prediction 2": "The Palais Garnier opera house is believed to be haunted by an entity known as the Phantom of the Opera, or simply the Opera Ghost. At a gala performance for the retirement of the opera house's two managers, a young little-known Swedish soprano, Christine Daa\u00e9, is called upon to sing in the place of the Opera's leading soprano, Carlotta, who is ill, and her performance is an astonishing success. The Vicomte Raoul de Chagny, who was present at the performance, recognizes Christine as his childhood playmate and recalls his love for her. He attempts to visit her backstage, but Christine leaves empty.", "prediction 3": "In The Phantom of the Opera, the main girl is played by Christine Daa\u00e9.", "prediction 4": "In The Phantom of the Opera, the main girl is played by Christine Daa\u00e9, a Swedish soprano.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 0, "end": 117}, {"error type": "Unverifiable", "start": 0, "end": 117}], "missing-info": [], "corrected-prediction": "In Phantom of the Opera, the main girl is played by the character Christine Daa\u00e9, a young, little-known Swedish soprano."}, "preference": [2, 1, 1, 1, 1, 0], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - The Phantom of the Opera\nS1. In Paris in the 1880s, the Palais Garnier opera house is believed to be haunted by an entity known as the Phantom of the Opera, or simply the Opera Ghost.\nS2. A stagehand named Joseph Buquet is found hanged and the rope around his neck goes missing.\nS3. At a gala performance for the retirement of the opera house's two managers, a young little-known Swedish soprano, Christine Daa\u00e9, is called upon to sing in the place of the Opera's leading soprano, Carlotta, who is ill, and her performance is an astonishing success.\nS4. The Vicomte Raoul de Chagny, who was present at the performance, recognizes her as his childhood playmate and recalls his love for her.\nS5. He attempts to visit her backstage, where he hears a man complimenting her from inside her dressing room.\nS6. He investigates the room once Christine leaves, only to find it empty.\nS7. At Perros-Guirec, Christine meets with Raoul, who confronts her about the voice he heard in her room.\nS8. Christine tells him she has been tutored by the Angel of Music, whom her father used to tell them about.\nS9. When Raoul suggests that she might be the victim of a prank, she storms off.\nS10. Christine visits her father's grave one night, where a mysterious figure appears and plays the violin for her.\nS11. Raoul attempts to confront it but is attacked and knocked out in the process.\n    \nInput Question:\nWho plays the main girl in phantom of the opera?\n\nCorrect Response:\nChristine Daa\u00e9, a young, little-known Swedish soprano in Phantom of the Opera, has been played by multiple actresses. In the original West End Cast, she was played by: Sarah Brightman, Claire Moore. In the original Broadway Cast, she was played by: Sarah Brightman, Patti Cohenour. In the original US Tour Cast, she was played by: Dale Kristien, Mary D'Arcy.\n\nModel Prediction:\nThe Phantom of the Opera, sometimes called the Opera Ghost, is believed to be haunted by an entity known as Carlotta. Swedish soprano Christine Daa\u00e9 plays the main girl in Phantom of the Opera.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "[The Phantom of the Opera, sometimes called the Opera Ghost, is believed to be haunted by an entity known as Carlotta.] Swedish soprano Christine Daa\u00e9 plays the main girl in Phantom of the Opera.\n\nExplanation:\n1. The first sentence in the model prediction is irrelevant as it does not provide an answer or crucial auxiliary information to the question. The information about the Opera Ghost and Carlotta is not necessary to answer the question about who plays the main girl in Phantom of the Opera."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The Phantom of the Opera, sometimes called the Opera Ghost, is believed to be haunted by an entity known as Carlotta.\nS2. Swedish soprano Christine Daa\u00e9 plays the main girl in Phantom of the Opera.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "1. S1\n\nExplanation:\n1. The first sentence is factually inconsistent with the passages. According to Passage 1, sentence 1, the Opera Ghost is known as the Phantom of the Opera, not Carlotta. Carlotta is mentioned as the Opera's leading soprano who is ill, not as the entity haunting the opera house."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. N/A\n\nExplanation:\n1. The model prediction does not miss any information that is expected in an ideal response. The passages do not provide any information about who played Christine Daa\u00e9 in different productions of Phantom of the Opera, which is included in the reference response but not in the passages. Therefore, this information is not expected in the model prediction."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "In Phantom of the Opera, the main girl is played by the character Christine Daa\u00e9, a young, little-known Swedish soprano."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 0, "end": 117}], "missing-info": [{"error type": "Missing-Minor-Auxiliary", "passage_id": 1, "sentence_id": [3]}], "corrected-prediction": "a young little-known Swedish soprano, Christine Daa\u00e9, is called upon to sing in the place of the Opera's leading soprano. "}}, {"question": "When were the common core state standards developed?", "passages": [["Common Core State Standards Initiative", "Common Core State Standards Initiative\n\nThe Common Core State Standards Initiative is an educational initiative from 2010 that details what K\u201312 students throughout the United States should know in English language arts and mathematics at the conclusion of each school grade.", "The initiative is sponsored by the National Governors Association (NGA) and the Council of Chief State School Officers (CCSSO) and seeks to establish consistent educational standards across the states as well as ensure that students graduating from high school are prepared to enter credit-bearing courses at two- or four-year college programs or to enter the workforce.", "In the 1990s, a movement for establishing national standards and accountability began in the United States as states began writing standards (a) outlining what students were expected to know and to be able to do at each grade level, and (b) implementing assessments designed to measure whether students were meeting the standards.", "As part of this education reform movement, the nation's governors and corporate leaders founded Achieve, Inc. in 1996 as a bipartisan organization to raise academic standards and graduation requirements, improve assessments, and strengthen accountability in all 50 states.", "The initial motivation for the development of the Common Core State Standards (CCSS) was part of the American Diploma Project (ADP)."], ["Common Core State Standards Initiative", "A 2004 report, titled \"Ready or Not: Creating a High School Diploma That Counts\", found that employers and colleges are demanding more of high school graduates than in the past.", "According to Achieve, Inc., \"current high-school exit expectations fall well short of employer and college demands.\"", "The report explained that the major problem currently facing the American school system is that high school graduates were not provided with the skills and knowledge they needed to succeed in college and careers.", "Furthermore, \"While students and their parents may still believe that the diploma reflects adequate preparation for the intellectual demands of adult life, in reality it falls far short of this common-sense goal.\"", "The report also stated that the high school diploma itself lost its value because graduates could not compete successfully beyond high school, and that the solution to this problem is a common set of rigorous standards.", "In 2009, the NGA convened a group of people to work on developing the standards.", "This team included David Coleman, William McCallum of the University of Arizona, Phil Daro, and Student Achievement Partners founders Jason Zimba and Susan Pimentel to write standards in the areas of English and language arts.", "Announced on June 1, 2009, the initiative's stated purpose is to \"provide a consistent, clear understanding of what students are expected to learn, so teachers and parents know what they need to do to help them.\""], ["Common Core State Standards Initiative", "Instead, it was indicated that the ELPD standards would be left to individual states.", "However, the need for more guidance quickly became apparent, and led to the creation of several initiatives to provide resources to states and educators, including:\nFurthermore, the U.S. Department of Education has since funded two grants to develop the next generation of ELPD assessments, which must measure students\u2019 proficiency against a set of common ELPD standards, which in turn correspond to the college/career-ready standards in English language arts and mathematics.", "The new assessment system must also:\n\n\nSince 2010, forty-two (42) of the fifty U.S. states and the District of Columbia have been members of the Common Core State Standards Initiative, while Oklahoma, Texas, Virginia, Alaska, Nebraska, Indiana, and South Carolina did not adopt the initiative at a state level.", "Minnesota adopted the English Language Arts standards but not the Mathematics standards.", "Although starting as a fast trend, the curriculum lost momentum and found at least 12 states introducing legislation to prohibit implementation.", "Four states that initially adopted Common Core have since decided to repeal or replace it: Indiana, Arizona, Oklahoma, and South Carolina.", "Standards were released for mathematics and English language arts on June 2, 2010, with a majority of states adopting the standards in the subsequent months.", "(See map for current status.)"]], "gold": "The Common Core State Standards Initiative is an educational initiative from 2010 that details what K\u201312 students throughout the United States should know in English language arts and mathematics at the conclusion of each school grade. Announced on June 1, 2009, the initiative's stated purpose is to \"provide a consistent, clear understanding of what students are expected to learn, so teachers and parents know what they need to do to help them.\" Standards were released for mathematics and English language arts on June 2, 2010, with a majority of states adopting the standards in the subsequent months.", "prediction 1": "The Common Core State Standards are an educational initiative that details what K\u201312 students throughout the United States should know in English language arts and mathematics at the conclusion of each school grade. In 2009, the NGA convened a group of people to work on developing the standards, which included David Coleman, William McCallum of the University of Arizona, Phil Daro, and Student Achievement Partners founders Jason Zimba and Susan Pimentel to write standards in the areas of English and language arts. The standards were released for mathematics on June 2, 2010, with a majority of states adopting the initiative in the subsequent months.", "prediction 2": "The Common Core State Standards Initiative is an educational initiative from 2010 that details what K\u201312 students throughout the United States should know in English language arts and mathematics at the conclusion of each school grade. The standards were announced on June 1, 2009, by the National Governors Association and the Council of Chief State School Officers.", "prediction 3": "The Common Core State Standards Initiative is a national initiative that details what K\u201312 students throughout the United States should know in English language arts and mathematics at the conclusion of each school grade. The Common Core State Standards Initiative was announced on June 1, 2009 by the National Governors Association. The standards were released for English language arts and mathematics on June 2, 2010, with a majority of states adopting the standards in the subsequent months.", "prediction 4": "The Common Core State Standards Initiative is an educational initiative from 2010 that details what K\u201312 students throughout the United States should know in English language arts and mathematics at the conclusion of each school grade. The initiative is sponsored by the National Governors Association and the Council of Chief State School Officers and seeks to establish consistent educational standards across the states as well as ensure that students graduating from high school are prepared to enter credit-bearing courses at two- or four-year college programs or to enter the workforce. On June 2, 2010, the English and mathematics standards were released on June 2, 2010.", "feedback": {"errors": [], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [1]}], "corrected-prediction": "The Common Core State Standards Initiative, an educational initiative from 2010, details what K\u201312 students throughout the United States should know in English language arts and mathematics at the conclusion of each school grade. In 2009, the NGA convened a group of people, including David Coleman, William McCallum of the University of Arizona, Phil Daro, and Student Achievement Partners founders Jason Zimba and Susan Pimentel, to work on developing the standards in the areas of English and language arts. The initiative was announced on June 1, 2009, and the standards were released for mathematics and English language arts on June 2, 2010, with a majority of states adopting the initiative in the subsequent months."}, "preference": [1, 1, 1, 2, 2, 2], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Common Core State Standards Initiative\nS1. Common Core State Standards Initiative  The Common Core State Standards Initiative is an educational initiative from 2010 that details what K\u201312 students throughout the United States should know in English language arts and mathematics at the conclusion of each school grade.\nS2. The initiative is sponsored by the National Governors Association (NGA) and the Council of Chief State School Officers (CCSSO) and seeks to establish consistent educational standards across the states as well as ensure that students graduating from high school are prepared to enter credit-bearing courses at two- or four-year college programs or to enter the workforce.\nS3. In the 1990s, a movement for establishing national standards and accountability began in the United States as states began writing standards (a) outlining what students were expected to know and to be able to do at each grade level, and (b) implementing assessments designed to measure whether students were meeting the standards.\nS4. As part of this education reform movement, the nation's governors and corporate leaders founded Achieve, Inc. in 1996 as a bipartisan organization to raise academic standards and graduation requirements, improve assessments, and strengthen accountability in all 50 states.\nS5. The initial motivation for the development of the Common Core State Standards (CCSS) was part of the American Diploma Project (ADP).\n\nPassage 2: Title (S0) - Common Core State Standards Initiative\nS1. A 2004 report, titled \"Ready or Not: Creating a High School Diploma That Counts\", found that employers and colleges are demanding more of high school graduates than in the past.\nS2. According to Achieve, Inc., \"current high-school exit expectations fall well short of employer and college demands.\"\nS3. The report explained that the major problem currently facing the American school system is that high school graduates were not provided with the skills and knowledge they needed to succeed in college and careers.\nS4. Furthermore, \"While students and their parents may still believe that the diploma reflects adequate preparation for the intellectual demands of adult life, in reality it falls far short of this common-sense goal.\"\nS5. The report also stated that the high school diploma itself lost its value because graduates could not compete successfully beyond high school, and that the solution to this problem is a common set of rigorous standards.\nS6. In 2009, the NGA convened a group of people to work on developing the standards.\nS7. This team included David Coleman, William McCallum of the University of Arizona, Phil Daro, and Student Achievement Partners founders Jason Zimba and Susan Pimentel to write standards in the areas of English and language arts.\nS8. Announced on June 1, 2009, the initiative's stated purpose is to \"provide a consistent, clear understanding of what students are expected to learn, so teachers and parents know what they need to do to help them.\"\n\nPassage 3: Title (S0) - Common Core State Standards Initiative\nS1. Instead, it was indicated that the ELPD standards would be left to individual states.\nS2. However, the need for more guidance quickly became apparent, and led to the creation of several initiatives to provide resources to states and educators, including: Furthermore, the U.S. Department of Education has since funded two grants to develop the next generation of ELPD assessments, which must measure students\u2019 proficiency against a set of common ELPD standards, which in turn correspond to the college/career-ready standards in English language arts and mathematics.\nS3. The new assessment system must also:   Since 2010, forty-two (42) of the fifty U.S. states and the District of Columbia have been members of the Common Core State Standards Initiative, while Oklahoma, Texas, Virginia, Alaska, Nebraska, Indiana, and South Carolina did not adopt the initiative at a state level.\nS4. Minnesota adopted the English Language Arts standards but not the Mathematics standards.\nS5. Although starting as a fast trend, the curriculum lost momentum and found at least 12 states introducing legislation to prohibit implementation.\nS6. Four states that initially adopted Common Core have since decided to repeal or replace it: Indiana, Arizona, Oklahoma, and South Carolina.\nS7. Standards were released for mathematics and English language arts on June 2, 2010, with a majority of states adopting the standards in the subsequent months.\nS8. (See map for current status.)\n    \nInput Question:\nWhen were the common core state standards developed?\n\nCorrect Response:\nThe Common Core State Standards Initiative is an educational initiative from 2010 that details what K\u201312 students throughout the United States should know in English language arts and mathematics at the conclusion of each school grade. Announced on June 1, 2009, the initiative's stated purpose is to \"provide a consistent, clear understanding of what students are expected to learn, so teachers and parents know what they need to do to help them.\" Standards were released for mathematics and English language arts on June 2, 2010, with a majority of states adopting the standards in the subsequent months.\n\nModel Prediction:\nThe Common Core State Standards are an educational initiative that details what K\u201312 students throughout the United States should know in English language arts and mathematics at the conclusion of each school grade. In 2009, the NGA convened a group of people to work on developing the standards, which included David Coleman, William McCallum of the University of Arizona, Phil Daro, and Student Achievement Partners founders Jason Zimba and Susan Pimentel to write standards in the areas of English and language arts. The standards were released for mathematics on June 2, 2010, with a majority of states adopting the initiative in the subsequent months.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "The Common Core State Standards are an educational initiative that details what K\u201312 students throughout the United States should know in English language arts and mathematics at the conclusion of each school grade. In 2009, the NGA convened a group of people to work on developing the standards, which included David Coleman, William McCallum of the University of Arizona, Phil Daro, and Student Achievement Partners founders Jason Zimba and Susan Pimentel to write standards in the areas of English and language arts. The standards were released for mathematics on June 2, 2010, with a majority of states adopting the initiative in the subsequent months.\n\nExplanation:\nThere are no irrelevant, incoherent, or repetitive spans in the model prediction. The information provided is relevant to the question, coherent with the context, and there is no repetition of information."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The Common Core State Standards are an educational initiative that details what K\u201312 students throughout the United States should know in English language arts and mathematics at the conclusion of each school grade.\nS2. In 2009, the NGA convened a group of people to work on developing the standards, which included David Coleman, William McCallum of the University of Arizona, Phil Daro, and Student Achievement Partners founders Jason Zimba and Susan Pimentel to write standards in the areas of English and language arts.\nS3. The standards were released for mathematics on June 2, 2010, with a majority of states adopting the initiative in the subsequent months.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "Inconsistent or Unverifiable Sentences:\nNone\n\nExplanation:\nAll the facts presented in the model prediction are consistent with the information provided in the passages and can be verified from the passages."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 1 [Missing Major Auxiliary Information]\n2. Passage 2, sentence 8 [Missing Major Auxiliary Information]\n\nExplanation:\n1. The model prediction does not mention that the Common Core State Standards Initiative is from 2010, which is a crucial piece of information to answer the question about when the standards were developed.\n2. The model prediction does not include the information from Passage 2, sentence 8, which states that the initiative was announced on June 1, 2009. This is a significant detail that provides context to the development timeline of the standards."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The Common Core State Standards Initiative, an educational initiative from 2010, details what K\u201312 students throughout the United States should know in English language arts and mathematics at the conclusion of each school grade. In 2009, the NGA convened a group of people, including David Coleman, William McCallum of the University of Arizona, Phil Daro, and Student Achievement Partners founders Jason Zimba and Susan Pimentel, to work on developing the standards in the areas of English and language arts. The initiative was announced on June 1, 2009, and the standards were released for mathematics and English language arts on June 2, 2010, with a majority of states adopting the initiative in the subsequent months."}], "feedback_human": {"errors": [], "missing-info": [{"error type": "Missing-Answer", "passage_id": 1, "sentence_id": [1]}, {"error type": "Missing-Major-Auxiliary", "passage_id": 2, "sentence_id": [8]}], "corrected-prediction": "The Common Core State Standards are an educational initiative from 2010 that details what K\u201312 students throughout the United States should know in English language arts and mathematics at the conclusion of each school grade. Announced on June 1, 2009, the initiative's stated purpose is to \"provide a consistent, clear understanding of what students are expected to learn, so teachers and parents know what they need to do to help them.\" The standards were released for mathematics on June 2, 2010, with a majority of states adopting the initiative in the subsequent months."}}, {"question": "When does how to get away with a murderer air season 4?", "passages": [["How to Get Away with Murder (season 4)", "How to Get Away with Murder (season 4)\n\n", "The fourth season of the ABC American television drama series \"How to Get Away with Murder\" was ordered on February 10, 2017, by ABC.", "It began airing on September 28, 2017, with 15 episodes like the previous seasons and concluded on March 15, 2018.", "This was made in a deal with Viola Davis that the series would be a limited series with only 15 or 16 episodes per season.", "Annalise (Viola Davis) and the Keating Four are still dealing with the aftermath of Wes's (Alfred Enoch) death.", "Annalise works with a therapist, Dr. Issac Roa, to see through her recovery from alcoholism, and cuts ties with her associates.", "In the mean time, Connor (Jack Falahee) declines Oliver's (Conrad Ricamora) proposal, Laurel (Karla Souza) expects Wes's baby, Michaela (Aja Naomi King) and Asher (Matt McGorry) team up for internships, and Bonnie (Liza Weil) seeks her professional future.", "Meanwhile, Laurel has deduced that her father, Jorge Castillo (Esai Morales), is responsible for Wes's murder and hatches a scheme to steal incriminating evidence with Michaela, Oliver, and a reluctant Frank and Asher."]], "gold": "The fourth season of the ABC American television drama series How to Get Away with Murder was ordered on February 10, 2017, by ABC. It began airing on September 28, 2017, with 15 episodes like the previous seasons. It aired from September 28, 2017 - March 15, 2018.", "prediction 1": "How to Get Away with Murder's fourth season premiered on September 28, 2017, and concluded on March 15, 2018.\n", "prediction 2": "How to Get Away with Murder, an ABC American crime drama series, began airing its fourth season on September 28, 2017, and concluded on March 15, 2018.", "prediction 3": "The fourth season of the ABC American television drama series How to Get Away with Murder was ordered on February 10, 2017, by ABC. It began airing on September 28, 2017, with 15 episodes like the previous seasons and concluded on March 15, 2018.", "prediction 4": "How to Get Away with Murder aired its fourth season on ABC on September 28, 2017, and ended March 15, 2018.", "feedback": {"errors": [], "missing-info": [{"error type": "Missing-Minor-Auxiliary", "passage_id": 1, "sentence_id": [2]}], "corrected-prediction": "The fourth season of How to Get Away with Murder was ordered on February 10, 2017, by ABC. It premiered on September 28, 2017, and concluded on March 15, 2018."}, "preference": [1, 1, 0, 1, 2, 2], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - How to Get Away with Murder (season 4)\nS1. How to Get Away with Murder (season 4)  \nS2. The fourth season of the ABC American television drama series \"How to Get Away with Murder\" was ordered on February 10, 2017, by ABC.\nS3. It began airing on September 28, 2017, with 15 episodes like the previous seasons and concluded on March 15, 2018.\nS4. This was made in a deal with Viola Davis that the series would be a limited series with only 15 or 16 episodes per season.\nS5. Annalise (Viola Davis) and the Keating Four are still dealing with the aftermath of Wes's (Alfred Enoch) death.\nS6. Annalise works with a therapist, Dr. Issac Roa, to see through her recovery from alcoholism, and cuts ties with her associates.\nS7. In the mean time, Connor (Jack Falahee) declines Oliver's (Conrad Ricamora) proposal, Laurel (Karla Souza) expects Wes's baby, Michaela (Aja Naomi King) and Asher (Matt McGorry) team up for internships, and Bonnie (Liza Weil) seeks her professional future.\nS8. Meanwhile, Laurel has deduced that her father, Jorge Castillo (Esai Morales), is responsible for Wes's murder and hatches a scheme to steal incriminating evidence with Michaela, Oliver, and a reluctant Frank and Asher.\n    \nInput Question:\nWhen does how to get away with a murderer air season 4?\n\nCorrect Response:\nThe fourth season of the ABC American television drama series How to Get Away with Murder was ordered on February 10, 2017, by ABC. It began airing on September 28, 2017, with 15 episodes like the previous seasons. It aired from September 28, 2017 - March 15, 2018.\n\nModel Prediction:\nHow to Get Away with Murder's fourth season premiered on September 28, 2017, and concluded on March 15, 2018.\n\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "How to Get Away with Murder's fourth season premiered on September 28, 2017, and concluded on March 15, 2018.\n\nExplanation: There are no irrelevant, incoherent, or repetitive spans in the model prediction. The information provided is relevant to the question, coherent, and not repetitive."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. How to Get Away with Murder's fourth season premiered on September 28, 2017, and concluded on March 15, 2018.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation: The model prediction does not contain any inconsistent or unverifiable facts. The dates provided for the premiere and conclusion of the fourth season of \"How to Get Away with Murder\" are accurate and can be verified from the passages."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 2 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. The model prediction does not include the information that the fourth season was ordered on February 10, 2017, by ABC. This is a minor auxiliary information that provides additional context to the answer but its absence does not hinder the understanding of the main answer."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The fourth season of How to Get Away with Murder was ordered on February 10, 2017, by ABC. It premiered on September 28, 2017, and concluded on March 15, 2018."}], "feedback_human": {"errors": [], "missing-info": [{"error type": "Missing-Minor-Auxiliary", "passage_id": 1, "sentence_id": [2]}], "corrected-prediction": "How to Get Away with Murder's fourth season was ordered on February 10, 2017, by ABC and premiered on September 28, 2017, and concluded on March 15, 2018.\n"}}, {"question": "Where is diamonds are a girl best friend from?", "passages": [["Gentlemen Prefer Blondes (1953 film)", "Gentlemen Prefer Blondes (1953 film)\n\n", "Gentlemen Prefer Blondes is a 1953 American musical comedy film based on the 1949 stage musical of the same name.", "It was directed by Howard Hawks and stars Jane Russell and Marilyn Monroe, with Charles Coburn, Elliott Reid, Tommy Noonan, George Winslow, Taylor Holmes, and Norma Varden in supporting roles.", "The film is filled with comedic gags and musical numbers, choreographed by Jack Cole, while the music was written by Hoagy Carmichael, Harold Adamson, Jule Styne, and Leo Robin.", "The songs by Styne and Robin are from the Broadway show, while the songs by Carmichael and Adamson were written especially for the film.", "Depsite the film's title, Monroe was paid her usual contract salary of $500 a week, while Russell, the more known and experienced actress of the two, earned $200,000.", "While Russell's down-to-earth, sharp wit has been noted by most critics, it was Monroe's turn as the gold-digging Lorelei Lee for which the film is often remembered."], ["Diamonds Are a Girl's Best Friend", "Diamonds Are a Girl's Best Friend\n\n\"Diamonds Are a Girl's Best Friend\" is a jazz song introduced by Carol Channing in the original Broadway production of \"Gentlemen Prefer Blondes\" (1949), which was written by Jule Styne and Leo Robin.", "It was based on a novel by Anita Loos.", "The song is perhaps most famously performed by Marilyn Monroe in the 1953 film \"Gentlemen Prefer Blondes\".", "Monroe's character, Lorelei Lee, has been followed on a Transatlantic ocean liner by a detective hired by her fianc\u00e9's father, who wants assurance that she is not marrying purely for money.", "He is informed of compromising pictures taken with a British diamond mine owner and cancels her letter of credit before she arrives in France, requiring her to work in a nightclub to survive.", "Her fianc\u00e9 arrives at the cabaret to see her perform this song, about exploiting men for riches.", "Diamonds are an element in another story line in the film, in which Lorelei is given a diamond tiara by the mine owner, in gratitude for her recovering the photographs.", "In a later scene, Jane Russell, who played opposite Monroe, sang \"Diamonds Are a Girl's Best Friend\" in court, while pretending to be Lorelei."], ["Diamonds Are a Girl's Best Friend", "\", in which it is sung principally by Nicole Kidman in the role of Satine, the (fictional) star performer of the famous Moulin Rouge nightclub in Paris, at the turn of the 20th century.", "This film version is technically a musical adaptation that director Baz Luhrmann titled \"Sparkling Diamonds\".", "Although it consists almost entirely of an adaptation of \"Diamonds Are a Girl's Best Friend\", this version differs from the lyrics in \"Gentlemen Prefer Blondes\" in several ways.", "For example, it does not include the name Harry Winston in the chant of famous jewelers; rather, Moulin Rouge founder Charles Zidler's name was changed to Harold in the film, so his name replaces Winston's in the song as \"Harry Zidler\".", "Black Starr & Frost-Gorham was known by that name only after 1925, but instead of using their 1875-1925 name of \"Black Starr & Frost\", their name was replaced in the Luhrmann film by nonsense words (understood by many listeners as \"Ross Cole;\" in the 2002 DVD release, the words printed in the text captioning are \"Black Star, Roscor\").", "And the potentially anachronistic line \"help you at the Automat\" was altered in the Luhrmann film to \"help you feed your pussycat.\""]], "gold": "\"Diamonds Are a Girl's Best Friend\" is a jazz song introduced by Carol Channing in the original Broadway production of Gentlemen Prefer Blondes in 1949.  An adaptation of the play was made into a musical comedy film with the same name. Actresses Marilyn Monroe and Jane Russell each sing the song at different times in the film. An adaptation of the song entitled, \"Sparkling Diamonds,\" was sung by Nicole Kidman's character, Satine, in the 2001 film, Moulin Rouge.", "prediction 1": "\"Diamonds Are a Girl's Best Friend\" is a jazz song introduced by Carol Channing in the original Broadway production of Gentlemen Prefer Blondes, which was written by Jule Styne and Leo Robin. It was based on a novel by Anita Loos. The 1953 American musical comedy film Gentlemen Prefer Blondes was filmed in the same location as the 1949 stage musical of the same name.", "prediction 2": "Diamonds Are a Girl's Best Friend is a jazz song introduced by Carol Channing in the original Broadway production of Gentlemen Prefer Blondes, which was written by Jule Styne and Leo Robin. It was based on a novel by Anita Loos. This 1953 American musical comedy film is filled with comedic gags and musical numbers, choreographed by Jack Cole, while the music is written by Hoagy Carmichael, Harold Adamson, Jule Styne and Leo Robin. The song is a jazz song from Gentlemen Prefer Blondes, which is a musical adaptation of Diamonds Are a Girl's Best Friend, which is s Are a Girl's Best Friend.", "prediction 3": "Diamonds Are a Girl's Best Friend is a jazz song introduced by Carol Channing in the original Broadway production of Gentlemen Prefer Blondes, which was written by Jule Styne and Leo Robin, and was based on a novel by Anita Loos. It is perhaps most famously performed by Marilyn Monroe in the 1953 American musical comedy film Gentlemen Prefer Blondes. The film version of the song is technically a musical adaptation that director Baz Luhrmann titled Sparkling Diamonds.", "prediction 4": "\"Diamonds Are a Girl's Best Friend\" is a jazz song introduced by Carol Channing in the original Broadway production of Gentlemen Prefer Blondes (1949), which was written by Jule Styne and Leo Robin. It was based on a novel by Anita Loos. It is in the 1953 American musical comedy film Gentlemen Prefer Blondes titled Sparkling Diamonds.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 192, "end": 369}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 2, "sentence_id": [3]}], "corrected-prediction": "\"Diamonds Are a Girl's Best Friend\" is a jazz song introduced by Carol Channing in the original Broadway production of Gentlemen Prefer Blondes, which was written by Jule Styne and Leo Robin. The song was famously performed by Marilyn Monroe in the 1953 film adaptation of \"Gentlemen Prefer Blondes\". Jane Russell, who played opposite Monroe, also sang \"Diamonds Are a Girl's Best Friend\" in the film. An adaptation of the song, titled \"Sparkling Diamonds,\" was performed by Nicole Kidman in the 2001 film, Moulin Rouge."}, "preference": [1, 1, 1, 2, 2, 2], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Gentlemen Prefer Blondes (1953 film)\nS1. Gentlemen Prefer Blondes (1953 film)  \nS2. Gentlemen Prefer Blondes is a 1953 American musical comedy film based on the 1949 stage musical of the same name.\nS3. It was directed by Howard Hawks and stars Jane Russell and Marilyn Monroe, with Charles Coburn, Elliott Reid, Tommy Noonan, George Winslow, Taylor Holmes, and Norma Varden in supporting roles.\nS4. The film is filled with comedic gags and musical numbers, choreographed by Jack Cole, while the music was written by Hoagy Carmichael, Harold Adamson, Jule Styne, and Leo Robin.\nS5. The songs by Styne and Robin are from the Broadway show, while the songs by Carmichael and Adamson were written especially for the film.\nS6. Depsite the film's title, Monroe was paid her usual contract salary of $500 a week, while Russell, the more known and experienced actress of the two, earned $200,000.\nS7. While Russell's down-to-earth, sharp wit has been noted by most critics, it was Monroe's turn as the gold-digging Lorelei Lee for which the film is often remembered.\n\nPassage 2: Title (S0) - Diamonds Are a Girl's Best Friend\nS1. Diamonds Are a Girl's Best Friend  \"Diamonds Are a Girl's Best Friend\" is a jazz song introduced by Carol Channing in the original Broadway production of \"Gentlemen Prefer Blondes\" (1949), which was written by Jule Styne and Leo Robin.\nS2. It was based on a novel by Anita Loos.\nS3. The song is perhaps most famously performed by Marilyn Monroe in the 1953 film \"Gentlemen Prefer Blondes\".\nS4. Monroe's character, Lorelei Lee, has been followed on a Transatlantic ocean liner by a detective hired by her fianc\u00e9's father, who wants assurance that she is not marrying purely for money.\nS5. He is informed of compromising pictures taken with a British diamond mine owner and cancels her letter of credit before she arrives in France, requiring her to work in a nightclub to survive.\nS6. Her fianc\u00e9 arrives at the cabaret to see her perform this song, about exploiting men for riches.\nS7. Diamonds are an element in another story line in the film, in which Lorelei is given a diamond tiara by the mine owner, in gratitude for her recovering the photographs.\nS8. In a later scene, Jane Russell, who played opposite Monroe, sang \"Diamonds Are a Girl's Best Friend\" in court, while pretending to be Lorelei.\n\nPassage 3: Title (S0) - Diamonds Are a Girl's Best Friend\nS1. \", in which it is sung principally by Nicole Kidman in the role of Satine, the (fictional) star performer of the famous Moulin Rouge nightclub in Paris, at the turn of the 20th century.\nS2. This film version is technically a musical adaptation that director Baz Luhrmann titled \"Sparkling Diamonds\".\nS3. Although it consists almost entirely of an adaptation of \"Diamonds Are a Girl's Best Friend\", this version differs from the lyrics in \"Gentlemen Prefer Blondes\" in several ways.\nS4. For example, it does not include the name Harry Winston in the chant of famous jewelers; rather, Moulin Rouge founder Charles Zidler's name was changed to Harold in the film, so his name replaces Winston's in the song as \"Harry Zidler\".\nS5. Black Starr & Frost-Gorham was known by that name only after 1925, but instead of using their 1875-1925 name of \"Black Starr & Frost\", their name was replaced in the Luhrmann film by nonsense words (understood by many listeners as \"Ross Cole;\" in the 2002 DVD release, the words printed in the text captioning are \"Black Star, Roscor\").\nS6. And the potentially anachronistic line \"help you at the Automat\" was altered in the Luhrmann film to \"help you feed your pussycat.\"\n    \nInput Question:\nWhere is diamonds are a girl best friend from?\n\nCorrect Response:\n\"Diamonds Are a Girl's Best Friend\" is a jazz song introduced by Carol Channing in the original Broadway production of Gentlemen Prefer Blondes in 1949.  An adaptation of the play was made into a musical comedy film with the same name. Actresses Marilyn Monroe and Jane Russell each sing the song at different times in the film. An adaptation of the song entitled, \"Sparkling Diamonds,\" was sung by Nicole Kidman's character, Satine, in the 2001 film, Moulin Rouge.\n\nModel Prediction:\n\"Diamonds Are a Girl's Best Friend\" is a jazz song introduced by Carol Channing in the original Broadway production of Gentlemen Prefer Blondes, which was written by Jule Styne and Leo Robin. It was based on a novel by Anita Loos. The 1953 American musical comedy film Gentlemen Prefer Blondes was filmed in the same location as the 1949 stage musical of the same name.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "\"Diamonds Are a Girl's Best Friend\" is a jazz song introduced by Carol Channing in the original Broadway production of Gentlemen Prefer Blondes, which was written by Jule Styne and Leo Robin. It was based on a novel by Anita Loos. The 1953 American musical comedy film Gentlemen Prefer Blondes was filmed in the same location as the 1949 stage musical of the same name. [It was based on a novel by Anita Loos. The 1953 American musical comedy film Gentlemen Prefer Blondes was filmed in the same location as the 1949 stage musical of the same name.]\n\nExplanation:\n1. The information about the song being based on a novel by Anita Loos is irrelevant to the question asked, as it does not provide any information about where the song \"Diamonds Are a Girl's Best Friend\" is from. \n2. The information about the 1953 film Gentlemen Prefer Blondes being filmed in the same location as the 1949 stage musical is also irrelevant, as it does not provide any information about where the song is from."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. \"Diamonds Are a Girl's Best Friend\" is a jazz song introduced by Carol Channing in the original Broadway production of Gentlemen Prefer Blondes, which was written by Jule Styne and Leo Robin.\nS2. It was based on a novel by Anita Loos.\nS3. The 1953 American musical comedy film Gentlemen Prefer Blondes was filmed in the same location as the 1949 stage musical of the same name.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation:\nAll the facts in the model prediction are consistent with the passages and can be verified."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 2, sentence 3 [Missing Major Auxiliary Information]\n2. Passage 2, sentence 8 [Missing Major Auxiliary Information]\n3. Passage 3, sentence 1 [Missing Major Auxiliary Information]\n\nExplanation:\n1. The model prediction does not mention that the song \"Diamonds Are a Girl's Best Friend\" was famously performed by Marilyn Monroe in the 1953 film \"Gentlemen Prefer Blondes\". This is a major piece of auxiliary information that helps to answer the question of where the song is from.\n2. The model prediction also misses the information that Jane Russell, who played opposite Monroe, sang \"Diamonds Are a Girl's Best Friend\" in court, while pretending to be Lorelei in the same film.\n3. The model prediction does not mention the adaptation of the song, \"Sparkling Diamonds,\" sung by Nicole Kidman's character, Satine, in the 2001 film, Moulin Rouge. This is also a major piece of auxiliary information that helps to answer the question of where the song is from."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "\"Diamonds Are a Girl's Best Friend\" is a jazz song introduced by Carol Channing in the original Broadway production of Gentlemen Prefer Blondes, which was written by Jule Styne and Leo Robin. The song was famously performed by Marilyn Monroe in the 1953 film adaptation of \"Gentlemen Prefer Blondes\". Jane Russell, who played opposite Monroe, also sang \"Diamonds Are a Girl's Best Friend\" in the film. An adaptation of the song, titled \"Sparkling Diamonds,\" was performed by Nicole Kidman in the 2001 film, Moulin Rouge."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 145, "end": 191}, {"error type": "Unverifiable", "explanation": "", "start": 231, "end": 369}], "missing-info": [{"error type": "Missing-Minor-Auxiliary", "passage_id": 2, "sentence_id": [1]}, {"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [2]}, {"error type": "Missing-Major-Auxiliary", "passage_id": 2, "sentence_id": [3]}, {"error type": "Missing-Major-Auxiliary", "passage_id": 2, "sentence_id": [8]}, {"error type": "Missing-Major-Auxiliary", "passage_id": 3, "sentence_id": [1]}, {"error type": "Missing-Major-Auxiliary", "passage_id": 3, "sentence_id": [2]}], "corrected-prediction": "\"Diamonds Are a Girl's Best Friend\" is a jazz song introduced by Carol Channing in the original Broadway production of Gentlemen Prefer Blondes in 1949. Gentlemen Prefer Blondes is a 1953 American musical comedy film based on the 1949 stage musical of the same name. Actresses Marilyn Monroe and Jane Russell each sing the song at different times in the film. An adaptation of the song entitled, \"Sparkling Diamonds,\" was sung by Nicole Kidman's character, Satine, in the film, Moulin Rouge."}}, {"question": "Where do the sacramento kings play at home?", "passages": [["Sacramento Kings", "Sacramento Kings\n\nThe Sacramento Kings are an American professional basketball team based in Sacramento, California.", "The Kings compete in the National Basketball Association (NBA) as a member of the Western Conference's Pacific Division.", "The Kings are the only team in the major professional North American sports leagues located in Sacramento.", "The team plays its home games at the Golden 1 Center.", "The Kings are one of the oldest continuously operating professional basketball franchises in the nation.", "They originated in Rochester, New York, as the Rochester Seagrams (a semi-professional team) in 1923 and joined the National Basketball League in 1945 as the Rochester Royals.", "They jumped to the Basketball Association of America, forerunner of the NBA, in 1948.", "As the Royals, the team was often successful on the court, winning the NBA championship in 1951.", "The team, however, found it increasingly difficult to turn a profit in the comparatively small market of Rochester and relocated to Cincinnati in , becoming the Cincinnati Royals.", "In the team relocated to Kansas City, Missouri, and was renamed the Kansas City-Omaha Kings because it initially split its home games between Kansas City and Omaha, Nebraska.", "In , the Kings ceased playing home games in Omaha and simply became the Kansas City Kings.", "The team again failed to find success in its market and moved to Sacramento in .", "The Royals defected to the NBL's rival, the Basketball Association of America, in 1948."], ["Sacramento Kings", "On May 9, 2016, the Kings hired former Memphis Grizzlies coach Dave Joerger as head coach.", "During the 2016 NBA draft, the Kings traded the 8th pick to the Phoenix Suns for the 13th and 28th pick in the draft, as well as the rights to Serbian guard Bogdan Bogdanovi\u0107.", "Later in the evening, the Kings traded Marco Belinelli to the Charlotte Hornets in exchange for the 22nd pick in the draft.", "The Kings selected four players in the 2016 NBA draft \u2013 Greek center Georgios Papagiannis with the 13th pick, Syracuse shooting guard Malachi Richardson with the 22nd pick, Kentucky forward Skal Labissiere with the 28th pick, and Oklahoma guard Isaiah Cousins with the 59th pick.", "In free agency, the Kings signed Anthony Tolliver, Garrett Temple, Arron Afflalo, Matt Barnes, and Ty Lawson.", "On February 20, 2017, the Kings traded DeMarcus Cousins, alongside Omri Casspi to the New Orleans Pelicans for Tyreke Evans, Buddy Hield, Langston Galloway and two future draft picks.", "The initial Rochester Royals logo featured a blue and white shield with the word \"ROCHESTER\" on the top, with a white banner with the word \"ROYALS\" on it.", "From the beginning the road uniforms were blue with the city name written in front, while home uniforms were white with the team name written in front."], ["Sleep Train Arena", "Sleep Train Arena\n\nSleep Train Arena, originally ARCO Arena and later Power Balance Pavilion, is a defunct indoor arena located in Sacramento, California, United States.", "Opened in 1988, it was the home of the Sacramento Kings of the National Basketball Association (NBA) from 1988 to 2016.", "It hosted nearly 200 spectator events each year.", "The arena is named for The Sleep Train, a chain of mattress and bed retailers based in Rocklin that at the time of the agreement was a subsidiary of Mattress Firm, a Houston-based retailer that has since re-branded all Sleep Train stores as Mattress Firm.", "The original ARCO Arena (1985\u20131988), where the Kings played their home games for three seasons (1985 to 1988), after moving from Kansas City had a capacity of 10,333 seats.", "This arena was also the home for the Sacramento Attack of the Arena Football League in 1992 in their only season and the WNBA's Sacramento Monarchs until they folded in 2009.", "Sleep Train Arena is located in a once isolated area on the expanding northern outskirts of the city.", "It was constructed at a cost of just $40 million, the lowest of any venue in the NBA.", "It is the smallest arena in the NBA with a seating capacity of 17,317, and has 30 luxury suites and 412 club seats.", "It can host such varied events as concerts, ice shows, rodeos and monster truck rallies."]], "gold": "From 1988-2016, the Sacramento Kings played their home games at the Sleep Train Arena, formerly ARCO Arena II/Power Balance Pavilion. Since 2016, the Kings play their home games at the Golden 1 Center, in Sacramento, California. ", "prediction 1": "The Sacramento Kings are an American professional basketball team based in Sacramento, California. The team plays its home games at the Golden 1 Center. Sleep Train Arena was the home of the Sacramento Kings from 1988 to 2016.", "prediction 2": "The Sacramento Kings are an American professional basketball team based in Sacramento, California. The Kings play their home games at the Golden 1 Center. The Kings were first introduced to the NBA as the Rochester Royals in 1923. As the Royals, the team found it increasingly difficult to turn a profit in the comparatively small market of Rochester and relocated to Cincinnati in 1945. In the following years, the team relocated to Kansas City, Missouri, where they were renamed the Kansas City-Omaha Kings. In 1988, the Sacramento Kings played at the Sleep Train Arena.", "prediction 3": "The Sacramento Kings are an American professional basketball team based in Sacramento, California. The Kings compete in the National Basketball Association (NBA) as a member of the Western Conference's Pacific Division. The Kings play their home games at the Golden 1 Center. The Kings originated in Rochester, New York, as the Rochester Seagrams (a semi-professional team) in 1923, and joined the National Basketball League in 1945 as the Rochester Royals. They jumped to the Basketball Association of America, forerunner to the NBA, in 1948.", "prediction 4": "The Sacramento Kings are an American professional basketball team based in Sacramento, California. The team plays its home games at the Golden 1 Center. The Kings originated in Rochester, New York, as the Rochester Seagrams (a semi- professional team) in 1923. They jumped to the NBA in 1948 as the Rochester Royals. The Kings played their home games in the ARCO Arena from 1985 to 1988, which was a defunct indoor arena located in Sacramento, California.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 0, "end": 98}], "missing-info": [], "corrected-prediction": "The team plays its home games at the Golden 1 Center. Sleep Train Arena was the home of the Sacramento Kings from 1988 to 2016."}, "preference": [1, 1, 1, 1, 1, 2], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Sacramento Kings\nS1. Sacramento Kings  The Sacramento Kings are an American professional basketball team based in Sacramento, California.\nS2. The Kings compete in the National Basketball Association (NBA) as a member of the Western Conference's Pacific Division.\nS3. The Kings are the only team in the major professional North American sports leagues located in Sacramento.\nS4. The team plays its home games at the Golden 1 Center.\nS5. The Kings are one of the oldest continuously operating professional basketball franchises in the nation.\nS6. They originated in Rochester, New York, as the Rochester Seagrams (a semi-professional team) in 1923 and joined the National Basketball League in 1945 as the Rochester Royals.\nS7. They jumped to the Basketball Association of America, forerunner of the NBA, in 1948.\nS8. As the Royals, the team was often successful on the court, winning the NBA championship in 1951.\nS9. The team, however, found it increasingly difficult to turn a profit in the comparatively small market of Rochester and relocated to Cincinnati in , becoming the Cincinnati Royals.\nS10. In the team relocated to Kansas City, Missouri, and was renamed the Kansas City-Omaha Kings because it initially split its home games between Kansas City and Omaha, Nebraska.\nS11. In , the Kings ceased playing home games in Omaha and simply became the Kansas City Kings.\nS12. The team again failed to find success in its market and moved to Sacramento in .\nS13. The Royals defected to the NBL's rival, the Basketball Association of America, in 1948.\n\nPassage 2: Title (S0) - Sacramento Kings\nS1. On May 9, 2016, the Kings hired former Memphis Grizzlies coach Dave Joerger as head coach.\nS2. During the 2016 NBA draft, the Kings traded the 8th pick to the Phoenix Suns for the 13th and 28th pick in the draft, as well as the rights to Serbian guard Bogdan Bogdanovi\u0107.\nS3. Later in the evening, the Kings traded Marco Belinelli to the Charlotte Hornets in exchange for the 22nd pick in the draft.\nS4. The Kings selected four players in the 2016 NBA draft \u2013 Greek center Georgios Papagiannis with the 13th pick, Syracuse shooting guard Malachi Richardson with the 22nd pick, Kentucky forward Skal Labissiere with the 28th pick, and Oklahoma guard Isaiah Cousins with the 59th pick.\nS5. In free agency, the Kings signed Anthony Tolliver, Garrett Temple, Arron Afflalo, Matt Barnes, and Ty Lawson.\nS6. On February 20, 2017, the Kings traded DeMarcus Cousins, alongside Omri Casspi to the New Orleans Pelicans for Tyreke Evans, Buddy Hield, Langston Galloway and two future draft picks.\nS7. The initial Rochester Royals logo featured a blue and white shield with the word \"ROCHESTER\" on the top, with a white banner with the word \"ROYALS\" on it.\nS8. From the beginning the road uniforms were blue with the city name written in front, while home uniforms were white with the team name written in front.\n\nPassage 3: Title (S0) - Sleep Train Arena\nS1. Sleep Train Arena  Sleep Train Arena, originally ARCO Arena and later Power Balance Pavilion, is a defunct indoor arena located in Sacramento, California, United States.\nS2. Opened in 1988, it was the home of the Sacramento Kings of the National Basketball Association (NBA) from 1988 to 2016.\nS3. It hosted nearly 200 spectator events each year.\nS4. The arena is named for The Sleep Train, a chain of mattress and bed retailers based in Rocklin that at the time of the agreement was a subsidiary of Mattress Firm, a Houston-based retailer that has since re-branded all Sleep Train stores as Mattress Firm.\nS5. The original ARCO Arena (1985\u20131988), where the Kings played their home games for three seasons (1985 to 1988), after moving from Kansas City had a capacity of 10,333 seats.\nS6. This arena was also the home for the Sacramento Attack of the Arena Football League in 1992 in their only season and the WNBA's Sacramento Monarchs until they folded in 2009.\nS7. Sleep Train Arena is located in a once isolated area on the expanding northern outskirts of the city.\nS8. It was constructed at a cost of just $40 million, the lowest of any venue in the NBA.\nS9. It is the smallest arena in the NBA with a seating capacity of 17,317, and has 30 luxury suites and 412 club seats.\nS10. It can host such varied events as concerts, ice shows, rodeos and monster truck rallies.\n    \nInput Question:\nWhere do the sacramento kings play at home?\n\nCorrect Response:\nFrom 1988-2016, the Sacramento Kings played their home games at the Sleep Train Arena, formerly ARCO Arena II/Power Balance Pavilion. Since 2016, the Kings play their home games at the Golden 1 Center, in Sacramento, California. \n\nModel Prediction:\nThe Sacramento Kings are an American professional basketball team based in Sacramento, California. The team plays its home games at the Golden 1 Center. Sleep Train Arena was the home of the Sacramento Kings from 1988 to 2016.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "[The Sacramento Kings are an American professional basketball team based in Sacramento, California.]\n\nExplanation:\nThe first sentence in the model prediction is irrelevant as it does not provide a direct answer to the question nor does it provide crucial auxiliary information. The question asks about the home location of the Sacramento Kings, not about the team's origin or base."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The Sacramento Kings are an American professional basketball team based in Sacramento, California.\nS2. The team plays its home games at the Golden 1 Center.\nS3. Sleep Train Arena was the home of the Sacramento Kings from 1988 to 2016.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation:\nAll the facts in the model prediction are consistent with the information provided in the passages."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "None\n\nExplanation:\nThe model prediction includes all the necessary information to answer the question. It correctly identifies both the current and former home locations of the Sacramento Kings, which are the Golden 1 Center and the Sleep Train Arena, respectively."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The team plays its home games at the Golden 1 Center. Sleep Train Arena was the home of the Sacramento Kings from 1988 to 2016."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 0, "end": 98}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 3, "sentence_id": [1]}], "corrected-prediction": "The team plays its home games at the Golden 1 Center. Sleep Train Arena was the home of the Sacramento Kings from 1988 to 2016 and was formerly known as ARCO Arena and later Power Balance Pavilion."}}, {"question": "Where did the formula for area of a circle come from?", "passages": [["Area of a circle", "Area of a circle\n\nIn geometry, the area enclosed by a circle of radius is .", "Here the Greek letter represents a constant, approximately equal to 3.14159, which is equal to the ratio of the circumference of any circle to its diameter.", "One method of deriving this formula, which originated with Archimedes, involves viewing the circle as the limit of a sequence of regular polygons.", "The area of a regular polygon is half its perimeter multiplied by the distance from its center to its sides, and the corresponding formula (that the area is half the perimeter times the radius, i.e. ) holds in the limit for a circle.", "Although often referred to as the area of a circle in informal contexts, strictly speaking the term \"disk\" refers to the interior of the circle, while \"circle\" is reserved for the boundary only, which is a curve and covers no area itself.", "Therefore, the area of a disk is the more precise phrase for the area enclosed by a circle.", "Modern mathematics can obtain the area using the methods of integral calculus or its more sophisticated offspring, real analysis.", "However the area of a disk was studied by the Ancient Greeks.", "Eudoxus of Cnidus in the fifth century B.C. had found that the area of a disk is proportional to its radius squared."], ["Area", "The mathematician Archimedes used the tools of Euclidean geometry to show that the area inside a circle is equal to that of a right triangle whose base has the length of the circle's circumference and whose height equals the circle's radius, in his book \"Measurement of a Circle\".", "(The circumference is 2\"r\", and the area of a triangle is half the base times the height, yielding the area \"r\" for the disk.)", "Archimedes approximated the value of \u03c0 (and hence the area of a unit-radius circle) with his doubling method, in which he inscribed a regular triangle in a circle and noted its area, then doubled the number of sides to give a regular hexagon, then repeatedly doubled the number of sides as the polygon's area got closer and closer to that of the circle (and did the same with circumscribed polygons).", "Swiss scientist Johann Heinrich Lambert in 1761 proved that \u03c0, the ratio of a circle's area to its squared radius, is irrational, meaning it is not equal to the quotient of any two whole numbers.", "In 1794 French mathematician Adrien-Marie Legendre proved that \u03c0 is irrational; this also proves that \u03c0 is irrational."], ["Area of a circle", "The area of a regular polygon is half its perimeter times the apothem.", "As the number of sides of the regular polygon increases, the polygon tends to a circle, and the apothem tends to the radius.", "This suggests that the area of a disk is half the circumference of its bounding circle times the radius.", "Following Archimedes' argument in \"The Measurement of a Circle\" (c. 260 BCE), compare the area enclosed by a circle to a right triangle whose base has the length of the circle's circumference and whose height equals the circle's radius.", "If the area of the circle is not equal to that of the triangle, then it must be either greater or less.", "We eliminate each of these by contradiction, leaving equality as the only possibility.", "We use regular polygons in the same way.", "Suppose that the area \"C\" enclosed by the circle is greater than the area \"T\"\u00a0= \u2044\"cr\" of the triangle.", "Let \"E\" denote the excess amount.", "Inscribe a square in the circle, so that its four corners lie on the circle.", "Between the square and the circle are four segments.", "If the total area of those gaps, \"G\", is greater than \"E\", split each arc in half."]], "gold": "In geometry, the area enclosed by a circle of radius r is \u03c0r2, where the Greek letter \u03c0 represents the constant ratio of the circumference of any circle to its diameter, approximately equal to 3.1416. One method of deriving this formula, which originated with Archimedes, involves viewing the circle as the limit of a sequence of regular polygons, where the area of a regular polygon is half its perimeter multiplied by the distance from its center to its sides, and the corresponding formula\u2013that the area is half the perimeter times the radius\u2013namely, A = 1/2 \u00d7 2\u03c0r \u00d7 r, holds in the limit for a circle. Archimedes showed the work for the formula for area of a circle in his book, The Measurement of a Circle.", "prediction 1": "The area of a circle is the area of a regular polygon, divided by the circumference of the circle and divided by its radius. One method of deriving this formula, which originated with Archimedes, involves viewing the circle as the limit of a sequence of regular polygons. The area of a regular polygon is half its perimeter multiplied by the distance from its center to its sides, and the corresponding formula (that the area is half the perimeter times the radius, i.e. ) holds in the limit for a circle.", "prediction 2": "The formula for the area of a circle come from Archimedes, who used the tools of Euclidean geometry to show that the area inside a circle is equal to that of a right triangle whose base has the length of the circle's circumference and whose height equals the circle's radius in his book Measurement of a Circle. Archimedes approximated the value of  with his doubling method, in which he inscribed a regular triangle in a circle and noted its area, then doubled the number of sides to give a regular hexagon, then repeatedly doubled the number of sides as the polygon's area got closer and closer to that of the circle.", "prediction 3": "In geometry, the area enclosed by a circle of radius is. One method of deriving this formula, which originated with Archimedes, involves viewing the circle as the limit of a sequence of regular polygons. The area of a regular polygon is half its perimeter multiplied by the distance from its center to its sides, and the corresponding formula (that the area is half the perimeter times the radius, i.e. ) holds in the limit for a circle.", "prediction 4": "Archimedes used the tools of Euclidean geometry to show that the area inside a circle is equal to that of a right triangle whose base has the length of the circle's circumference and whose height equals the circle's radius, in his book Measurement of a Circle. However, the mathematician approximated the value of  with his doubling method in which he inscribed a regular triangle in a circle and noted its area, then doubled the number of sides to give a regular hexagon, then repeatedly doubled the number of sides as the polygon's area got closer and closer to that of the circle.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 0, "end": 124}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 1, "sentence_id": [1]}], "corrected-prediction": "The formula for the area of a circle, which is \u03c0r^2, originated with Archimedes. In this formula, the Greek letter \u03c0 represents a constant approximately equal to 3.14159, which is the ratio of the circumference of any circle to its diameter. Archimedes derived this formula by viewing the circle as the limit of a sequence of regular polygons. The area of a regular polygon is half its perimeter multiplied by the distance from its center to its sides, and the corresponding formula (that the area is half the perimeter times the radius) holds in the limit for a circle. Archimedes detailed this work in his book, The Measurement of a Circle."}, "preference": [2, 0, 2, 1, 0, 2], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Area of a circle\nS1. Area of a circle  In geometry, the area enclosed by a circle of radius is .\nS2. Here the Greek letter represents a constant, approximately equal to 3.14159, which is equal to the ratio of the circumference of any circle to its diameter.\nS3. One method of deriving this formula, which originated with Archimedes, involves viewing the circle as the limit of a sequence of regular polygons.\nS4. The area of a regular polygon is half its perimeter multiplied by the distance from its center to its sides, and the corresponding formula (that the area is half the perimeter times the radius, i.e. ) holds in the limit for a circle.\nS5. Although often referred to as the area of a circle in informal contexts, strictly speaking the term \"disk\" refers to the interior of the circle, while \"circle\" is reserved for the boundary only, which is a curve and covers no area itself.\nS6. Therefore, the area of a disk is the more precise phrase for the area enclosed by a circle.\nS7. Modern mathematics can obtain the area using the methods of integral calculus or its more sophisticated offspring, real analysis.\nS8. However the area of a disk was studied by the Ancient Greeks.\nS9. Eudoxus of Cnidus in the fifth century B.C. had found that the area of a disk is proportional to its radius squared.\n\nPassage 2: Title (S0) - Area\nS1. The mathematician Archimedes used the tools of Euclidean geometry to show that the area inside a circle is equal to that of a right triangle whose base has the length of the circle's circumference and whose height equals the circle's radius, in his book \"Measurement of a Circle\".\nS2. (The circumference is 2\"r\", and the area of a triangle is half the base times the height, yielding the area \"r\" for the disk.)\nS3. Archimedes approximated the value of \u03c0 (and hence the area of a unit-radius circle) with his doubling method, in which he inscribed a regular triangle in a circle and noted its area, then doubled the number of sides to give a regular hexagon, then repeatedly doubled the number of sides as the polygon's area got closer and closer to that of the circle (and did the same with circumscribed polygons).\nS4. Swiss scientist Johann Heinrich Lambert in 1761 proved that \u03c0, the ratio of a circle's area to its squared radius, is irrational, meaning it is not equal to the quotient of any two whole numbers.\nS5. In 1794 French mathematician Adrien-Marie Legendre proved that \u03c0 is irrational; this also proves that \u03c0 is irrational.\n\nPassage 3: Title (S0) - Area of a circle\nS1. The area of a regular polygon is half its perimeter times the apothem.\nS2. As the number of sides of the regular polygon increases, the polygon tends to a circle, and the apothem tends to the radius.\nS3. This suggests that the area of a disk is half the circumference of its bounding circle times the radius.\nS4. Following Archimedes' argument in \"The Measurement of a Circle\" (c. 260 BCE), compare the area enclosed by a circle to a right triangle whose base has the length of the circle's circumference and whose height equals the circle's radius.\nS5. If the area of the circle is not equal to that of the triangle, then it must be either greater or less.\nS6. We eliminate each of these by contradiction, leaving equality as the only possibility.\nS7. We use regular polygons in the same way.\nS8. Suppose that the area \"C\" enclosed by the circle is greater than the area \"T\"\u00a0= \u2044\"cr\" of the triangle.\nS9. Let \"E\" denote the excess amount.\nS10. Inscribe a square in the circle, so that its four corners lie on the circle.\nS11. Between the square and the circle are four segments.\nS12. If the total area of those gaps, \"G\", is greater than \"E\", split each arc in half.\n    \nInput Question:\nWhere did the formula for area of a circle come from?\n\nCorrect Response:\nIn geometry, the area enclosed by a circle of radius r is \u03c0r2, where the Greek letter \u03c0 represents the constant ratio of the circumference of any circle to its diameter, approximately equal to 3.1416. One method of deriving this formula, which originated with Archimedes, involves viewing the circle as the limit of a sequence of regular polygons, where the area of a regular polygon is half its perimeter multiplied by the distance from its center to its sides, and the corresponding formula\u2013that the area is half the perimeter times the radius\u2013namely, A = 1/2 \u00d7 2\u03c0r \u00d7 r, holds in the limit for a circle. Archimedes showed the work for the formula for area of a circle in his book, The Measurement of a Circle.\n\nModel Prediction:\nThe area of a circle is the area of a regular polygon, divided by the circumference of the circle and divided by its radius. One method of deriving this formula, which originated with Archimedes, involves viewing the circle as the limit of a sequence of regular polygons. The area of a regular polygon is half its perimeter multiplied by the distance from its center to its sides, and the corresponding formula (that the area is half the perimeter times the radius, i.e. ) holds in the limit for a circle.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "[The area of a circle is the area of a regular polygon, divided by the circumference of the circle and divided by its radius.] One method of deriving this formula, which originated with Archimedes, involves viewing the circle as the limit of a sequence of regular polygons. The area of a regular polygon is half its perimeter multiplied by the distance from its center to its sides, and the corresponding formula (that the area is half the perimeter times the radius, i.e. ) holds in the limit for a circle.\n\nExplanation:\n1. The first sentence in the model prediction is factually incorrect and does not provide relevant information to the question. The area of a circle is not calculated by dividing the area of a regular polygon by the circumference of the circle and its radius. Therefore, it should be marked as \"Irrelevant\"."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The area of a circle is the area of a regular polygon, divided by the circumference of the circle and divided by its radius.\nS2. One method of deriving this formula, which originated with Archimedes, involves viewing the circle as the limit of a sequence of regular polygons.\nS3. The area of a regular polygon is half its perimeter multiplied by the distance from its center to its sides, and the corresponding formula (that the area is half the perimeter times the radius, i.e. )\nS4. holds in the limit for a circle.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "Inconsistent or Unverifiable Sentences:\n1. S1\n\nExplanation:\n1. The first sentence is factually inconsistent with the passages. The area of a circle is not calculated by dividing the area of a regular polygon by the circumference of the circle and its radius. This information is not found in any of the provided passages."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 1 [Missing Answer]\n2. Passage 1, sentence 2 [Missing Major Auxiliary Information]\n3. Passage 2, sentence 1 [Missing Major Auxiliary Information]\n\nExplanation:\n1. The model prediction does not mention the formula for the area of a circle, which is \u03c0r^2. This is the direct answer to the question and is found in Passage 1, sentence 1.\n2. The model prediction does not mention the Greek letter \u03c0, which represents a constant approximately equal to 3.14159. This is crucial auxiliary information for understanding the formula for the area of a circle and is found in Passage 1, sentence 2.\n3. The model prediction does not mention that Archimedes showed the work for the formula for the area of a circle in his book, The Measurement of a Circle. This is crucial auxiliary information for understanding where the formula for the area of a circle came from and is found in Passage 2, sentence 1."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The formula for the area of a circle, which is \u03c0r^2, originated with Archimedes. In this formula, the Greek letter \u03c0 represents a constant approximately equal to 3.14159, which is the ratio of the circumference of any circle to its diameter. Archimedes derived this formula by viewing the circle as the limit of a sequence of regular polygons. The area of a regular polygon is half its perimeter multiplied by the distance from its center to its sides, and the corresponding formula (that the area is half the perimeter times the radius) holds in the limit for a circle. Archimedes detailed this work in his book, The Measurement of a Circle."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 0, "end": 124}], "missing-info": [{"error type": "Missing-Minor-Auxiliary", "passage_id": 2, "sentence_id": [1]}, {"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [1]}, {"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [2]}], "corrected-prediction": "In geometry, the area enclosed by a circle of radius r is \u03c0r2, where the Greek letter \u03c0 represents the constant ratio of the circumference of any circle to its diameter, approximately equal to 3.1416. One method of deriving this formula, which originated with Archimedes, involves viewing the circle as the limit of a sequence of regular polygons. The area of a regular polygon is half its perimeter multiplied by the distance from its center to its sides, and the corresponding formula (that the area is half the perimeter times the radius, i.e. ) holds in the limit for a circle. Archimedes showed the work for the formula for area of a circle in his book, The Measurement of a Circle."}}, {"question": "What pink floyd album is wish you were here on?", "passages": [["Wish You Were Here (Pink Floyd song)", "Wish You Were Here (Pink Floyd song)\n\n", "\"Wish You Were Here\" is the title track on Pink Floyd's 1975 album \"Wish You Were Here\".", "David Gilmour and Roger Waters collaborated to write the music, and Gilmour sang the lead vocal.", "In 2011, the song was ranked No. 324 on Rolling Stone's 500 Greatest Songs of All Time.", "In the original album version, the song segues from \"Have a Cigar\" as if a radio had been tuned away from one station, through several others (including a radio play and one playing the opening of the finale movement of Tchaikovsky's Fourth Symphony), and finally to a new station where \"Wish You Were Here\" is beginning.", "The radio was recorded from Gilmour's car radio.", "He performed the intro on a twelve-string guitar, processed to sound like it was playing through an AM radio, and then overdubbed a fuller-sounding acoustic guitar solo.", "This passage was mixed to sound as though a guitarist were listening to the radio and playing along.", "As the acoustic part becomes more complex, the 'radio broadcast' fades away and Gilmour's voice enters, becoming joined by the full band.", "The intro riff is repeated several times, before Gilmour plays further solos with scat singing accompaniment."], ["Wish You Were Here (Pink Floyd song)", "Mason discussed the alternative version on the BBC Radio 4 Front Row program and revealed that Yehudi Menuhin, who was recording with Grappelli in Abbey Road's Studio Two, was also invited to play on \"Wish You Were Here\" but declined, as he wasn't as comfortable as Grappelli at improvising.", "\"Wish You Were Here (Live)\" is a live recording of Pink Floyd's title track off their ninth studio album \"Wish You Were Here\", recorded by the band for their third live album, \"Pulse\".", "\"Wish You Were Here (Live)\" was released as a single on 20 July 1995 in the United Kingdom and Europe, notably the very last single released by the band until October 2014.", "\"Wish You Were Here\" served as the fourth and final single from Wyclef Jean's second studio album, \"\".", "It was released in December 2001, peaking at #28 on the UK Singles Chart."], ["Wish You Were Here (Pink Floyd album)", "Wish You Were Here (Pink Floyd album)\n\n", "Wish You Were Here is the ninth studio album by the English rock band Pink Floyd.", "It was released on 12 September 1975 in the United Kingdom by Harvest Records and a day later in the United States by Columbia Records, their first American release for the label.", "Based on material Pink Floyd composed while performing in Europe, \"Wish You Were Here\" was recorded over numerous sessions at Abbey Road Studios in London.", "Two songs criticise the music business, another expresses alienation, and the multi-part composition \"Shine On You Crazy Diamond\" is a tribute to Pink Floyd founder Syd Barrett, who left seven years earlier due to mental health problems.", "As with their previous album \"The Dark Side of the Moon\" (1973), Pink Floyd used studio effects and synthesizers, and brought in guest singers: Roy Harper, who provided the lead vocals on \"Have a Cigar\", and Venetta Fields, who added backing vocals to \"Shine On You Crazy Diamond\".", "\"Wish You Were Here\" topped record charts in the United Kingdom and the United States, and Harvest Records' parent company EMI was unable to print enough copies to meet demand."]], "gold": "The song \"Wish you were here\" by English Rock band Pink Floyd originally appeared in the album Wish You Were Here. The album was released on 12 September 1975. A live version of the song  is included on Pulse, released on 29 May 1995. The song was arranged more closely to the original album version. ", "prediction 1": "Wish You Were Here is the title track on Pink Floyd's 1975 album \"Wish You Were Here\". David Gilmour and Roger Waters collaborated to write the music, and Gilmour sang the lead vocal. \"Wish You Were Here (Live)\" is a live recording of Pink Floyd's title track off their ninth studio album \"Wish You Were Here\", recorded by the band for their third live album, \"Pulse\". \"Wish You Were Here (Live)\" was released as a single on 20 July 1995 in the United Kingdom and Europe, notably the last single released by the band until October 2014.", "prediction 2": "Wish You Were Here is the title track on Pink Floyd's 1975 album Wish You Were Here. David Gilmour and Roger Waters collaborated to write the music, and Gilmour sang the lead vocal. In 2011, the song was ranked No. 324 on Rolling Stone's 500 Greatest Songs of All Time. Wish You Were Here (Live) is a live recording of Pink Floyd's title track off their ninth studio album Wish You Were Here, recorded by the band for their third live album, Pulse. \"Wish You Were Here (Live)\" was released as a single on 20 July 1995 in the United Kingdom and Europe, notably the last single released by the band until October 2014.", "prediction 3": "Wish You Were Here is the title track on Pink Floyd's 1975 album \"Wish You Were Here\". David Gilmour and Roger Waters collaborated to write the music, and Gilmour sang the lead vocal. \"Wish You Were Here (Live)\" is a live recording of Pink Floyd's title track off their ninth studio album \"Wish You Were Here\", recorded by the band for their third live album, \"Pulse\". \"Wish You Were Here (Live)\" was released as a single on 20 July 1995 in the United Kingdom and Europe, notably the very last single released by the band until October 2014. \"Wish You Were Here\" served as the fourth and final single from Wyclef Jean's second studio album, \"Wish You Were Here\" which was released in December 2001, peaking at #28 on the UK Singles Charts.", "prediction 4": "\"Wish You Were Here\" is the title track on Pink Floyd's 1975 album Wish You Were Here. David Gilmour and Roger Waters collaborated to write the music, and Gilmour sang the lead vocal. \"Wish You Were Here (Live)\" is a live recording of Pink Floyd's title track off their ninth studio album Wish You Were Here, recorded by the band for their third live album, Pulse.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 87, "end": 183}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 3, "sentence_id": [3]}], "corrected-prediction": "\"Wish You Were Here\" is the title track on Pink Floyd's 1975 album \"Wish You Were Here\", which was released on 12 September 1975. Additionally, \"Wish You Were Here (Live)\" is a live recording of Pink Floyd's title track off their ninth studio album \"Wish You Were Here\", recorded by the band for their third live album, \"Pulse\". This live version was released as a single on 20 July 1995 in the United Kingdom and Europe, notably the last single released by the band until October 2014."}, "preference": [0, 1, 2, 1, 2, 2], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Wish You Were Here (Pink Floyd song)\nS1. Wish You Were Here (Pink Floyd song)  \nS2. \"Wish You Were Here\" is the title track on Pink Floyd's 1975 album \"Wish You Were Here\".\nS3. David Gilmour and Roger Waters collaborated to write the music, and Gilmour sang the lead vocal.\nS4. In 2011, the song was ranked No. 324 on Rolling Stone's 500 Greatest Songs of All Time.\nS5. In the original album version, the song segues from \"Have a Cigar\" as if a radio had been tuned away from one station, through several others (including a radio play and one playing the opening of the finale movement of Tchaikovsky's Fourth Symphony), and finally to a new station where \"Wish You Were Here\" is beginning.\nS6. The radio was recorded from Gilmour's car radio.\nS7. He performed the intro on a twelve-string guitar, processed to sound like it was playing through an AM radio, and then overdubbed a fuller-sounding acoustic guitar solo.\nS8. This passage was mixed to sound as though a guitarist were listening to the radio and playing along.\nS9. As the acoustic part becomes more complex, the 'radio broadcast' fades away and Gilmour's voice enters, becoming joined by the full band.\nS10. The intro riff is repeated several times, before Gilmour plays further solos with scat singing accompaniment.\n\nPassage 2: Title (S0) - Wish You Were Here (Pink Floyd song)\nS1. Mason discussed the alternative version on the BBC Radio 4 Front Row program and revealed that Yehudi Menuhin, who was recording with Grappelli in Abbey Road's Studio Two, was also invited to play on \"Wish You Were Here\" but declined, as he wasn't as comfortable as Grappelli at improvising.\nS2. \"Wish You Were Here (Live)\" is a live recording of Pink Floyd's title track off their ninth studio album \"Wish You Were Here\", recorded by the band for their third live album, \"Pulse\".\nS3. \"Wish You Were Here (Live)\" was released as a single on 20 July 1995 in the United Kingdom and Europe, notably the very last single released by the band until October 2014.\nS4. \"Wish You Were Here\" served as the fourth and final single from Wyclef Jean's second studio album, \"\".\nS5. It was released in December 2001, peaking at #28 on the UK Singles Chart.\n\nPassage 3: Title (S0) - Wish You Were Here (Pink Floyd album)\nS1. Wish You Were Here (Pink Floyd album)  \nS2. Wish You Were Here is the ninth studio album by the English rock band Pink Floyd.\nS3. It was released on 12 September 1975 in the United Kingdom by Harvest Records and a day later in the United States by Columbia Records, their first American release for the label.\nS4. Based on material Pink Floyd composed while performing in Europe, \"Wish You Were Here\" was recorded over numerous sessions at Abbey Road Studios in London.\nS5. Two songs criticise the music business, another expresses alienation, and the multi-part composition \"Shine On You Crazy Diamond\" is a tribute to Pink Floyd founder Syd Barrett, who left seven years earlier due to mental health problems.\nS6. As with their previous album \"The Dark Side of the Moon\" (1973), Pink Floyd used studio effects and synthesizers, and brought in guest singers: Roy Harper, who provided the lead vocals on \"Have a Cigar\", and Venetta Fields, who added backing vocals to \"Shine On You Crazy Diamond\".\nS7. \"Wish You Were Here\" topped record charts in the United Kingdom and the United States, and Harvest Records' parent company EMI was unable to print enough copies to meet demand.\n    \nInput Question:\nWhat pink floyd album is wish you were here on?\n\nCorrect Response:\nThe song \"Wish you were here\" by English Rock band Pink Floyd originally appeared in the album Wish You Were Here. The album was released on 12 September 1975. A live version of the song  is included on Pulse, released on 29 May 1995. The song was arranged more closely to the original album version. \n\nModel Prediction:\nWish You Were Here is the title track on Pink Floyd's 1975 album \"Wish You Were Here\". David Gilmour and Roger Waters collaborated to write the music, and Gilmour sang the lead vocal. \"Wish You Were Here (Live)\" is a live recording of Pink Floyd's title track off their ninth studio album \"Wish You Were Here\", recorded by the band for their third live album, \"Pulse\". \"Wish You Were Here (Live)\" was released as a single on 20 July 1995 in the United Kingdom and Europe, notably the last single released by the band until October 2014.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "Wish You Were Here is the title track on Pink Floyd's 1975 album \"Wish You Were Here\". [David Gilmour and Roger Waters collaborated to write the music, and Gilmour sang the lead vocal.] \"Wish You Were Here (Live)\" is a live recording of Pink Floyd's title track off their ninth studio album \"Wish You Were Here\", recorded by the band for their third live album, \"Pulse\". \"Wish You Were Here (Live)\" was released as a single on 20 July 1995 in the United Kingdom and Europe, notably the last single released by the band until October 2014.\n\nExplanation:\nThe information about David Gilmour and Roger Waters collaborating to write the music, and Gilmour singing the lead vocal is not relevant to the question asked. The question is asking about the album the song is on, not who wrote or sang the song. Therefore, this information is marked as \"Irrelevant\"."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. Wish You Were Here is the title track on Pink Floyd's 1975 album \"Wish You Were Here\".\nS2. David Gilmour and Roger Waters collaborated to write the music, and Gilmour sang the lead vocal.\nS3. \"Wish You Were Here (Live)\" is a live recording of Pink Floyd's title track off their ninth studio album \"Wish You Were Here\", recorded by the band for their third live album, \"Pulse\".\nS4. \"Wish You Were Here (Live)\" was released as a single on 20 July 1995 in the United Kingdom and Europe, notably the last single released by the band until October 2014.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation:\nAll the facts mentioned in the model prediction are consistent with the information provided in the passages. Therefore, there are no spans that contain inconsistent or unverifiable facts."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 3, sentence 3 [Missing Major Auxiliary Information]\n\nExplanation:\nThe model prediction does not mention the release date of the album \"Wish You Were Here\", which is a significant detail found in the reference response. This information can be found in Passage 3, Sentence 3."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "\"Wish You Were Here\" is the title track on Pink Floyd's 1975 album \"Wish You Were Here\", which was released on 12 September 1975. Additionally, \"Wish You Were Here (Live)\" is a live recording of Pink Floyd's title track off their ninth studio album \"Wish You Were Here\", recorded by the band for their third live album, \"Pulse\". This live version was released as a single on 20 July 1995 in the United Kingdom and Europe, notably the last single released by the band until October 2014."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 87, "end": 183}, {"error type": "Irrelevant", "explanation": "", "start": 184, "end": 368}, {"error type": "Irrelevant", "explanation": "", "start": 438, "end": 536}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 3, "sentence_id": [3]}], "corrected-prediction": "Wish You Were Here is the title track on Pink Floyd's 1975 album \"Wish You Were Here\". The album was released on 12 September 1975. \"Wish You Were Here (Live)\" was released as a single on 20 July 1995."}}, {"question": "When did low down dirty shame come out?", "passages": [["A Low Down Dirty Shame", "A Low Down Dirty Shame\n\nA Low Down Dirty Shame is a 1994 American action comedy film written, directed by, and starring Keenen Ivory Wayans.", "The film also stars Charles S. Dutton, Jada Pinkett, and Salli Richardson.", "Former LAPD detective Andre Shame is a private investigator who owns A Low Down Dirty Shame Investigations.", "He runs it with Peaches, whom he arrested six years before and has romantic feelings for him.", "Despite the high-risk jobs, Shame is unable to keep the firm afloat, and may be forced to close.", "Five years earlier, Shame and a team of detectives went into Mexico to apprehend drug lord Ernesto Mendoza.", "Though Shame seemingly shot and killed Mendoza in a shoot-out, the other detectives were killed, with Shame and Sonny Rothmiller being the only survivors.", "This caused Shame to leave the force in disgrace.", "In the present day, Rothmiller, who is now working for the DEA, tells him that Mendoza is still alive.", "He hires Shame to find the only witness who would testify against him...his ex-girlfriend Angela, who was caught in the middle of a love triangle with the two men.", "Angela escaped from the Witness Protection Program in New York and is in LA.", "Shame is hesitant at first, but seeing this as a chance to arrest the man who took everything from him, decides to take the case."], ["A Low Down Dirty Shame", "She attempts to kill Shame, but Peaches beats her in a fistfight.", "Nunez threatens to arrest Shame, but Shame reminds Nunez that he helped take down a drug lord, find a federal witness and recover $15 million in stolen drug money.", "Shame keeps $5 million for expenses, with Peaches getting perks of a romantic relationship with Shame.", "A soundtrack containing hip hop and R&B music was released on November 8, 1994, by Hollywood Records and Jive Records.", "It peaked at #70 on the \"Billboard\" 200 and #14 on the Top R&B/Hip-Hop Albums.", "Rotten Tomatoes, a review aggregator, reports that 0% of 21 surveyed critics gave the film a positive review; the average rating is 3.6/10."]], "gold": "A Low Down Dirty Shame is an American action comedy film written, directed by, and starring Keenen Ivory Wayans. The movie follows Andre Shame, a former LAPD detective turned private investigator in risk of being forced to close down his own firm. The movie was released on November 23, 1994, shortly after its soundtrack came out on November 8, 1994. The album contained hip hop and R&B music and peaked at #70 on the Billboard 200 and #14 on the Top R&B/Hip-Hop Albums.", "prediction 1": "A Low Down Dirty Shame is a 1994 American action comedy film written, directed, and starring Keenen Ivory Wayans. The film also stars Charles S. Dutton, Jada Pinkett, and Salli Richardson. The film's soundtrack containing hip hop and R&B music was released on November 8, 1994, by Hollywood Records and Jive Records.", "prediction 2": "A Low Down Dirty Shame is a 1994 American action comedy film written, directed by, and starring Keenen Ivory Wayans. The film stars Charles S. Dutton, Jada Pinkett, and Salli Richardson. The film's soundtrack containing hip hop and R&B music was released on November 8, 1994, by Hollywood Records and Jive Records.", "prediction 3": "A Low Down Dirty Shame is a 1994 American action comedy film written, directed by, and starring Keenen Ivory Wayans. The film also stars Charles S. Dutton, Jada Pinkett, and Salli Richardson. The film stars former LAPD detective Andre Shame and former ex-girlfriend Peaches, whom he arrested six years before and has romantic feelings for him. The soundtrack containing hip hop and R&B music was released on November 8, 1994, by Hollywood Records and Jive Records. It peaked at #70 on the \"Billboard\" 200 and #14 on the Top R&B/Hip-Hip-Hip-Hop-Hip-Hop-Hop-Hip-Hop-Hip-Hop Albums.", "prediction 4": "A Low Down Dirty Shame is a 1994 American action comedy film written, directed by, and starring Keenen Ivory Wayans. The film also stars Charles S. Dutton, Jada Pinkett, and Salli Richardson. The soundtrack containing hip hop and R&B music was released on November 8, 1994, by Hollywood Records and Jive Records.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 114, "end": 188}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 1, "sentence_id": [1]}], "corrected-prediction": "A Low Down Dirty Shame is a 1994 American action comedy film written, directed, and starring Keenen Ivory Wayans. The film was released in 1994. The film's soundtrack containing hip hop and R&B music was released on November 8, 1994, by Hollywood Records and Jive Records. The album peaked at #70 on the Billboard 200 and #14 on the Top R&B/Hip-Hop Albums."}, "preference": [0, 1, 0, 1, 0, 2], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - A Low Down Dirty Shame\nS1. A Low Down Dirty Shame  A Low Down Dirty Shame is a 1994 American action comedy film written, directed by, and starring Keenen Ivory Wayans.\nS2. The film also stars Charles S. Dutton, Jada Pinkett, and Salli Richardson.\nS3. Former LAPD detective Andre Shame is a private investigator who owns A Low Down Dirty Shame Investigations.\nS4. He runs it with Peaches, whom he arrested six years before and has romantic feelings for him.\nS5. Despite the high-risk jobs, Shame is unable to keep the firm afloat, and may be forced to close.\nS6. Five years earlier, Shame and a team of detectives went into Mexico to apprehend drug lord Ernesto Mendoza.\nS7. Though Shame seemingly shot and killed Mendoza in a shoot-out, the other detectives were killed, with Shame and Sonny Rothmiller being the only survivors.\nS8. This caused Shame to leave the force in disgrace.\nS9. In the present day, Rothmiller, who is now working for the DEA, tells him that Mendoza is still alive.\nS10. He hires Shame to find the only witness who would testify against him...his ex-girlfriend Angela, who was caught in the middle of a love triangle with the two men.\nS11. Angela escaped from the Witness Protection Program in New York and is in LA.\nS12. Shame is hesitant at first, but seeing this as a chance to arrest the man who took everything from him, decides to take the case.\n\nPassage 2: Title (S0) - A Low Down Dirty Shame\nS1. She attempts to kill Shame, but Peaches beats her in a fistfight.\nS2. Nunez threatens to arrest Shame, but Shame reminds Nunez that he helped take down a drug lord, find a federal witness and recover $15 million in stolen drug money.\nS3. Shame keeps $5 million for expenses, with Peaches getting perks of a romantic relationship with Shame.\nS4. A soundtrack containing hip hop and R&B music was released on November 8, 1994, by Hollywood Records and Jive Records.\nS5. It peaked at #70 on the \"Billboard\" 200 and #14 on the Top R&B/Hip-Hop Albums.\nS6. Rotten Tomatoes, a review aggregator, reports that 0% of 21 surveyed critics gave the film a positive review; the average rating is 3.6/10.\n    \nInput Question:\nWhen did low down dirty shame come out?\n\nCorrect Response:\nA Low Down Dirty Shame is an American action comedy film written, directed by, and starring Keenen Ivory Wayans. The movie follows Andre Shame, a former LAPD detective turned private investigator in risk of being forced to close down his own firm. The movie was released on November 23, 1994, shortly after its soundtrack came out on November 8, 1994. The album contained hip hop and R&B music and peaked at #70 on the Billboard 200 and #14 on the Top R&B/Hip-Hop Albums.\n\nModel Prediction:\nA Low Down Dirty Shame is a 1994 American action comedy film written, directed, and starring Keenen Ivory Wayans. The film also stars Charles S. Dutton, Jada Pinkett, and Salli Richardson. The film's soundtrack containing hip hop and R&B music was released on November 8, 1994, by Hollywood Records and Jive Records.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "A Low Down Dirty Shame is a 1994 American action comedy film written, directed, and starring Keenen Ivory Wayans. [The film also stars Charles S. Dutton, Jada Pinkett, and Salli Richardson.] The film's soundtrack containing hip hop and R&B music was released on November 8, 1994, by Hollywood Records and Jive Records.\n\nExplanation:\nThe second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\"."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. A Low Down Dirty Shame is a 1994 American action comedy film written, directed, and starring Keenen Ivory Wayans.\nS2. The film also stars Charles S. Dutton, Jada Pinkett, and Salli Richardson.\nS3. The film's soundtrack containing hip hop and R&B music was released on November 8, 1994, by Hollywood Records and Jive Records.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation:\nAll the facts in the model prediction are consistent with the passages and verifiable."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 1 [Missing Answer]\n2. Passage 2, sentence 4 [Missing Major Auxiliary Information]\n\nExplanation:\n1. The model prediction does not mention the specific release date of the film \"A Low Down Dirty Shame\", which is the direct answer to the question. This information is found in Passage 1, Sentence 1.\n2. The model prediction also misses the auxiliary information about the performance of the film's soundtrack on the Billboard 200 and the Top R&B/Hip-Hop Albums. This information is found in Passage 2, Sentence 5. This information is considered major as it provides context about the film's cultural impact and popularity."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "A Low Down Dirty Shame is a 1994 American action comedy film written, directed, and starring Keenen Ivory Wayans. The film was released in 1994. The film's soundtrack containing hip hop and R&B music was released on November 8, 1994, by Hollywood Records and Jive Records. The album peaked at #70 on the Billboard 200 and #14 on the Top R&B/Hip-Hop Albums."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 114, "end": 188}, {"error type": "Irrelevant", "explanation": "", "start": 278, "end": 316}], "missing-info": [{"error type": "Missing-Minor-Auxiliary", "passage_id": 2, "sentence_id": [3]}, {"error type": "Missing-Minor-Auxiliary", "passage_id": 1, "sentence_id": [3]}], "corrected-prediction": "A Low Down Dirty Shame is a 1994 American action comedy film written, directed, and starring Keenen Ivory Wayans. The film follows Former LAPD detective, Andre Shame, who is a private investigator at risk of being forced to close down his own firm. The film's soundtrack containing hip hop and R&B music was released on November 8, 1994. It peaked at #70 on the \"Billboard\" 200 and #14 on the Top R&B/Hip-Hop Albums."}}, {"question": "When was the count of monte cristo set?", "passages": [["The Count of Monte Cristo", "The Count of Monte Cristo\n\nThe Count of Monte Cristo () is an adventure novel by French author Alexandre Dumas (\"p\u00e8re\") completed in 1844.", "It is one of the author's most popular works, along with \"The Three Musketeers\".", "Like many of his novels, it was expanded from plot outlines suggested by his collaborating ghostwriter Auguste Maquet.", "Another important work by Dumas, written prior to his work with Maquet, was the short novel \"Georges\"; this novel is of particular interest to scholars because Dumas reused many of the ideas and plot devices later in \"The Count of Monte Cristo\".", "The story takes place in France, Italy, and islands in the Mediterranean during the historical events of 1815\u20131839: the era of the Bourbon Restoration through the reign of Louis-Philippe of France.", "It begins just before the Hundred Days period (when Napoleon returned to power after his exile).", "The historical setting is a fundamental element of the book, an adventure story primarily concerned with themes of hope, justice, vengeance, mercy, and forgiveness.", "It centres on a man who is wrongfully imprisoned, escapes from jail, acquires a fortune, and sets about exacting revenge on those responsible for his imprisonment.", "His plans have devastating consequences for both the innocent and the guilty.", "The book is considered a literary classic today."], ["The Count of Monte Cristo (1943 film)", "The Count of Monte Cristo (1943 film)\n\nThe Count of Monte Cristo is a 1943 French-Italian film directed by Robert Vernay with Ferruccio Cerio as the supervising director.", "Based on the classic novel \"Le Comte de Monte Cristo\" by Alexandre Dumas p\u00e8re, this two-part film stars Pierre Richard-Willm in the title role."], ["The Count of Monte Cristo (2002 film)", "The Count of Monte Cristo (2002 film)\n\nThe Count of Monte Cristo is a 2002 adventure drama film produced by Roger Birnbaum, Gary Barber, and Jonathan Glickman that was directed by Kevin Reynolds.", "An international co-production between the United States, the United Kingdom, and Ireland, the film is an adaptation of the book of the same name by Alexandre Dumas, p\u00e8re and stars Jim Caviezel, Guy Pearce, and Richard Harris.", "It follows the general plot of the novel (the main storyline of imprisonment and revenge is preserved); but many aspects, including the relationships between major characters and the ending, have been changed, simplified, or removed; and action scenes have been added.", "The film met with modest box office success.", "In 1815, Edmond Dant\u00e8s, Second Mate of a French merchant vessel, and his friend Fernand Mondego, representative of the shipping company, seek medical help at Elba for their ailing captain.", "Napoleon Bonaparte, having kept his guardians from killing the pair, exchanges his physician\u2019s services with Edmond for the delivery of a letter.", "Edmond is sworn to its secrecy, but the exchange is witnessed by Fernand."]], "gold": "The Count of Monte Cristo is an adventure novel written by French author Alexandre Dumas completed in 1844, that has spawned several adaptations. The original book takes place on takes place in France, Italy, and islands in the Mediterranean during the historical events of 1815\u20131839: the era of the Bourbon Restoration, while the 2002 American adaptation takes place in the island of Elba and the mainland city of Marseille, during the same time frame. Alternatively, the 1999 version called Forever Mine is mostly set in Miami in the year 1987. In 1986, an Indian take on the story was released with the movie Veta, which takes place in India in 1939.", "prediction 1": "The Count of Monte Cristo is an adventure novel by French author Alexandre Dumas completed in 1844. The story takes place in France, Italy, and islands in the Mediterranean during the historical events of 1815\u20131839: the era of the Bourbon Restoration through the reign of Louis-Philippe of France. The 1943 French-Italian film The Count of Monte Cristo, is also considered a classic. The Count of Monte Cristo is also considered an international co-production between the United States, the United Kingdom, and Ireland.", "prediction 2": "The Count of Monte Cristo is an adventure novel by French author Alexandre Dumas, completed in 1844. The story takes place in France, Italy, and islands in the Mediterranean during the historical events of 1815\u20131839: the era of the Bourbon Restoration through the reign of Louis-Philippe of France. It begins just before the Hundred Days period, when Napoleon returned to power after his exile. The 1943 French-Italian film, The Count of Monte Cristo, is an adaptation of the book by Alexandre Dumas p\u00e8re and stars Pierre Richard-Willm in the title role. The 2002 film is an adaptation of the book of the same name by Alexandre Dumas p\u00e8re and stars Guy Pearce, Richard Harris, and Jim Caviezel.", "prediction 3": "The Count of Monte Cristo is an adventure novel by French author Alexandre Dumas, \"p\u00e8re\", completed in 1844. It is one of the author's most popular works, along with \"The Three Musketeers\". The story takes place in France, Italy, and islands in the Mediterranean during the historical events of 1815\u20131839: the era of the Bourbon Restoration through the reign of Louis-Philippe of France. The Count of Monte Cristo is also the title of a 1943 French-Italian film that was directed by Kevin Reynolds.", "prediction 4": "The Count of Monte Cristo is a novel by French author Alexandre Dumas. It was completed in 1844. The story takes place in France, Italy, and islands in the Mediterranean during the historical events of 1815\u20131839. The 1943 French-Italian film version of the novel is an adaptation of the book and is based on the 1815 story.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 298, "end": 519}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 3, "sentence_id": [5]}], "corrected-prediction": "The Count of Monte Cristo is an adventure novel by French author Alexandre Dumas completed in 1844. The story takes place in France, Italy, and islands in the Mediterranean during the historical events of 1815\u20131839: the era of the Bourbon Restoration through the reign of Louis-Philippe of France. The 2002 film adaptation of The Count of Monte Cristo, an international co-production between the United States, the United Kingdom, and Ireland, takes place in the island of Elba and the mainland city of Marseille during the same historical period."}, "preference": [1, 1, 1, 1, 1, 1], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - The Count of Monte Cristo\nS1. The Count of Monte Cristo  The Count of Monte Cristo () is an adventure novel by French author Alexandre Dumas (\"p\u00e8re\") completed in 1844.\nS2. It is one of the author's most popular works, along with \"The Three Musketeers\".\nS3. Like many of his novels, it was expanded from plot outlines suggested by his collaborating ghostwriter Auguste Maquet.\nS4. Another important work by Dumas, written prior to his work with Maquet, was the short novel \"Georges\"; this novel is of particular interest to scholars because Dumas reused many of the ideas and plot devices later in \"The Count of Monte Cristo\".\nS5. The story takes place in France, Italy, and islands in the Mediterranean during the historical events of 1815\u20131839: the era of the Bourbon Restoration through the reign of Louis-Philippe of France.\nS6. It begins just before the Hundred Days period (when Napoleon returned to power after his exile).\nS7. The historical setting is a fundamental element of the book, an adventure story primarily concerned with themes of hope, justice, vengeance, mercy, and forgiveness.\nS8. It centres on a man who is wrongfully imprisoned, escapes from jail, acquires a fortune, and sets about exacting revenge on those responsible for his imprisonment.\nS9. His plans have devastating consequences for both the innocent and the guilty.\nS10. The book is considered a literary classic today.\n\nPassage 2: Title (S0) - The Count of Monte Cristo (1943 film)\nS1. The Count of Monte Cristo (1943 film)  The Count of Monte Cristo is a 1943 French-Italian film directed by Robert Vernay with Ferruccio Cerio as the supervising director.\nS2. Based on the classic novel \"Le Comte de Monte Cristo\" by Alexandre Dumas p\u00e8re, this two-part film stars Pierre Richard-Willm in the title role.\n\nPassage 3: Title (S0) - The Count of Monte Cristo (2002 film)\nS1. The Count of Monte Cristo (2002 film)  The Count of Monte Cristo is a 2002 adventure drama film produced by Roger Birnbaum, Gary Barber, and Jonathan Glickman that was directed by Kevin Reynolds.\nS2. An international co-production between the United States, the United Kingdom, and Ireland, the film is an adaptation of the book of the same name by Alexandre Dumas, p\u00e8re and stars Jim Caviezel, Guy Pearce, and Richard Harris.\nS3. It follows the general plot of the novel (the main storyline of imprisonment and revenge is preserved); but many aspects, including the relationships between major characters and the ending, have been changed, simplified, or removed; and action scenes have been added.\nS4. The film met with modest box office success.\nS5. In 1815, Edmond Dant\u00e8s, Second Mate of a French merchant vessel, and his friend Fernand Mondego, representative of the shipping company, seek medical help at Elba for their ailing captain.\nS6. Napoleon Bonaparte, having kept his guardians from killing the pair, exchanges his physician\u2019s services with Edmond for the delivery of a letter.\nS7. Edmond is sworn to its secrecy, but the exchange is witnessed by Fernand.\n    \nInput Question:\nWhen was the count of monte cristo set?\n\nCorrect Response:\nThe Count of Monte Cristo is an adventure novel written by French author Alexandre Dumas completed in 1844, that has spawned several adaptations. The original book takes place on takes place in France, Italy, and islands in the Mediterranean during the historical events of 1815\u20131839: the era of the Bourbon Restoration, while the 2002 American adaptation takes place in the island of Elba and the mainland city of Marseille, during the same time frame. Alternatively, the 1999 version called Forever Mine is mostly set in Miami in the year 1987. In 1986, an Indian take on the story was released with the movie Veta, which takes place in India in 1939.\n\nModel Prediction:\nThe Count of Monte Cristo is an adventure novel by French author Alexandre Dumas completed in 1844. The story takes place in France, Italy, and islands in the Mediterranean during the historical events of 1815\u20131839: the era of the Bourbon Restoration through the reign of Louis-Philippe of France. The 1943 French-Italian film The Count of Monte Cristo, is also considered a classic. The Count of Monte Cristo is also considered an international co-production between the United States, the United Kingdom, and Ireland.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "The Count of Monte Cristo is an adventure novel by French author Alexandre Dumas completed in 1844. The story takes place in France, Italy, and islands in the Mediterranean during the historical events of 1815\u20131839: the era of the Bourbon Restoration through the reign of Louis-Philippe of France. [The 1943 French-Italian film The Count of Monte Cristo, is also considered a classic. The Count of Monte Cristo is also considered an international co-production between the United States, the United Kingdom, and Ireland.]\n\nExplanation:\n1. The last two sentences in the model prediction are irrelevant to the question. The question asks about the setting of \"The Count of Monte Cristo\", but these sentences provide information about the film adaptations, not their settings. Thus, they should be marked as \"Irrelevant\"."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The Count of Monte Cristo is an adventure novel by French author Alexandre Dumas completed in 1844.\nS2. The story takes place in France, Italy, and islands in the Mediterranean during the historical events of 1815\u20131839: the era of the Bourbon Restoration through the reign of Louis-Philippe of France.\nS3. The 1943 French-Italian film The Count of Monte Cristo, is also considered a classic.\nS4. The Count of Monte Cristo is also considered an international co-production between the United States, the United Kingdom, and Ireland.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation:\nAll the facts presented in the model prediction are consistent with the provided passages and none of them are unverifiable."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 3, sentence 5 [Missing Major Auxiliary Information]\n\nExplanation:\n1. The model prediction does not mention that the 2002 film adaptation of \"The Count of Monte Cristo\" takes place in the island of Elba and the mainland city of Marseille, which is a significant detail about the setting of the story. This information is found in Passage 3, sentence 5."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The Count of Monte Cristo is an adventure novel by French author Alexandre Dumas completed in 1844. The story takes place in France, Italy, and islands in the Mediterranean during the historical events of 1815\u20131839: the era of the Bourbon Restoration through the reign of Louis-Philippe of France. The 2002 film adaptation of The Count of Monte Cristo, an international co-production between the United States, the United Kingdom, and Ireland, takes place in the island of Elba and the mainland city of Marseille during the same historical period."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 251, "end": 297}, {"error type": "Irrelevant", "explanation": "", "start": 298, "end": 383}, {"error type": "Irrelevant", "explanation": "", "start": 384, "end": 519}], "missing-info": [], "corrected-prediction": "The Count of Monte Cristo is an adventure novel by French author Alexandre Dumas completed in 1844. The story takes place in France, Italy, and islands in the Mediterranean during the historical events of 1815\u20131839: the era of the Bourbon Restoration. "}}, {"question": "How long is the staton island ferry ride?", "passages": [["Staten Island Ferry", "Staten Island Ferry\n\nThe Staten Island Ferry is a passenger ferry route operated by the New York City Department of Transportation.", "The ferry's single route runs through New York Harbor between the New York City boroughs of Manhattan and Staten Island, with ferry boats making the trip in approximately 25 minutes.", "The ferry operates 24 hours a day, 7 days a week, with boats leaving every 15 to 20 minutes during peak hours and every 30 minutes at other times.", "It is the only direct mass-transit connection between the two boroughs.", "Historically, the Staten Island Ferry has charged a relatively low fare compared to other modes of transit in the area; and since 1997 the route has been fare-free.", "The Staten Island Ferry is one of several ferry systems in the New York City area and is operated separately from systems such as NYC Ferry and NY Waterway.", "The Staten Island Ferry route terminates at Whitehall Terminal, on Whitehall Street in Lower Manhattan, and at St. George Terminal, in St. George, Staten Island.", "At Whitehall, connections are available to the New York City Subway and several local New York City Bus routes.", "At St. George, there are transfers to the Staten Island Railway and to the St. George Bus Terminal's many bus routes."]], "gold": "The Staten Island Ferry's single route runs 5.2 miles (8.4 km) through New York Harbor between the New York City boroughs of Manhattan and Staten Island, with ferry boats making the trip in approximately 25 minutes.", "prediction 1": "The Staten Island Ferry is a passenger ferry route operated by the New York City Department of Transportation. The ferry's single route runs through New York Harbor between the New York City boroughs of Manhattan and Staten Island, with ferry boats making the trip in approximately 25 minutes. Historically, the Staten Island Ferry has charged a relatively low fare compared to other modes of transit in the area; and since 1997 the route has been fare-free.", "prediction 2": "The Staten Island Ferry is a passenger ferry route operated by the New York City Department of Transportation. The ferry's single route runs through New York Harbor between the New York City boroughs of Manhattan and Staten Island, with ferry boats making the trip in approximately 25 minutes. The ferry operates 24 hours a day, 7 days a week, with boats leaving every 15 to 20 minutes during peak hours and every 30 minutes at other times. The ferry operates 24 hours a day, 7 days a week, with boats leaving every 15 to 20 minutes during peak hours and every 30 minutes at other times.", "prediction 3": "The Staten Island Ferry is a passenger ferry route operated by the New York City Department of Transportation. The ferry's single route runs through New York Harbor between the New York City boroughs of Manhattan and Staten Island, with ferry boats making the trip in approximately 25 minutes. The ferry operates 24 hours a day, 7 days a week, with boats leaving every 15 to 20 minutes during peak hours and every 30 minutes at other times. The trip takes approximately 25 minutes.", "prediction 4": "The Staten Island Ferry is a passenger ferry route operated by the New York City Department of Transportation. The ferry's single route runs through New York Harbor between the New York City boroughs of Manhattan and Staten Island, with ferry boats making the trip in approximately 25 minutes. It is the only direct mass-transit connection between the two boroughs.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 294, "end": 458}], "missing-info": [], "corrected-prediction": "The Staten Island Ferry is a passenger ferry route operated by the New York City Department of Transportation. The ferry's single route runs through New York Harbor between the New York City boroughs of Manhattan and Staten Island, with ferry boats making the trip in approximately 25 minutes."}, "preference": [1, 1, 1, 2, 2, 1], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Staten Island Ferry\nS1. Staten Island Ferry  The Staten Island Ferry is a passenger ferry route operated by the New York City Department of Transportation.\nS2. The ferry's single route runs through New York Harbor between the New York City boroughs of Manhattan and Staten Island, with ferry boats making the trip in approximately 25 minutes.\nS3. The ferry operates 24 hours a day, 7 days a week, with boats leaving every 15 to 20 minutes during peak hours and every 30 minutes at other times.\nS4. It is the only direct mass-transit connection between the two boroughs.\nS5. Historically, the Staten Island Ferry has charged a relatively low fare compared to other modes of transit in the area; and since 1997 the route has been fare-free.\nS6. The Staten Island Ferry is one of several ferry systems in the New York City area and is operated separately from systems such as NYC Ferry and NY Waterway.\nS7. The Staten Island Ferry route terminates at Whitehall Terminal, on Whitehall Street in Lower Manhattan, and at St. George Terminal, in St. George, Staten Island.\nS8. At Whitehall, connections are available to the New York City Subway and several local New York City Bus routes.\nS9. At St. George, there are transfers to the Staten Island Railway and to the St. George Bus Terminal's many bus routes.\n    \nInput Question:\nHow long is the staton island ferry ride?\n\nCorrect Response:\nThe Staten Island Ferry's single route runs 5.2 miles (8.4 km) through New York Harbor between the New York City boroughs of Manhattan and Staten Island, with ferry boats making the trip in approximately 25 minutes.\n\nModel Prediction:\nThe Staten Island Ferry is a passenger ferry route operated by the New York City Department of Transportation. The ferry's single route runs through New York Harbor between the New York City boroughs of Manhattan and Staten Island, with ferry boats making the trip in approximately 25 minutes. Historically, the Staten Island Ferry has charged a relatively low fare compared to other modes of transit in the area; and since 1997 the route has been fare-free.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "The Staten Island Ferry is a passenger ferry route operated by the New York City Department of Transportation. The ferry's single route runs through New York Harbor between the New York City boroughs of Manhattan and Staten Island, with ferry boats making the trip in approximately 25 minutes. [Historically, the Staten Island Ferry has charged a relatively low fare compared to other modes of transit in the area; and since 1997 the route has been fare-free.]\n\nExplanation:\nThe last sentence in the model prediction is irrelevant to the question asked. The question is about the duration of the ferry ride, not the fare. Therefore, it should be marked as \"Irrelevant\"."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The Staten Island Ferry is a passenger ferry route operated by the New York City Department of Transportation.\nS2. The ferry's single route runs through New York Harbor between the New York City boroughs of Manhattan and Staten Island, with ferry boats making the trip in approximately 25 minutes.\nS3. Historically, the Staten Island Ferry has charged a relatively low fare compared to other modes of transit in the area; and since 1997 the route has been fare-free.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation:\nAll the facts presented in the model prediction are consistent with the information provided in the passages. Therefore, there are no spans that contain inconsistent or unverifiable facts."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "None\n\nExplanation:\nThe model prediction includes all the necessary information to answer the question. It correctly states that the ferry ride takes approximately 25 minutes, which is the main point of the question. Therefore, there is no missing information in the model prediction."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The Staten Island Ferry is a passenger ferry route operated by the New York City Department of Transportation. The ferry's single route runs through New York Harbor between the New York City boroughs of Manhattan and Staten Island, with ferry boats making the trip in approximately 25 minutes."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 0, "end": 110}, {"error type": "Irrelevant", "explanation": "", "start": 294, "end": 458}], "missing-info": [], "corrected-prediction": "The ferry's single route runs through New York Harbor between the New York City boroughs of Manhattan and Staten Island, with ferry boats making the trip in approximately 25 minutes. "}}, {"question": "When did star wars the last jedi cone out?", "passages": [["Star Wars: The Last Jedi", "\"The Last Jedi\" is part of a new trilogy of films announced after Disney's acquisition of Lucasfilm in October 2012.", "It was produced by Lucasfilm President Kathleen Kennedy and Ram Bergman, with \"Force Awakens\" director J. J. Abrams as an executive producer.", "John Williams, composer for the previous films, returned to compose the score.", "A number of scenes were filmed at Skellig Michael in Ireland during pre-production in September 2015, but principal photography began at Pinewood Studios in the United Kingdom in February 2016, and ended in July 2016.", "Post-production wrapped in September 2017.", "\"The Last Jedi\" had its world premiere in Los Angeles on December 9, 2017, and was released in the United States on December 15, 2017.", "It grossed over $1.3billion worldwide, becoming the highest-grossing film of 2017, the seventh-highest-ever grossing film in North America and the ninth-highest-grossing film of all time during its theatrical run.", "It is also the second-highest-grossing film of the \"Star Wars\" franchise, and turned a net profit of over $417\u00a0million.", "It was positively received by film critics, who praised the ensemble cast, visual effects, musical score, action sequences and emotional weight."]], "gold": "Star Wars the Last Jedi had an early premiere viewing at the Shrine Auditorium in Los Angeles on December 9, 2017. It was later released across the United States on December 15, 2017, becoming the seventh-highest-ever grossing film in North America. ", "prediction 1": "The Last Jedi had its world premiere at the Dolby Theatre in Los Angeles on December 9, 2017, and was released in the United States on December 15, 2017.", "prediction 2": "The Last Jedi had its world premiere in Los Angeles on December 9, 2017, and was released in the United States on December 15, 2017. It grossed over $1.3billion worldwide.", "prediction 3": "Star wars The Last Jedi had its world premiere at the Shrine Auditorium in Los Angeles on December 9, 2017, and was released in the United States on December 15, 2017.", "prediction 4": "The Last Jedi had its world premiere in Los Angeles on December 9, 2017, and was released in the United States on December 15, 2017.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 44, "end": 57}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [7]}], "corrected-prediction": "The Last Jedi had its world premiere in Los Angeles on December 9, 2017, and was released in the United States on December 15, 2017. It became the seventh-highest-ever grossing film in North America."}, "preference": [1, 2, 2, 2, 2, 2], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Star Wars: The Last Jedi\nS1. \"The Last Jedi\" is part of a new trilogy of films announced after Disney's acquisition of Lucasfilm in October 2012.\nS2. It was produced by Lucasfilm President Kathleen Kennedy and Ram Bergman, with \"Force Awakens\" director J. J. Abrams as an executive producer.\nS3. John Williams, composer for the previous films, returned to compose the score.\nS4. A number of scenes were filmed at Skellig Michael in Ireland during pre-production in September 2015, but principal photography began at Pinewood Studios in the United Kingdom in February 2016, and ended in July 2016.\nS5. Post-production wrapped in September 2017.\nS6. \"The Last Jedi\" had its world premiere in Los Angeles on December 9, 2017, and was released in the United States on December 15, 2017.\nS7. It grossed over $1.3billion worldwide, becoming the highest-grossing film of 2017, the seventh-highest-ever grossing film in North America and the ninth-highest-grossing film of all time during its theatrical run.\nS8. It is also the second-highest-grossing film of the \"Star Wars\" franchise, and turned a net profit of over $417\u00a0million.\nS9. It was positively received by film critics, who praised the ensemble cast, visual effects, musical score, action sequences and emotional weight.\n    \nInput Question:\nWhen did star wars the last jedi cone out?\n\nCorrect Response:\nStar Wars the Last Jedi had an early premiere viewing at the Shrine Auditorium in Los Angeles on December 9, 2017. It was later released across the United States on December 15, 2017, becoming the seventh-highest-ever grossing film in North America. \n\nModel Prediction:\nThe Last Jedi had its world premiere at the Dolby Theatre in Los Angeles on December 9, 2017, and was released in the United States on December 15, 2017.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "The Last Jedi had its world premiere at the [Dolby Theatre] in Los Angeles on December 9, 2017, and was released in the United States on December 15, 2017.\n\nExplanation:\nThe model prediction incorrectly states that the premiere of \"The Last Jedi\" took place at the \"Dolby Theatre\". This information is not found in the passages and is therefore \"Inconsistent Fact\". The correct location, according to the passages, is not specified."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The Last Jedi had its world premiere at the Dolby Theatre in Los Angeles on December 9, 2017, and was released in the United States on December 15, 2017.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "Inconsistent or Unverifiable Sentences:\n1. S1\n\nExplanation:\n1. The model prediction incorrectly states that the premiere of \"The Last Jedi\" took place at the \"Dolby Theatre\". This information is not found in the passages and is therefore \"Inconsistent Fact\". The correct location, according to the passages, is not specified."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 7 [Missing Major Auxiliary Information]\n\nExplanation:\n1. The model prediction does not mention that \"The Last Jedi\" became the seventh-highest-ever grossing film in North America, which is a significant detail about the film's release and success. This information is found in Passage 1, sentence 7 and is also included in the reference response, making it a \"Missing Major Auxiliary Information\"."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The Last Jedi had its world premiere in Los Angeles on December 9, 2017, and was released in the United States on December 15, 2017. It became the seventh-highest-ever grossing film in North America."}], "feedback_human": {"errors": [{"error type": "Unverifiable", "explanation": "", "start": 44, "end": 57}], "missing-info": [{"error type": "Missing-Minor-Auxiliary", "passage_id": 1, "sentence_id": [7]}], "corrected-prediction": "Star Wars: The Last Jedi had its world premiere in Los Angeles on December 9, 2017, and was released in the United States on December 15, 2017, becoming the seventh-highest-ever grossing film in North America."}}, {"question": "When did the last song of ice and fire book come out?", "passages": [["Themes in A Song of Ice and Fire", "Themes in A Song of Ice and Fire\n\n\"A Song of Ice and Fire\" is an ongoing series of epic fantasy novels by American novelist and screenwriter George R. R. Martin.", "The first installment of the series, \"A Game of Thrones\", which was originally planned as a trilogy, was published in 1996.", "The series now consists of five published volumes, and two more volumes are planned.", "The series is told in the third-person through the eyes of a number of point of view characters.", "A television series adaptation, \"Game of Thrones\", premiered on HBO in 2011.", "\"A Song of Ice and Fire\" takes place in a fictional world, primarily on a continent called Westeros, and additionally on a large landmass to the east, known as Essos.", "Three main story lines become increasingly interwoven: a dynastic civil war for control of Westeros among several competing families; the rising threat of the Others, who dwell beyond the immense wall of ice that forms Westeros's northern border; and the ambitions of Daenerys Targaryen, exiled daughter of the deposed king, to return to Westeros and claim her throne.", "Martin has said he believes in \"judicious use of magic\" in epic fantasy."], ["A Storm of Swords", "A Storm of Swords\n\nA Storm of Swords is the third of seven planned novels in \"A Song of Ice and Fire\", a fantasy series by American author George R. R. Martin.", "It was first published on August 8, 2000, in the United Kingdom, with a United States edition following in November 2000.", "Its publication was preceded by a novella called \"Path of the Dragon\", which collects some of the Daenerys Targaryen chapters from the novel into a single book.", "At the time of its publication, \"A Storm of Swords\" was the longest novel in the series.", "It was so long that in the UK, Australia, and Israel, its paperback edition was split in half, Part 1 being published as \"Steel and Snow\" in June 2001 (with the one-volume cover) and Part 2 as \"Blood and Gold\" in August 2001 (with a specially-commissioned new cover).", "The same division was used in the Polish and Greek editions.", "In France, the decision was made to cut the novel into four separate volumes.", "\"A Storm of Swords\" won the 2001 Locus Award, the 2002 Geffen Award for Best Novel and was nominated for the 2001 Nebula Award for Best Novel."], ["A Feast for Crows", "A Feast for Crows\n\nA Feast for Crows is the fourth of seven planned novels in the epic fantasy series \"A Song of Ice and Fire\" by American author George R. R. Martin.", "The novel was first published on October 17, 2005, in the United Kingdom, with a United States edition following on November 8, 2005.", "In May 2005, Martin announced that the \"sheer size\" of his still-unfinished manuscript for \"A Feast for Crows\" had led him and his publishers to split the narrative into two books.", "Rather than divide the text in half chronologically, Martin opted to instead split the material by character and location, resulting in \"two novels taking place simultaneously\" with different casts of characters.", "\"A Feast for Crows\" was published months later, and the concurrent novel \"A Dance with Dragons\" was released on July 12, 2011.", "Martin also noted that the \"A Song of Ice and Fire\" series would now likely total seven novels.", "\"A Feast for Crows\" was the first novel in the series to debut at number one on \"The New York Times\" Best Seller list, a feat among fantasy writers only previously achieved by Robert Jordan and Neil Gaiman.", "In 2006 the novel was nominated for the Hugo Award, the Locus Award, and the British Fantasy Society Award."]], "gold": "A Song of Ice and Fire is a series of epic fantasy novels by the American novelist and screenwriter George R. R. Martin. Book 3 of the A Song of Ice and Fire series was released in the US on November 2000. Book 3 was released in the UK on August 8, 2000. Book 4 of the A Song of Ice and Fire series was released in the US on October 17, 2005 and in the UK on November 8, 2005. Book 5 of the A Song of Ice and Fire series was released on July 12, 2011.", "prediction 1": "The last book in the epic fantasy series A Song of Ice and Fire was A Feast for Crows, which came out on October 17, 2005. The second book in the series, A Storm of Swords, came out on August 8, 2000, in the United Kingdom, with a United States edition coming out on November 8, 2005. The third book, A Feast for Crows, came out on August 9, 2000, in the United States. The fifth book, A Dance with Dragons, came out on July 12, 2011.", "prediction 2": "A Song of Ice and Fire is an ongoing series of epic fantasy novels by American novelist and screenwriter George R. R. Martin. The last book in the series, A Feast for Crows, came out on July 12, 2011. A Storm of Swords is the first of seven planned novels in A Song of Ice and Fire, a fantasy series by American author George R. R. Martin. A Feast for Crows was first published on October 17, 2005, in the United Kingdom, with a United States edition following on November 8, 2005. A Feast for Crows was published on July 15, 2012.", "prediction 3": "The last book in the Song of Ice and Fire series, A Game of Thrones, came out on December 8, 2016. A Feast for Crows came out on July 12, 2011 and A Storm of Swords came out on August 8, 2000.", "prediction 4": "A Song of Ice and Fire is an ongoing series of epic fantasy novels by American novelist and screenwriter George R. R. Martin. The first installment of the series, A Game of Thrones, was originally planned as a trilogy, and was published in 1996. The second installment, A Feast for Crows, was published on October 17, 2005. The third installment, A Storm of Swords, was published on August 8, 2000, in the United Kingdom, with a United States edition following in November 2000. A Dance with Dragons was released on July 12, 2011 and the fourth novel was released on July 12, 2011. The final volume was published on September 10, 2011 in the United States in July 12, 2011, with a concurrent novel called A Feast for Crows, which was published on August 8, 2001.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 68, "end": 121}, {"error type": "Irrelevant", "explanation": "", "start": 285, "end": 369}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 3, "sentence_id": [5]}], "corrected-prediction": "The second book in the series, A Storm of Swords, was published on August 8, 2000, in the United Kingdom, with a United States edition following in November 2000. The fourth book, A Feast for Crows, was published on October 17, 2005, in the United Kingdom, with a United States edition following on November 8, 2005. The last book in the epic fantasy series A Song of Ice and Fire, A Dance with Dragons, was released on July 12, 2011."}, "preference": [1, 1, 1, 2, 2, 2], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Themes in A Song of Ice and Fire\nS1. Themes in A Song of Ice and Fire  \"A Song of Ice and Fire\" is an ongoing series of epic fantasy novels by American novelist and screenwriter George R. R. Martin.\nS2. The first installment of the series, \"A Game of Thrones\", which was originally planned as a trilogy, was published in 1996.\nS3. The series now consists of five published volumes, and two more volumes are planned.\nS4. The series is told in the third-person through the eyes of a number of point of view characters.\nS5. A television series adaptation, \"Game of Thrones\", premiered on HBO in 2011.\nS6. \"A Song of Ice and Fire\" takes place in a fictional world, primarily on a continent called Westeros, and additionally on a large landmass to the east, known as Essos.\nS7. Three main story lines become increasingly interwoven: a dynastic civil war for control of Westeros among several competing families; the rising threat of the Others, who dwell beyond the immense wall of ice that forms Westeros's northern border; and the ambitions of Daenerys Targaryen, exiled daughter of the deposed king, to return to Westeros and claim her throne.\nS8. Martin has said he believes in \"judicious use of magic\" in epic fantasy.\n\nPassage 2: Title (S0) - A Storm of Swords\nS1. A Storm of Swords  A Storm of Swords is the third of seven planned novels in \"A Song of Ice and Fire\", a fantasy series by American author George R. R. Martin.\nS2. It was first published on August 8, 2000, in the United Kingdom, with a United States edition following in November 2000.\nS3. Its publication was preceded by a novella called \"Path of the Dragon\", which collects some of the Daenerys Targaryen chapters from the novel into a single book.\nS4. At the time of its publication, \"A Storm of Swords\" was the longest novel in the series.\nS5. It was so long that in the UK, Australia, and Israel, its paperback edition was split in half, Part 1 being published as \"Steel and Snow\" in June 2001 (with the one-volume cover) and Part 2 as \"Blood and Gold\" in August 2001 (with a specially-commissioned new cover).\nS6. The same division was used in the Polish and Greek editions.\nS7. In France, the decision was made to cut the novel into four separate volumes.\nS8. \"A Storm of Swords\" won the 2001 Locus Award, the 2002 Geffen Award for Best Novel and was nominated for the 2001 Nebula Award for Best Novel.\n\nPassage 3: Title (S0) - A Feast for Crows\nS1. A Feast for Crows  A Feast for Crows is the fourth of seven planned novels in the epic fantasy series \"A Song of Ice and Fire\" by American author George R. R. Martin.\nS2. The novel was first published on October 17, 2005, in the United Kingdom, with a United States edition following on November 8, 2005.\nS3. In May 2005, Martin announced that the \"sheer size\" of his still-unfinished manuscript for \"A Feast for Crows\" had led him and his publishers to split the narrative into two books.\nS4. Rather than divide the text in half chronologically, Martin opted to instead split the material by character and location, resulting in \"two novels taking place simultaneously\" with different casts of characters.\nS5. \"A Feast for Crows\" was published months later, and the concurrent novel \"A Dance with Dragons\" was released on July 12, 2011.\nS6. Martin also noted that the \"A Song of Ice and Fire\" series would now likely total seven novels.\nS7. \"A Feast for Crows\" was the first novel in the series to debut at number one on \"The New York Times\" Best Seller list, a feat among fantasy writers only previously achieved by Robert Jordan and Neil Gaiman.\nS8. In 2006 the novel was nominated for the Hugo Award, the Locus Award, and the British Fantasy Society Award.\n    \nInput Question:\nWhen did the last song of ice and fire book come out?\n\nCorrect Response:\nA Song of Ice and Fire is a series of epic fantasy novels by the American novelist and screenwriter George R. R. Martin. Book 3 of the A Song of Ice and Fire series was released in the US on November 2000. Book 3 was released in the UK on August 8, 2000. Book 4 of the A Song of Ice and Fire series was released in the US on October 17, 2005 and in the UK on November 8, 2005. Book 5 of the A Song of Ice and Fire series was released on July 12, 2011.\n\nModel Prediction:\nThe last book in the epic fantasy series A Song of Ice and Fire was A Feast for Crows, which came out on October 17, 2005. The second book in the series, A Storm of Swords, came out on August 8, 2000, in the United Kingdom, with a United States edition coming out on November 8, 2005. The third book, A Feast for Crows, came out on August 9, 2000, in the United States. The fifth book, A Dance with Dragons, came out on July 12, 2011.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "The last book in the epic fantasy series A Song of Ice and Fire was [A Feast for Crows, which came out on October 17, 2005]. The second book in the series, A Storm of Swords, came out on August 8, 2000, in the United Kingdom, with a United States edition coming out on November 8, 2005. [The third book, A Feast for Crows, came out on August 9, 2000, in the United States.] The fifth book, A Dance with Dragons, came out on July 12, 2011.\n\nExplanation:\n1. The first sentence is incorrect as the last book in the series is \"A Dance with Dragons\", not \"A Feast for Crows\". This is an \"Irrelevant\" error.\n2. The third sentence is incorrect as \"A Feast for Crows\" is the fourth book in the series, not the third. Also, the release date provided is incorrect. This is also an \"Irrelevant\" error."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The last book in the epic fantasy series A Song of Ice and Fire was A Feast for Crows, which came out on October 17, 2005.\nS2. The second book in the series, A Storm of Swords, came out on August 8, 2000, in the United Kingdom, with a United States edition coming out on November 8, 2005.\nS3. The third book, A Feast for Crows, came out on August 9, 2000, in the United States.\nS4. The fifth book, A Dance with Dragons, came out on July 12, 2011.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "Inconsistent or Unverifiable Sentences:\n1. S1\n2. S3\n\nExplanation:\n1. The first sentence is factually inconsistent with the passages. According to Passage 3, Sentence 5, the last book in the series is \"A Dance with Dragons\", not \"A Feast for Crows\".\n2. The third sentence is factually inconsistent with the passages. According to Passage 3, Sentence 2, \"A Feast for Crows\" was published on November 8, 2005 in the United States, not on August 9, 2000."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 3, sentence 5 [Missing Answer]\n\nExplanation:\n1. The model prediction is missing the release date of the actual last book in the series, \"A Dance with Dragons\", which is mentioned in Passage 3, Sentence 5. This is a \"Missing Answer\" error."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The second book in the series, A Storm of Swords, was published on August 8, 2000, in the United Kingdom, with a United States edition following in November 2000. The fourth book, A Feast for Crows, was published on October 17, 2005, in the United Kingdom, with a United States edition following on November 8, 2005. The last book in the epic fantasy series A Song of Ice and Fire, A Dance with Dragons, was released on July 12, 2011."}], "feedback_human": {"errors": [{"error type": "Wrong-Grounding", "explanation": "{\"passage_id\":3,\"sentence_id\":[1]}", "start": 4, "end": 8}, {"error type": "Wrong-Grounding", "explanation": "{\"passage_id\":2,\"sentence_id\":[2]}", "start": 267, "end": 284}, {"error type": "Wrong-Grounding", "explanation": "{\"passage_id\":3,\"sentence_id\":[1]}", "start": 289, "end": 294}, {"error type": "Redundant", "explanation": "The last book in the epic fantasy series A Song of Ice and Fire was A Feast for Crows, which came out on October 17, 2005. ", "start": 303, "end": 331}, {"error type": "Wrong-Grounding", "explanation": "{\"passage_id\":3,\"sentence_id\":[2]}", "start": 332, "end": 369}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 3, "sentence_id": [2]}, {"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [1]}], "corrected-prediction": "\"A Song of Ice and Fire\" is an ongoing series of epic fantasy novels by American novelist and screenwriter George R. R. Martin. The fourth book in the epic fantasy series A Song of Ice and Fire was A Feast for Crows, which came out on October 17, 2005 in the United Kingdom, with a United States edition following on November 8, 2005. The second book in the series, A Storm of Swords, came out on August 8, 2000, in the United Kingdom, with a United States edition following in November 2000. The fifth book, A Dance with Dragons, came out on July 12, 2011."}}, {"question": "Who is the football coach at georgia southern?", "passages": [["Georgia Southern Eagles football", "In addition to serving as safeties coach for Georgia Southern during the 2006 season under Brian VanGorder, Summers had previously served as defensive coordinator and safeties coach at Colorado State in 2015.", "During Summers' first season in 2016, Georgia Southern suffered its first losing season in the FBS era, and fourth overall in the modern era.", "Summers was fired on October 22, 2017 after starting the 2017 season with a six-game losing streak.", "Assistant head coach Chad Lunsford was initially appointed as interim head coach for the remainder of the season and was officially named head coach on November 27, 2017.", "Lunsford finished out the 2017 season at 2\u20134, giving the Eagles an overall record of 2\u201310, the worst record in the program's overall history, and the first time in the modern era that the Eagles posted back-to-back losing seasons.", "In Lunsford's first official season as head coach, he led the Eagles back to a winning record and bowl eligibility, finishing the regular season with a 9\u20133 record, with a 6\u20132 record in conference play.", "Georgia Southern defeated Eastern Michigan 23\u201321 in the Camellia Bowl on December 15, 2018, giving the Eagles their first 10-win season since the FCS-to-FBS transition.", "\u2020 Co-championship\n\nThe Eagles have participated in two bowl games with a record of 2\u20130."], ["Georgia Southern Eagles football", "In the Eagles' first FBS season, the team finished the season 9\u20133 overall and was undefeated in Sun Belt Conference play at 8\u20130, winning the outright conference championship.", "The Eagles became only the third team ever to win a conference title in its first FBS season, after Nevada in 1992 (Big West Conference) and Marshall in 1997 (Mid-American Conference).", "They were also the first team ever to go unbeaten in conference play in their first FBS season.", "Since the Eagles were under transitional status, the university filed for a postseason waiver to allow the Eagles to play in a bowl game; however, the NCAA denied Georgia Southern's waiver request and a subsequent appeal since enough full member FBS teams became bowl-eligible during the season.", "In the 2015 season, Fritz led the Eagles to an 8-4 record, receiving their first bowl bid to the GoDaddy Bowl on December 23, 2015 against Bowling Green.", "On December 11, 2015, Fritz resigned as the Eagles head coach to accept the head coaching position at Tulane University.", "Assistant head coach and running backs coach Dell McGee was appointed as interim head coach for the GoDaddy Bowl game, where Georgia Southern defeated Bowling Green 58\u201327.", "Tyson Summers was hired on December 21, 2015 to succeed Fritz."], ["Chad Lunsford", "Chad Lunsford\n\nChad Lunsford (born February 24, 1977) is the current head coach of the Georgia Southern Eagles football team.", "He was awarded the job on November 27th, 2017 after serving as interim for the second half of the season following the firing of Tyson Summers."], ["Tyson Summers", "Tyson Summers\n\nTyson Summers (born April 11, 1980) is a former American college football coach, most recently serving as the head coach of the Georgia Southern Eagles football team.", "He was named to the position at the end of the 2015 season.", "Summers was fired by Georgia Southern mid-way through the 2017 season, after posting an 0\u20136 start.", "He is currently the quality control coordinator at the University of Georgia.", "A four-year letterwinner at Presbyterian Blue Hose, Summers earned All-South Atlantic Conference honors as a linebacker in 1999 and was selected as team captain as a senior.", "He received his bachelor's degree in political science from Presbyterian in 2002.", "2016\nHead Coach for Georgia Southern; finished the season 5-7 after beginning the season 3-0. 2017\nLoses to FCS - New Hampshire University.", "First time since 1994 that Georgia Southern lost to an opponent in a lower division.", "In 2015, The Georgia Southern Eagles led the nation in Rushing.", "As for 2017, they opened up the season being last (#130) for yards-per-play.", "On October 22, midway through the 2017 season, he was fired from his position as Head Coach after an 0-6 start to the season, with the college stating \"the results on the field weren't where we needed them to be as we continue our growth as an FBS program.\""]], "gold": "Chad Lunsford is the current head coach of the Georgia Southern Eagles football team. He was awarded the job on November 27, 2017 after serving as interim for the second half of the season following the firing and departure of Tyson Summers, who was coach from 2016-2017. Willie Fritz was named Georgia Southern's ninth modern era head coach on January 10, 2014 and he led the team to win the outright conference championship that year. On December 11, 2015, Fritz resigned as the Eagles head coach and assistant head coach and running backs coach Dell McGee was briefly appointed as interim head coach until Tyson Summer became the new coach on the 21st of that month.", "prediction 1": "Tyson Summers, a former American college football coach, has been the head coach of the Georgia Southern Eagles football team since December 21, 2015. Summers was fired on October 22, 2017 after starting the 2017 season with a six-game losing streak. Assistant head coach Chad Lunsford was initially appointed as interim head coach for the remainder of the season and was officially named head coach on November 27, 2017. Lunsford finished out the 2017 season at 2\u20134, giving the Eagles an overall record of 2\u201310, the worst record in the program's overall history.", "prediction 2": "Tyson Summers was hired on December 21, 2015, as the head coach of the Georgia Southern Eagles football team. Summers was fired on October 22, 2017 after starting the 2017 season with a six-game losing streak. Assistant head coach Chad Lunsford was initially appointed as interim head coach for the remainder of the season and was officially named head coach on November 27, 2017. Lunsford finished out the 2017 season at 2\u20134, giving the Eagles an overall record of 2\u201310, the worst record in the program's overall history.", "prediction 3": "Tyson Summers was the head coach of the Georgia Southern Eagles football team during the 2015-2017 season. He was fired on October 22, 2017 after starting the 2017 season with a six-game losing streak. Chad Lunsford was initially appointed as interim head coach for the remainder of the season and was officially named head coach on November 27, 2017. In his first official season as head coach, Lunsford led the Eagles back to a winning record and bowl eligibility, finishing the regular season with a 9-3 record, with a 6\u20132 record in conference play. Lunsford was hired as interim head coach on November 27, 2017 after serving as interim head coach for the second half of the season following the firing of Tyson Summers.", "prediction 4": "Tyson Summers was hired as the head coach of the Georgia Southern Eagles football team in December 2015 after serving as the safeties coach for the team during the 2006 season under Brian VanGorder. Summers was fired on October 22, 2017 after starting the 2017 season with a six-game losing streak. Chad Lunsford was initially appointed as interim head coach for the remainder of the season and was officially named head coach on November 27, 2017.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 0, "end": 150}, {"error type": "Irrelevant", "explanation": "", "start": 422, "end": 563}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 3, "sentence_id": [1]}], "corrected-prediction": "Chad Lunsford is the current head coach of the Georgia Southern Eagles football team. He was initially appointed as interim head coach for the remainder of the season after Tyson Summers was fired on October 22, 2017, and was officially named head coach on November 27, 2017."}, "preference": [0, 1, 1, 1, 1, 1], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Georgia Southern Eagles football\nS1. In addition to serving as safeties coach for Georgia Southern during the 2006 season under Brian VanGorder, Summers had previously served as defensive coordinator and safeties coach at Colorado State in 2015.\nS2. During Summers' first season in 2016, Georgia Southern suffered its first losing season in the FBS era, and fourth overall in the modern era.\nS3. Summers was fired on October 22, 2017 after starting the 2017 season with a six-game losing streak.\nS4. Assistant head coach Chad Lunsford was initially appointed as interim head coach for the remainder of the season and was officially named head coach on November 27, 2017.\nS5. Lunsford finished out the 2017 season at 2\u20134, giving the Eagles an overall record of 2\u201310, the worst record in the program's overall history, and the first time in the modern era that the Eagles posted back-to-back losing seasons.\nS6. In Lunsford's first official season as head coach, he led the Eagles back to a winning record and bowl eligibility, finishing the regular season with a 9\u20133 record, with a 6\u20132 record in conference play.\nS7. Georgia Southern defeated Eastern Michigan 23\u201321 in the Camellia Bowl on December 15, 2018, giving the Eagles their first 10-win season since the FCS-to-FBS transition.\nS8. \u2020 Co-championship  The Eagles have participated in two bowl games with a record of 2\u20130.\n\nPassage 2: Title (S0) - Georgia Southern Eagles football\nS1. In the Eagles' first FBS season, the team finished the season 9\u20133 overall and was undefeated in Sun Belt Conference play at 8\u20130, winning the outright conference championship.\nS2. The Eagles became only the third team ever to win a conference title in its first FBS season, after Nevada in 1992 (Big West Conference) and Marshall in 1997 (Mid-American Conference).\nS3. They were also the first team ever to go unbeaten in conference play in their first FBS season.\nS4. Since the Eagles were under transitional status, the university filed for a postseason waiver to allow the Eagles to play in a bowl game; however, the NCAA denied Georgia Southern's waiver request and a subsequent appeal since enough full member FBS teams became bowl-eligible during the season.\nS5. In the 2015 season, Fritz led the Eagles to an 8-4 record, receiving their first bowl bid to the GoDaddy Bowl on December 23, 2015 against Bowling Green.\nS6. On December 11, 2015, Fritz resigned as the Eagles head coach to accept the head coaching position at Tulane University.\nS7. Assistant head coach and running backs coach Dell McGee was appointed as interim head coach for the GoDaddy Bowl game, where Georgia Southern defeated Bowling Green 58\u201327.\nS8. Tyson Summers was hired on December 21, 2015 to succeed Fritz.\n\nPassage 3: Title (S0) - Chad Lunsford\nS1. Chad Lunsford  Chad Lunsford (born February 24, 1977) is the current head coach of the Georgia Southern Eagles football team.\nS2. He was awarded the job on November 27th, 2017 after serving as interim for the second half of the season following the firing of Tyson Summers.\n\nPassage 4: Title (S0) - Tyson Summers\nS1. Tyson Summers  Tyson Summers (born April 11, 1980) is a former American college football coach, most recently serving as the head coach of the Georgia Southern Eagles football team.\nS2. He was named to the position at the end of the 2015 season.\nS3. Summers was fired by Georgia Southern mid-way through the 2017 season, after posting an 0\u20136 start.\nS4. He is currently the quality control coordinator at the University of Georgia.\nS5. A four-year letterwinner at Presbyterian Blue Hose, Summers earned All-South Atlantic Conference honors as a linebacker in 1999 and was selected as team captain as a senior.\nS6. He received his bachelor's degree in political science from Presbyterian in 2002.\nS7. 2016 Head Coach for Georgia Southern; finished the season 5-7 after beginning the season 3-0. 2017 Loses to FCS - New Hampshire University.\nS8. First time since 1994 that Georgia Southern lost to an opponent in a lower division.\nS9. In 2015, The Georgia Southern Eagles led the nation in Rushing.\nS10. As for 2017, they opened up the season being last (#130) for yards-per-play.\nS11. On October 22, midway through the 2017 season, he was fired from his position as Head Coach after an 0-6 start to the season, with the college stating \"the results on the field weren't where we needed them to be as we continue our growth as an FBS program.\"\n    \nInput Question:\nWho is the football coach at georgia southern?\n\nCorrect Response:\nChad Lunsford is the current head coach of the Georgia Southern Eagles football team. He was awarded the job on November 27, 2017 after serving as interim for the second half of the season following the firing and departure of Tyson Summers, who was coach from 2016-2017. Willie Fritz was named Georgia Southern's ninth modern era head coach on January 10, 2014 and he led the team to win the outright conference championship that year. On December 11, 2015, Fritz resigned as the Eagles head coach and assistant head coach and running backs coach Dell McGee was briefly appointed as interim head coach until Tyson Summer became the new coach on the 21st of that month.\n\nModel Prediction:\nTyson Summers, a former American college football coach, has been the head coach of the Georgia Southern Eagles football team since December 21, 2015. Summers was fired on October 22, 2017 after starting the 2017 season with a six-game losing streak. Assistant head coach Chad Lunsford was initially appointed as interim head coach for the remainder of the season and was officially named head coach on November 27, 2017. Lunsford finished out the 2017 season at 2\u20134, giving the Eagles an overall record of 2\u201310, the worst record in the program's overall history.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "[Tyson Summers, a former American college football coach, has been the head coach of the Georgia Southern Eagles football team since December 21, 2015.] Summers was fired on October 22, 2017 after starting the 2017 season with a six-game losing streak. Assistant head coach Chad Lunsford was initially appointed as interim head coach for the remainder of the season and was officially named head coach on November 27, 2017. [Lunsford finished out the 2017 season at 2\u20134, giving the Eagles an overall record of 2\u201310, the worst record in the program's overall history.]\n\nExplanation:\n1. The first sentence is irrelevant because the question asks for the current coach, not the former coach. \n2. The last sentence is also irrelevant because it provides information about the team's performance, not about the coach."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. Tyson Summers, a former American college football coach, has been the head coach of the Georgia Southern Eagles football team since December 21, 2015.\nS2. Summers was fired on October 22, 2017 after starting the 2017 season with a six-game losing streak.\nS3. Assistant head coach Chad Lunsford was initially appointed as interim head coach for the remainder of the season and was officially named head coach on November 27, 2017.\nS4. Lunsford finished out the 2017 season at 2\u20134, giving the Eagles an overall record of 2\u201310, the worst record in the program's overall history.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "Inconsistent or Unverifiable Sentences:\n1. S1\n\nExplanation:\n1. The first sentence is inconsistent with the passages. According to Passage 3, Sentence 2, Chad Lunsford is the current head coach of the Georgia Southern Eagles football team, not Tyson Summers."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 3, sentence 1 [Missing Answer]\n\nExplanation:\n1. The model prediction does not mention that Chad Lunsford is the current head coach of the Georgia Southern Eagles football team, which is a direct answer to the question. This information is found in Passage 3, Sentence 1."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "Chad Lunsford is the current head coach of the Georgia Southern Eagles football team. He was initially appointed as interim head coach for the remainder of the season after Tyson Summers was fired on October 22, 2017, and was officially named head coach on November 27, 2017."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 15, "end": 56}, {"error type": "Irrelevant", "explanation": "", "start": 189, "end": 250}, {"error type": "Irrelevant", "explanation": "", "start": 422, "end": 563}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 2, "sentence_id": [5, 6]}, {"error type": "Missing-Answer", "passage_id": 2, "sentence_id": [7]}], "corrected-prediction": "Tyson Summers has been the head coach of the Georgia Southern Eagles football team since December 21, 2015. Summers was fired on October 22, 2017. Assistant head coach Chad Lunsford was initially appointed as interim head coach for the remainder of the season and was officially named head coach on November 27, 2017. Fritz was the head coach in the 2015 season; on December 11, 2015, Fritz resigned as the Eagles head coach. Assistant head coach and running backs coach Dell McGee was appointed as interim head coach."}}, {"question": "Who is the guy in the take on me video?", "passages": [["Take On Me", "It was filmed in 1985 at Kim's Caf\u00e9 (now called Savoy Caf\u00e9) (on Wandsworth Road, London SW8), and on a sound stage in London.", "The video used a pencil-sketch animation / live-action combination called rotoscoping, in which the live-action footage is traced over frame by frame to give the characters realistic movements.", "Approximately 3,000 frames were rotoscoped, which took 16 weeks to complete.", "The video's main theme is a romantic fantasy narrative.", "It begins with a montage of pencil drawings in a comic-book style representing motorcycle sidecar racing, in which the hero, played by Morten Harket, is pursued by two opponents, one of whom is played by English actor Philip Jackson.", "It then cuts to a scene in a cafe, in which a young woman, played by Bunty Bailey (Harket's girlfriend at the time), is seen drinking coffee and reading the comic book in a coffee shop.", "As the woman reads, the waitress brings her the bill.", "The comic's hero, after winning the race, seemingly winks at the woman from the page.", "His pencil-drawn hand reaches out of the comic book, inviting the woman into it."], ["Synth-pop", "Pursuing a more dance-orientated sound were Bronski Beat whose album \"The Age of Consent\" (1984), dealing with issues of homophobia and alienation, reached the top 20 in the UK and top 40 in the US. and Thompson Twins, whose popularity peaked in 1984 with the album \"Into The Gap\", which reached No.1 in the UK and the US top ten and spawned several top ten singles.", "Initially dismissed in the music press as a \"teeny bop sensation\" were Norwegian band a-ha, whose use of guitars and real drums produced an accessible form of synth-pop, which, along with an MTV friendly video, took their 1985 single \"Take On Me\" to number two in the UK and number one in the US.", "Synth-pop continued into the late 1980s, with a format that moved closer to dance music, including the work of acts such as British duos Pet Shop Boys, Erasure and the Communards.", "The Communards' major hits were covers of disco classics \"Don't Leave Me This Way\" (1986) and \"Never Can Say Goodbye\" (1987).", "After adding other elements to their sound, and with the help of a gay audience, several synth-pop acts had success on the US dance charts."], ["Steve Barron", "Steve Barron\n\nSteven Barron (born 4 May 1956) is an Irish film director, film producer, writer, and music video director.", "He is best known for directing the films \"Teenage Mutant Ninja Turtles\" (1990), \"Coneheads\" (1993) and the innovative music videos for a-ha's \"Take on Me\" and Michael Jackson's \"Billie Jean\".", "Barron was born in Dublin, Ireland, the younger child of jewish filmmaker Zelda Ruth (n\u00e9e Solomons) Barron (1929\u20132006) and actor Ron Barron, who met in London.", "Zelda and Ron married in 1953; the marriage was later dissolved.", "His mother was a Manchester-born filmmaker.", "He has an older sister, Siobhan.", "He attended St Marylebone Grammar School in London.", "Barron made his music video directorial debut in 1979 with \"Time for Action\" by Secret Affair and their following hit singles \"My World\" and \"Sound of Confusion\" and directed, and occasionally wrote additional treatment, various music videos, including \"Billie Jean\" by Michael Jackson, \"Money for Nothing\" by Dire Straits, and \"Take on Me\" by a-ha.", "He founded the production company Limelight with his sister Siobhan and Adam Whitaker."], ["Breaking Out Is Hard to Do", "Lois pulls Joe to safety, and in gratitude, Joe manages to get Lois' sentence cancelled, and life returns to normal for the family.", "\"Breaking Out Is Hard to Do\" is the first \"Family Guy\" episode to be written by Tom Devanney.", "When Stewie attempts to asphyxiate himself in the supermarket, he was originally meant to state \"Either I was a C-section or you're Stretch Vagstrong\", which would have been a reference to the Stretch Armstrong action figure, but broadcasting standards prohibited them from showing it.", "During the \"Take On Me\" sequence, \"Family Guy\" had obtained full rights to use the \"Take On Me\" music video completely, but animators re-produced the video to make it easier for production.", "Originally, a joke had been drafted showing Brian standing next to a tabloid newspaper with a picture of Kirstie Alley and commenting on her weight, only for her to enter the grocery shop in Godzilla-like size and throw items from the shelves, but the sketch was removed to save time during the episode.", "The Matisse painting shown in the Griffins' dining room is only animated similar to an actual Matisse painting due to a legal issue with the paintings.", "The episode production staff spent a lot of time deciding what would be Lois' motivation for stealing en masse."], ["Call on Me (Eric Prydz song)", "The music video for \"Call on Me\", directed by Huse Monfaradi, features an aerobics class of women wearing 1980s styled aerobics outfits performing sexually suggestive gym routines led by dancer and choreographer Deanne Berry, who is wearing a thong leotard \u2013 much to the enjoyment of the sole man in the group, played by Juan Pablo Di Pace.", "The video was filmed in the Laban Dance Centre in Deptford, England and spoofs a scene in the 1985 film \"Perfect\" starring John Travolta and Jamie Lee Curtis.", "In late 2004, while being interviewed by Chris Evans for UK Radio Aid, a 12-hour fundraising broadcast for tsunami victims, the then Prime Minister of the United Kingdom Tony Blair said: \"The first time it came on, I nearly fell off my rowing machine.\"", "Vice Media via their Thump website would go on to call the video the \"Sexiest Music Video of All Time\" There are two videos\u2014an edited one shown in daylight hours and a late night version which is uncut and features the dancers rubbing their breasts and one dancer slapping her buttocks.", "The video was the highest-downloaded music video of all time in Australia, downloaded over 35,000 times through 3 Mobile mobile phones with 3G technology in association with the \"Rage\" music television show."]], "gold": "In the second and far more widely-recognized music video for the A-ha song \"Take On Me\", the hero of the video's romantic fantasy narrative is played by Morten Harket, whose character is pursued by two opponents, played by Philip Jackson and Alife Curtis. When Family Guy reproduced the video for its episode \"Breaking Out Is Hard to Do\", the hero is portrayed by Seth Green as Chris Griffin.", "prediction 1": "The 1985 synth-pop music video \"Take On Me\" starred English actor Philip Jackson as the hero. The video's main theme is a romantic fantasy narrative. The hero in the video is Morten Harket, who is seen riding a motorcycle and winning a sidecar race. The music video was directed by Steve Barron, an Irish film director, film producer, writer, and music video director.\n", "prediction 2": "The 1985 synth-pop music video for a-ha's \"Take on Me\" features an ensemble cast of multi-talented characters in dialogue and dramatic moments of intense physical combat, with the main character played by Norwegian actor Morten Harket. The episode Star Trek: The Next Generation premier premiered on April 1, 1985 and produced by Sony Music Video.", "prediction 3": "The guy in the 1985 video, Take On Me, is English actor Philip Jackson.", "prediction 4": "The 1985 music video by English synth-pop band a-ha, titled \"Take On Me,\" features live action stunts with performers like American cyclist Ne Neeson, who plays the character of Ricky Lee Jones, Morven Harket, and George Clooney as Ringo Starr.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 52, "end": 92}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [6]}], "corrected-prediction": "The 1985 synth-pop music video \"Take On Me\" stars Morten Harket as the hero. The video's main theme is a romantic fantasy narrative. The hero in the video is seen riding a motorcycle and winning a sidecar race. In a scene in a cafe, a young woman, played by Bunty Bailey, is seen reading a comic book featuring the hero."}, "preference": [1, 1, 1, 1, 1, 0], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Take On Me\nS1. It was filmed in 1985 at Kim's Caf\u00e9 (now called Savoy Caf\u00e9) (on Wandsworth Road, London SW8), and on a sound stage in London.\nS2. The video used a pencil-sketch animation / live-action combination called rotoscoping, in which the live-action footage is traced over frame by frame to give the characters realistic movements.\nS3. Approximately 3,000 frames were rotoscoped, which took 16 weeks to complete.\nS4. The video's main theme is a romantic fantasy narrative.\nS5. It begins with a montage of pencil drawings in a comic-book style representing motorcycle sidecar racing, in which the hero, played by Morten Harket, is pursued by two opponents, one of whom is played by English actor Philip Jackson.\nS6. It then cuts to a scene in a cafe, in which a young woman, played by Bunty Bailey (Harket's girlfriend at the time), is seen drinking coffee and reading the comic book in a coffee shop.\nS7. As the woman reads, the waitress brings her the bill.\nS8. The comic's hero, after winning the race, seemingly winks at the woman from the page.\nS9. His pencil-drawn hand reaches out of the comic book, inviting the woman into it.\n\nPassage 2: Title (S0) - Synth-pop\nS1. Pursuing a more dance-orientated sound were Bronski Beat whose album \"The Age of Consent\" (1984), dealing with issues of homophobia and alienation, reached the top 20 in the UK and top 40 in the US. and Thompson Twins, whose popularity peaked in 1984 with the album \"Into The Gap\", which reached No.1 in the UK and the US top ten and spawned several top ten singles.\nS2. Initially dismissed in the music press as a \"teeny bop sensation\" were Norwegian band a-ha, whose use of guitars and real drums produced an accessible form of synth-pop, which, along with an MTV friendly video, took their 1985 single \"Take On Me\" to number two in the UK and number one in the US.\nS3. Synth-pop continued into the late 1980s, with a format that moved closer to dance music, including the work of acts such as British duos Pet Shop Boys, Erasure and the Communards.\nS4. The Communards' major hits were covers of disco classics \"Don't Leave Me This Way\" (1986) and \"Never Can Say Goodbye\" (1987).\nS5. After adding other elements to their sound, and with the help of a gay audience, several synth-pop acts had success on the US dance charts.\n\nPassage 3: Title (S0) - Steve Barron\nS1. Steve Barron  Steven Barron (born 4 May 1956) is an Irish film director, film producer, writer, and music video director.\nS2. He is best known for directing the films \"Teenage Mutant Ninja Turtles\" (1990), \"Coneheads\" (1993) and the innovative music videos for a-ha's \"Take on Me\" and Michael Jackson's \"Billie Jean\".\nS3. Barron was born in Dublin, Ireland, the younger child of jewish filmmaker Zelda Ruth (n\u00e9e Solomons) Barron (1929\u20132006) and actor Ron Barron, who met in London.\nS4. Zelda and Ron married in 1953; the marriage was later dissolved.\nS5. His mother was a Manchester-born filmmaker.\nS6. He has an older sister, Siobhan.\nS7. He attended St Marylebone Grammar School in London.\nS8. Barron made his music video directorial debut in 1979 with \"Time for Action\" by Secret Affair and their following hit singles \"My World\" and \"Sound of Confusion\" and directed, and occasionally wrote additional treatment, various music videos, including \"Billie Jean\" by Michael Jackson, \"Money for Nothing\" by Dire Straits, and \"Take on Me\" by a-ha.\nS9. He founded the production company Limelight with his sister Siobhan and Adam Whitaker.\n\nPassage 4: Title (S0) - Breaking Out Is Hard to Do\nS1. Lois pulls Joe to safety, and in gratitude, Joe manages to get Lois' sentence cancelled, and life returns to normal for the family.\nS2. \"Breaking Out Is Hard to Do\" is the first \"Family Guy\" episode to be written by Tom Devanney.\nS3. When Stewie attempts to asphyxiate himself in the supermarket, he was originally meant to state \"Either I was a C-section or you're Stretch Vagstrong\", which would have been a reference to the Stretch Armstrong action figure, but broadcasting standards prohibited them from showing it.\nS4. During the \"Take On Me\" sequence, \"Family Guy\" had obtained full rights to use the \"Take On Me\" music video completely, but animators re-produced the video to make it easier for production.\nS5. Originally, a joke had been drafted showing Brian standing next to a tabloid newspaper with a picture of Kirstie Alley and commenting on her weight, only for her to enter the grocery shop in Godzilla-like size and throw items from the shelves, but the sketch was removed to save time during the episode.\nS6. The Matisse painting shown in the Griffins' dining room is only animated similar to an actual Matisse painting due to a legal issue with the paintings.\nS7. The episode production staff spent a lot of time deciding what would be Lois' motivation for stealing en masse.\n\nPassage 5: Title (S0) - Call on Me (Eric Prydz song)\nS1. The music video for \"Call on Me\", directed by Huse Monfaradi, features an aerobics class of women wearing 1980s styled aerobics outfits performing sexually suggestive gym routines led by dancer and choreographer Deanne Berry, who is wearing a thong leotard \u2013 much to the enjoyment of the sole man in the group, played by Juan Pablo Di Pace.\nS2. The video was filmed in the Laban Dance Centre in Deptford, England and spoofs a scene in the 1985 film \"Perfect\" starring John Travolta and Jamie Lee Curtis.\nS3. In late 2004, while being interviewed by Chris Evans for UK Radio Aid, a 12-hour fundraising broadcast for tsunami victims, the then Prime Minister of the United Kingdom Tony Blair said: \"The first time it came on, I nearly fell off my rowing machine.\"\nS4. Vice Media via their Thump website would go on to call the video the \"Sexiest Music Video of All Time\" There are two videos\u2014an edited one shown in daylight hours and a late night version which is uncut and features the dancers rubbing their breasts and one dancer slapping her buttocks.\nS5. The video was the highest-downloaded music video of all time in Australia, downloaded over 35,000 times through 3 Mobile mobile phones with 3G technology in association with the \"Rage\" music television show.\n    \nInput Question:\nWho is the guy in the take on me video?\n\nCorrect Response:\nIn the second and far more widely-recognized music video for the A-ha song \"Take On Me\", the hero of the video's romantic fantasy narrative is played by Morten Harket, whose character is pursued by two opponents, played by Philip Jackson and Alife Curtis. When Family Guy reproduced the video for its episode \"Breaking Out Is Hard to Do\", the hero is portrayed by Seth Green as Chris Griffin.\n\nModel Prediction:\nThe 1985 synth-pop music video \"Take On Me\" starred English actor Philip Jackson as the hero. The video's main theme is a romantic fantasy narrative. The hero in the video is Morten Harket, who is seen riding a motorcycle and winning a sidecar race. The music video was directed by Steve Barron, an Irish film director, film producer, writer, and music video director.\n\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "The 1985 synth-pop music video \"Take On Me\" starred [English actor Philip Jackson as the hero]. The video's main theme is a romantic fantasy narrative. The hero in the video is Morten Harket, who is seen riding a motorcycle and winning a sidecar race. The music video was directed by Steve Barron, an Irish film director, film producer, writer, and music video director.\n\nExplanation:\nThe first sentence is incorrect as Philip Jackson is not the hero in the video, Morten Harket is. This is an \"Inconsistent Fact\". The information about Steve Barron, while true, is not relevant to the question and is therefore marked as \"Irrelevant\". The question asks about the actor, not the director."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 1985 synth-pop music video \"Take On Me\" starred English actor Philip Jackson as the hero.\nS2. The video's main theme is a romantic fantasy narrative.\nS3. The hero in the video is Morten Harket, who is seen riding a motorcycle and winning a sidecar race.\nS4. The music video was directed by Steve Barron, an Irish film director, film producer, writer, and music video director.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "Inconsistent or Unverifiable Sentences:\n1. S1\n\nExplanation:\n1. The first sentence is factually inconsistent with the passages. Passage 1, sentence 5 clearly states that the hero in the video is played by Morten Harket, not English actor Philip Jackson."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 6 [Missing Major Auxiliary Information]\n\nExplanation:\n1. The model prediction fails to mention the role of Bunty Bailey, who played a significant part in the video as the young woman in the cafe. This information is crucial to understanding the narrative of the video and the role of the hero, Morten Harket."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The 1985 synth-pop music video \"Take On Me\" stars Morten Harket as the hero. The video's main theme is a romantic fantasy narrative. The hero in the video is seen riding a motorcycle and winning a sidecar race. In a scene in a cafe, a young woman, played by Bunty Bailey, is seen reading a comic book featuring the hero."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 0, "end": 30}, {"error type": "Wrong-Grounding", "explanation": "{\"passage_id\":1,\"sentence_id\":[5]}", "start": 84, "end": 93}, {"error type": "Irrelevant", "explanation": "", "start": 190, "end": 249}, {"error type": "Irrelevant", "explanation": "", "start": 250, "end": 369}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [5]}, {"error type": "Missing-Minor-Auxiliary", "passage_id": 2, "sentence_id": [2]}, {"error type": "Missing-Minor-Auxiliary", "passage_id": 4, "sentence_id": [2, 4]}], "corrected-prediction": "A-ha's \"Take On Me\" main theme is a romantic fantasy narrative. The hero in the video is Morten Harket, is pursued by two opponents, one of whom is played by English actor Philip Jackson. Family Guy had a \"Take on Me\" sequence in their episode, \"Breaking Out Is Hard to Do\"."}}, {"question": "Who sings i just want to use your love?", "passages": [["Sweet Kisses", "\"Betcha She Don't Love You\" is an uptempo pop-rock track, which also features influences of Hip-Hop and R&B. The songs lyrics see Simpson trying to convince a boy that she could love him more than his current girlfriend, as Simpson feels that nobody could love him the way she does.", "'My Wonderful' is a love ballad, which is moderately paced through the verses, while slow at the chorus.", "The song speaks of Simpson talking about how much she loves her boyfriend, and how he must have been \"sent from above just for [her].\"", "\"Sweet Kisses\", the album's title track, is a love ballad similar to the previous song.", "The song features an acoustic guitar playing over a soft R&B inspired beat.", "The song lyrically deals with how Simpson loves her boyfriend's \"sweet kisses\", and how he does not even need to say he loves her, because his kisses \"move her.\"", "\"Your Faith In Me\" is another pop ballad, which plays with many instruments such as a violin and piano.", "Lyrically, the song sees Simpson stating she doesn't need love, but she just needs her lover's \"faith in her\"."], ["Ur So Gay (EP)", "Ur So Gay (EP)\n\n", "Ur So Gay is the debut extended play (EP) by American singer Katy Perry.", "It was released digitally on November 20, 2007 by Capitol Records.", "A physical edition of the EP was released on January 15, 2008.", "The EP contains four tracks: the title track \"Ur So Gay\", a remix of the title track by American DJ Junior Sanchez, \"Use Your Love\" (a remake of The Outfield's 1986 song \"Your Love\"), and \"Lost\".", "\"Ur So Gay\" and \"Lost\" would later appear on Perry's second studio album, \"One of the Boys\" (2008).", "According to Perry, she had a couple of different choices in mind for covers.", "She initially wanted to record a Queen song, but could not think of one that was particularly club-worthy.", "While at a club with her friends, The Outfield's song \"Your Love\" was played.", "Perry said that when the song came on, every girl there went onto the dance floor and had \"the best time\", which is something that she wanted to capture on the EP.", "The EP was not expected to be a huge seller and only \"a few thousand\" copies were sold."]], "gold": "Your Love is a 1986 song by the English rock band The Outfield. This song is an up-tempo new wave, power pop and pop rock song sung by lead vocalist Tony Lewis. The song's lyrics are vague but imply that the narrator is interested in an older girl with whom he isn't in a relationship. The narrator asks the older girl to let him use her love; or have a one night stand with him, while his current girlfriend, Josie, is on vacation. In the end, the older girl declines because she wants him to be faithful to Josie. Additionally, Ur So Gay, the first extended play by American singer Katy Perry, includes the song Use Your Love, a remake of The Outfield's 1986 song. Perry's remake, Use Your Love, was released digitally on November 20, 2007.", "prediction 1": "American singer Katy Perry sang \"I Just Want to Use Your Love\", a cover of The Outfield's 1986 song Your Love.", "prediction 2": "\"Ur So Gay\" is the debut extended play (EP) by American singer Katy Perry. The EP contains 4 tracks: the title track, a remix of the title track by American DJ Junior Sanchez, \"Use Your Love\" (a remake of The Outfield's 1986 song \"Your Love\"), and \"Lost\".", "prediction 3": "The Outfield sang \"I just want to use your love\" in 1986, while Katy Perry sang \"I Just Want To Use Your Love\" in 1986.", "prediction 4": "American singer Katy Perry sings the song i just want to use your love in her debut extended play. The song is a remake of The Outfield's 1986 song, Your Love. American singer Junior Sanchez sings the song.", "feedback": {"errors": [], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 2, "sentence_id": [5]}], "corrected-prediction": "American singer Katy Perry sang \"Use Your Love\", a remake of The Outfield's 1986 song \"Your Love\". The song was included in her debut extended play (EP) \"Ur So Gay\", which was released digitally on November 20, 2007, and physically on January 15, 2008."}, "preference": [2, 0, 2, 1, 0, 2], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Sweet Kisses\nS1. \"Betcha She Don't Love You\" is an uptempo pop-rock track, which also features influences of Hip-Hop and R&B. The songs lyrics see Simpson trying to convince a boy that she could love him more than his current girlfriend, as Simpson feels that nobody could love him the way she does.\nS2. 'My Wonderful' is a love ballad, which is moderately paced through the verses, while slow at the chorus.\nS3. The song speaks of Simpson talking about how much she loves her boyfriend, and how he must have been \"sent from above just for [her].\"\nS4. \"Sweet Kisses\", the album's title track, is a love ballad similar to the previous song.\nS5. The song features an acoustic guitar playing over a soft R&B inspired beat.\nS6. The song lyrically deals with how Simpson loves her boyfriend's \"sweet kisses\", and how he does not even need to say he loves her, because his kisses \"move her.\"\nS7. \"Your Faith In Me\" is another pop ballad, which plays with many instruments such as a violin and piano.\nS8. Lyrically, the song sees Simpson stating she doesn't need love, but she just needs her lover's \"faith in her\".\n\nPassage 2: Title (S0) - Ur So Gay (EP)\nS1. Ur So Gay (EP)  \nS2. Ur So Gay is the debut extended play (EP) by American singer Katy Perry.\nS3. It was released digitally on November 20, 2007 by Capitol Records.\nS4. A physical edition of the EP was released on January 15, 2008.\nS5. The EP contains four tracks: the title track \"Ur So Gay\", a remix of the title track by American DJ Junior Sanchez, \"Use Your Love\" (a remake of The Outfield's 1986 song \"Your Love\"), and \"Lost\".\nS6. \"Ur So Gay\" and \"Lost\" would later appear on Perry's second studio album, \"One of the Boys\" (2008).\nS7. According to Perry, she had a couple of different choices in mind for covers.\nS8. She initially wanted to record a Queen song, but could not think of one that was particularly club-worthy.\nS9. While at a club with her friends, The Outfield's song \"Your Love\" was played.\nS10. Perry said that when the song came on, every girl there went onto the dance floor and had \"the best time\", which is something that she wanted to capture on the EP.\nS11. The EP was not expected to be a huge seller and only \"a few thousand\" copies were sold.\n    \nInput Question:\nWho sings i just want to use your love?\n\nCorrect Response:\nYour Love is a 1986 song by the English rock band The Outfield. This song is an up-tempo new wave, power pop and pop rock song sung by lead vocalist Tony Lewis. The song's lyrics are vague but imply that the narrator is interested in an older girl with whom he isn't in a relationship. The narrator asks the older girl to let him use her love; or have a one night stand with him, while his current girlfriend, Josie, is on vacation. In the end, the older girl declines because she wants him to be faithful to Josie. Additionally, Ur So Gay, the first extended play by American singer Katy Perry, includes the song Use Your Love, a remake of The Outfield's 1986 song. Perry's remake, Use Your Love, was released digitally on November 20, 2007.\n\nModel Prediction:\nAmerican singer Katy Perry sang \"I Just Want to Use Your Love\", a cover of The Outfield's 1986 song Your Love.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "American singer Katy Perry sang \"I Just Want to Use Your Love\", a cover of The Outfield's 1986 song Your Love.\n\nExplanation: There are no irrelevant, incoherent, or repetitive spans in the model prediction. The information provided is relevant to the question, coherent, and not repeated."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. American singer Katy Perry sang \"I Just Want to Use Your Love\", a cover of The Outfield's 1986 song Your Love.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "S1\n\nExplanation:\nThe song title in the model prediction is incorrect. According to Passage 2 Sentence 5, the song Katy Perry covered is called \"Use Your Love\", not \"I Just Want to Use Your Love\". This is an \"Inconsistent Fact\"."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 2, sentence 5 [Missing Major Auxiliary Information]\n2. Passage 2, sentence 3 [Missing Minor Auxiliary Information]\n3. Passage 2, sentence 4 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. The model prediction is missing the information that \"Use Your Love\" is a remake of The Outfield's 1986 song \"Your Love\". This is a major piece of auxiliary information that helps to understand the context of the song.\n2. The model prediction does not mention that the song was released digitally on November 20, 2007. This is minor auxiliary information that provides additional context about the song's release.\n3. The model prediction also does not mention that a physical edition of the EP was released on January 15, 2008. This is another piece of minor auxiliary information that provides further context about the song's release."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "American singer Katy Perry sang \"Use Your Love\", a remake of The Outfield's 1986 song \"Your Love\". The song was included in her debut extended play (EP) \"Ur So Gay\", which was released digitally on November 20, 2007, and physically on January 15, 2008."}], "feedback_human": {"errors": [], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 2, "sentence_id": [3]}], "corrected-prediction": "American singer Katy Perry sang \"I Just Want to Use Your Love\", a cover of The Outfield's 1986 song Your Love. It was released digitally on November 20, 2007 by Capitol Records."}}, {"question": "When do babies start breathing on their own?", "passages": [], "gold": "Babies start taking practice breaths at 10-12 weeks gestation. They take their first real breath within 10 seconds of birth.", "prediction 1": "When do babies start breathing on their own?", "prediction 2": "When do babies start breathing on their own?", "prediction 3": "When do babies start breathing on their own?", "prediction 4": "When do babies start breathing on their own?", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 0, "end": 44}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 1, "sentence_id": [1]}], "corrected-prediction": "Babies start taking practice breaths at 10-12 weeks gestation. They take their first real breath within 10 seconds of birth."}, "preference": [0, 0, 0, 0, 0, 0], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\n\n    \nInput Question:\nWhen do babies start breathing on their own?\n\nCorrect Response:\nBabies start taking practice breaths at 10-12 weeks gestation. They take their first real breath within 10 seconds of birth.\n\nModel Prediction:\nWhen do babies start breathing on their own?\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "[When do babies start breathing on their own?]\n\nExplanation:\nThe model prediction is simply repeating the question, which is irrelevant to providing an answer."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. When do babies start breathing on their own?\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation:\nThe model prediction does not provide any factual information, so there are no inconsistent or unverifiable facts."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 1 [Missing Answer]\n2. Passage 1, sentence 2 [Missing Major Auxiliary Information]\n\nExplanation:\n1. The model prediction does not provide an answer to the question, which is missing from Passage 1, sentence 1.\n2. The model prediction also lacks the major auxiliary information about babies taking their first real breath within 10 seconds of birth, which is found in Passage 1, sentence 2."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "Babies start taking practice breaths at 10-12 weeks gestation. They take their first real breath within 10 seconds of birth."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 0, "end": 44}], "missing-info": [], "corrected-prediction": ""}}, {"question": "How many episodes in marvels runaways season 1?", "passages": [["Runaways (TV series)", "Filming on the pilot began in Los Angeles in February 2017.", "The series was officially ordered by Hulu in May 2017.", "The first season was released from November 21, 2017, to January 9, 2018.", "In January 2018, \"Runaways\" was renewed for a 13-episode second season, which is scheduled to be released in its entirety on December 21, 2018.", "Six teenagers from different backgrounds unite against a common enemy \u2013 their criminal parents, collectively known as the Pride.", "In the second season, the teenagers are now on the run from their parents, living on their own and figuring out how to stop the Pride, before learning there may be a mole among them who contacts Jonah, the leader of Pride, aiding his dangerous plan.", "Old Lace, a genetically engineered \"Deinonychus\" telepathically linked with Gert Yorkes, appears in the series.", "The character is portrayed by a puppet that was operated by six people, including one person pumping air through the puppet to show the dinosaur breathing.", "Barer called the puppet \"incredible ...", "You see her emotions.", "We don't not make use of that.\"", "Stan Lee makes a cameo appearance as a limo driver.", "Brian K. Vaughan was hired to write a screenplay for Marvel Studios in May 2008, based on his comic book \"Runaways\"."], ["Runaways (TV series)", "Runaways (TV series)\n\nMarvel's Runaways, or simply Runaways, is an American web television series created for Hulu by Josh Schwartz and Stephanie Savage, based on the Marvel Comics superhero team of the same name.", "It is set in the Marvel Cinematic Universe (MCU), sharing continuity with the films and other television series of the franchise.", "The series is produced by ABC Signature Studios, Marvel Television and Fake Empire Productions, with Schwartz and Savage serving as showrunners.", "Rhenzy Feliz, Lyrica Okano, Virginia Gardner, Ariela Barer, Gregg Sulkin, and Allegra Acosta star as the Runaways, six teenagers from different backgrounds who unite against their parents, the Pride, portrayed by Angel Parker, Ryan Sands, Annie Wersching, Kip Pardue, Ever Carradine, James Marsters, Brigid Brannagh, Kevin Weisman, Brittany Ishibashi, and James Yaegashi.", "A film from Marvel Studios based on the \"Runaways\" began development in May 2008, before being shelved in 2013 due to the success of \"The Avengers\".", "In August 2016, Marvel Television announced that \"Runaways\" had received a pilot order from Hulu, after being developed and written by Schwartz and Savage.", "Casting for the Runaways and the Pride were revealed in February 2017."], ["Runaways (TV series)", "Marvel's position is everything is connected, but our show is trying to walk that line where the reality our kids are facing, they are facing for the first time.\"", "He also said they \"were very capable of telling the story that we wanted to tell independent of any of the other Marvel stories that are out there.\"", "Loeb added that there were no plans to crossover across networks with the similarly themed \"Cloak & Dagger\" on Freeform and \"New Warriors\", as Marvel wanted the series to find its footing before further connecting with other elements of the universe, though \"You'll see things that comment on each other; we try to touch base wherever we can... things that are happening in L.A. are not exactly going to be affecting what's happening in New Orleans [where \"Cloak & Dagger\" is set]...", "It's being aware of it and trying to find a way [to connect] that makes sense.\"", "Speaking to the second season, Schwartz said there would be a reference late in the season \"that will probably be our first real bread crumb that connects to the MCU.\"", "\"Runaways\" premiered its first three episodes on Hulu in the United States on November 21, 2017, with the first season consisting of 10 episodes, and concluding on January 9, 2018."]], "gold": "The superhero TV series Marvel's Runaways ran for a total of three seasons and 33 episodes, all of which aired on the streaming service Hulu. The first season of 10 episodes was released on November 21, 2017. The second season of 13 episodes was released on December 21, 2018, and the third season of 10 episodes was released on December 13, 2019.", "prediction 1": "Marvel's Runaways, or simply Runaways, is an American web television series created for Hulu by Josh Schwartz and Stephanie Savage, based on the Marvel Comics superhero team of the same name. The first three episodes of the first season were released on Hulu in the United States on November 21, 2017. The first 10 episodes of the second season were released on Hulu in the United States on January 9, 2018.", "prediction 2": "Marvel's Runaways, or simply Runaways, is an American web television series created for Hulu by Josh Schwartz and Stephanie Savage, based on the Marvel Comics superhero team of the same name. The series premiered its first three episodes on Hulu in the United States on November 21, 2017, with the first season consisting of 10 episodes, and concluding on January 9, 2018. In January 2018, Marvel's Runaways was renewed for a 13-episode second season, which is scheduled to be released in its entirety on December 21, 2018.", "prediction 3": "Marvel's Runaways, or simply Runaways, is an American web television series created for Hulu by Josh Schwartz and Stephanie Savage, based on the Marvel Comics superhero team of the same name. The first season consisted of 10 episodes, and concluded on January 9, 2018. In January 2018, \"Runaways\" was renewed for a 13-episode second season, which is scheduled to be released in its entirety on December 21, 2018.", "prediction 4": "Marvel's Runaways, or simply Runaways, is an American web television series created for Hulu by Josh Schwartz and Stephanie Savage, based on the Marvel Comics superhero team of the same name. The first season premiered its first three episodes on Hulu in the United States on November 21, 2017, with the first season consisting of 10 episodes, and concluding on January 9, 2018. In January 2018, \"Runaways\" was renewed for a 13-episode second season, which is scheduled to be released in its entirety on December 21, 2018.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 0, "end": 191}, {"error type": "Irrelevant", "explanation": "", "start": 302, "end": 407}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 1, "sentence_id": [3]}], "corrected-prediction": "The first season of Marvel's Runaways was released on Hulu in the United States on November 21, 2017, and it consists of 10 episodes."}, "preference": [1, 0, 1, 0, 0, 0], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Runaways (TV series)\nS1. Filming on the pilot began in Los Angeles in February 2017.\nS2. The series was officially ordered by Hulu in May 2017.\nS3. The first season was released from November 21, 2017, to January 9, 2018.\nS4. In January 2018, \"Runaways\" was renewed for a 13-episode second season, which is scheduled to be released in its entirety on December 21, 2018.\nS5. Six teenagers from different backgrounds unite against a common enemy \u2013 their criminal parents, collectively known as the Pride.\nS6. In the second season, the teenagers are now on the run from their parents, living on their own and figuring out how to stop the Pride, before learning there may be a mole among them who contacts Jonah, the leader of Pride, aiding his dangerous plan.\nS7. Old Lace, a genetically engineered \"Deinonychus\" telepathically linked with Gert Yorkes, appears in the series.\nS8. The character is portrayed by a puppet that was operated by six people, including one person pumping air through the puppet to show the dinosaur breathing.\nS9. Barer called the puppet \"incredible ...\nS10. You see her emotions.\nS11. We don't not make use of that.\"\nS12. Stan Lee makes a cameo appearance as a limo driver.\nS13. Brian K. Vaughan was hired to write a screenplay for Marvel Studios in May 2008, based on his comic book \"Runaways\".\n\nPassage 2: Title (S0) - Runaways (TV series)\nS1. Runaways (TV series)  Marvel's Runaways, or simply Runaways, is an American web television series created for Hulu by Josh Schwartz and Stephanie Savage, based on the Marvel Comics superhero team of the same name.\nS2. It is set in the Marvel Cinematic Universe (MCU), sharing continuity with the films and other television series of the franchise.\nS3. The series is produced by ABC Signature Studios, Marvel Television and Fake Empire Productions, with Schwartz and Savage serving as showrunners.\nS4. Rhenzy Feliz, Lyrica Okano, Virginia Gardner, Ariela Barer, Gregg Sulkin, and Allegra Acosta star as the Runaways, six teenagers from different backgrounds who unite against their parents, the Pride, portrayed by Angel Parker, Ryan Sands, Annie Wersching, Kip Pardue, Ever Carradine, James Marsters, Brigid Brannagh, Kevin Weisman, Brittany Ishibashi, and James Yaegashi.\nS5. A film from Marvel Studios based on the \"Runaways\" began development in May 2008, before being shelved in 2013 due to the success of \"The Avengers\".\nS6. In August 2016, Marvel Television announced that \"Runaways\" had received a pilot order from Hulu, after being developed and written by Schwartz and Savage.\nS7. Casting for the Runaways and the Pride were revealed in February 2017.\n\nPassage 3: Title (S0) - Runaways (TV series)\nS1. Marvel's position is everything is connected, but our show is trying to walk that line where the reality our kids are facing, they are facing for the first time.\"\nS2. He also said they \"were very capable of telling the story that we wanted to tell independent of any of the other Marvel stories that are out there.\"\nS3. Loeb added that there were no plans to crossover across networks with the similarly themed \"Cloak & Dagger\" on Freeform and \"New Warriors\", as Marvel wanted the series to find its footing before further connecting with other elements of the universe, though \"You'll see things that comment on each other; we try to touch base wherever we can... things that are happening in L.A. are not exactly going to be affecting what's happening in New Orleans [where \"Cloak & Dagger\" is set]...\nS4. It's being aware of it and trying to find a way [to connect] that makes sense.\"\nS5. Speaking to the second season, Schwartz said there would be a reference late in the season \"that will probably be our first real bread crumb that connects to the MCU.\"\nS6. \"Runaways\" premiered its first three episodes on Hulu in the United States on November 21, 2017, with the first season consisting of 10 episodes, and concluding on January 9, 2018.\n    \nInput Question:\nHow many episodes in marvels runaways season 1?\n\nCorrect Response:\nThe superhero TV series Marvel's Runaways ran for a total of three seasons and 33 episodes, all of which aired on the streaming service Hulu. The first season of 10 episodes was released on November 21, 2017. The second season of 13 episodes was released on December 21, 2018, and the third season of 10 episodes was released on December 13, 2019.\n\nModel Prediction:\nMarvel's Runaways, or simply Runaways, is an American web television series created for Hulu by Josh Schwartz and Stephanie Savage, based on the Marvel Comics superhero team of the same name. The first three episodes of the first season were released on Hulu in the United States on November 21, 2017. The first 10 episodes of the second season were released on Hulu in the United States on January 9, 2018.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "[Marvel's Runaways, or simply Runaways, is an American web television series created for Hulu by Josh Schwartz and Stephanie Savage, based on the Marvel Comics superhero team of the same name.] The first three episodes of the first season were released on Hulu in the United States on November 21, 2017. [The first 10 episodes of the second season were released on Hulu in the United States on January 9, 2018.]\n\nExplanation:\n1. The first sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\".\n2. The third sentence is factually incorrect and irrelevant to the question asked. The question asks about the first season, not the second. Therefore, it should be marked as \"Irrelevant\"."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. Marvel's Runaways, or simply Runaways, is an American web television series created for Hulu by Josh Schwartz and Stephanie Savage, based on the Marvel Comics superhero team of the same name.\nS2. The first three episodes of the first season were released on Hulu in the United States on November 21, 2017.\nS3. The first 10 episodes of the second season were released on Hulu in the United States on January 9, 2018.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "S3\n\nExplanation:\nThe third sentence is factually incorrect. The passages do not mention that the first 10 episodes of the second season were released on January 9, 2018. This is an \"Inconsistent Fact\"."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 3 [Missing Answer]\n\nExplanation:\n1. The model prediction does not mention the total number of episodes in the first season of Marvel's Runaways. This information, which is the direct answer to the question, can be found in Passage 1, sentence 3."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The first season of Marvel's Runaways was released on Hulu in the United States on November 21, 2017, and it consists of 10 episodes."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 19, "end": 38}, {"error type": "Irrelevant", "explanation": "", "start": 42, "end": 57}, {"error type": "Irrelevant", "explanation": "", "start": 76, "end": 131}, {"error type": "Irrelevant", "explanation": "", "start": 132, "end": 158}, {"error type": "Irrelevant", "explanation": "", "start": 169, "end": 191}, {"error type": "Irrelevant", "explanation": "", "start": 192, "end": 219}, {"error type": "Irrelevant", "explanation": "", "start": 259, "end": 279}, {"error type": "Wrong-Grounding", "explanation": "{\"passage_id\":1,\"sentence_id\":[4]}", "start": 306, "end": 314}, {"error type": "Redundant", "explanation": "on Hulu", "start": 359, "end": 366}, {"error type": "Irrelevant", "explanation": "", "start": 367, "end": 387}, {"error type": "Wrong-Grounding", "explanation": "{\"passage_id\":1,\"sentence_id\":[4]}", "start": 391, "end": 407}], "missing-info": [], "corrected-prediction": "Marvel's Runaways is superhero television series aired on Hulu. The first season of 10 episodes was released on November 21, 2017.  The second season of 13 episodes was released on December 21, 2018."}}, {"question": "Who has the most championships in the wnba?", "passages": [["Van Chancellor", "Van Chancellor\n\nVan Winston Chancellor (born September 27, 1943) is a former college and professional basketball coach.", "He coached University of Mississippi women's basketball, Louisiana State University women's basketball, and the professional Houston Comets.", "He was named head coach of the Lady Tigers on April 11, 2007, replacing Pokey Chatman.", "In 2001, Chancellor was elected to the Women's Basketball Hall of Fame, located in Knoxville, Tennessee.", "He was enshrined as a member of the Naismith Memorial Basketball Hall of Fame in September 2007.", "Chancellor currently serves as an analyst for Southland Conference games on ESPN3.", "Chancellor played two years of basketball at East Central Junior College in Decatur, Mississippi, before transferring to Mississippi State University, where he earned a bachelor\u2019s degree in mathematics & physical education in 1965.", "During his senior year at Mississippi State, he served as head coach of the boys' basketball team at Noxapater High School.", "Chancellor went on to coach boys' and girls' basketball at Horn Lake High School and Harrison Central High School in Mississippi.", "He received his master\u2019s degree in physical education from the University of Mississippi in 1973.", "Chancellor spent 19 seasons (1978\u20131997) as the head coach of the University of Mississippi Rebels, compiling an overall record of 439-154 (.740)."], ["Cheryl Reeve", "Cheryl Reeve\n\nCheryl Reeve is an American basketball head coach and general manager for the Minnesota Lynx of the WNBA.", "She has coached the Lynx to four league championships.", "In WNBA history, she has the highest winning percentage, she won the most games of any female coach, and she won the most postseason games of any coach.", "Reeve was named the WNBA Coach of the Year in 2011 and 2016.", "Reeve grew up in Washington Township, Gloucester County, New Jersey and graduated from Washington Township High School in 1984, where she was part of the school's first team to make the state finals.", "In 1988, Reeve was a Rhodes Scholar nominee and received a MAAC Scholar-Athlete Post Graduate Award and a NCAA Post-Graduate Scholarship.", "She earned a bachelors in computer science that year and then an MBA, both from La Salle University.", "Reeve started out as assistant coach at her alma mater, La Salle for two years.", "She was then an assistant at George Washington for five years.", "The Colonials posted five 20-win seasons, captured three Atlantic 10 Conference Championships and appeared in four NCAA tournaments during Reeve's stint at George Washington.", "Her first head coaching position was with the Indiana State Sycamores from 1995 to the middle of the 1999-2000 season (replaced by her assistant coach Jim Wiedie)."], ["Minnesota Lynx", "Minnesota Lynx\n\nThe Minnesota Lynx are a professional basketball team based in Minneapolis, Minnesota, playing in the Western Conference in the Women's National Basketball Association (WNBA).", "The team won the WNBA title in 2011, 2013, 2015, and 2017.", "Founded prior to the 1999 season, the team is owned by Glen Taylor, who is also the majority owner of the Lynx' NBA counterpart, the Minnesota Timberwolves.", "The franchise has been home to many high-quality players such as Katie Smith, explosive small-forward Seimone Augustus, native Minnesotan Lindsay Whalen, Connecticut standout Maya Moore, forward Rebekkah Brunson, and center Sylvia Fowles.", "The Lynx have qualified for the WNBA playoffs in ten of their twenty years.", "With four championships, the Lynx are tied with the Houston Comets for the most titles in WNBA history, and they have won more Western Conference championships than any other franchise.", "On April 22, 1998, the WNBA announced they would add two expansion teams (Minnesota and the Orlando Miracle) for the 1999 season.", "The team was officially named the Minnesota Lynx on December 5, 1998.", "The Lynx started their inaugural season in 1999 with 12,122 fans in attendance to watch the first regular-season game against the Detroit Shock at Target Center.", "The Lynx defeated Detroit 68\u201351 in the franchise's first game."]], "gold": "The teams and the coaches with the most championships in the WNBA differ. The teams with the most are the Seattle Storm, Minnesota Lynx and Houston Comets, who are tied with four championships. The coaches with the most are Van Chancellor, who coached the Houston Comets, and Cheryl Reeve, who is the Minnesota Lynx's head manager.", "prediction 1": "The most championships in the WNBA were won by the Houston Comets in 1995 and 1996. The most titles won by a woman by a male head coach by the Minnesota Lynx in 2011 and 2017 respectively. Van Chancellor, a former college and professional basketball coach, has the most titles in WNBA history.", "prediction 2": "In the Women's National Basketball Association, the Houston Comets have won the most championships in its history. Van Winston Chancellor holds the record for most championships in the WNBA with five. American head coach Cheryl Reeve holds the record for most WNBA league championships with four.", "prediction 3": "There are several women's basketball teams in the WNBA. The Houston Comets have the most championships in WNBA history. The Minnesota Lynx have won the WNBA title in 2011, 2013, 2015, and 2017. The Houston Comets have won the most Western Conference championships.", "prediction 4": "The Houston Comets have the most championships in WNBA history. Van Winston Chancellor has the most championships in WNBA history. Cheryl Reeve has the most championships in WNBA history.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 0, "end": 83}, {"error type": "Irrelevant", "explanation": "", "start": 189, "end": 293}, {"error type": "Unverifiable", "start": 0, "end": 83}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 1, "sentence_id": [2]}], "corrected-prediction": "The teams with the most championships in the WNBA are the Minnesota Lynx and the Houston Comets, both with four championships each. The Minnesota Lynx's championships were won under the coaching of Cheryl Reeve, and the Houston Comets' championships were won under the coaching of Van Chancellor."}, "preference": [1, 1, 1, 2, 2, 1], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Van Chancellor\nS1. Van Chancellor  Van Winston Chancellor (born September 27, 1943) is a former college and professional basketball coach.\nS2. He coached University of Mississippi women's basketball, Louisiana State University women's basketball, and the professional Houston Comets.\nS3. He was named head coach of the Lady Tigers on April 11, 2007, replacing Pokey Chatman.\nS4. In 2001, Chancellor was elected to the Women's Basketball Hall of Fame, located in Knoxville, Tennessee.\nS5. He was enshrined as a member of the Naismith Memorial Basketball Hall of Fame in September 2007.\nS6. Chancellor currently serves as an analyst for Southland Conference games on ESPN3.\nS7. Chancellor played two years of basketball at East Central Junior College in Decatur, Mississippi, before transferring to Mississippi State University, where he earned a bachelor\u2019s degree in mathematics & physical education in 1965.\nS8. During his senior year at Mississippi State, he served as head coach of the boys' basketball team at Noxapater High School.\nS9. Chancellor went on to coach boys' and girls' basketball at Horn Lake High School and Harrison Central High School in Mississippi.\nS10. He received his master\u2019s degree in physical education from the University of Mississippi in 1973.\nS11. Chancellor spent 19 seasons (1978\u20131997) as the head coach of the University of Mississippi Rebels, compiling an overall record of 439-154 (.740).\n\nPassage 2: Title (S0) - Cheryl Reeve\nS1. Cheryl Reeve  Cheryl Reeve is an American basketball head coach and general manager for the Minnesota Lynx of the WNBA.\nS2. She has coached the Lynx to four league championships.\nS3. In WNBA history, she has the highest winning percentage, she won the most games of any female coach, and she won the most postseason games of any coach.\nS4. Reeve was named the WNBA Coach of the Year in 2011 and 2016.\nS5. Reeve grew up in Washington Township, Gloucester County, New Jersey and graduated from Washington Township High School in 1984, where she was part of the school's first team to make the state finals.\nS6. In 1988, Reeve was a Rhodes Scholar nominee and received a MAAC Scholar-Athlete Post Graduate Award and a NCAA Post-Graduate Scholarship.\nS7. She earned a bachelors in computer science that year and then an MBA, both from La Salle University.\nS8. Reeve started out as assistant coach at her alma mater, La Salle for two years.\nS9. She was then an assistant at George Washington for five years.\nS10. The Colonials posted five 20-win seasons, captured three Atlantic 10 Conference Championships and appeared in four NCAA tournaments during Reeve's stint at George Washington.\nS11. Her first head coaching position was with the Indiana State Sycamores from 1995 to the middle of the 1999-2000 season (replaced by her assistant coach Jim Wiedie).\n\nPassage 3: Title (S0) - Minnesota Lynx\nS1. Minnesota Lynx  The Minnesota Lynx are a professional basketball team based in Minneapolis, Minnesota, playing in the Western Conference in the Women's National Basketball Association (WNBA).\nS2. The team won the WNBA title in 2011, 2013, 2015, and 2017.\nS3. Founded prior to the 1999 season, the team is owned by Glen Taylor, who is also the majority owner of the Lynx' NBA counterpart, the Minnesota Timberwolves.\nS4. The franchise has been home to many high-quality players such as Katie Smith, explosive small-forward Seimone Augustus, native Minnesotan Lindsay Whalen, Connecticut standout Maya Moore, forward Rebekkah Brunson, and center Sylvia Fowles.\nS5. The Lynx have qualified for the WNBA playoffs in ten of their twenty years.\nS6. With four championships, the Lynx are tied with the Houston Comets for the most titles in WNBA history, and they have won more Western Conference championships than any other franchise.\nS7. On April 22, 1998, the WNBA announced they would add two expansion teams (Minnesota and the Orlando Miracle) for the 1999 season.\nS8. The team was officially named the Minnesota Lynx on December 5, 1998.\nS9. The Lynx started their inaugural season in 1999 with 12,122 fans in attendance to watch the first regular-season game against the Detroit Shock at Target Center.\nS10. The Lynx defeated Detroit 68\u201351 in the franchise's first game.\n    \nInput Question:\nWho has the most championships in the wnba?\n\nCorrect Response:\nThe teams and the coaches with the most championships in the WNBA differ. The teams with the most are the Seattle Storm, Minnesota Lynx and Houston Comets, who are tied with four championships. The coaches with the most are Van Chancellor, who coached the Houston Comets, and Cheryl Reeve, who is the Minnesota Lynx's head manager.\n\nModel Prediction:\nThe most championships in the WNBA were won by the Houston Comets in 1995 and 1996. The most titles won by a woman by a male head coach by the Minnesota Lynx in 2011 and 2017 respectively. Van Chancellor, a former college and professional basketball coach, has the most titles in WNBA history.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "[The most championships in the WNBA were won by the Houston Comets in 1995 and 1996.] The most titles won by a woman by a male head coach by the Minnesota Lynx in 2011 and 2017 respectively. [Van Chancellor, a former college and professional basketball coach, has the most titles in WNBA history.]\n\nExplanation:\n1. The first sentence is incorrect as the Houston Comets did not win the championships in 1995 and 1996. This is factually inconsistent with the passages.\n2. The phrase \"The most titles won by a woman by a male head coach by the Minnesota Lynx in 2011 and 2017 respectively.\" is incoherent and does not make sense in the context of the question.\n3. The last sentence is irrelevant as it does not directly answer the question and is not crucial auxiliary information. It is also factually inconsistent as Van Chancellor does not have the most titles in WNBA history according to the passages."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The most championships in the WNBA were won by the Houston Comets in 1995 and 1996.\nS2. The most titles won by a woman by a male head coach by the Minnesota Lynx in 2011 and 2017 respectively.\nS3. Van Chancellor, a former college and professional basketball coach, has the most titles in WNBA history.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "1. S1\n2. S3\n\nExplanation:\n1. The first sentence is factually inconsistent with the passages. The Houston Comets did not win the championships in 1995 and 1996 according to the passages.\n2. The third sentence is factually inconsistent with the passages. Van Chancellor does not have the most titles in WNBA history according to the passages."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 2 [Missing Answer]\n2. Passage 2, sentence 2 [Missing Answer]\n3. Passage 3, sentence 2 [Missing Answer]\n\nExplanation:\n1. The model prediction fails to mention that Van Chancellor coached the Houston Comets, which is crucial information for answering the question about who has the most championships in the WNBA.\n2. The model prediction does not mention that Cheryl Reeve has coached the Minnesota Lynx to four league championships, which is a direct answer to the question.\n3. The model prediction does not mention that the Minnesota Lynx won the WNBA title in 2011, 2013, 2015, and 2017, which is a direct answer to the question."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The teams with the most championships in the WNBA are the Minnesota Lynx and the Houston Comets, both with four championships each. The Minnesota Lynx's championships were won under the coaching of Cheryl Reeve, and the Houston Comets' championships were won under the coaching of Van Chancellor."}], "feedback_human": {"errors": [{"error type": "Unverifiable", "explanation": "", "start": 69, "end": 83}, {"error type": "Incoherent", "explanation": "", "start": 115, "end": 157}, {"error type": "Unverifiable", "explanation": "", "start": 161, "end": 188}, {"error type": "Irrelevant", "explanation": "", "start": 207, "end": 256}, {"error type": "Unverifiable", "explanation": "", "start": 257, "end": 293}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 3, "sentence_id": [6]}, {"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [2]}, {"error type": "Missing-Answer", "passage_id": 2, "sentence_id": [1, 2]}], "corrected-prediction": "The most championships in the WNBA were won by the Houston Comets and the Minnesota Lynx with 4 each. The most titles won by a woman is Cheryl Reeve with 4 with the Lynx and she's their general manager. Van Chancellor has coached the Houston Comets. "}}, {"question": "Who carried the us flag in the 2018?", "passages": [["2018 Winter Olympics closing ceremony flag bearers", "2018 Winter Olympics closing ceremony flag bearers\n\nDuring the closing ceremony of the 2018 Winter Olympics in Pyeongchang, the flag bearers of 92 National Olympic Committees (NOCs) arrived into Pyeongchang Olympic Stadium.", "The flag bearers from each participating country entered the stadium informally in single file, and behind them marched all the athletes, without any distinction or grouping by nationality.", "The blending of all the athletes is a tradition that dates from the 1956 Summer Olympics, after a suggestion by Australian-born British student John Ian Wing, who thought it would be a way of bringing the athletes of the world together as \"one nation.\"", "The flags of each country were not necessarily carried by the same flag bearer as in the opening ceremony.", "The flag-bearers entered in \"ganada\" order of the Korean alphabet.", "The following is a list of each country's flag bearer.", "The list is sorted by the order in which each nation appears in the parade of nations.", "This table is sortable by country name in English, country name in Korean, the flag bearer's name, or the flag bearer's sport.", "Names are given as were officially designated by the International Olympic Committee (IOC)."], ["2018 Winter Olympics", "2018 Winter Olympics\n\nThe 2018 Winter Olympics, officially known as the XXIII Olympic Winter Games () and commonly known as PyeongChang 2018, was an international winter multi-sport event that was held between 9 and 25 February 2018 in Pyeongchang County, Gangwon Province, South Korea, with the opening rounds for certain events held on 8 February 2018, the eve of the opening ceremony.", "Pyeongchang was elected as the host city in July 2011, during the 123rd IOC Session in Durban, South Africa.", "This was the first time that South Korea had hosted the Winter Olympics and the second Olympics held in the country overall, after the 1988 Summer Olympics in Seoul.", "It was the third time that an East Asian country had hosted the Winter Games, after Sapporo (1972) and Nagano (1998), both in Japan.", "It was also the first of three consecutive Olympics to be held in East Asia, the other two being the 2020 Summer Olympics in Tokyo and the 2022 Winter Olympics in Beijing.", "The Games featured 102 events over fifteen disciplines in seven sports, with the addition of \"big air\" snowboarding, mass start speed skating, mixed doubles curling, and mixed team alpine skiing to the Winter Olympic programme.", "2,914 athletes from 92 NOCs competed, including the debuts of Ecuador, Eritrea, Kosovo, Malaysia, Nigeria and Singapore."], ["Erin Hamlin", "Erin Hamlin\n\nErin Mullady Hamlin (born 19 November 1986) is a four-time Olympian and the first female American luger to medal at any Winter Olympics, as well as the first American of either gender to medal in luge singles competition.", "She took the singles bronze medal in Sochi's 2014 Winter Olympics, something the Associated Press called \"a feat that will surely go down as perhaps the greatest moment in USA Luge history\".", "At age 12 Hamlin took an interest in luge and attended the U.S. Luge Screening Camp in Syracuse, NY.", "By age 17 Hamlin won a gold medal at the Junior National Luge Championship held in Lake Placid, NY.", "At this event Hamlin finished first in the women's singles race with a two-run time of 1-minute, 34.097 seconds.", "In 2004, Hamlin won ten medals in five years of racing.", "Hamlin raced in the Junior World Cups held in Germany and Austria.", "She participated in the Junior World Championships.", "She placed seventh in the 2004 Junior World Cups, making her a U.S. junior national luge champion where she competed around the world as a member of the U.S. Junior National Team."]], "gold": "Flag bearers carry the national flag of their country at the opening ceremony and closing ceremony of the Olympic Games. The 2018 Winter Olympics, officially known as the XXIII Olympic Winter Games and commonly known as PyeongChang 2018, was an international winter multi-sport event that was held between February 9 and 25 in Pyeongchang County, Gangwon Province, South Korea, with the opening rounds for certain events held on February 8,  2018, the day before the opening ceremony. Four time Olympian Erin Hamlin, who was the first female American luger to medal at any Winter Olympics, as well as the first American of either gender to medal in luge singles competition, carried the US flag in the opening ceremony for the event. The US flag in the closing ceremony of the event was carried by American cross-country skier, Jessica Diggins won the United States' first ever cross-country skiing gold medal at the Winter Olympics in women's team sprint that year.", "prediction 1": "The flag bearers of the United States at the 2018 Winter Olympics were Erin Hamlin, a four-time Olympian and the first female American luger to medal at any Winter Olympics, as well as the first American of either gender to medal in luge singles competition. However, during the 2018 Winter Olympics closing ceremony, the flag bearers of 92 National Olympic Committees (NOCs) entered the stadium informally in single file, and behind them marched all the athletes, without any distinction or grouping by nationality.", "prediction 2": "A list of the flag bearers for the 2018 Winter Olympics is provided below. Erin Hamlin, the first female American luger to medal at any Winter Olympics, carried the us flag in the closing ceremony of the 2018 Winter Olympics in Pyeongchang. The flags of each participating country were carried by the flag bearers of 92 National Olympic Committees (NOCs) during the closing ceremony of the 2018 Winter Olympics in Pyeongchang.", "prediction 3": "The flags of each participating country were not necessarily carried by the same flag bearer as in the opening ceremony. The flag-bearers entered Pyeongchang Olympic Stadium in single file, and behind them marched all the athletes, without any distinction or grouping by nationality.", "prediction 4": "The flags of each participating country were carried by different flag bearers at the 2018 Winter Olympics closing ceremony. Flag bearers of 92 National Olympic Committees carried the flags of the United States in the opening ceremony and the flag bearer of the United States in the closing ceremony. The flags of each participating country were carried by different flag bearers at the closing ceremony. The flag bearers carried the flags of each participating country in the closing ceremony.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 259, "end": 516}], "missing-info": [], "corrected-prediction": "The flag bearer of the United States at the 2018 Winter Olympics opening ceremony was Erin Hamlin, a four-time Olympian and the first female American luger to medal at any Winter Olympics, as well as the first American of either gender to medal in luge singles competition. The flag bearer for the closing ceremony is not mentioned in the provided passages."}, "preference": [1, 1, 1, 1, 2, 2], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - 2018 Winter Olympics closing ceremony flag bearers\nS1. 2018 Winter Olympics closing ceremony flag bearers  During the closing ceremony of the 2018 Winter Olympics in Pyeongchang, the flag bearers of 92 National Olympic Committees (NOCs) arrived into Pyeongchang Olympic Stadium.\nS2. The flag bearers from each participating country entered the stadium informally in single file, and behind them marched all the athletes, without any distinction or grouping by nationality.\nS3. The blending of all the athletes is a tradition that dates from the 1956 Summer Olympics, after a suggestion by Australian-born British student John Ian Wing, who thought it would be a way of bringing the athletes of the world together as \"one nation.\"\nS4. The flags of each country were not necessarily carried by the same flag bearer as in the opening ceremony.\nS5. The flag-bearers entered in \"ganada\" order of the Korean alphabet.\nS6. The following is a list of each country's flag bearer.\nS7. The list is sorted by the order in which each nation appears in the parade of nations.\nS8. This table is sortable by country name in English, country name in Korean, the flag bearer's name, or the flag bearer's sport.\nS9. Names are given as were officially designated by the International Olympic Committee (IOC).\n\nPassage 2: Title (S0) - 2018 Winter Olympics\nS1. 2018 Winter Olympics  The 2018 Winter Olympics, officially known as the XXIII Olympic Winter Games () and commonly known as PyeongChang 2018, was an international winter multi-sport event that was held between 9 and 25 February 2018 in Pyeongchang County, Gangwon Province, South Korea, with the opening rounds for certain events held on 8 February 2018, the eve of the opening ceremony.\nS2. Pyeongchang was elected as the host city in July 2011, during the 123rd IOC Session in Durban, South Africa.\nS3. This was the first time that South Korea had hosted the Winter Olympics and the second Olympics held in the country overall, after the 1988 Summer Olympics in Seoul.\nS4. It was the third time that an East Asian country had hosted the Winter Games, after Sapporo (1972) and Nagano (1998), both in Japan.\nS5. It was also the first of three consecutive Olympics to be held in East Asia, the other two being the 2020 Summer Olympics in Tokyo and the 2022 Winter Olympics in Beijing.\nS6. The Games featured 102 events over fifteen disciplines in seven sports, with the addition of \"big air\" snowboarding, mass start speed skating, mixed doubles curling, and mixed team alpine skiing to the Winter Olympic programme.\nS7. 2,914 athletes from 92 NOCs competed, including the debuts of Ecuador, Eritrea, Kosovo, Malaysia, Nigeria and Singapore.\n\nPassage 3: Title (S0) - Erin Hamlin\nS1. Erin Hamlin  Erin Mullady Hamlin (born 19 November 1986) is a four-time Olympian and the first female American luger to medal at any Winter Olympics, as well as the first American of either gender to medal in luge singles competition.\nS2. She took the singles bronze medal in Sochi's 2014 Winter Olympics, something the Associated Press called \"a feat that will surely go down as perhaps the greatest moment in USA Luge history\".\nS3. At age 12 Hamlin took an interest in luge and attended the U.S. Luge Screening Camp in Syracuse, NY.\nS4. By age 17 Hamlin won a gold medal at the Junior National Luge Championship held in Lake Placid, NY.\nS5. At this event Hamlin finished first in the women's singles race with a two-run time of 1-minute, 34.097 seconds.\nS6. In 2004, Hamlin won ten medals in five years of racing.\nS7. Hamlin raced in the Junior World Cups held in Germany and Austria.\nS8. She participated in the Junior World Championships.\nS9. She placed seventh in the 2004 Junior World Cups, making her a U.S. junior national luge champion where she competed around the world as a member of the U.S. Junior National Team.\n    \nInput Question:\nWho carried the us flag in the 2018?\n\nCorrect Response:\nFlag bearers carry the national flag of their country at the opening ceremony and closing ceremony of the Olympic Games. The 2018 Winter Olympics, officially known as the XXIII Olympic Winter Games and commonly known as PyeongChang 2018, was an international winter multi-sport event that was held between February 9 and 25 in Pyeongchang County, Gangwon Province, South Korea, with the opening rounds for certain events held on February 8,  2018, the day before the opening ceremony. Four time Olympian Erin Hamlin, who was the first female American luger to medal at any Winter Olympics, as well as the first American of either gender to medal in luge singles competition, carried the US flag in the opening ceremony for the event. The US flag in the closing ceremony of the event was carried by American cross-country skier, Jessica Diggins won the United States' first ever cross-country skiing gold medal at the Winter Olympics in women's team sprint that year.\n\nModel Prediction:\nThe flag bearers of the United States at the 2018 Winter Olympics were Erin Hamlin, a four-time Olympian and the first female American luger to medal at any Winter Olympics, as well as the first American of either gender to medal in luge singles competition. However, during the 2018 Winter Olympics closing ceremony, the flag bearers of 92 National Olympic Committees (NOCs) entered the stadium informally in single file, and behind them marched all the athletes, without any distinction or grouping by nationality.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "The flag bearers of the United States at the 2018 Winter Olympics were Erin Hamlin, a four-time Olympian and the first female American luger to medal at any Winter Olympics, as well as the first American of either gender to medal in luge singles competition. [However, during the 2018 Winter Olympics closing ceremony, the flag bearers of 92 National Olympic Committees (NOCs) entered the stadium informally in single file, and behind them marched all the athletes, without any distinction or grouping by nationality.]\n\nExplanation:\nThe last sentence in the model prediction is irrelevant to the question. The question asks about who carried the US flag in 2018, not about the process of the closing ceremony. Thus, it should be marked as \"Irrelevant\"."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The flag bearers of the United States at the 2018 Winter Olympics were Erin Hamlin, a four-time Olympian and the first female American luger to medal at any Winter Olympics, as well as the first American of either gender to medal in luge singles competition.\nS2. However, during the 2018 Winter Olympics closing ceremony, the flag bearers of 92 National Olympic Committees (NOCs) entered the stadium informally in single file, and behind them marched all the athletes, without any distinction or grouping by nationality.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation:\nAll the facts in the model prediction are consistent with the passages and can be verified."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. [Missing Answer]\n\nExplanation:\n1. The model prediction does not mention who carried the US flag in the closing ceremony of the 2018 Winter Olympics. This information is missing from the model prediction and is considered a missing answer. The passages do not provide this information, so it cannot be marked with a specific passage and sentence number."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The flag bearer of the United States at the 2018 Winter Olympics opening ceremony was Erin Hamlin, a four-time Olympian and the first female American luger to medal at any Winter Olympics, as well as the first American of either gender to medal in luge singles competition. The flag bearer for the closing ceremony is not mentioned in the provided passages."}], "feedback_human": {"errors": [{"error type": "Unverifiable", "explanation": "", "start": 71, "end": 83}, {"error type": "Irrelevant", "explanation": "", "start": 259, "end": 516}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 2, "sentence_id": [1]}], "corrected-prediction": "The 2018 Winter Olympics, officially known as the XXIII Olympic Winter Games, and commonly known as PyeongChang 2018, was an international winter multi-sport event that was held between 9 and 25 February 2018 in Pyeongchang County, Gangwon Province, South Korea, with the opening rounds for certain events held on 8 February 2018, the eve of the opening ceremony. Erin Hamlin is a four-time Olympian and the first female American luger to medal at any Winter Olympics, as well as the first American of either gender to medal in luge singles competition. "}}, {"question": "Another name of x axis and y axis?", "passages": [["Abscissa and ordinate", "Abscissa and ordinate\n\nIn mathematics, the abscissa (; plural \"abscissae\" or \"absciss\u00e6\" or \"abscissas\") and the ordinate are respectively the first and second coordinate of a point in a coordinate system.", "The abscissa of a point is the signed measure of its projection on the primary axis, whose absolute value is the distance between the projection and the origin of the axis, and whose sign is given by the location on the projection relative to the origin (before: negative; after: positive).", "The ordinate of a point is the signed measure of its projection on the secondary axis, whose absolute value is the distance between the projection and the origin of the axis, and whose sign is given by the location on the projection relative to the origin (before: negative; after: positive).", "Usually these are the horizontal and vertical coordinates of a point in a two-dimensional rectangular Cartesian coordinate system.", "The terms can also refer to the horizontal and vertical axes respectively (typically \"x\"-axis and \"y\"\u2013axis) of a two-dimensional graph."], ["Cartesian coordinate system", "Cartesian coordinate system\n\nA Cartesian coordinate system is a coordinate system that specifies each point uniquely in a plane by a set of numerical coordinates, which are the signed distances to the point from two fixed perpendicular oriented lines, measured in the same unit of length.", "Each reference line is called a \"coordinate axis\" or just \"axis\" (plural \"axes\") of the system, and the point where they meet is its \"origin\", at ordered pair .", "The coordinates can also be defined as the positions of the perpendicular projections of the point onto the two axes, expressed as signed distances from the origin.", "One can use the same principle to specify the position of any point in three-dimensional space by three Cartesian coordinates, its signed distances to three mutually perpendicular planes (or, equivalently, by its perpendicular projection onto three mutually perpendicular lines).", "In general, \"n\" Cartesian coordinates (an element of real \"n\"-space) specify the point in an \"n\"-dimensional Euclidean space for any dimension \"n\".", "These coordinates are equal, up to sign, to distances from the point to \"n\" mutually perpendicular hyperplanes.", "The invention of Cartesian coordinates in the 17th century by Ren\u00e9 Descartes (Latinized name: \"Cartesius\") revolutionized mathematics by providing the first systematic link between Euclidean geometry and algebra."]], "gold": "A Cartesian coordinate system in a plane is a coordinate system that specifies each point uniquely by a pair of numerical coordinates, which are the signed distances to the point from two fixed perpendicular oriented lines, measured in the same unit of length. The two lines that make it up are the x-axis, also known as abscissa, and the y-axis, also known as ordinate.", "prediction 1": "In mathematics, the abscissa and the ordinate are respectively the first and second coordinate of a point in a coordinate system. In general, the horizontal and vertical axes of a two-dimensional graph are called x axis and y axis, respectively.", "prediction 2": "A Cartesian coordinate system is a coordinate system that specifies each point uniquely in a plane by a set of numerical coordinates, which are the signed distances to the point from two fixed perpendicular oriented lines, measured in the same unit of length. Each reference line is called a coordinate axis (plural \"axes\") of the system, and the point where they meet is its \"origin\".", "prediction 3": "In mathematics, the abscissa and the ordinate are respectively the first and second coordinates of a point in a coordinate system. A Cartesian coordinate system is a coordinate system that specifies each point uniquely in a plane by a set of numerical coordinates, which are the signed distances to the point from two fixed perpendicular oriented lines, measured in the same unit of length. Each reference line is called a coordinate axis or just \"axis\" of the system, and the point where they meet is its \"origin\".", "prediction 4": "A Cartesian coordinate system is a coordinate system that specifies each point uniquely in a plane by a set of numerical coordinates, which are the signed distances to the point from two fixed perpendicular oriented lines, measured in the same unit of length. Each reference line is called a coordinate axis or just \"axis\" of the system. The horizontal and vertical axes respectively (typically \"x\"-axis and \"y\"\u2013axis) of a two-dimensional graph.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 130, "end": 245}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [4]}], "corrected-prediction": "In mathematics, the abscissa and the ordinate are respectively the first and second coordinate of a point in a Cartesian coordinate system. These are usually the horizontal and vertical coordinates of a point in a two-dimensional rectangular Cartesian coordinate system. The abscissa, also known as the x-axis, and the ordinate, also known as the y-axis, specify each point uniquely in a plane by a set of numerical coordinates, which are the signed distances to the point from two fixed perpendicular oriented lines, measured in the same unit of length."}, "preference": [2, 2, 2, 0, 1, 1], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Abscissa and ordinate\nS1. Abscissa and ordinate  In mathematics, the abscissa (; plural \"abscissae\" or \"absciss\u00e6\" or \"abscissas\") and the ordinate are respectively the first and second coordinate of a point in a coordinate system.\nS2. The abscissa of a point is the signed measure of its projection on the primary axis, whose absolute value is the distance between the projection and the origin of the axis, and whose sign is given by the location on the projection relative to the origin (before: negative; after: positive).\nS3. The ordinate of a point is the signed measure of its projection on the secondary axis, whose absolute value is the distance between the projection and the origin of the axis, and whose sign is given by the location on the projection relative to the origin (before: negative; after: positive).\nS4. Usually these are the horizontal and vertical coordinates of a point in a two-dimensional rectangular Cartesian coordinate system.\nS5. The terms can also refer to the horizontal and vertical axes respectively (typically \"x\"-axis and \"y\"\u2013axis) of a two-dimensional graph.\n\nPassage 2: Title (S0) - Cartesian coordinate system\nS1. Cartesian coordinate system  A Cartesian coordinate system is a coordinate system that specifies each point uniquely in a plane by a set of numerical coordinates, which are the signed distances to the point from two fixed perpendicular oriented lines, measured in the same unit of length.\nS2. Each reference line is called a \"coordinate axis\" or just \"axis\" (plural \"axes\") of the system, and the point where they meet is its \"origin\", at ordered pair .\nS3. The coordinates can also be defined as the positions of the perpendicular projections of the point onto the two axes, expressed as signed distances from the origin.\nS4. One can use the same principle to specify the position of any point in three-dimensional space by three Cartesian coordinates, its signed distances to three mutually perpendicular planes (or, equivalently, by its perpendicular projection onto three mutually perpendicular lines).\nS5. In general, \"n\" Cartesian coordinates (an element of real \"n\"-space) specify the point in an \"n\"-dimensional Euclidean space for any dimension \"n\".\nS6. These coordinates are equal, up to sign, to distances from the point to \"n\" mutually perpendicular hyperplanes.\nS7. The invention of Cartesian coordinates in the 17th century by Ren\u00e9 Descartes (Latinized name: \"Cartesius\") revolutionized mathematics by providing the first systematic link between Euclidean geometry and algebra.\n    \nInput Question:\nAnother name of x axis and y axis?\n\nCorrect Response:\nA Cartesian coordinate system in a plane is a coordinate system that specifies each point uniquely by a pair of numerical coordinates, which are the signed distances to the point from two fixed perpendicular oriented lines, measured in the same unit of length. The two lines that make it up are the x-axis, also known as abscissa, and the y-axis, also known as ordinate.\n\nModel Prediction:\nIn mathematics, the abscissa and the ordinate are respectively the first and second coordinate of a point in a coordinate system. In general, the horizontal and vertical axes of a two-dimensional graph are called x axis and y axis, respectively.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "In mathematics, the abscissa and the ordinate are respectively the first and second coordinate of a point in a coordinate system. [In general, the horizontal and vertical axes of a two-dimensional graph are called x axis and y axis, respectively.]\n\nExplanation:\nThe second sentence in the model prediction is repetitive as it repeats the information that the x-axis and y-axis are the horizontal and vertical axes respectively, which is already implied in the first sentence."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. In mathematics, the abscissa and the ordinate are respectively the first and second coordinate of a point in a coordinate system.\nS2. In general, the horizontal and vertical axes of a two-dimensional graph are called x axis and y axis, respectively.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation:\nAll the facts in the model prediction are consistent with the provided passages and can be verified."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 4 [Missing Major Auxiliary Information]\n2. Passage 2, sentence 1 [Missing Major Auxiliary Information]\n\nExplanation:\n1. The model prediction does not mention that the abscissa and ordinate are usually the horizontal and vertical coordinates of a point in a two-dimensional rectangular Cartesian coordinate system, which is crucial information for understanding the context of the terms.\n2. The model prediction also misses the information that a Cartesian coordinate system specifies each point uniquely in a plane by a set of numerical coordinates, which are the signed distances to the point from two fixed perpendicular oriented lines, measured in the same unit of length. This information is important for understanding the concept of a Cartesian coordinate system and its relation to the terms abscissa and ordinate."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "In mathematics, the abscissa and the ordinate are respectively the first and second coordinate of a point in a Cartesian coordinate system. These are usually the horizontal and vertical coordinates of a point in a two-dimensional rectangular Cartesian coordinate system. The abscissa, also known as the x-axis, and the ordinate, also known as the y-axis, specify each point uniquely in a plane by a set of numerical coordinates, which are the signed distances to the point from two fixed perpendicular oriented lines, measured in the same unit of length."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 130, "end": 245}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 2, "sentence_id": [1]}], "corrected-prediction": "A Cartesian coordinate system in a plane is a coordinate system that specifies each point uniquely by a pair of numerical coordinates, which are the signed distances to the point from two fixed perpendicular oriented lines, measured in the same unit of length. In mathematics, the abscissa and the ordinate are respectively the first and second coordinate of a point in a coordinate system. "}}, {"question": "When did the 6th generation ipod come out?", "passages": [["IPod Classic", "Gapless playback and support for iPod games was enabled on all fifth-generation iPods through a firmware update released at the same time.", "During a special iPod-centric event on September 5, 2007, Steve Jobs introduced the sixth-generation iPod and the suffix \"classic\".", "Featuring slightly thinner bodies, the sixth-generation iPod also had dramatically improved battery life, claiming up to 36 hours of music playback and 6 hours of video playback.", "The iPod Classic has a 2.5\" backlit display at a resolution of 320\u00d7240.", "The front plate of the iPod is now made of anodized aluminium instead of polycarbonate plastic, and \"Signature iPod White\" has been replaced by silver.", "This marks the first time white is not available as a color option for an iPod.", "The sixth-generation iPod also introduced a completely overhauled user interface, incorporating more graphics and Cover Flow.", "The iPod Classic was offered in an 80GB model for MSRP US$249 and a 160GB model for MSRP US$349.", "During the 'Let's Rock' Apple Event on September 9, 2008, the 80GB and the thicker 160GB model were discontinued in favor of a thin 120GB version retailing for US$249."], ["IPod Classic", "It introduced Genius and audio recording capabilities which are also available in other iPod models released at similar times; no firmware update provides either feature to the first-generation iPods.", "Also, the black model's faceplate was replaced with a gray colored faceplate, while retaining the silver backing and the black Click Wheel.", "Prior to the 'It's Only Rock and Roll' event on September 9, 2009, the price of the 120GB version was dropped to US$229.", "During the event, Apple replaced the 120GB version with an 160GB model, featuring the same slim profile which retailed at US$249.", "U2 Special Editions\nThere are four different U2 Special Edition iPod models, each with widely differing capabilities.", "However, each of the U2 models -- the iPod U2 (4th Gen), iPod U2 (Color), iPod U2 (5th Gen/Video), and iPod U2 (5th Gen Enhanced) -- are the same internally as the \"standard\" iPod model available at the time, and the U2 models vary only in case design and cost."], ["IPod Nano", "Just like the fourth-generation iPod Nano, Product Red and the yellow Nano were only available on the Apple Online Store and Apple Retail Store.", "This generation was discontinued on September 1, 2010.", "At a media event on September 1, 2010, Apple announced the sixth generation iPod Nano, which, among many new features, was designed around a high resolution square touch-screen.", "The device featured a small 1.55\u00a0inch multi-touch screen with a lower resolution of 240\u00d7240 pixels but a higher pixel density of 220 pixels per inch, as opposed to the larger 2.2\u00a0inch screen on the fifth-generation iPod Nano.", "The device had a 0.39 watt-hour battery rated at 3.7 volts, giving a capacity of 105 mAh, and specified to give 24 hours of music playback on a single full charge.", "The device takes about three hours for one full charge.", "The device retained the same 30-pin dock connector as previous generations.", "This Nano lost the previous generation's video camera, built-in voice recorder microphone (although plugging in headphones with a built in microphone revealed a Voice Memos app) and built-in speaker, and games."]], "gold": "During a special iPod-centric event on September 5, 2007, Steve Jobs introduced the sixth-generation iPod and the suffix classic. Featuring slightly thinner bodies, the sixth-generation iPod also had dramatically improved battery life, claiming up to 36 hours of music playback and 6 hours of video playback. The next year, during the Let's Rock Apple Event on September 9, 2008, the 80GB and the thicker 160GB model of the sixth-generation iPod were discontinued in favor of a thin 120GB version retailing for $249. This version introduced Genius and audio recording capabilities. The following year, prior to the It's Only Rock and Roll event on September 9, 2009, the price of the 120GB version was dropped to $229. During this event, Apple replaced the 120GB version with a 160GB model, featuring the same slim profile of the 80GB and 120GB models. It retailed for $249. The next year, at a media event on September 1, 2010, Apple announced the sixth generation iPod Nano, which, among many new features, was designed around a high-resolution square touchscreen. Additionally, the sixth-generation iPod Touch, a multipurpose handheld device designed and marketed by Apple with a touchscreen-based user interface, was the successor to the iPod Touch fifth generation. This sixth-generation iPod Touch became the first major update to the iPod lineup in more than two and a half years. It was released in the online Apple Store on July 15, 2015.", "prediction 1": "The sixth-generation iPod was introduced on September 5, 2007 at an iPod-centric event. At a media event on September 1, 2010, Apple announced the sixth-generation iPod Nano. The device featured a small 1.55 inch multi-touch screen with a lower resolution of 240240 pixels but a higher pixel density of 220 pixels per inch, as opposed to the larger 2.2 inch screen on the fifth-generation iPod Nano.", "prediction 2": "The sixth-generation iPod came out on September 5, 2007, along with the suffix \"classic\" and a completely revamped user interface with more graphics and Cover Flow. During a special iPod-centric event on September 5, 2007, Steve Jobs introduced the sixth-generation iPod and the suffix \"classic\". At a media event on September 1, 2010, Apple announced the sixth generation iPod Nano, which, among many new features, was designed around a high resolution square touch-screen and featured a small 1.55 inch multi-touch screen with a lower resolution of 240240 pixels but a higher pixel density of 220 pixels per inch, as opposed to the larger 2.2 inch screen of the larger 2.2 inch screen on the previous generation's larger 2.2 inch resolution of 240240240 pixels per inch.", "prediction 3": "On September 5, 2007, Steve Jobs introduced the sixth-generation iPod and the suffix \"classic\". In addition, the sixth-generation iPod introduced a completely overhauled user interface, incorporating more graphics and Cover Flow.", "prediction 4": "The sixth-generation iPod was announced during a special iPod-centric event on September 5, 2007 by Steve Jobs. The sixth-generation iPod had dramatically improved battery life, claiming up to 36 hours of music playback and 6 hours of video playback. At a media event on September 1, 2010, Apple announced the sixth generation iPod Nano, which, among many new features, was designed around a high resolution square touch-screen.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 175, "end": 399}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [3]}], "corrected-prediction": "The sixth-generation iPod was introduced on September 5, 2007 at an iPod-centric event. This model featured slightly thinner bodies and dramatically improved battery life, claiming up to 36 hours of music playback and 6 hours of video playback. The following year, during the 'Let's Rock' Apple Event on September 9, 2008, the 80GB and the thicker 160GB model were discontinued in favor of a thin 120GB version. Prior to the 'It's Only Rock and Roll' event on September 9, 2009, the price of the 120GB version was dropped to $229. During this event, Apple replaced the 120GB version with a 160GB model. At a media event on September 1, 2010, Apple announced the sixth-generation iPod Nano."}, "preference": [2, 1, 1, 1, 1, 2], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - IPod Classic\nS1. Gapless playback and support for iPod games was enabled on all fifth-generation iPods through a firmware update released at the same time.\nS2. During a special iPod-centric event on September 5, 2007, Steve Jobs introduced the sixth-generation iPod and the suffix \"classic\".\nS3. Featuring slightly thinner bodies, the sixth-generation iPod also had dramatically improved battery life, claiming up to 36 hours of music playback and 6 hours of video playback.\nS4. The iPod Classic has a 2.5\" backlit display at a resolution of 320\u00d7240.\nS5. The front plate of the iPod is now made of anodized aluminium instead of polycarbonate plastic, and \"Signature iPod White\" has been replaced by silver.\nS6. This marks the first time white is not available as a color option for an iPod.\nS7. The sixth-generation iPod also introduced a completely overhauled user interface, incorporating more graphics and Cover Flow.\nS8. The iPod Classic was offered in an 80GB model for MSRP US$249 and a 160GB model for MSRP US$349.\nS9. During the 'Let's Rock' Apple Event on September 9, 2008, the 80GB and the thicker 160GB model were discontinued in favor of a thin 120GB version retailing for US$249.\n\nPassage 2: Title (S0) - IPod Classic\nS1. It introduced Genius and audio recording capabilities which are also available in other iPod models released at similar times; no firmware update provides either feature to the first-generation iPods.\nS2. Also, the black model's faceplate was replaced with a gray colored faceplate, while retaining the silver backing and the black Click Wheel.\nS3. Prior to the 'It's Only Rock and Roll' event on September 9, 2009, the price of the 120GB version was dropped to US$229.\nS4. During the event, Apple replaced the 120GB version with an 160GB model, featuring the same slim profile which retailed at US$249.\nS5. U2 Special Editions There are four different U2 Special Edition iPod models, each with widely differing capabilities.\nS6. However, each of the U2 models -- the iPod U2 (4th Gen), iPod U2 (Color), iPod U2 (5th Gen/Video), and iPod U2 (5th Gen Enhanced) -- are the same internally as the \"standard\" iPod model available at the time, and the U2 models vary only in case design and cost.\n\nPassage 3: Title (S0) - IPod Nano\nS1. Just like the fourth-generation iPod Nano, Product Red and the yellow Nano were only available on the Apple Online Store and Apple Retail Store.\nS2. This generation was discontinued on September 1, 2010.\nS3. At a media event on September 1, 2010, Apple announced the sixth generation iPod Nano, which, among many new features, was designed around a high resolution square touch-screen.\nS4. The device featured a small 1.55\u00a0inch multi-touch screen with a lower resolution of 240\u00d7240 pixels but a higher pixel density of 220 pixels per inch, as opposed to the larger 2.2\u00a0inch screen on the fifth-generation iPod Nano.\nS5. The device had a 0.39 watt-hour battery rated at 3.7 volts, giving a capacity of 105 mAh, and specified to give 24 hours of music playback on a single full charge.\nS6. The device takes about three hours for one full charge.\nS7. The device retained the same 30-pin dock connector as previous generations.\nS8. This Nano lost the previous generation's video camera, built-in voice recorder microphone (although plugging in headphones with a built in microphone revealed a Voice Memos app) and built-in speaker, and games.\n    \nInput Question:\nWhen did the 6th generation ipod come out?\n\nCorrect Response:\nDuring a special iPod-centric event on September 5, 2007, Steve Jobs introduced the sixth-generation iPod and the suffix classic. Featuring slightly thinner bodies, the sixth-generation iPod also had dramatically improved battery life, claiming up to 36 hours of music playback and 6 hours of video playback. The next year, during the Let's Rock Apple Event on September 9, 2008, the 80GB and the thicker 160GB model of the sixth-generation iPod were discontinued in favor of a thin 120GB version retailing for $249. This version introduced Genius and audio recording capabilities. The following year, prior to the It's Only Rock and Roll event on September 9, 2009, the price of the 120GB version was dropped to $229. During this event, Apple replaced the 120GB version with a 160GB model, featuring the same slim profile of the 80GB and 120GB models. It retailed for $249. The next year, at a media event on September 1, 2010, Apple announced the sixth generation iPod Nano, which, among many new features, was designed around a high-resolution square touchscreen. Additionally, the sixth-generation iPod Touch, a multipurpose handheld device designed and marketed by Apple with a touchscreen-based user interface, was the successor to the iPod Touch fifth generation. This sixth-generation iPod Touch became the first major update to the iPod lineup in more than two and a half years. It was released in the online Apple Store on July 15, 2015.\n\nModel Prediction:\nThe sixth-generation iPod was introduced on September 5, 2007 at an iPod-centric event. At a media event on September 1, 2010, Apple announced the sixth-generation iPod Nano. The device featured a small 1.55 inch multi-touch screen with a lower resolution of 240240 pixels but a higher pixel density of 220 pixels per inch, as opposed to the larger 2.2 inch screen on the fifth-generation iPod Nano.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "The sixth-generation iPod was introduced on September 5, 2007 at an iPod-centric event. At a media event on September 1, 2010, Apple announced the sixth-generation iPod Nano. [The device featured a small 1.55 inch multi-touch screen with a lower resolution of 240240 pixels but a higher pixel density of 220 pixels per inch, as opposed to the larger 2.2 inch screen on the fifth-generation iPod Nano.]\n\nExplanation:\nThe last sentence in the model prediction is irrelevant as it does not directly answer the question nor provide crucial auxiliary information. The question is asking about the release date of the 6th generation iPod, not its technical specifications. Therefore, the information about the screen size and resolution is not relevant to the question."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The sixth-generation iPod was introduced on September 5, 2007 at an iPod-centric event.\nS2. At a media event on September 1, 2010, Apple announced the sixth-generation iPod Nano.\nS3. The device featured a small 1.55 inch multi-touch screen with a lower resolution of 240240 pixels but a higher pixel density of 220 pixels per inch, as opposed to the larger 2.2 inch screen on the fifth-generation iPod Nano.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation:\nAll the facts presented in the model prediction are consistent with the information provided in the passages. There are no inconsistencies or unverifiable facts in the model prediction."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 3 [Missing Major Auxiliary Information]\n2. Passage 1, sentence 9 [Missing Major Auxiliary Information]\n3. Passage 2, sentence 3 [Missing Major Auxiliary Information]\n4. Passage 2, sentence 4 [Missing Major Auxiliary Information]\n\nExplanation:\n1. The model prediction is missing the information about the improved battery life of the sixth-generation iPod, which is a major auxiliary information that helps to understand the features of the sixth-generation iPod.\n2. The model prediction does not mention the discontinuation of the 80GB and 160GB models of the sixth-generation iPod in favor of a thin 120GB version, which is a significant event in the timeline of the sixth-generation iPod.\n3. The price drop of the 120GB version to $229 prior to the 'It's Only Rock and Roll' event on September 9, 2009, is missing from the model prediction.\n4. The replacement of the 120GB version with a 160GB model during the 'It's Only Rock and Roll' event is also not mentioned in the model prediction. This is a significant detail in the history of the sixth-generation iPod."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The sixth-generation iPod was introduced on September 5, 2007 at an iPod-centric event. This model featured slightly thinner bodies and dramatically improved battery life, claiming up to 36 hours of music playback and 6 hours of video playback. The following year, during the 'Let's Rock' Apple Event on September 9, 2008, the 80GB and the thicker 160GB model were discontinued in favor of a thin 120GB version. Prior to the 'It's Only Rock and Roll' event on September 9, 2009, the price of the 120GB version was dropped to $229. During this event, Apple replaced the 120GB version with a 160GB model. At a media event on September 1, 2010, Apple announced the sixth-generation iPod Nano."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 175, "end": 399}], "missing-info": [{"error type": "Missing-Minor-Auxiliary", "passage_id": 1, "sentence_id": [2]}, {"error type": "Missing-Minor-Auxiliary", "passage_id": 1, "sentence_id": [3]}, {"error type": "Missing-Minor-Auxiliary", "passage_id": 2, "sentence_id": [3]}, {"error type": "Missing-Minor-Auxiliary", "passage_id": 2, "sentence_id": [4]}, {"error type": "Missing-Minor-Auxiliary", "passage_id": 2, "sentence_id": [1]}, {"error type": "Missing-Minor-Auxiliary", "passage_id": 3, "sentence_id": [3]}], "corrected-prediction": "The sixth-generation iPod and the suffix \"classic\" were introduced by Steve Jobs on September 5, 2007 at an iPod-centric event. Featuring slightly thinner bodies, the sixth-generation iPod also had dramatically improved battery life, claiming up to 36 hours of music playback and 6 hours of video playback. During the 'It's Only Rock and Roll' event on September 9, 2009, the price of the 120GB version was dropped to US$229 and Apple replaced the 120GB version with an 160GB model, featuring the same slim profile which retailed at US$249. This version introduced Genius and audio recording capabilities.  At a media event on September 1, 2010, Apple announced the sixth-generation iPod Nano,  which, among many new features, was designed around a high resolution square touch-screen."}}, {"question": "When did they change the australian national anthem?", "passages": [["Advance Australia Fair", "In January 1976 the Fraser government reinstated \"God Save the Queen\" for royal, vice-regal, defence and loyal toast occasions as well as making plans to conduct a national poll to find a song for use on ceremonial occasions when it was desired to mark a separate Australian identity.", "This was conducted as a plebiscite to choose the National Song, held as an optional additional question in the 1977 referendum on various issues.", "\"Advance Australia Fair\" received 43.29% of the vote, defeating the three alternatives, \"Waltzing Matilda\" (28.28%), \"Song of Australia\" (9.65%) and the existing national anthem, \"God Save the Queen\" (18.78%).", "\"Advance Australia Fair\", with modified lyrics from the original (see development of lyrics), was adopted as the Australian national anthem on 19 April 1984 by a proclamation by the Governor-General, Sir Ninian Stephen, on a recommendation by the Labor government of Bob Hawke.", "\"God Save the Queen\", now known as the royal anthem, continues to be played alongside the Australian national anthem at public engagements in Australia that are attended by the Queen or members of the Royal Family."], ["Advance Australia Fair", "The contest was held in two stages, the first seeking lyrics and the second music, each having an A$5,000 prize for the winning entry.", "On the recommendation of the Council for the Arts, none of the new entries were felt worthy enough, so the contest ended with the suggestions for \"Advance Australia Fair\", \"Waltzing Matilda\" and \"Song of Australia\".", "In 1974 the Whitlam government then performed a nationwide opinion survey to determine the song to be sung on occasions of national significance.", "Conducted through the Australian Bureau of Statistics, it polled 60,000 people nationally.", "\"Advance Australia Fair\" was chosen and was enshrined as the national song, to be used on all occasions excepting those of a specifically regal nature.", "A spokesman for the Prime Minister Gough Whitlam stated that the Government regarded the tune primarily as the national anthem.", "During the 1975 election campaign following the dismissal of Whitlam by Sir John Kerr, it was proposed by David Combe that the song be played at the start of the Labor Party's official campaign launch on 24 November 1975 at Festival Hall, Melbourne.", "Whitlam's speechwriter Graham Freudenberg rejected this idea, on two grounds, one of which was that the status of the anthem was still tentative."], ["Waltzing Matilda", "The song was one of four included in a national plebiscite to choose Australia's national song held on 21 May 1977 by the Fraser Government to determine which song was preferred as Australia's national anthem.", "\"Waltzing Matilda\" received 28% of the vote compared with 43% for \"Advance Australia Fair\", 19% for \"God Save the Queen\" and 10% for \"Song of Australia\".", "Australian passports issued from 2003 have had the lyrics of \"Waltzing Matilda\" hidden microscopically in the background pattern of most of the pages for visas and arrival/departure stamps.", "\"Waltzing Matilda\" was used at the 1974 FIFA World Cup and at the Montreal Olympic Games in 1976 and, as a response to the New Zealand All Blacks haka, it has gained popularity as a sporting anthem for the Australia national rugby union team.", "It is also performed, along with \"Advance Australia Fair\", at the annual AFL Grand Final.", "Matilda the Kangaroo was the mascot at the 1982 Commonwealth Games held in Brisbane, Queensland.", "Matilda was a cartoon kangaroo, who appeared as a high mechanical kangaroo at the opening ceremony, accompanied by Rolf Harris singing \"Waltzing Matilda\".", "The Australian women's national soccer team is nicknamed the Matildas after this song."]], "gold": "In 1974 a national survey was conducted to change the Australian National Anthem to \"Advance Australia Fair\". In January 1976 the Fraser government reinstated \"God Save the Queen\" for royal, vice-regal, defense and loyal toast occasions as well as making plans to conduct a national poll to find a song for use on ceremonial occasions when it was desired to mark a separate Australian identity. On 21 May 1977, a formal vote was conducted to make the change. And on 19 April 1984 \"Advance Australia Fair\", with modified lyrics from the original, was adopted as the Australian national anthem. ", "prediction 1": "In 1977, the federal government reintroduced \"God Save the Queen\" as the national anthem for their country. In January 1976, the Fraser government reinstated \"God Save the Queen\" for royal, vice-regal, defence and loyal toast occasions as well as making plans to conduct a national poll to find a song for use on ceremonial occasions when it was desired to mark a separate Australian identity. Advance Australia Fair, with modified lyrics from the original, was adopted as the Australian national anthem on 19 April 1984 by a proclamation by the Governor-General, Sir Ninian Stephen, on a recommendation by the Labor government of Bob Hawke.", "prediction 2": "The australian national anthem was changed in January 1976 by the Fraser government to \"Advance Australia Fair\", in which the lyrics were altered from the original. On April 19, 1984 the song was adopted as the official national anthem of Australia by a proclamation by the Governor-General, Sir Ninian Stephen, on a recommendation by the Labor government of Bob Hawke.", "prediction 3": "In January 1976 the Fraser government reinstated \"God Save the Queen\" for royal, vice-regal, defence and loyal toast occasions as well as making plans to conduct a national poll to find a song for use on ceremonial occasions when it was desired to mark a separate Australian identity. This was conducted as a plebiscite to choose the National Song, held as an optional additional question in the 1977 referendum on various issues. Then on May 21, 1977 the Fraser Government held a national plebiscite to choose Australia's national anthem, with modified lyrics from the original, was adopted as the Australian national anthem on April 19, 1984 by a proclamation by the Governor-General, Sir Ninian Stephen, on a recommendation by the Labor government of Bob Hawke.", "prediction 4": "In January 1976 the Fraser government reinstated \"God Save the Queen\" for royal, vice-regal, defence and loyal toast occasions as well as making plans to conduct a national poll to find a song for use on ceremonial occasions when it was desired to mark a separate Australian identity. This was conducted as a plebiscite to choose the National Song, held as an optional additional question in the 1977 referendum on various issues. Then, on 19 April 1984, the government changed the song to \"Advance Australia Fair\" with modified lyrics from the original. The song was then adopted as the national anthem on 19 April 1984 by a proclamation by the Governor-General, Sir Ninian Stephen, on a recommendation by the Labor government of Bob Hawke.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 0, "end": 107}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 2, "sentence_id": [3]}], "corrected-prediction": "In January 1976, the Fraser government reinstated \"God Save the Queen\" for royal, vice-regal, defence and loyal toast occasions as well as making plans to conduct a national poll to find a song for use on ceremonial occasions when it was desired to mark a separate Australian identity. In 1974, a nationwide opinion survey was conducted to determine the song to be sung on occasions of national significance. A formal vote was conducted in 1977, where \"Advance Australia Fair\" received 43.29% of the vote, defeating the three alternatives. Finally, \"Advance Australia Fair\", with modified lyrics from the original, was adopted as the Australian national anthem on 19 April 1984 by a proclamation by the Governor-General, Sir Ninian Stephen, on a recommendation by the Labor government of Bob Hawke."}, "preference": [1, 1, 1, 2, 2, 1], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Advance Australia Fair\nS1. In January 1976 the Fraser government reinstated \"God Save the Queen\" for royal, vice-regal, defence and loyal toast occasions as well as making plans to conduct a national poll to find a song for use on ceremonial occasions when it was desired to mark a separate Australian identity.\nS2. This was conducted as a plebiscite to choose the National Song, held as an optional additional question in the 1977 referendum on various issues.\nS3. \"Advance Australia Fair\" received 43.29% of the vote, defeating the three alternatives, \"Waltzing Matilda\" (28.28%), \"Song of Australia\" (9.65%) and the existing national anthem, \"God Save the Queen\" (18.78%).\nS4. \"Advance Australia Fair\", with modified lyrics from the original (see development of lyrics), was adopted as the Australian national anthem on 19 April 1984 by a proclamation by the Governor-General, Sir Ninian Stephen, on a recommendation by the Labor government of Bob Hawke.\nS5. \"God Save the Queen\", now known as the royal anthem, continues to be played alongside the Australian national anthem at public engagements in Australia that are attended by the Queen or members of the Royal Family.\n\nPassage 2: Title (S0) - Advance Australia Fair\nS1. The contest was held in two stages, the first seeking lyrics and the second music, each having an A$5,000 prize for the winning entry.\nS2. On the recommendation of the Council for the Arts, none of the new entries were felt worthy enough, so the contest ended with the suggestions for \"Advance Australia Fair\", \"Waltzing Matilda\" and \"Song of Australia\".\nS3. In 1974 the Whitlam government then performed a nationwide opinion survey to determine the song to be sung on occasions of national significance.\nS4. Conducted through the Australian Bureau of Statistics, it polled 60,000 people nationally.\nS5. \"Advance Australia Fair\" was chosen and was enshrined as the national song, to be used on all occasions excepting those of a specifically regal nature.\nS6. A spokesman for the Prime Minister Gough Whitlam stated that the Government regarded the tune primarily as the national anthem.\nS7. During the 1975 election campaign following the dismissal of Whitlam by Sir John Kerr, it was proposed by David Combe that the song be played at the start of the Labor Party's official campaign launch on 24 November 1975 at Festival Hall, Melbourne.\nS8. Whitlam's speechwriter Graham Freudenberg rejected this idea, on two grounds, one of which was that the status of the anthem was still tentative.\n\nPassage 3: Title (S0) - Waltzing Matilda\nS1. The song was one of four included in a national plebiscite to choose Australia's national song held on 21 May 1977 by the Fraser Government to determine which song was preferred as Australia's national anthem.\nS2. \"Waltzing Matilda\" received 28% of the vote compared with 43% for \"Advance Australia Fair\", 19% for \"God Save the Queen\" and 10% for \"Song of Australia\".\nS3. Australian passports issued from 2003 have had the lyrics of \"Waltzing Matilda\" hidden microscopically in the background pattern of most of the pages for visas and arrival/departure stamps.\nS4. \"Waltzing Matilda\" was used at the 1974 FIFA World Cup and at the Montreal Olympic Games in 1976 and, as a response to the New Zealand All Blacks haka, it has gained popularity as a sporting anthem for the Australia national rugby union team.\nS5. It is also performed, along with \"Advance Australia Fair\", at the annual AFL Grand Final.\nS6. Matilda the Kangaroo was the mascot at the 1982 Commonwealth Games held in Brisbane, Queensland.\nS7. Matilda was a cartoon kangaroo, who appeared as a high mechanical kangaroo at the opening ceremony, accompanied by Rolf Harris singing \"Waltzing Matilda\".\nS8. The Australian women's national soccer team is nicknamed the Matildas after this song.\n    \nInput Question:\nWhen did they change the australian national anthem?\n\nCorrect Response:\nIn 1974 a national survey was conducted to change the Australian National Anthem to \"Advance Australia Fair\". In January 1976 the Fraser government reinstated \"God Save the Queen\" for royal, vice-regal, defense and loyal toast occasions as well as making plans to conduct a national poll to find a song for use on ceremonial occasions when it was desired to mark a separate Australian identity. On 21 May 1977, a formal vote was conducted to make the change. And on 19 April 1984 \"Advance Australia Fair\", with modified lyrics from the original, was adopted as the Australian national anthem. \n\nModel Prediction:\nIn 1977, the federal government reintroduced \"God Save the Queen\" as the national anthem for their country. In January 1976, the Fraser government reinstated \"God Save the Queen\" for royal, vice-regal, defence and loyal toast occasions as well as making plans to conduct a national poll to find a song for use on ceremonial occasions when it was desired to mark a separate Australian identity. Advance Australia Fair, with modified lyrics from the original, was adopted as the Australian national anthem on 19 April 1984 by a proclamation by the Governor-General, Sir Ninian Stephen, on a recommendation by the Labor government of Bob Hawke.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "[In 1977, the federal government reintroduced \"God Save the Queen\" as the national anthem for their country.] In January 1976, the Fraser government reinstated \"God Save the Queen\" for royal, vice-regal, defence and loyal toast occasions as well as making plans to conduct a national poll to find a song for use on ceremonial occasions when it was desired to mark a separate Australian identity. Advance Australia Fair, with modified lyrics from the original, was adopted as the Australian national anthem on 19 April 1984 by a proclamation by the Governor-General, Sir Ninian Stephen, on a recommendation by the Labor government of Bob Hawke.\n\nExplanation:\n1. The first sentence is irrelevant because it does not provide any useful information related to the question. The federal government did not reintroduce \"God Save the Queen\" as the national anthem in 1977. Instead, they conducted a national poll to choose a new national song. This information is neither an answer nor crucial auxiliary information, so it should be marked as \"Irrelevant\"."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. In 1977, the federal government reintroduced \"God Save the Queen\" as the national anthem for their country.\nS2. In January 1976, the Fraser government reinstated \"God Save the Queen\" for royal, vice-regal, defence and loyal toast occasions as well as making plans to conduct a national poll to find a song for use on ceremonial occasions when it was desired to mark a separate Australian identity.\nS3. Advance Australia Fair, with modified lyrics from the original, was adopted as the Australian national anthem on 19 April 1984 by a proclamation by the Governor-General, Sir Ninian Stephen, on a recommendation by the Labor government of Bob Hawke.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "Inconsistent or Unverifiable Sentences:\n1. S1\n\nExplanation:\n1. The first sentence is factually inconsistent with the passages. According to Passage 1 Sentence 1 and Passage 2 Sentence 3, \"God Save the Queen\" was reinstated for certain occasions in 1976, not reintroduced as the national anthem in 1977. Therefore, this sentence contains an \"Inconsistent Fact\"."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 2, sentence 3 [Missing Answer]\n2. Passage 1, sentence 3 [Missing Major Auxiliary Information]\n\nExplanation:\n1. The model prediction is missing the information about the nationwide opinion survey conducted in 1974 to determine the song to be sung on occasions of national significance, which is an important part of the process of changing the national anthem. This is a \"Missing Answer\" from Passage 2, sentence 3.\n2. The model prediction also omits the information about the 1977 plebiscite where \"Advance Australia Fair\" received 43.29% of the vote, defeating the three alternatives. This is a \"Missing Major Auxiliary Information\" from Passage 1, sentence 3, as it provides crucial context about the selection process of the new national anthem."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "In January 1976, the Fraser government reinstated \"God Save the Queen\" for royal, vice-regal, defence and loyal toast occasions as well as making plans to conduct a national poll to find a song for use on ceremonial occasions when it was desired to mark a separate Australian identity. In 1974, a nationwide opinion survey was conducted to determine the song to be sung on occasions of national significance. A formal vote was conducted in 1977, where \"Advance Australia Fair\" received 43.29% of the vote, defeating the three alternatives. Finally, \"Advance Australia Fair\", with modified lyrics from the original, was adopted as the Australian national anthem on 19 April 1984 by a proclamation by the Governor-General, Sir Ninian Stephen, on a recommendation by the Labor government of Bob Hawke."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 0, "end": 107}, {"error type": "Irrelevant", "explanation": "", "start": 521, "end": 641}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 2, "sentence_id": [3]}, {"error type": "Missing-Major-Auxiliary", "passage_id": 3, "sentence_id": [1]}], "corrected-prediction": "In 1974, a nationwide opinion survey to determine the song to be sung on occasions of national significance. In January 1976, the Fraser government reinstated \"God Save the Queen\" for royal, vice-regal, defence and loyal toast occasions as well as making plans to conduct a national poll to find a song for use on ceremonial occasions when it was desired to mark a separate Australian identity. A national plebiscite to choose Australia's national song held on 21 May 1977. Advance Australia Fair, with modified lyrics from the original, was adopted as the Australian national anthem on 19 April 1984."}}, {"question": "Who changed the date of the day of the dead?", "passages": [["Day of the Dead", "Day of the Dead\n\nThe Day of the Dead () is a Mexican holiday celebrated throughout Mexico, in particular the Central and South regions, and by people of Mexican heritage elsewhere.", "The multi-day holiday focuses on gatherings of family and friends to pray for and remember friends and family members who have died, and help support their spiritual journey.", "In 2008, the tradition was inscribed in the Representative List of the Intangible Cultural Heritage of Humanity by UNESCO.", "The holiday is sometimes called D\u00eda de los Muertos in Anglophone countries, a back-translation of its original name, \"D\u00eda de Muertos\".", "It is particularly celebrated in Mexico where the day is a public holiday.", "Prior to Spanish colonization in the 16th century, the celebration took place at the beginning of summer.", "Gradually, it was associated with October 31, November 1, and November 2 to coincide with the Western Christianity triduum of Allhallowtide: All Saints' Eve, All Saints' Day, and All Souls' Day.", "Traditions connected with the holiday include building private altars called \"ofrendas\", honoring the deceased using calaveras, aztec marigolds, and the favorite foods and beverages of the departed, and visiting graves with these as gifts.", "Visitors also leave possessions of the deceased at the graves."]], "gold": "The Day of the Dead is a Mexican holiday that involves family and friends gathering to pray for and to remember friends and family members who have died. Prior to Spanish colonization of Mexico in the 16th century, the celebration took place at the beginning of summer, but it gradually became associated with the dates of October 31, November 1, and November 2.", "prediction 1": "The Day of the Dead is a Mexican holiday celebrated throughout Mexico, in particular the Central and South regions, and by people of Mexican heritage elsewhere. The multi-day holiday focuses on gatherings of family and friends to pray for and remember friends and family members who have died, and help support their spiritual journey. Prior to Spanish colonization in the 16th century, the celebration took place at the beginning of summer.", "prediction 2": "The Day of the Dead is a Mexican holiday celebrated throughout Mexico, in particular the Central and South regions, and by people of Mexican heritage elsewhere. The multi-day holiday focuses on gatherings of family and friends to pray for and remember friends and family members who have died, and help support their spiritual journey. There are several variations of the day, but for the most part, the date of the day of the dead was changed several times. Before Spanish colonization in the 16th century, the celebration took place at the beginning of summer. Gradually, it was associated with October 31, November 1, and November 2.", "prediction 3": "Prior to Spanish colonization in the 16th century, the celebration took place at the beginning of summer. Gradually, it was associated with October 31, November 1, and November 2 to coincide with the Western Christianity triduum of Allhallowtide: All Saints' Eve, All Saints' Day, and All Souls' Day. In 1581, the date was changed to November 2, 931. The date of the current Day of the Dead is November 2.", "prediction 4": "The Day of the Dead is a Mexican holiday celebrated throughout Mexico, in particular the Central and South regions, and by people of Mexican heritage elsewhere. The multi-day holiday focuses on gatherings of family and friends to pray for and remember friends and family members who have died, and help support their spiritual journey. The date of the holiday was changed from August 20, 1698, to November 2, 1698, and from 1798 to 1898.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 161, "end": 335}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 1, "sentence_id": [7]}], "corrected-prediction": "The Day of the Dead is a Mexican holiday celebrated throughout Mexico, in particular the Central and South regions, and by people of Mexican heritage elsewhere. Prior to Spanish colonization in the 16th century, the celebration took place at the beginning of summer. Gradually, it was associated with October 31, November 1, and November 2 to coincide with the Western Christianity triduum of Allhallowtide: All Saints' Eve, All Saints' Day, and All Souls' Day."}, "preference": [2, 1, 1, 1, 1, 1], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Day of the Dead\nS1. Day of the Dead  The Day of the Dead () is a Mexican holiday celebrated throughout Mexico, in particular the Central and South regions, and by people of Mexican heritage elsewhere.\nS2. The multi-day holiday focuses on gatherings of family and friends to pray for and remember friends and family members who have died, and help support their spiritual journey.\nS3. In 2008, the tradition was inscribed in the Representative List of the Intangible Cultural Heritage of Humanity by UNESCO.\nS4. The holiday is sometimes called D\u00eda de los Muertos in Anglophone countries, a back-translation of its original name, \"D\u00eda de Muertos\".\nS5. It is particularly celebrated in Mexico where the day is a public holiday.\nS6. Prior to Spanish colonization in the 16th century, the celebration took place at the beginning of summer.\nS7. Gradually, it was associated with October 31, November 1, and November 2 to coincide with the Western Christianity triduum of Allhallowtide: All Saints' Eve, All Saints' Day, and All Souls' Day.\nS8. Traditions connected with the holiday include building private altars called \"ofrendas\", honoring the deceased using calaveras, aztec marigolds, and the favorite foods and beverages of the departed, and visiting graves with these as gifts.\nS9. Visitors also leave possessions of the deceased at the graves.\n    \nInput Question:\nWho changed the date of the day of the dead?\n\nCorrect Response:\nThe Day of the Dead is a Mexican holiday that involves family and friends gathering to pray for and to remember friends and family members who have died. Prior to Spanish colonization of Mexico in the 16th century, the celebration took place at the beginning of summer, but it gradually became associated with the dates of October 31, November 1, and November 2.\n\nModel Prediction:\nThe Day of the Dead is a Mexican holiday celebrated throughout Mexico, in particular the Central and South regions, and by people of Mexican heritage elsewhere. The multi-day holiday focuses on gatherings of family and friends to pray for and remember friends and family members who have died, and help support their spiritual journey. Prior to Spanish colonization in the 16th century, the celebration took place at the beginning of summer.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "The Day of the Dead is a Mexican holiday celebrated throughout Mexico, in particular the Central and South regions, and by people of Mexican heritage elsewhere. [The multi-day holiday focuses on gatherings of family and friends to pray for and remember friends and family members who have died, and help support their spiritual journey.] Prior to Spanish colonization in the 16th century, the celebration took place at the beginning of summer.\n\nExplanation:\nThe second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\"."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The Day of the Dead is a Mexican holiday celebrated throughout Mexico, in particular the Central and South regions, and by people of Mexican heritage elsewhere.\nS2. The multi-day holiday focuses on gatherings of family and friends to pray for and remember friends and family members who have died, and help support their spiritual journey.\nS3. Prior to Spanish colonization in the 16th century, the celebration took place at the beginning of summer.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation:\nAll the facts mentioned in the model prediction are consistent with the provided passages and none of them are unverifiable."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 7 [Missing Answer]\n\nExplanation:\n1. The model prediction does not mention that the date of the Day of the Dead was changed to coincide with the Western Christianity triduum of Allhallowtide: All Saints' Eve, All Saints' Day, and All Souls' Day. This information is crucial to answering the question and is found in Passage 1, sentence 7."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The Day of the Dead is a Mexican holiday celebrated throughout Mexico, in particular the Central and South regions, and by people of Mexican heritage elsewhere. Prior to Spanish colonization in the 16th century, the celebration took place at the beginning of summer. Gradually, it was associated with October 31, November 1, and November 2 to coincide with the Western Christianity triduum of Allhallowtide: All Saints' Eve, All Saints' Day, and All Souls' Day."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 41, "end": 160}, {"error type": "Irrelevant", "explanation": "", "start": 161, "end": 182}, {"error type": "Irrelevant", "explanation": "", "start": 294, "end": 335}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [7]}], "corrected-prediction": "The Day of the Dead is a Mexican holiday that focuses on gatherings of family and friends to pray for and remember friends and family members who have died. Prior to Spanish colonization in the 16th century, the celebration took place at the beginning of summer, but it gradually became associated with the dates of October 31, November 1, and November 2."}}, {"question": "When did presidents start running with vice presidents?", "passages": [["Running mate", "As more and more states subsequently began to choose their electors by popular election instead of appointment (South Carolina being the last state to change, in 1860), candidates began to realize they could run together as a team for president and vice president instead of running completely separately for each office.", "The practice of a presidential candidate having a running mate was solidified during the American Civil War.", "In 1864, in the interest of fostering national unity, Abraham Lincoln from the Republican Party (popular in the North) and Andrew Johnson of the Democratic Party (popular in the South) were co-endorsed and ran together for President and Vice-President as candidates of the National Union Party.", "Notwithstanding this party disbanded after the war ended, with the result that Republican Lincoln was succeeded by Democrat Johnson; the states began to place candidates for President and Vice-President together on the same ballot ticket - thus making it impossible to vote for a presidential candidate from one party and a vice-presidential candidate from another party, as had previously been possible.", "Presidential candidates from smaller states sometimes choose a vice presidential running mate from a state with a large number of electoral votes - as in 1984 when Walter Mondale of Minnesota (10 votes) selected Geraldine Ferraro of New York (then 36 votes)."]], "gold": "The practice of having a presidential candidate run with a running mate began during the civil war. In 1864, in the interest of fostering national unity, Abraham Lincoln from the Republican Party (popular in the North) and Andrew Johnson of the Democratic Party (popular in the South) were co-endorsed and ran together for President and Vice-President as candidates of the National Union Party.", "prediction 1": "The practice of a presidential candidate having a running mate was solidified during the American Civil War. In 1864, in the interest of fostering national unity, Abraham Lincoln from the Republican Party (popular in the North) and Andrew Johnson of the Democratic Party (popular in the South) were co-endorsed and ran together for President and Vice-President as candidates of the National Union Party. The practice of a presidential candidate having a running mate was solidified during the 1865 election, when William Jefferson Harrison was the vice president and Lincoln from the Democratic Party.", "prediction 2": "The practice of a presidential candidate having a running mate was solidified during the American Civil War. In 1864, in the interest of fostering national unity, Abraham Lincoln from the Republican Party (popular in the North) and Andrew Johnson of the Democratic Party (popular in the South) were co-endorsed and ran together for President and Vice-President as candidates of the National Union Party. Presidential candidates from smaller states sometimes choose a vice presidential running mate from a state with a large number of electoral votes, as in 1984 when Walter Mondale of Minnesota selected Geraldine Ferraro of New York.", "prediction 3": "The practice of a presidential candidate having a running mate was solidified during the American Civil War. In 1864, in the interest of fostering national unity, Abraham Lincoln from the Republican Party (popular in the North) and Andrew Johnson of the Democratic Party (popular in the South) were co-endorsed and ran together for President and Vice-President as candidates of the National Union Party.", "prediction 4": "In 1864, in the interest of fostering national unity, Abraham Lincoln from the Republican Party (popular in the North) and Andrew Johnson of the Democratic Party (popular in the South) were co-endorsed and ran together for President and Vice-President as candidates of the National Union Party. However, this practice was formalized during the American Civil War, when Abraham Lincoln from the Republican Party (popular in the North) and Andrew Johnson of the Democratic Party (popular in the South) were co-endorsed and ran together for President and Vice-President as candidates of the National Union Party. This practice of a running mates was solidified during the American Civil War.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 404, "end": 601}], "missing-info": [], "corrected-prediction": "The practice of a presidential candidate having a running mate was solidified during the American Civil War. In 1864, in the interest of fostering national unity, Abraham Lincoln from the Republican Party (popular in the North) and Andrew Johnson of the Democratic Party (popular in the South) were co-endorsed and ran together for President and Vice-President as candidates of the National Union Party."}, "preference": [0, 2, 1, 2, 1, 1], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Running mate\nS1. As more and more states subsequently began to choose their electors by popular election instead of appointment (South Carolina being the last state to change, in 1860), candidates began to realize they could run together as a team for president and vice president instead of running completely separately for each office.\nS2. The practice of a presidential candidate having a running mate was solidified during the American Civil War.\nS3. In 1864, in the interest of fostering national unity, Abraham Lincoln from the Republican Party (popular in the North) and Andrew Johnson of the Democratic Party (popular in the South) were co-endorsed and ran together for President and Vice-President as candidates of the National Union Party.\nS4. Notwithstanding this party disbanded after the war ended, with the result that Republican Lincoln was succeeded by Democrat Johnson; the states began to place candidates for President and Vice-President together on the same ballot ticket - thus making it impossible to vote for a presidential candidate from one party and a vice-presidential candidate from another party, as had previously been possible.\nS5. Presidential candidates from smaller states sometimes choose a vice presidential running mate from a state with a large number of electoral votes - as in 1984 when Walter Mondale of Minnesota (10 votes) selected Geraldine Ferraro of New York (then 36 votes).\n    \nInput Question:\nWhen did presidents start running with vice presidents?\n\nCorrect Response:\nThe practice of having a presidential candidate run with a running mate began during the civil war. In 1864, in the interest of fostering national unity, Abraham Lincoln from the Republican Party (popular in the North) and Andrew Johnson of the Democratic Party (popular in the South) were co-endorsed and ran together for President and Vice-President as candidates of the National Union Party.\n\nModel Prediction:\nThe practice of a presidential candidate having a running mate was solidified during the American Civil War. In 1864, in the interest of fostering national unity, Abraham Lincoln from the Republican Party (popular in the North) and Andrew Johnson of the Democratic Party (popular in the South) were co-endorsed and ran together for President and Vice-President as candidates of the National Union Party. The practice of a presidential candidate having a running mate was solidified during the 1865 election, when William Jefferson Harrison was the vice president and Lincoln from the Democratic Party.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "The practice of a presidential candidate having a running mate was solidified during the American Civil War. In 1864, in the interest of fostering national unity, Abraham Lincoln from the Republican Party (popular in the North) and Andrew Johnson of the Democratic Party (popular in the South) were co-endorsed and ran together for President and Vice-President as candidates of the National Union Party. [The practice of a presidential candidate having a running mate was solidified during the 1865 election, when William Jefferson Harrison was the vice president and Lincoln from the Democratic Party.]\n\nExplanation:\n1. The last sentence in the model prediction is repetitive as it repeats the information about the practice of a presidential candidate having a running mate being solidified during the American Civil War. It also contains irrelevant and unverifiable information about William Jefferson Harrison being the vice president in 1865 and Lincoln being from the Democratic Party. Therefore, it should be marked as \"Repetitive\" and \"Irrelevant\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The practice of a presidential candidate having a running mate was solidified during the American Civil War.\nS2. In 1864, in the interest of fostering national unity, Abraham Lincoln from the Republican Party (popular in the North) and Andrew Johnson of the Democratic Party (popular in the South) were co-endorsed and ran together for President and Vice-President as candidates of the National Union Party.\nS3. The practice of a presidential candidate having a running mate was solidified during the 1865 election, when William Jefferson Harrison was the vice president and Lincoln from the Democratic Party.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "Inconsistent or Unverifiable Sentences:\n1. S3\n\nExplanation:\n1. The third sentence in the model prediction contains unverifiable facts. The passages do not mention anything about the 1865 election, William Jefferson Harrison being the vice president, or Lincoln being from the Democratic Party. Therefore, these facts are \"Unverifiable\"."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "No missing information in the model prediction. The model prediction contains all the necessary information to answer the question."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The practice of a presidential candidate having a running mate was solidified during the American Civil War. In 1864, in the interest of fostering national unity, Abraham Lincoln from the Republican Party (popular in the North) and Andrew Johnson of the Democratic Party (popular in the South) were co-endorsed and ran together for President and Vice-President as candidates of the National Union Party."}], "feedback_human": {"errors": [{"error type": "Unverifiable", "explanation": "", "start": 404, "end": 601}], "missing-info": [], "corrected-prediction": "The practice of a presidential candidate having a running mate was solidified during the American Civil War. In 1864, in the interest of fostering national unity, Abraham Lincoln from the Republican Party (popular in the North) and Andrew Johnson of the Democratic Party (popular in the South) were co-endorsed and ran together for President and Vice-President as candidates of the National Union Party. "}}, {"question": "When did joseph campbell create the hero's journey?", "passages": [["Hero's journey", "Hero's journey\n\nIn narratology and comparative mythology, the monomyth, or the hero's journey, is the common template of a broad category of tales that involve a hero who goes on an adventure, and in a decisive crisis wins a victory, and then comes home changed or transformed.", "The study of hero myth narratives started in 1871 with anthropologist Edward Burnett Tylor's observations of common patterns in plots of heroes' journeys.", "Later on, others introduced various theories on hero myth narratives such as Otto Rank and his Freudian psychoanalytic approach to myth, Lord Raglan's unification of myth and rituals, and eventually hero myth pattern studies were popularized by Joseph Campbell, who was influenced by Carl Jung's view of myth.", "In his 1949 work \"The Hero with a Thousand Faces\", Campbell described the basic narrative pattern as follows:\nCampbell and other scholars, such as Erich Neumann, describe narratives of Gautama Buddha, Moses, and Christ in terms of the monomyth.", "While others, such as Otto Rank and Lord Raglan, describe hero narrative patterns in terms of Freudian psychoanalysis and ritualistic senses.", "Critics argue that the concept is too broad or general to be of much usefulness in comparative mythology."], ["Joseph Campbell", "Joseph Campbell\n\nJoseph John Campbell (1904\u20131987) was an American Professor of Literature at Sarah Lawrence College who worked in comparative mythology and comparative religion.", "His work covers many aspects of the human experience.", "Campbell's most well-known work is his book \"The Hero with a Thousand Faces\" (1949), in which he discusses his theory of the journey of the archetypal hero shared by world mythologies, termed the monomyth.", "Since the publication of \"The Hero with a Thousand Faces\", Campbell's theory has been applied by a wide variety of modern writers and artists.", "His philosophy has been summarized by his own often repeated phrase: \"Follow your bliss.\"", "He gained recognition in Hollywood when George Lucas credited Campbell's work as influencing his \"Star Wars\" saga.", "Joseph Campbell was born in White Plains, New York, on March 26, 1904, the son of Josephine (n\u00e9e Lynch) and Charles William Campbell.", "He was from an upper-middle-class Irish Catholic family.", "During his childhood, he moved with his family to nearby New Rochelle, New York.", "In 1919, a fire destroyed the family home in New Rochelle, killing his grandmother.", "In 1921, Campbell graduated from the Canterbury School in New Milford, Connecticut.", "While at Dartmouth College he studied biology and mathematics, but decided that he preferred the humanities."], ["The Hero with a Thousand Faces", "The Hero with a Thousand Faces\n\nThe Hero with a Thousand Faces (first published in 1949) is a work of comparative mythology by Joseph Campbell.", "In this book, Campbell discusses his theory of the mythological structure of the journey of the archetypal hero found in world myths.", "Since the publication of \"The Hero with a Thousand Faces\", Campbell's theory has been consciously applied by a wide variety of modern writers and artists.", "Filmmaker George Lucas acknowledged Campbell's theory in mythology, and its influence on the \"Star Wars\" films.", "The Joseph Campbell Foundation and New World Library issued a new edition of \"The Hero with a Thousand Faces\" in July 2008 as part of the Collected Works of Joseph Campbell series of books, audio and video recordings.", "In 2011, \"Time\" placed the book in its list of the 100 best and most influential books written in English since the magazine was founded in 1923.", "Campbell explores the theory that mythological narratives frequently share a fundamental structure.", "The similarities of these myths brought Campbell to write his book in which he details the structure of the \"monomyth\".", "He calls the motif of the archetypal narrative, \"the hero's journey\"."]], "gold": "In narratology and comparative mythology, the hero's journey, or the monomyth, is the common template of stories that involve a hero who goes on an adventure, is victorious in a decisive crisis, and comes home changed or transformed. Joseph Campbell, an American professor of literature at Sarah Lawrence College, began exploring mythology and creating the hero's journey in 1934. He published his book, \"The Hero with a Thousand Faces\", in 1949, in which he discusses his theory of the journey of the archetypal hero shared by world mythologies.", "prediction 1": "In Narratology and Comparative Mythology, the monomyth, or the hero's journey, is the common template of a broad category of tales that involve a hero who goes on an adventure, and in a decisive crisis wins a victory, and then comes home changed or transformed. The study of hero myth narratives started in 1871 with anthropologist Edward Burnett Tylor's observations of common patterns in plots of heroes' journeys. Later on, others introduced various theories on hero myth narratives, Lord Raglan's unification of myth and rituals, and eventually hero myth pattern studies were popularized by Joseph Campbell, who was influenced by Carl Jung's view of myth.", "prediction 2": "In narratology and comparative mythology, the monomyth, or the hero's journey, is the common template of a broad category of tales that involve a hero who goes on an adventure, and in a decisive crisis wins a victory, and then comes home changed or transformed. The study of hero myth narratives started in 1871 with anthropologist Edward Burnett Tylor's observations of common patterns in plots of heroes' journeys. Later on, others introduced various theories on hero mythologies such as Otto Rank and his Freudian psychoanalytic approach to myth, Lord Raglan's unification of myth and rituals, and eventually hero myth pattern studies were popularized by Joseph Campbell. Since the publication of The Hero with a Thousand Faces, Campbell's theory has been consciously applied by a wide variety of modern writers and artists.", "prediction 3": "In narratology and comparative mythology, the monomyth, or the hero's journey, is the common template of a broad category of tales that involve a hero who goes on an adventure, and in a decisive crisis wins a victory, and then comes home changed or transformed. In his 1949 book The Hero with a Thousand Faces, Joseph Campbell discusses his theory of the mythological structure of the journey of the archetypal hero shared by world mythologies, termed the monomyth. The similarities between these myths brought Campbell to write his book in which he describes the structure of the mythological narrative.", "prediction 4": "The hero's journey is a broad category of tales that involve a hero who goes on an adventure, wins a victory in a decisive crisis, and then comes home changed or transformed. In narratology and comparative mythology, the monomyth, or the hero's journey, is the common template of a broad category of tales that involve a hero who goes on an adventure, and in a decisive crisis wins a victory, and then comes home changed or transformed.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 262, "end": 533}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 3, "sentence_id": [1]}], "corrected-prediction": "In Narratology and Comparative Mythology, the monomyth, or the hero's journey, is the common template of a broad category of tales that involve a hero who goes on an adventure, and in a decisive crisis wins a victory, and then comes home changed or transformed. This concept was popularized by Joseph Campbell, who was influenced by Carl Jung's view of myth. Campbell discussed his theory of the journey of the archetypal hero shared by world mythologies in his 1949 work \"The Hero with a Thousand Faces\"."}, "preference": [2, 2, 1, 2, 1, 1], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Hero's journey\nS1. Hero's journey  In narratology and comparative mythology, the monomyth, or the hero's journey, is the common template of a broad category of tales that involve a hero who goes on an adventure, and in a decisive crisis wins a victory, and then comes home changed or transformed.\nS2. The study of hero myth narratives started in 1871 with anthropologist Edward Burnett Tylor's observations of common patterns in plots of heroes' journeys.\nS3. Later on, others introduced various theories on hero myth narratives such as Otto Rank and his Freudian psychoanalytic approach to myth, Lord Raglan's unification of myth and rituals, and eventually hero myth pattern studies were popularized by Joseph Campbell, who was influenced by Carl Jung's view of myth.\nS4. In his 1949 work \"The Hero with a Thousand Faces\", Campbell described the basic narrative pattern as follows: Campbell and other scholars, such as Erich Neumann, describe narratives of Gautama Buddha, Moses, and Christ in terms of the monomyth.\nS5. While others, such as Otto Rank and Lord Raglan, describe hero narrative patterns in terms of Freudian psychoanalysis and ritualistic senses.\nS6. Critics argue that the concept is too broad or general to be of much usefulness in comparative mythology.\n\nPassage 2: Title (S0) - Joseph Campbell\nS1. Joseph Campbell  Joseph John Campbell (1904\u20131987) was an American Professor of Literature at Sarah Lawrence College who worked in comparative mythology and comparative religion.\nS2. His work covers many aspects of the human experience.\nS3. Campbell's most well-known work is his book \"The Hero with a Thousand Faces\" (1949), in which he discusses his theory of the journey of the archetypal hero shared by world mythologies, termed the monomyth.\nS4. Since the publication of \"The Hero with a Thousand Faces\", Campbell's theory has been applied by a wide variety of modern writers and artists.\nS5. His philosophy has been summarized by his own often repeated phrase: \"Follow your bliss.\"\nS6. He gained recognition in Hollywood when George Lucas credited Campbell's work as influencing his \"Star Wars\" saga.\nS7. Joseph Campbell was born in White Plains, New York, on March 26, 1904, the son of Josephine (n\u00e9e Lynch) and Charles William Campbell.\nS8. He was from an upper-middle-class Irish Catholic family.\nS9. During his childhood, he moved with his family to nearby New Rochelle, New York.\nS10. In 1919, a fire destroyed the family home in New Rochelle, killing his grandmother.\nS11. In 1921, Campbell graduated from the Canterbury School in New Milford, Connecticut.\nS12. While at Dartmouth College he studied biology and mathematics, but decided that he preferred the humanities.\n\nPassage 3: Title (S0) - The Hero with a Thousand Faces\nS1. The Hero with a Thousand Faces  The Hero with a Thousand Faces (first published in 1949) is a work of comparative mythology by Joseph Campbell.\nS2. In this book, Campbell discusses his theory of the mythological structure of the journey of the archetypal hero found in world myths.\nS3. Since the publication of \"The Hero with a Thousand Faces\", Campbell's theory has been consciously applied by a wide variety of modern writers and artists.\nS4. Filmmaker George Lucas acknowledged Campbell's theory in mythology, and its influence on the \"Star Wars\" films.\nS5. The Joseph Campbell Foundation and New World Library issued a new edition of \"The Hero with a Thousand Faces\" in July 2008 as part of the Collected Works of Joseph Campbell series of books, audio and video recordings.\nS6. In 2011, \"Time\" placed the book in its list of the 100 best and most influential books written in English since the magazine was founded in 1923.\nS7. Campbell explores the theory that mythological narratives frequently share a fundamental structure.\nS8. The similarities of these myths brought Campbell to write his book in which he details the structure of the \"monomyth\".\nS9. He calls the motif of the archetypal narrative, \"the hero's journey\".\n    \nInput Question:\nWhen did joseph campbell create the hero's journey?\n\nCorrect Response:\nIn narratology and comparative mythology, the hero's journey, or the monomyth, is the common template of stories that involve a hero who goes on an adventure, is victorious in a decisive crisis, and comes home changed or transformed. Joseph Campbell, an American professor of literature at Sarah Lawrence College, began exploring mythology and creating the hero's journey in 1934. He published his book, \"The Hero with a Thousand Faces\", in 1949, in which he discusses his theory of the journey of the archetypal hero shared by world mythologies.\n\nModel Prediction:\nIn Narratology and Comparative Mythology, the monomyth, or the hero's journey, is the common template of a broad category of tales that involve a hero who goes on an adventure, and in a decisive crisis wins a victory, and then comes home changed or transformed. The study of hero myth narratives started in 1871 with anthropologist Edward Burnett Tylor's observations of common patterns in plots of heroes' journeys. Later on, others introduced various theories on hero myth narratives, Lord Raglan's unification of myth and rituals, and eventually hero myth pattern studies were popularized by Joseph Campbell, who was influenced by Carl Jung's view of myth.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "In Narratology and Comparative Mythology, the monomyth, or the hero's journey, is the common template of a broad category of tales that involve a hero who goes on an adventure, and in a decisive crisis wins a victory, and then comes home changed or transformed. [The study of hero myth narratives started in 1871 with anthropologist Edward Burnett Tylor's observations of common patterns in plots of heroes' journeys. Later on, others introduced various theories on hero myth narratives, Lord Raglan's unification of myth and rituals,] and eventually hero myth pattern studies were popularized by Joseph Campbell, who was influenced by Carl Jung's view of myth.\n\nExplanation:\nThe information about Edward Burnett Tylor's observations and Lord Raglan's unification of myth and rituals is irrelevant to the question asking about when Joseph Campbell created the hero's journey. It does not provide a direct answer or crucial auxiliary information to the question. Therefore, it should be marked as \"Irrelevant\"."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. In Narratology and Comparative Mythology, the monomyth, or the hero's journey, is the common template of a broad category of tales that involve a hero who goes on an adventure, and in a decisive crisis wins a victory, and then comes home changed or transformed.\nS2. The study of hero myth narratives started in 1871 with anthropologist Edward Burnett Tylor's observations of common patterns in plots of heroes' journeys.\nS3. Later on, others introduced various theories on hero myth narratives, Lord Raglan's unification of myth and rituals, and eventually hero myth pattern studies were popularized by Joseph Campbell, who was influenced by Carl Jung's view of myth.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation:\nAll the facts presented in the model prediction are consistent with the information provided in the passages and can be verified. Therefore, there are no spans that contain inconsistent or unverifiable facts."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 3, sentence 1 [Missing Answer]\n2. Passage 1, sentence 4 [Missing Major Auxiliary Information]\n\nExplanation:\n1. The model prediction does not provide a specific year when Joseph Campbell created the hero's journey. This information is crucial to answer the question and can be found in Passage 3, sentence 1.\n2. The model prediction also lacks the major auxiliary information about Campbell's book \"The Hero with a Thousand Faces\", which is where he discusses his theory of the hero's journey. This information can be found in Passage 1, sentence 4."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "In Narratology and Comparative Mythology, the monomyth, or the hero's journey, is the common template of a broad category of tales that involve a hero who goes on an adventure, and in a decisive crisis wins a victory, and then comes home changed or transformed. This concept was popularized by Joseph Campbell, who was influenced by Carl Jung's view of myth. Campbell discussed his theory of the journey of the archetypal hero shared by world mythologies in his 1949 work \"The Hero with a Thousand Faces\"."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 262, "end": 416}, {"error type": "Irrelevant", "explanation": "", "start": 417, "end": 659}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 2, "sentence_id": [1]}, {"error type": "Missing-Major-Auxiliary", "passage_id": 2, "sentence_id": [3]}], "corrected-prediction": "In Narratology and Comparative Mythology, the monomyth, or the hero's journey, is the common template of a broad category of tales that involve a hero who goes on an adventure, and in a decisive crisis wins a victory, and then comes home changed or transformed. Joseph Campbell Joseph John Campbell (1904\u20131987) was an American Professor of Literature at Sarah Lawrence College who worked in comparative mythology and comparative religion. Campbell's most well-known work is his book \"The Hero with a Thousand Faces\" (1949), in which he discusses his theory of the journey of the archetypal hero shared by world mythologies"}}, {"question": "When is the movie thor ragnarok coming out?", "passages": [["Thor: Ragnarok", "Ruffalo joined the cast reprising the role of Hulk from previous MCU films, which allowed elements of the 2006 comic storyline \"Planet Hulk\" to be adapted for \"Ragnarok\".", "The rest of the cast, including Blanchett as Hela, was confirmed in May 2016, with Pearson's involvement revealed at the start of filming that July.", "Principal photography took place in Brisbane and Sydney, Australia, with the film also having exclusive use of Village Roadshow Studios in Oxenford, concluding in October 2016.", "\"Thor: Ragnarok\" premiered in Los Angeles on October 10, 2017, and was released in the United States on November 3, in 3D, IMAX, and", "IMAX 3D.", "The film received praise for its acting, direction, action sequences, soundtrack, and humor, with many critics considering it the best of the \"Thor\" trilogy.", "It grossed $854\u00a0million, becoming the highest-grossing film of the trilogy and the ninth-highest-grossing film of 2017.", "Two years after the battle of Sokovia, Thor is imprisoned by the fire demon Surtur in Muspelheim, who reveals that Thor's father Odin is no longer on Asgard."], ["Thor: Ragnarok", "The film was released in the United States and Canada on November 3, in 4,080 theaters, of which over 3,400 were 3D, 381 were IMAX and IMAX 3D, and 204 were D-Box.", "The film opened in 1,187 IMAX theaters globally, which was a November opening weekend record.", "It was originally scheduled for release on July 28, 2017.", "\"Thor: Ragnarok\" was released on digital download by Walt Disney Studios Home Entertainment on February 20, 2018, and on Ultra HD Blu-ray, Blu-ray, DVD and On-Demand on March 6.", "The digital and Blu-ray releases include behind-the-scenes featurettes; audio commentary; deleted scenes; a blooper reel; and \"Team Darryl\", a continuation of the \"mockumentary\" short films \"Team Thor\" and \"Team Thor: Part 2\", in which the Grandmaster moves in with Darryl after Thor leaves.", "In one of the deleted scenes, Michael Rooker makes an appearance as Yondu, reprising the role from the first two \"Guardians of the Galaxy\" films."], ["Thor: Ragnarok", "Thor: Ragnarok\n\nThor: Ragnarok is a 2017 American superhero film based on the Marvel Comics character Thor, produced by Marvel Studios and distributed by Walt Disney Studios Motion Pictures.", "It is the sequel to 2011's \"Thor\" and 2013's \"\", and is the seventeenth film in the Marvel Cinematic Universe (MCU).", "The film is directed by Taika Waititi from a screenplay by Eric Pearson and the writing team of Craig Kyle and Christopher L. Yost, and stars Chris Hemsworth as Thor alongside Tom Hiddleston, Cate Blanchett, Idris Elba, Jeff Goldblum, Tessa Thompson, Karl Urban, Mark Ruffalo, and Anthony Hopkins.", "In \"Thor: Ragnarok\", Thor must escape the alien planet Sakaar in time to save Asgard from Hela and the impending Ragnar\u00f6k.", "A third \"Thor\" film was confirmed in January 2014, with Kyle and Yost beginning work on the screenplay.", "The involvement of Hemsworth and Hiddleston was announced that October.", "Waititi joined the film as director a year later, after \"Thor: The Dark World\" director Alan Taylor chose not to return."]], "gold": "Thor: Ragnarok is a 2017 American superhero film based on the Marvel Comics character Thor, produced by Marvel Studios and distributed by Walt Disney Studios Motion Pictures. \"Thor: Ragnarok\" had its world premiere at the El Capitan Theatre in Los Angeles on October 10, 2017, and its Australian premiere took place on October 13, 2017, on the Gold Coast. It was released in the United Kingdom on October 24, 2017, with additional international releases on October 25, and in Australia on October 26, 2017. The film was released in the United States and Canada on November 3, 2017, in 4,080 theaters, of which over 3,400 were 3D, 381 were IMAX and IMAX 3D, and 204 were D-Box.", "prediction 1": "Thor Ragnarok, a superhero film based on the Marvel Comics character Thor, is a sequel to the 2011 and 2013 Thor films, and is the seventeenth film in the Marvel Cinematic Universe (MCU). The film premiered in Los Angeles on October 10, 2017 and was released in the United States and Canada on November 3, in 3,080 theaters, of which over 3,400 were 3D, IMAX, and IMAX 3D. The film was released on digital download by Walt Disney Studios Home Entertainment on February 20, 2018 and on Ultra HD Blu-ray, Blu-ray, DVD and On-Deman on March 6.", "prediction 2": "Thor Ragnarok is a 2017 American superhero film based on the Marvel Comics character Thor, produced by Marvel Studios and distributed by Walt Disney Studios Motion Pictures. The film premiered in Los Angeles on October 10, 2017. It was released in the United States and Canada on November 3, in 3,080 theaters, of which over 3,400 were 3D, IMAX, and IMAX 3D, and 204 were D-Box.", "prediction 3": "Thor: Ragnarok is a 2017 American superhero film based on the Marvel Comics character Thor, produced by Marvel Studios and distributed by Walt Disney Studios Motion Pictures. It is the sequel to 2011's Thor and 2013's Thor, and is the seventeenth film in the Marvel Cinematic Universe (MCU). It premiered in Los Angeles on October 10, 2017 and was released in the United States on November 3, in 3D, IMAX, and IMAX 3D.", "prediction 4": "Thor Ragnarok was premiered in Los Angeles on October 10, 2017, and was released in the United States and Canada on November 3, in 3,080 theaters, of which over 3,400 were 3D, 381 were IMAX, and IMAX 3D, and 204 were D-Box. The film is directed by Taika Waititi from a screenplay by Eric Pearson and the writing team of Craig Kyle and Christopher L. Yost, and stars Chris Hemsworth as Thor alongside Tom Hiddleston as Loki and Hela.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 309, "end": 314}, {"error type": "Irrelevant", "explanation": "", "start": 373, "end": 540}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [4]}], "corrected-prediction": "Thor Ragnarok, a superhero film based on the Marvel Comics character Thor, is a sequel to the 2011 and 2013 Thor films, and is the seventeenth film in the Marvel Cinematic Universe (MCU). The film premiered in Los Angeles on October 10, 2017 and was released in the United States and Canada on November 3, in 4,080 theaters, of which over 3,400 were 3D, IMAX, and IMAX 3D."}, "preference": [1, 1, 1, 1, 1, 2], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Thor: Ragnarok\nS1. Ruffalo joined the cast reprising the role of Hulk from previous MCU films, which allowed elements of the 2006 comic storyline \"Planet Hulk\" to be adapted for \"Ragnarok\".\nS2. The rest of the cast, including Blanchett as Hela, was confirmed in May 2016, with Pearson's involvement revealed at the start of filming that July.\nS3. Principal photography took place in Brisbane and Sydney, Australia, with the film also having exclusive use of Village Roadshow Studios in Oxenford, concluding in October 2016.\nS4. \"Thor: Ragnarok\" premiered in Los Angeles on October 10, 2017, and was released in the United States on November 3, in 3D, IMAX, and\nS5. IMAX 3D.\nS6. The film received praise for its acting, direction, action sequences, soundtrack, and humor, with many critics considering it the best of the \"Thor\" trilogy.\nS7. It grossed $854\u00a0million, becoming the highest-grossing film of the trilogy and the ninth-highest-grossing film of 2017.\nS8. Two years after the battle of Sokovia, Thor is imprisoned by the fire demon Surtur in Muspelheim, who reveals that Thor's father Odin is no longer on Asgard.\n\nPassage 2: Title (S0) - Thor: Ragnarok\nS1. The film was released in the United States and Canada on November 3, in 4,080 theaters, of which over 3,400 were 3D, 381 were IMAX and IMAX 3D, and 204 were D-Box.\nS2. The film opened in 1,187 IMAX theaters globally, which was a November opening weekend record.\nS3. It was originally scheduled for release on July 28, 2017.\nS4. \"Thor: Ragnarok\" was released on digital download by Walt Disney Studios Home Entertainment on February 20, 2018, and on Ultra HD Blu-ray, Blu-ray, DVD and On-Demand on March 6.\nS5. The digital and Blu-ray releases include behind-the-scenes featurettes; audio commentary; deleted scenes; a blooper reel; and \"Team Darryl\", a continuation of the \"mockumentary\" short films \"Team Thor\" and \"Team Thor: Part 2\", in which the Grandmaster moves in with Darryl after Thor leaves.\nS6. In one of the deleted scenes, Michael Rooker makes an appearance as Yondu, reprising the role from the first two \"Guardians of the Galaxy\" films.\n\nPassage 3: Title (S0) - Thor: Ragnarok\nS1. Thor: Ragnarok  Thor: Ragnarok is a 2017 American superhero film based on the Marvel Comics character Thor, produced by Marvel Studios and distributed by Walt Disney Studios Motion Pictures.\nS2. It is the sequel to 2011's \"Thor\" and 2013's \"\", and is the seventeenth film in the Marvel Cinematic Universe (MCU).\nS3. The film is directed by Taika Waititi from a screenplay by Eric Pearson and the writing team of Craig Kyle and Christopher L. Yost, and stars Chris Hemsworth as Thor alongside Tom Hiddleston, Cate Blanchett, Idris Elba, Jeff Goldblum, Tessa Thompson, Karl Urban, Mark Ruffalo, and Anthony Hopkins.\nS4. In \"Thor: Ragnarok\", Thor must escape the alien planet Sakaar in time to save Asgard from Hela and the impending Ragnar\u00f6k.\nS5. A third \"Thor\" film was confirmed in January 2014, with Kyle and Yost beginning work on the screenplay.\nS6. The involvement of Hemsworth and Hiddleston was announced that October.\nS7. Waititi joined the film as director a year later, after \"Thor: The Dark World\" director Alan Taylor chose not to return.\n    \nInput Question:\nWhen is the movie thor ragnarok coming out?\n\nCorrect Response:\nThor: Ragnarok is a 2017 American superhero film based on the Marvel Comics character Thor, produced by Marvel Studios and distributed by Walt Disney Studios Motion Pictures. \"Thor: Ragnarok\" had its world premiere at the El Capitan Theatre in Los Angeles on October 10, 2017, and its Australian premiere took place on October 13, 2017, on the Gold Coast. It was released in the United Kingdom on October 24, 2017, with additional international releases on October 25, and in Australia on October 26, 2017. The film was released in the United States and Canada on November 3, 2017, in 4,080 theaters, of which over 3,400 were 3D, 381 were IMAX and IMAX 3D, and 204 were D-Box.\n\nModel Prediction:\nThor Ragnarok, a superhero film based on the Marvel Comics character Thor, is a sequel to the 2011 and 2013 Thor films, and is the seventeenth film in the Marvel Cinematic Universe (MCU). The film premiered in Los Angeles on October 10, 2017 and was released in the United States and Canada on November 3, in 3,080 theaters, of which over 3,400 were 3D, IMAX, and IMAX 3D. The film was released on digital download by Walt Disney Studios Home Entertainment on February 20, 2018 and on Ultra HD Blu-ray, Blu-ray, DVD and On-Deman on March 6.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "Thor Ragnarok, a superhero film based on the Marvel Comics character Thor, is a sequel to the 2011 and 2013 Thor films, and is the seventeenth film in the Marvel Cinematic Universe (MCU). The film premiered in Los Angeles on October 10, 2017 and was released in the United States and Canada on November 3, in [3,080] theaters, of which over 3,400 were 3D, IMAX, and IMAX 3D. [The film was released on digital download by Walt Disney Studios Home Entertainment on February 20, 2018 and on Ultra HD Blu-ray, Blu-ray, DVD and On-Deman on March 6.]\n\nExplanation:\n1. The number of theaters in which the film was released in the United States and Canada is incorrectly stated as 3,080 instead of 4,080 as per Passage 2, Sentence 1. This is marked as an [Inconsistent Fact].\n2. The information about the film's release on digital download and other formats is not relevant to the question about the film's theatrical release date. Therefore, it is marked as [Irrelevant]."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. Thor Ragnarok, a superhero film based on the Marvel Comics character Thor, is a sequel to the 2011 and 2013 Thor films, and is the seventeenth film in the Marvel Cinematic Universe (MCU).\nS2. The film premiered in Los Angeles on October 10, 2017 and was released in the United States and Canada on November 3, in 3,080 theaters, of which over 3,400 were 3D, IMAX, and IMAX 3D.\nS3. The film was released on digital download by Walt Disney Studios Home Entertainment on February 20, 2018 and on Ultra HD Blu-ray, Blu-ray, DVD and On-Deman on March 6.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "Inconsistent or Unverifiable Sentences:\n1. S2\n\nExplanation:\n1. The number of theaters in which the film was released in the United States and Canada is incorrectly stated as 3,080 instead of 4,080 as per Passage 2, Sentence 1. This is marked as an [Inconsistent Fact]."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 4 [Missing Major Auxiliary Information]\n\nExplanation:\n1. The model prediction does not mention that the film was also released in 3D, IMAX, and IMAX 3D, which is important auxiliary information that provides more context about the film's release. This information can be found in Passage 1, Sentence 4."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "Thor Ragnarok, a superhero film based on the Marvel Comics character Thor, is a sequel to the 2011 and 2013 Thor films, and is the seventeenth film in the Marvel Cinematic Universe (MCU). The film premiered in Los Angeles on October 10, 2017 and was released in the United States and Canada on November 3, in 4,080 theaters, of which over 3,400 were 3D, IMAX, and IMAX 3D."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 75, "end": 187}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 3, "sentence_id": [1]}], "corrected-prediction": "Thor: Ragnarok is a 2017 American superhero film based on the Marvel Comics character Thor, produced by Marvel Studios and distributed by Walt Disney Studios Motion Pictures. The film premiered in Los Angeles on October 10, 2017 and was released in the United States and Canada on November 3, in 3,080 theaters, of which over 3,400 were 3D, IMAX, and IMAX 3D. The film was released on digital download by Walt Disney Studios Home Entertainment on February 20, 2018 and on Ultra HD Blu-ray, Blu-ray, DVD and On-Deman on March 6."}}, {"question": "When did france manage to get away from the church's hold over it?", "passages": [["Separation of church and state", "Separation of church and state\n\nThe separation of church and state is a philosophic and jurisprudential concept for defining political distance in the relationship between religious organizations and the nation state.", "Conceptually, the term refers to the creation of a secular state (with or without legally explicit church\u2013state separation) and to disestablishment, the changing of an existing, formal relationship between the church and the state.", "In a society, the degree of political separation between the church and the civil state is determined by the legal structures and prevalent legal views that define the proper relationship between organized religion and the state.", "The arm's length principle proposes a relationship wherein the two political entities interact as organizations independent of the authority of the other.", "The strict application of secular principle of \"la\u00efcit\u00e9\" (secularity) is used in France, while secular societies, such as Denmark and the United Kingdom, maintain a form of constitutional recognition of an official state religion.", "The philosophy of the separation of the church from the civil state parallels the philosophies of secularism, disestablishmentarianism, religious liberty, and religious pluralism, by way of which the European states assumed some of the social roles of the church, the welfare state, a social shift that produced a culturally secular population and public sphere."], ["Relations between the Catholic Church and the state", "During the French Wars of Religion, the Monarchomachs began to contest the divine right of kings, setting up the bases for the theory of popular sovereignty and theorizing the right of tyrannicides.", "The central principle of the medieval, Renaissance and \"ancien r\u00e9gime\" periods, monarchical rule 'by God's will', was fundamentally challenged by the 1789 French Revolution.", "The revolution began as a conjunction of a need to fix French national finances and a rising middle class who resented the privileges of the clergy (in their role as the First Estate) and nobility (in their role as the Second Estate).", "The pent-up frustrations caused by lack of political reform over a period of generations led the revolution to spiral in ways unimaginable only a few years earlier, and indeed unplanned and unanticipated by the initial wave of reformers.", "Almost from the start, the revolution was a direct threat to clerical and noble privilege: the legislation that abolished the feudal privileges of the Church and nobility dates from August 4, 1789, a mere three weeks after the fall of the Bastille (although it would be several years before this legislation came fully into effect).", "At the same time, the revolution also challenged the theological basis of royal authority.", "The doctrine of popular sovereignty directly challenged the former divine right of kings."], ["France", "The counter-revolution, begun in March 1793 in the Vend\u00e9e, by July had spread to Brittany, Normandy, Bordeaux, Marseilles, Toulon, Lyon.", "Paris' Convention government between October and December 1793 with brutal measures managed to subdue most internal uprisings, at the cost of tens of thousands of lives.", "Some historians consider the civil war to have lasted until 1796 with a toll of possibly 450,000 lives.", "France in February 1794 abolished slavery in its American colonies, but would reintroduce it later.", "Political disagreements and enmity in the National Convention between October 1793 and July 1794 reached unprecedented levels, leading to dozens of Convention members being sentenced to death and guillotined.", "Meanwhile, France's external wars in 1794 were going prosperous, for example in Belgium.", "In 1795, the government seemed to return to indifference towards the desires and needs of the lower classes concerning freedom of (Catholic) religion and fair distribution of food.", "Until 1799, politicians, apart from inventing a new parliamentary system (the 'Directory'), busied themselves with dissuading the people from Catholicism and from royalism.", "Napoleon Bonaparte seized control of the Republic in 1799 becoming First Consul and later Emperor of the French Empire (1804\u20131814; 1815)."]], "gold": "The separation of church and state is a philosophic and jurisprudential concept for defining political distance in the relationship between religious organizations and the state. Conceptually, the term refers to the creation of a secular state and to disestablishment, the changing of an existing, formal relationship between the church and the state. France got away from the Church's hold in September 1792 with the issue of divorce, and on August 4, 1789 they eliminated the tithe. In October 1793, the Christian calendar was replaced. ", "prediction 1": "Separation of church and state is a philosophic and jurisprudential concept for defining political distance in the relationship between religious organizations and the nation state. Conceptually, the term refers to the creation of a secular state, with or without legally explicit church-state separation, and to disestablishment, the changing of an existing, formal relationship between the church and the state. The philosophy of the separation of the church from the civil state parallels the philosophies of secularism, disestablishmentarianism, religious liberty, and religious pluralism, by way the European states assumed some of the social roles of the church, the state.", "prediction 2": "The separation of church and state is a philosophic and jurisprudential concept for defining political distance in the relationship between religious organizations and the nation state. Conceptually, the term refers to the creation of a secular state, with or without legally explicit church-state separation, and to disestablishment, the changing of an existing, formal relationship between the church and the state. The principle of monarchical rule 'by God's will', fundamentally challenged by the 1789 French Revolution, led to spiral in ways unimaginable only a few years earlier, unplanned and unanticipated by the initial wave of reformers. The philosophy of the separation of the church from the civil state parallels the philosophies of secularism, disestablishmentarianism, religious liberty, religious liberty, religious liberty, and religious pluralism,", "prediction 3": "The separation of church and state is a philosophic and jurisprudential concept for defining political distance in the relationship between religious organizations and the nation state. Conceptually, the term refers to the creation of a secular state (with or without legally explicit church\u2013state separation) and to disestablishment, the changing of an existing, formal relationship between the church and the state. The 1789 French Revolution challenged the central principle of the medieval, Renaissance and \"ancien r\u00e9gime\", monarchical rule 'by God's will', challenging the doctrine of popular sovereignty, challenging the theology of royal authority. The separation of church from the state is a philosophy of secularism, disestablishmentarianism, religious liberty, and religious pluralism, by way that European states assume some of the social roles of the church.", "prediction 4": "The separation of church and state is a philosophic and jurisprudential concept for defining political distance in the relationship between religious organizations and the nation state. Conceptually, the term refers to the creation of a secular state (with or without legally explicit church\u2013state separation) and to disestablishment, the changing of an existing, formal relationship between the church and the state. The philosophy of the separation of the church from the civil state parallels the philosophies of secularism, disestablishmentarianism, religious liberty, and religious pluralism.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 414, "end": 679}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 2, "sentence_id": [5]}], "corrected-prediction": "The separation of church and state is a philosophic and jurisprudential concept for defining political distance in the relationship between religious organizations and the nation state. Conceptually, the term refers to the creation of a secular state, with or without legally explicit church-state separation, and to disestablishment, the changing of an existing, formal relationship between the church and the state. In France, the church's hold over the state began to diminish with the legislation that abolished the feudal privileges of the Church in August 1789. Furthermore, until 1799, politicians busied themselves with dissuading the people from Catholicism and from royalism, further reducing the church's influence over the state."}, "preference": [1, 1, 0, 1, 2, 2], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Separation of church and state\nS1. Separation of church and state  The separation of church and state is a philosophic and jurisprudential concept for defining political distance in the relationship between religious organizations and the nation state.\nS2. Conceptually, the term refers to the creation of a secular state (with or without legally explicit church\u2013state separation) and to disestablishment, the changing of an existing, formal relationship between the church and the state.\nS3. In a society, the degree of political separation between the church and the civil state is determined by the legal structures and prevalent legal views that define the proper relationship between organized religion and the state.\nS4. The arm's length principle proposes a relationship wherein the two political entities interact as organizations independent of the authority of the other.\nS5. The strict application of secular principle of \"la\u00efcit\u00e9\" (secularity) is used in France, while secular societies, such as Denmark and the United Kingdom, maintain a form of constitutional recognition of an official state religion.\nS6. The philosophy of the separation of the church from the civil state parallels the philosophies of secularism, disestablishmentarianism, religious liberty, and religious pluralism, by way of which the European states assumed some of the social roles of the church, the welfare state, a social shift that produced a culturally secular population and public sphere.\n\nPassage 2: Title (S0) - Relations between the Catholic Church and the state\nS1. During the French Wars of Religion, the Monarchomachs began to contest the divine right of kings, setting up the bases for the theory of popular sovereignty and theorizing the right of tyrannicides.\nS2. The central principle of the medieval, Renaissance and \"ancien r\u00e9gime\" periods, monarchical rule 'by God's will', was fundamentally challenged by the 1789 French Revolution.\nS3. The revolution began as a conjunction of a need to fix French national finances and a rising middle class who resented the privileges of the clergy (in their role as the First Estate) and nobility (in their role as the Second Estate).\nS4. The pent-up frustrations caused by lack of political reform over a period of generations led the revolution to spiral in ways unimaginable only a few years earlier, and indeed unplanned and unanticipated by the initial wave of reformers.\nS5. Almost from the start, the revolution was a direct threat to clerical and noble privilege: the legislation that abolished the feudal privileges of the Church and nobility dates from August 4, 1789, a mere three weeks after the fall of the Bastille (although it would be several years before this legislation came fully into effect).\nS6. At the same time, the revolution also challenged the theological basis of royal authority.\nS7. The doctrine of popular sovereignty directly challenged the former divine right of kings.\n\nPassage 3: Title (S0) - France\nS1. The counter-revolution, begun in March 1793 in the Vend\u00e9e, by July had spread to Brittany, Normandy, Bordeaux, Marseilles, Toulon, Lyon.\nS2. Paris' Convention government between October and December 1793 with brutal measures managed to subdue most internal uprisings, at the cost of tens of thousands of lives.\nS3. Some historians consider the civil war to have lasted until 1796 with a toll of possibly 450,000 lives.\nS4. France in February 1794 abolished slavery in its American colonies, but would reintroduce it later.\nS5. Political disagreements and enmity in the National Convention between October 1793 and July 1794 reached unprecedented levels, leading to dozens of Convention members being sentenced to death and guillotined.\nS6. Meanwhile, France's external wars in 1794 were going prosperous, for example in Belgium.\nS7. In 1795, the government seemed to return to indifference towards the desires and needs of the lower classes concerning freedom of (Catholic) religion and fair distribution of food.\nS8. Until 1799, politicians, apart from inventing a new parliamentary system (the 'Directory'), busied themselves with dissuading the people from Catholicism and from royalism.\nS9. Napoleon Bonaparte seized control of the Republic in 1799 becoming First Consul and later Emperor of the French Empire (1804\u20131814; 1815).\n    \nInput Question:\nWhen did france manage to get away from the church's hold over it?\n\nCorrect Response:\nThe separation of church and state is a philosophic and jurisprudential concept for defining political distance in the relationship between religious organizations and the state. Conceptually, the term refers to the creation of a secular state and to disestablishment, the changing of an existing, formal relationship between the church and the state. France got away from the Church's hold in September 1792 with the issue of divorce, and on August 4, 1789 they eliminated the tithe. In October 1793, the Christian calendar was replaced. \n\nModel Prediction:\nSeparation of church and state is a philosophic and jurisprudential concept for defining political distance in the relationship between religious organizations and the nation state. Conceptually, the term refers to the creation of a secular state, with or without legally explicit church-state separation, and to disestablishment, the changing of an existing, formal relationship between the church and the state. The philosophy of the separation of the church from the civil state parallels the philosophies of secularism, disestablishmentarianism, religious liberty, and religious pluralism, by way the European states assumed some of the social roles of the church, the state.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "Separation of church and state is a philosophic and jurisprudential concept for defining political distance in the relationship between religious organizations and the nation state. Conceptually, the term refers to the creation of a secular state, with or without legally explicit church-state separation, and to disestablishment, the changing of an existing, formal relationship between the church and the state. [The philosophy of the separation of the church from the civil state parallels the philosophies of secularism, disestablishmentarianism, religious liberty, and religious pluralism, by way the European states assumed some of the social roles of the church, the state.]\n\nExplanation:\nThe last sentence in the model prediction is irrelevant as it does not provide a direct answer to the question nor is it crucial auxiliary information. It talks about the philosophies that parallel the separation of church and state, which is not necessary to answer the question about when France managed to get away from the church's hold."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. Separation of church and state is a philosophic and jurisprudential concept for defining political distance in the relationship between religious organizations and the nation state.\nS2. Conceptually, the term refers to the creation of a secular state, with or without legally explicit church-state separation, and to disestablishment, the changing of an existing, formal relationship between the church and the state.\nS3. The philosophy of the separation of the church from the civil state parallels the philosophies of secularism, disestablishmentarianism, religious liberty, and religious pluralism, by way the European states assumed some of the social roles of the church, the state.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation:\nAll the facts presented in the model prediction are consistent with the information provided in the passages and none of them are unverifiable."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 2, sentence 5 [Missing Answer]\n2. Passage 3, sentence 8 [Missing Answer]\n\nExplanation:\n1. The model prediction does not mention the specific event in France's history when the church's hold over the state was diminished. This information is found in Passage 2, sentence 5, which talks about the legislation that abolished the feudal privileges of the Church in August 1789.\n2. Passage 3, sentence 8 also provides information about the French government's efforts to dissuade the people from Catholicism and royalism until 1799, which is another key aspect of France getting away from the church's hold. This is also a missing answer in the model prediction."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The separation of church and state is a philosophic and jurisprudential concept for defining political distance in the relationship between religious organizations and the nation state. Conceptually, the term refers to the creation of a secular state, with or without legally explicit church-state separation, and to disestablishment, the changing of an existing, formal relationship between the church and the state. In France, the church's hold over the state began to diminish with the legislation that abolished the feudal privileges of the Church in August 1789. Furthermore, until 1799, politicians busied themselves with dissuading the people from Catholicism and from royalism, further reducing the church's influence over the state."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 414, "end": 679}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 2, "sentence_id": [5]}], "corrected-prediction": "Separation of church and state is a philosophic and jurisprudential concept for defining political distance in the relationship between religious organizations and the nation state. Conceptually, the term refers to the creation of a secular state, with or without legally explicit church-state separation, and to disestablishment, the changing of an existing, formal relationship between the church and the state.  The legislation that abolished the feudal privileges of the Church and nobility dates from August 4, 1789."}}, {"question": "Who did the cleveland browns beat last year?", "passages": [["2017 Cleveland Browns season", "2017 Cleveland Browns season\n\nThe 2017 season was the Cleveland Browns' 69th as a professional sports franchise, their 65th season as a member of the National Football League, their second under head coach Hue Jackson and their second and final season under GM Sashi Brown.", "The Browns failed to improve upon their 1\u201315 record from the previous season, losing all sixteen games in 2017 and continuing a losing streak dating to the final game of the previous season.", "They became the second team in NFL history to go 0\u201316 after the 2008 Detroit Lions.", "The Browns became the twelfth NFL team to have gone winless playing eight games or more and the fourth since the AFL-NFL merger in 1970.", "In going 0\u201316, the Browns became the first franchise in NFL history to have multiple seasons with 15 or more losses and the first to start consecutive seasons with at least 14 losses.", "They were mathematically eliminated from the AFC North title contention in Week 11, extending an active NFL record drought of 25 consecutive seasons without a division title.", "They were then eliminated from playoff contention in Week 12, extending their franchise record playoff drought to 15 consecutive seasons.", "With the Buffalo Bills qualifying for the postseason for the first time since 1999, the Browns now have the longest postseason drought in the NFL and the second longest in the four major American sports leagues, only behind the Seattle Mariners of Major League Baseball."], ["2015 Cleveland Browns season", "With their seventh straight loss, the Browns dropped to 2-10 and became the first team in the league to be mathematically eliminated from playoff contention for the season.", "This marked the 13th straight year that the team missed the playoffs.", "It was also their 13th consecutive loss in the month of the December.", "The 34-point margin of defeat was the team's largest since Week 16 of the 2005 season, when they lost to the Pittsburgh Steelers by 41-0.", "With the win, the Browns snapped their 7-game losing streak and improved to 3-10.", "This is the Browns' last win until Week 16, 2016 against the San Diego Chargers.", "With the loss, the Browns fell to 3-11.", "The Browns fall to 3-12 with the loss.", "With the Ravens' win over the Steelers, they are assured last place in the AFC North for the season.", "The Steelers made the playoffs with a dominating 28-12 win over the Browns (coupled with a Jets loss to the Bills).", "The game was competitive for three quarters, but the Browns failed to get into the endzone, scoring 4 field goals and committing 3 turnovers (2 of them in the 4th quarter, both of which resulted in Steelers scores).", "The Browns finished the season with a 3-13 record, their worst record since the 2000 season (when they also went 3-13)."], ["2016 Cleveland Browns season", "After this game, the Browns would have a 19-game winless streak and would not win again until week 3 of the 2018 season.", "The Browns entered this game looking to win consecutive games for the first time since they won three in a row during Weeks 8 to 10 of the 2014 season.", "The Steelers entered the game locked into the AFC\u2019s #3 seed and rested most of their starters.", "However, the Browns would still fall to the Steelers, losing 27\u201324 in an overtime affair.", "With the loss, the Browns finished the season with a 1\u201315 record, their worst record in franchise history.", "The Browns also became the tenth team in NFL history, but the first since the 2009 Rams, to finish 1\u201315.", "They failed to win a division game for the first time since the 2011 season and extended their losing streak within the division to 11 games.", "The Browns also failed to win a road game in a season for only the second time in franchise history and the first since the 1975 season.", "They also extended their road losing streak to 13 games and failed to win a road game against the Steelers for the 13th consecutive season.", "The Browns finished with the worst record in the NFL and secured the #1 overall pick in the 2017 NFL Draft.", "This marked the beginning of a 17 game losing streak continuing through the 2017 season and ending with a tie in Week 1 of the 2018 season."]], "gold": "In 2017, the Cleveland Browns went winless. They became the second team in NFL history to go 0\u201316 in the regular season. The Browns finished the season with a losing record for the tenth consecutive season, extending a franchise record. However, the team had beaten the New Orleans Saints, New York Giants, Tampa Bay Buccaneers, and Chicago Bears in the 2017 preseason. In 2016, the Browns were winless in the preseason and then went 1-15 in the regular season, defeating only the San Diego Chargers. The Browns failed to make the playoffs for a franchise-record 14th straight season. In 2015, the Browns defeated the Tampa Bay Buccaneers in the preseason. The Browns then went 3-13 in the regular season, defeating only the Tennessee Titans, Baltimore Ravens, and San Francisco 49ers. The Browns tied for the worst record in the league and fired their coach and general manager at the end of the 2015 season.  ", "prediction 1": "The Cleveland Browns have defeated several teams during the course of their careers. The Browns have lost all 16 games they have played since 2005 and finished the season losing to the Pittsburgh Steelers in Week 15. They finished the season losing to the Chiefs in Week 15 of the 2016 season. The Browns finished the season losing to the Atlanta Falcons in Week 17 of the 2017 season.", "prediction 2": "The Cleveland Browns have lost a total of 14 games last season. They lost 16 of those games to the Pittsburgh Steelers, and lost 14 of those to the Baltimore Ravens. The Browns are currently ranked #5 in the NFL by the number of wins.", "prediction 3": "The Cleveland Browns have lost 16 consecutive games to the Pittsburgh Steelers in the 2017 season and failed to improve on their 1\u201315 record from the previous season. The Browns have also lost to the New England Patriots in the 2015 season and in the 2016 season. The 2015 Cleveland Browns defeated the Baltimore Ravens in the 2016 season and the Cleveland Browns defeated the Seattle Seahawks in the 2017 season.", "prediction 4": "The Cleveland Browns have defeated various teams throughout their history. In 2017, the Browns lost all sixteen games and continued a losing streak dating to the final game of the previous season. In 2015, the Browns lost to the Baltimore Ravens, a team that is part of the National Football League. In 2016, the Browns lost to the Cleveland Browns in the divisional round of the playoffs, but they did so in the first round of the playoffs to the Indianapolis Colts.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 0, "end": 84}, {"error type": "Irrelevant", "explanation": "", "start": 217, "end": 385}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 1, "sentence_id": [2]}], "corrected-prediction": "In 2017, the Cleveland Browns did not win any games, going 0-16 for the season. Their last victory was in the 2016 season against the San Diego Chargers."}, "preference": [1, 0, 1, 2, 2, 1], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - 2017 Cleveland Browns season\nS1. 2017 Cleveland Browns season  The 2017 season was the Cleveland Browns' 69th as a professional sports franchise, their 65th season as a member of the National Football League, their second under head coach Hue Jackson and their second and final season under GM Sashi Brown.\nS2. The Browns failed to improve upon their 1\u201315 record from the previous season, losing all sixteen games in 2017 and continuing a losing streak dating to the final game of the previous season.\nS3. They became the second team in NFL history to go 0\u201316 after the 2008 Detroit Lions.\nS4. The Browns became the twelfth NFL team to have gone winless playing eight games or more and the fourth since the AFL-NFL merger in 1970.\nS5. In going 0\u201316, the Browns became the first franchise in NFL history to have multiple seasons with 15 or more losses and the first to start consecutive seasons with at least 14 losses.\nS6. They were mathematically eliminated from the AFC North title contention in Week 11, extending an active NFL record drought of 25 consecutive seasons without a division title.\nS7. They were then eliminated from playoff contention in Week 12, extending their franchise record playoff drought to 15 consecutive seasons.\nS8. With the Buffalo Bills qualifying for the postseason for the first time since 1999, the Browns now have the longest postseason drought in the NFL and the second longest in the four major American sports leagues, only behind the Seattle Mariners of Major League Baseball.\n\nPassage 2: Title (S0) - 2015 Cleveland Browns season\nS1. With their seventh straight loss, the Browns dropped to 2-10 and became the first team in the league to be mathematically eliminated from playoff contention for the season.\nS2. This marked the 13th straight year that the team missed the playoffs.\nS3. It was also their 13th consecutive loss in the month of the December.\nS4. The 34-point margin of defeat was the team's largest since Week 16 of the 2005 season, when they lost to the Pittsburgh Steelers by 41-0.\nS5. With the win, the Browns snapped their 7-game losing streak and improved to 3-10.\nS6. This is the Browns' last win until Week 16, 2016 against the San Diego Chargers.\nS7. With the loss, the Browns fell to 3-11.\nS8. The Browns fall to 3-12 with the loss.\nS9. With the Ravens' win over the Steelers, they are assured last place in the AFC North for the season.\nS10. The Steelers made the playoffs with a dominating 28-12 win over the Browns (coupled with a Jets loss to the Bills).\nS11. The game was competitive for three quarters, but the Browns failed to get into the endzone, scoring 4 field goals and committing 3 turnovers (2 of them in the 4th quarter, both of which resulted in Steelers scores).\nS12. The Browns finished the season with a 3-13 record, their worst record since the 2000 season (when they also went 3-13).\n\nPassage 3: Title (S0) - 2016 Cleveland Browns season\nS1. After this game, the Browns would have a 19-game winless streak and would not win again until week 3 of the 2018 season.\nS2. The Browns entered this game looking to win consecutive games for the first time since they won three in a row during Weeks 8 to 10 of the 2014 season.\nS3. The Steelers entered the game locked into the AFC\u2019s #3 seed and rested most of their starters.\nS4. However, the Browns would still fall to the Steelers, losing 27\u201324 in an overtime affair.\nS5. With the loss, the Browns finished the season with a 1\u201315 record, their worst record in franchise history.\nS6. The Browns also became the tenth team in NFL history, but the first since the 2009 Rams, to finish 1\u201315.\nS7. They failed to win a division game for the first time since the 2011 season and extended their losing streak within the division to 11 games.\nS8. The Browns also failed to win a road game in a season for only the second time in franchise history and the first since the 1975 season.\nS9. They also extended their road losing streak to 13 games and failed to win a road game against the Steelers for the 13th consecutive season.\nS10. The Browns finished with the worst record in the NFL and secured the #1 overall pick in the 2017 NFL Draft.\nS11. This marked the beginning of a 17 game losing streak continuing through the 2017 season and ending with a tie in Week 1 of the 2018 season.\n    \nInput Question:\nWho did the cleveland browns beat last year?\n\nCorrect Response:\nIn 2017, the Cleveland Browns went winless. They became the second team in NFL history to go 0\u201316 in the regular season. The Browns finished the season with a losing record for the tenth consecutive season, extending a franchise record. However, the team had beaten the New Orleans Saints, New York Giants, Tampa Bay Buccaneers, and Chicago Bears in the 2017 preseason. In 2016, the Browns were winless in the preseason and then went 1-15 in the regular season, defeating only the San Diego Chargers. The Browns failed to make the playoffs for a franchise-record 14th straight season. In 2015, the Browns defeated the Tampa Bay Buccaneers in the preseason. The Browns then went 3-13 in the regular season, defeating only the Tennessee Titans, Baltimore Ravens, and San Francisco 49ers. The Browns tied for the worst record in the league and fired their coach and general manager at the end of the 2015 season.  \n\nModel Prediction:\nThe Cleveland Browns have defeated several teams during the course of their careers. The Browns have lost all 16 games they have played since 2005 and finished the season losing to the Pittsburgh Steelers in Week 15. They finished the season losing to the Chiefs in Week 15 of the 2016 season. The Browns finished the season losing to the Atlanta Falcons in Week 17 of the 2017 season.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "[The Cleveland Browns have defeated several teams during the course of their careers.] The Browns have lost all 16 games they have played since 2005 and finished the season losing to the Pittsburgh Steelers in Week 15. [They finished the season losing to the Chiefs in Week 15 of the 2016 season. The Browns finished the season losing to the Atlanta Falcons in Week 17 of the 2017 season.]\n\nExplanation:\n1. The first sentence is irrelevant as it does not provide a direct answer to the question nor does it provide crucial auxiliary information.\n2. The last two sentences are irrelevant as they do not provide information about the team the Browns defeated last year. Instead, they provide information about the teams the Browns lost to in previous seasons."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The Cleveland Browns have defeated several teams during the course of their careers.\nS2. The Browns have lost all 16 games they have played since 2005 and finished the season losing to the Pittsburgh Steelers in Week 15.\nS3. They finished the season losing to the Chiefs in Week 15 of the 2016 season.\nS4. The Browns finished the season losing to the Atlanta Falcons in Week 17 of the 2017 season.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "Inconsistent or Unverifiable Sentences:\n1. S2\n2. S3\n3. S4\n\nExplanation:\n1. Sentence 2 states that the Browns have lost all 16 games they have played since 2005, which is inconsistent with the passages that show the Browns have won some games in the years following 2005.\n2. Sentence 3 states that the Browns lost to the Chiefs in Week 15 of the 2016 season, which is unverifiable as the passages do not provide information about this game.\n3. Sentence 4 states that the Browns lost to the Atlanta Falcons in Week 17 of the 2017 season, which is unverifiable as the passages do not provide information about this game."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 2 [Missing Answer]\n2. Passage 3, sentence 5 [Missing Major Auxiliary Information]\n\nExplanation:\n1. The model prediction does not mention that the Cleveland Browns did not win any games in the 2017 season, which is the direct answer to the question. This information can be found in Passage 1, sentence 2.\n2. The model prediction does not mention that the Browns' last win was in the 2016 season against the San Diego Chargers. This is a crucial piece of auxiliary information that helps to understand the answer. This information can be found in Passage 3, sentence 5."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "In 2017, the Cleveland Browns did not win any games, going 0-16 for the season. Their last victory was in the 2016 season against the San Diego Chargers."}], "feedback_human": {"errors": [{"error type": "Wrong-Grounding", "explanation": "{\"passage_id\":2,\"sentence_id\":[4]}", "start": 119, "end": 146}, {"error type": "Unverifiable", "explanation": "", "start": 208, "end": 216}, {"error type": "Wrong-Grounding", "explanation": "{\"passage_id\":3,\"sentence_id\":[4,5]}", "start": 256, "end": 273}, {"error type": "Unverifiable", "explanation": "", "start": 339, "end": 365}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [3]}, {"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [2]}, {"error type": "Missing-Major-Auxiliary", "passage_id": 2, "sentence_id": [12]}, {"error type": "Missing-Answer", "passage_id": 2, "sentence_id": [6]}, {"error type": "Missing-Major-Auxiliary", "passage_id": 2, "sentence_id": [2]}], "corrected-prediction": "The Cleveland Browns have defeated several teams during the course of their careers. The Browns have lost all 16 games in 2017. They became the second team in NFL history to go 0\u201316 after the 2008 Detroit Lions. They finished the 2016 season with a score of 1\u201315. They beat the San Diego Chargers. In 2015, the Browns finished the season with a 3-13 record. Their 2015 season was their 13th year of missing playoffs, 14 and 15 respectively for 2016 and 2017."}}, {"question": "Where did pluvial lakes form during the last ice age?", "passages": [["Pluvial lake", "Pluvial lake\n\nA pluvial lake is a body of water that accumulated in a basin because of a greater moisture availability resulting from changes in temperature and/or precipitation.", "These intervals of greater moisture availability are not always contemporaneous with glacial periods.", "Pluvial lakes are typically closed lakes that occupied endorheic basins.", "Pluvial lakes that have since evaporated and dried out may also be referred to as \"paleolakes\".", "The word comes from the Latin \"pluvia\", which means \"rain\".", "Pluvial lakes represent changes in the hydrological cycle: wet cycles generate large lakes, and dry cycles cause the lakes to dry up leaving large flat plains.", "Accumulated sediments show the variation in water level.", "During glacial periods, when the lake level is fairly high, mud sediments will settle out and be deposited.", "At times in between glaciers (interglacial), salt deposits may be present because of the arid climate and the evaporation of lakewater.", "Several pluvial lakes formed in what is now the southwestern United States during the glaciation of the late Pleistocene.", "One of these was Lake Bonneville in western Utah, which covered roughly .", "When Lake Bonneville was at its maximum water level, it was higher than the Great Salt Lake."], ["Pluvial lake", "Fresh water mollusks have been found in mud deposits from Searles Lake in California and suggest that the water temperature was about 7 degrees Fahrenheit (or 4 degrees Celsius) cooler than current temperatures.", "Radiocarbon dating of the youngest mud beds yield dates from 24,000 to 12,000 years ago.", "When warm air from arid regions meets chilled air from glaciers, cloudy, cool, rainy weather is created beyond the terminus of the glacier.", "That humid climate was present during the last glacial period in North America and caused more precipitation than evaporation.", "The increase in rainfall fills the drainage basin and forms a lake.", "During interglacial periods, the climate becomes arid once more and causes the lakes to evaporate and dry up."]], "gold": "A pluvial lake is a body of water that accumulated in a basin because of a greater moisture availability resulting from changes in temperature and/or precipitation. Several pluvial lakes formed in what is now the southwestern United States, specifically in Utah and California, during the last Ice Age. One of these was Lake Bonneville in western Utah, which covered roughly 19,000 square miles and when it reached maximum water level, it was 1,000 feet higher than the Great Salt Lake. Fresh water mollusks have also been found in mud deposits from Searles Lake in California and suggest that the water temperature was about 7 degrees Fahrenheit cooler than current temperatures and radiocarbon dating of the youngest mud beds yield dates from 24,000 to 12,000 years ago.", "prediction 1": "A pluvial lake is a body of water that accumulated in a basin because of a greater moisture availability resulting from changes in temperature and/or precipitation. These intervals of greater moisture availability are not always contemporaneous with glacial periods. Several pluvial lakes formed in what is now the southwestern United States during the glaciation of the late Pleistocene. One of these was Lake Bonneville in western Utah, which covered roughly.", "prediction 2": "A pluvial lake is a body of water that accumulated in a basin because of a greater moisture availability resulting from changes in temperature and/or precipitation. These intervals of greater moisture availability are not always contemporaneous with glacial periods. Several pluvial lakes formed in what is now the southwestern United States during the glaciation of the late Pleistocene. One of these was Lake Bonneville in western Utah. The other lakes were Lake St. George in Illinois and Lake Ontario in Ontario, Canada.", "prediction 3": "A pluvial lake is a body of water that accumulated in a basin because of a greater moisture availability resulting from changes in temperature and/or precipitation. Pluvial lakes that have since evaporated and dried out may also be referred to as \"paleolakes\". Several pluvial lakes formed in what is now the southwestern United States during the glaciation of the late Pleistocene.", "prediction 4": "A pluvial lake is a body of water that accumulated in a basin because of a greater moisture availability resulting from changes in temperature and/or precipitation. These intervals of greater moisture availability are not always contemporaneous with glacial periods. Several pluvial lakes formed in what is now the southwestern United States during the glaciation of the late Pleistocene. For example, one of these was Lake Bonneville in western Utah, which covered roughly.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 165, "end": 266}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [12]}], "corrected-prediction": "A pluvial lake is a body of water that accumulated in a basin because of a greater moisture availability resulting from changes in temperature and/or precipitation. Several pluvial lakes formed in what is now the southwestern United States during the glaciation of the late Pleistocene. One of these was Lake Bonneville in western Utah, which covered roughly 19,000 square miles. When Lake Bonneville was at its maximum water level, it was 1,000 feet higher than the Great Salt Lake. Additionally, fresh water mollusks have been found in mud deposits from Searles Lake in California, suggesting that the water temperature was about 7 degrees Fahrenheit cooler than current temperatures. Radiocarbon dating of the youngest mud beds yield dates from 24,000 to 12,000 years ago, indicating the time period of these pluvial lakes."}, "preference": [1, 1, 0, 2, 2, 2], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Pluvial lake\nS1. Pluvial lake  A pluvial lake is a body of water that accumulated in a basin because of a greater moisture availability resulting from changes in temperature and/or precipitation.\nS2. These intervals of greater moisture availability are not always contemporaneous with glacial periods.\nS3. Pluvial lakes are typically closed lakes that occupied endorheic basins.\nS4. Pluvial lakes that have since evaporated and dried out may also be referred to as \"paleolakes\".\nS5. The word comes from the Latin \"pluvia\", which means \"rain\".\nS6. Pluvial lakes represent changes in the hydrological cycle: wet cycles generate large lakes, and dry cycles cause the lakes to dry up leaving large flat plains.\nS7. Accumulated sediments show the variation in water level.\nS8. During glacial periods, when the lake level is fairly high, mud sediments will settle out and be deposited.\nS9. At times in between glaciers (interglacial), salt deposits may be present because of the arid climate and the evaporation of lakewater.\nS10. Several pluvial lakes formed in what is now the southwestern United States during the glaciation of the late Pleistocene.\nS11. One of these was Lake Bonneville in western Utah, which covered roughly .\nS12. When Lake Bonneville was at its maximum water level, it was higher than the Great Salt Lake.\n\nPassage 2: Title (S0) - Pluvial lake\nS1. Fresh water mollusks have been found in mud deposits from Searles Lake in California and suggest that the water temperature was about 7 degrees Fahrenheit (or 4 degrees Celsius) cooler than current temperatures.\nS2. Radiocarbon dating of the youngest mud beds yield dates from 24,000 to 12,000 years ago.\nS3. When warm air from arid regions meets chilled air from glaciers, cloudy, cool, rainy weather is created beyond the terminus of the glacier.\nS4. That humid climate was present during the last glacial period in North America and caused more precipitation than evaporation.\nS5. The increase in rainfall fills the drainage basin and forms a lake.\nS6. During interglacial periods, the climate becomes arid once more and causes the lakes to evaporate and dry up.\n    \nInput Question:\nWhere did pluvial lakes form during the last ice age?\n\nCorrect Response:\nA pluvial lake is a body of water that accumulated in a basin because of a greater moisture availability resulting from changes in temperature and/or precipitation. Several pluvial lakes formed in what is now the southwestern United States, specifically in Utah and California, during the last Ice Age. One of these was Lake Bonneville in western Utah, which covered roughly 19,000 square miles and when it reached maximum water level, it was 1,000 feet higher than the Great Salt Lake. Fresh water mollusks have also been found in mud deposits from Searles Lake in California and suggest that the water temperature was about 7 degrees Fahrenheit cooler than current temperatures and radiocarbon dating of the youngest mud beds yield dates from 24,000 to 12,000 years ago.\n\nModel Prediction:\nA pluvial lake is a body of water that accumulated in a basin because of a greater moisture availability resulting from changes in temperature and/or precipitation. These intervals of greater moisture availability are not always contemporaneous with glacial periods. Several pluvial lakes formed in what is now the southwestern United States during the glaciation of the late Pleistocene. One of these was Lake Bonneville in western Utah, which covered roughly.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "A pluvial lake is a body of water that accumulated in a basin because of a greater moisture availability resulting from changes in temperature and/or precipitation. [These intervals of greater moisture availability are not always contemporaneous with glacial periods.] Several pluvial lakes formed in what is now the southwestern United States during the glaciation of the late Pleistocene. One of these was Lake Bonneville in western Utah, which covered roughly.\n\nExplanation:\n1. The second sentence in the model prediction is not directly related to the question nor is it crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\"."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. A pluvial lake is a body of water that accumulated in a basin because of a greater moisture availability resulting from changes in temperature and/or precipitation.\nS2. These intervals of greater moisture availability are not always contemporaneous with glacial periods.\nS3. Several pluvial lakes formed in what is now the southwestern United States during the glaciation of the late Pleistocene.\nS4. One of these was Lake Bonneville in western Utah, which covered roughly.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation:\nAll the facts mentioned in the model prediction are consistent with the information provided in the passages and can be verified. Therefore, there are no spans that contain inconsistent or unverifiable facts."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 12 [Missing Major Auxiliary Information]\n2. Passage 2, sentence 1 [Missing Major Auxiliary Information]\n3. Passage 2, sentence 2 [Missing Major Auxiliary Information]\n\nExplanation:\n1. The model prediction does not mention that when Lake Bonneville was at its maximum water level, it was higher than the Great Salt Lake, which is a crucial piece of information for understanding the size and impact of these pluvial lakes.\n2. The model prediction also misses the information about the presence of fresh water mollusks in mud deposits from Searles Lake in California, which is an important detail that provides evidence of the existence of these pluvial lakes.\n3. The model prediction does not include the information about the radiocarbon dating of the youngest mud beds yielding dates from 24,000 to 12,000 years ago, which helps to understand the timeline of these pluvial lakes."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "A pluvial lake is a body of water that accumulated in a basin because of a greater moisture availability resulting from changes in temperature and/or precipitation. Several pluvial lakes formed in what is now the southwestern United States during the glaciation of the late Pleistocene. One of these was Lake Bonneville in western Utah, which covered roughly 19,000 square miles. When Lake Bonneville was at its maximum water level, it was 1,000 feet higher than the Great Salt Lake. Additionally, fresh water mollusks have been found in mud deposits from Searles Lake in California, suggesting that the water temperature was about 7 degrees Fahrenheit cooler than current temperatures. Radiocarbon dating of the youngest mud beds yield dates from 24,000 to 12,000 years ago, indicating the time period of these pluvial lakes."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 165, "end": 266}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 2, "sentence_id": [1]}, {"error type": "Missing-Major-Auxiliary", "passage_id": 2, "sentence_id": [2]}], "corrected-prediction": "A pluvial lake is a body of water that accumulated in a basin because of a greater moisture availability resulting from changes in temperature and/or precipitation. Several pluvial lakes formed in what is now the southwestern United States during the glaciation of the late Pleistocene. One of these was Lake Bonneville in western Utah, which covered roughly. Fresh water mollusks have been found in mud deposits from Searles Lake in California and suggest that the water temperature was about 7 degrees Fahrenheit (or 4 degrees Celsius) cooler than current temperatures. Radiocarbon dating of the youngest mud beds yield dates from 24,000 to 12,000 years ago."}}, {"question": "What book of the bible is the ten commandments in?", "passages": [["Ten Commandments", "Ten Commandments\n\nThe Ten Commandments (, \"Aseret ha'Dibrot\"), also known as the Decalogue, are a set of biblical principles relating to ethics and worship, which play a fundamental role in Judaism and Christianity.", "The commandments include instructions to worship only God, to honour one's parents, and to keep the sabbath, as well as prohibitions against idolatry, blasphemy, murder, adultery, theft, dishonesty, and coveting.", "Different religious groups follow different traditions for interpreting and numbering them.", "The Ten Commandments appear twice in the Hebrew Bible, in the books of Exodus and Deuteronomy.", "Modern scholarship has found likely influences in Hittite and Mesopotamian laws and treaties, but is divided over exactly when the Ten Commandments were written and who wrote them.", "In biblical Hebrew, the Ten Commandments are called (transliterated ) and in Mishnaic Hebrew (transliterated ), both translatable as \"the ten words\", \"the ten sayings\", or \"the ten matters\".", "The Tyndale and Coverdale English biblical translations used \"ten verses\".", "The Geneva Bible used \"tenne commandements\", which was followed by the Bishops' Bible and the Authorized Version (the \"King James\" version) as \"ten commandments\"."]], "gold": "The Ten Commandments, also known as the Decalogue, are a set of Biblical principles relating to ethics and worship, which play a fundamental role in the Abrahamic religions. The Ten Commandments appear twice in the Hebrew Bible: in the books of Exodus and Deuteronomy.", "prediction 1": "The Ten Commandments are a set of biblical principles relating to ethics and worship, which play a fundamental role in Judaism and Christianity. The commandments appear twice in the Hebrew Bible, in the books of Exodus and Deuteronomy.", "prediction 2": "The Ten Commandments appear twice in the Hebrew Bible, in the books of Exodus and Deuteronomy.", "prediction 3": "The Ten Commandments are a set of biblical principles relating to ethics and worship, which play a fundamental role in Judaism and Christianity. The commandments include instructions to worship only God, to honour one's parents, and to keep the sabbath, as well as prohibitions against idolatry, blasphemy, murder, adultery, theft, dishonesty, and coveting. The commandments appear twice in the Hebrew Bible, in the books of Exodus and Deuteronomy.", "prediction 4": "The Ten Commandments are found in 2 books of the Bible: Exodus and Deuteronomy. The commandments also play a fundamental role in Judaism and Christianity.", "feedback": {"errors": [], "missing-info": [], "corrected-prediction": "The Ten Commandments are a set of biblical principles relating to ethics and worship, which play a fundamental role in Judaism and Christianity. The commandments appear twice in the Hebrew Bible, in the books of Exodus and Deuteronomy."}, "preference": [1, 1, 1, 2, 2, 1], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Ten Commandments\nS1. Ten Commandments  The Ten Commandments (, \"Aseret ha'Dibrot\"), also known as the Decalogue, are a set of biblical principles relating to ethics and worship, which play a fundamental role in Judaism and Christianity.\nS2. The commandments include instructions to worship only God, to honour one's parents, and to keep the sabbath, as well as prohibitions against idolatry, blasphemy, murder, adultery, theft, dishonesty, and coveting.\nS3. Different religious groups follow different traditions for interpreting and numbering them.\nS4. The Ten Commandments appear twice in the Hebrew Bible, in the books of Exodus and Deuteronomy.\nS5. Modern scholarship has found likely influences in Hittite and Mesopotamian laws and treaties, but is divided over exactly when the Ten Commandments were written and who wrote them.\nS6. In biblical Hebrew, the Ten Commandments are called (transliterated ) and in Mishnaic Hebrew (transliterated ), both translatable as \"the ten words\", \"the ten sayings\", or \"the ten matters\".\nS7. The Tyndale and Coverdale English biblical translations used \"ten verses\".\nS8. The Geneva Bible used \"tenne commandements\", which was followed by the Bishops' Bible and the Authorized Version (the \"King James\" version) as \"ten commandments\".\n    \nInput Question:\nWhat book of the bible is the ten commandments in?\n\nCorrect Response:\nThe Ten Commandments, also known as the Decalogue, are a set of Biblical principles relating to ethics and worship, which play a fundamental role in the Abrahamic religions. The Ten Commandments appear twice in the Hebrew Bible: in the books of Exodus and Deuteronomy.\n\nModel Prediction:\nThe Ten Commandments are a set of biblical principles relating to ethics and worship, which play a fundamental role in Judaism and Christianity. The commandments appear twice in the Hebrew Bible, in the books of Exodus and Deuteronomy.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "The Ten Commandments are a set of biblical principles relating to ethics and worship, which play a fundamental role in Judaism and Christianity. The commandments appear twice in the Hebrew Bible, in the books of Exodus and Deuteronomy.\n\nExplanation: There are no irrelevant, incoherent or repetitive spans in the model prediction. The information provided is relevant to the question, coherent, and not repetitive."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The Ten Commandments are a set of biblical principles relating to ethics and worship, which play a fundamental role in Judaism and Christianity.\nS2. The commandments appear twice in the Hebrew Bible, in the books of Exodus and Deuteronomy.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation: All the facts in the model prediction are consistent with the information provided in the passages. There are no unverifiable or inconsistent facts."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "None\n\nExplanation: The model prediction includes all the necessary information to answer the question. It correctly states that the Ten Commandments appear in the books of Exodus and Deuteronomy in the Hebrew Bible, which is the main point of the question. There is no missing information."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The Ten Commandments are a set of biblical principles relating to ethics and worship, which play a fundamental role in Judaism and Christianity. The commandments appear twice in the Hebrew Bible, in the books of Exodus and Deuteronomy."}], "feedback_human": {"errors": [], "missing-info": [{"error type": "Missing-Minor-Auxiliary", "passage_id": 1, "sentence_id": [1]}], "corrected-prediction": "The Ten Commandments, also known as the Decalogue, are a set of biblical principles relating to ethics and worship, which play a fundamental role in Judaism and Christianity. The commandments appear twice in the Hebrew Bible, in the books of Exodus and Deuteronomy."}}, {"question": "Where does chicago get its drinking water from?", "passages": [["Water cribs in Chicago", "Water cribs in Chicago\n\n", "The water cribs in Chicago are structures built to house and protect offshore water intakes used to supply the City of Chicago with drinking water from Lake Michigan.", "Water is collected and transported through tunnels located close to beneath the lake, varying in shape from circular to oval, and ranging in diameter from .", "The tunnels lead from the water cribs to one of two water purification plants located onshore, the Jardine Water Purification Plant (the world's largest) and the Eugene Sawyer Water Purification Plant, where the water is then treated before being pumped to all parts of the city as well as 118 suburbs.", "The city has had nine permanent cribs of which six are still standing and two are in active use.", "The Two-Mile Crib was constructed as part of a scheme by Ellis S. Chesbrough in 1865, to help with the purification of the water because of damage caused by the city dumping sewage into the lake.", "Construction of the crib began in May 1864, miners and workers worked 24 hours a day and six days a week.", "The total completion of the project was in March 1867 and cost the city $380,784.", "Purified water was pumped to the Chicago Avenue Pumping Station which still stands to this day on North Michigan Avenue."], ["Chicago Sanitary and Ship Canal", "Chicago Sanitary and Ship Canal\n\nThe Chicago Sanitary and Ship Canal, historically known as the Chicago Drainage Canal, is a canal system that connects the Chicago River to the Des Plaines River.", "It reverses the direction of the Main Stem and the South Branch of the Chicago River, which now flows out of Lake Michigan rather than into it.", "The related Calumet-Saganashkee Channel does the same for the Calumet River a short distance to the south, joining the Chicago canal about half way along its route to the Des Plaines.", "The two provide the only navigation for ships between the Great Lakes Waterway and the Mississippi River system.", "The canal was primarily built as a sewage treatment scheme.", "Prior to its opening in 1900, sewage from the city of Chicago was dumped into the Chicago River and flowed into Lake Michigan.", "The city's drinking water supply was located offshore, and there were fears that the sewage could reach the intake and cause serious disease outbreaks.", "Since the sewer systems were already flowing into the river, the decision was made to dam the river and reverse its flow, thereby sending all the sewage inland where it could be treated before emptying it into the Des Plaines.", "A secondary goal was to replace the shallow and narrow Illinois and Michigan Canal (I&M), which had originally connected Lake Michigan with the Mississippi starting in 1848."]], "gold": "The water supply for the City of Chicago comes from Lake Michigan. Water is collected from the lake and stored in offshore water crib structures, before being transported through tunnels located beneath the lake that lead from the water cribs to pumping stations located onshore. The water then travels to water purification plants where it is treated before being pumped to all parts of the city as well as 118 suburbs.", "prediction 1": "The water cribs in Chicago are structures built to house and protect offshore water intakes used to supply the City of Chicago with drinking water from Lake Michigan. Water is collected and transported through tunnels located close to beneath the lake, varying in shape from circular to oval, and ranging in diameter from. The tunnels lead from the water cribs to one of two water purification plants located onshore, the Jardine Water Purification Plant and the Eugene Sawyer Water Purification Plant, where the water is then treated before being pumped to all parts of the city as well as well as well as 118 suburbs.", "prediction 2": "The Chicago Sanitary and Ship Canal is a canal system that connects the Chicago River to the Des Plaines River. It reverses the direction of the Main Stem and the South Branch of the Chicago River, which now flows out of Lake Michigan rather than into it. Prior to its opening in 1900, sewage from the city of Chicago was dumped into the Chicago River and flowed into Lake Michigan. The city's drinking water supply was located offshore, there were fears that the sewage could reach the intake and cause serious disease outbreaks.", "prediction 3": "The Chicago Sanitary and Ship Canal, historically known as the Chicago Drainage Canal, is a canal system that connects the Chicago River to the Des Plaines River. It reverses the direction of the Main Stem and the South Branch of the Chicago River, which now flows out of Lake Michigan rather than into it. Prior to its opening in 1900, sewage from the city of Chicago was dumped into the Chicago River and flowed into Lake Michigan. The city's drinking water supply was located offshore, and there were fears that the sewage could reach the intake and cause serious disease outbreaks.", "prediction 4": "The City of Chicago gets its drinking water from two sources. The water cribs in Chicago are structures built to house and protect offshore water intakes used to supply the City of Chicago with drinking water from Lake Michigan. Water is collected and transported through tunnels located close to beneath the lake, varying in shape from circular to oval, and ranging in diameter from. One of two water purification plants located onshore, the Jardine Water Purification Plant and the Eugene Sawyer Water Purification Plant, treat the water before it is pumped to all parts of the city as well as wells and 118 suburbs. The Chicago Drainage Canal is a canal system that connects the Chicago River to the Des Plaines River. It is a canal system that connects the Chicago River to the Des Plaines River.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 591, "end": 619}], "missing-info": [], "corrected-prediction": "The water cribs in Chicago are structures built to house and protect offshore water intakes used to supply the City of Chicago with drinking water from Lake Michigan. Water is collected and transported through tunnels located close to beneath the lake, varying in shape from circular to oval, and ranging in diameter from. The tunnels lead from the water cribs to one of two water purification plants located onshore, the Jardine Water Purification Plant and the Eugene Sawyer Water Purification Plant, where the water is then treated before being pumped to all parts of the city as well as 118 suburbs."}, "preference": [2, 1, 1, 1, 1, 1], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Water cribs in Chicago\nS1. Water cribs in Chicago  \nS2. The water cribs in Chicago are structures built to house and protect offshore water intakes used to supply the City of Chicago with drinking water from Lake Michigan.\nS3. Water is collected and transported through tunnels located close to beneath the lake, varying in shape from circular to oval, and ranging in diameter from .\nS4. The tunnels lead from the water cribs to one of two water purification plants located onshore, the Jardine Water Purification Plant (the world's largest) and the Eugene Sawyer Water Purification Plant, where the water is then treated before being pumped to all parts of the city as well as 118 suburbs.\nS5. The city has had nine permanent cribs of which six are still standing and two are in active use.\nS6. The Two-Mile Crib was constructed as part of a scheme by Ellis S. Chesbrough in 1865, to help with the purification of the water because of damage caused by the city dumping sewage into the lake.\nS7. Construction of the crib began in May 1864, miners and workers worked 24 hours a day and six days a week.\nS8. The total completion of the project was in March 1867 and cost the city $380,784.\nS9. Purified water was pumped to the Chicago Avenue Pumping Station which still stands to this day on North Michigan Avenue.\n\nPassage 2: Title (S0) - Chicago Sanitary and Ship Canal\nS1. Chicago Sanitary and Ship Canal  The Chicago Sanitary and Ship Canal, historically known as the Chicago Drainage Canal, is a canal system that connects the Chicago River to the Des Plaines River.\nS2. It reverses the direction of the Main Stem and the South Branch of the Chicago River, which now flows out of Lake Michigan rather than into it.\nS3. The related Calumet-Saganashkee Channel does the same for the Calumet River a short distance to the south, joining the Chicago canal about half way along its route to the Des Plaines.\nS4. The two provide the only navigation for ships between the Great Lakes Waterway and the Mississippi River system.\nS5. The canal was primarily built as a sewage treatment scheme.\nS6. Prior to its opening in 1900, sewage from the city of Chicago was dumped into the Chicago River and flowed into Lake Michigan.\nS7. The city's drinking water supply was located offshore, and there were fears that the sewage could reach the intake and cause serious disease outbreaks.\nS8. Since the sewer systems were already flowing into the river, the decision was made to dam the river and reverse its flow, thereby sending all the sewage inland where it could be treated before emptying it into the Des Plaines.\nS9. A secondary goal was to replace the shallow and narrow Illinois and Michigan Canal (I&M), which had originally connected Lake Michigan with the Mississippi starting in 1848.\n    \nInput Question:\nWhere does chicago get its drinking water from?\n\nCorrect Response:\nThe water supply for the City of Chicago comes from Lake Michigan. Water is collected from the lake and stored in offshore water crib structures, before being transported through tunnels located beneath the lake that lead from the water cribs to pumping stations located onshore. The water then travels to water purification plants where it is treated before being pumped to all parts of the city as well as 118 suburbs.\n\nModel Prediction:\nThe water cribs in Chicago are structures built to house and protect offshore water intakes used to supply the City of Chicago with drinking water from Lake Michigan. Water is collected and transported through tunnels located close to beneath the lake, varying in shape from circular to oval, and ranging in diameter from. The tunnels lead from the water cribs to one of two water purification plants located onshore, the Jardine Water Purification Plant and the Eugene Sawyer Water Purification Plant, where the water is then treated before being pumped to all parts of the city as well as well as well as 118 suburbs.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "The water cribs in Chicago are structures built to house and protect offshore water intakes used to supply the City of Chicago with drinking water from Lake Michigan. Water is collected and transported through tunnels located close to beneath the lake, varying in shape from circular to oval, and ranging in diameter from. The tunnels lead from the water cribs to one of two water purification plants located onshore, the Jardine Water Purification Plant and the Eugene Sawyer Water Purification Plant, where the water is then treated before being pumped to all parts of the city as well as [well as well as 118 suburbs.]\n\nExplanation:\nThe phrase \"well as well as\" is repeated twice in the last sentence, which makes it \"Repetitive\". The repeated phrase should be marked as \"Repetitive\". Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains a factual or coherence issue. However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The water cribs in Chicago are structures built to house and protect offshore water intakes used to supply the City of Chicago with drinking water from Lake Michigan.\nS2. Water is collected and transported through tunnels located close to beneath the lake, varying in shape from circular to oval, and ranging in diameter from.\nS3. The tunnels lead from the water cribs to one of two water purification plants located onshore, the Jardine Water Purification Plant and the Eugene Sawyer Water Purification Plant, where the water is then treated before being pumped to all parts of the city as well as well as well as 118 suburbs.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation:\nAll the facts mentioned in the model prediction are consistent with the provided passages and there are no unverifiable facts."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "None\n\nExplanation:\nThe model prediction contains all the necessary information to answer the question. It correctly states that Chicago gets its drinking water from Lake Michigan, which is collected and transported through tunnels from offshore water cribs to onshore water purification plants. There is no missing information in the model prediction."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The water cribs in Chicago are structures built to house and protect offshore water intakes used to supply the City of Chicago with drinking water from Lake Michigan. Water is collected and transported through tunnels located close to beneath the lake, varying in shape from circular to oval, and ranging in diameter from. The tunnels lead from the water cribs to one of two water purification plants located onshore, the Jardine Water Purification Plant and the Eugene Sawyer Water Purification Plant, where the water is then treated before being pumped to all parts of the city as well as 118 suburbs."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 253, "end": 322}, {"error type": "Irrelevant", "explanation": "", "start": 418, "end": 502}], "missing-info": [], "corrected-prediction": "The water cribs in Chicago are structures built to house and protect offshore water intakes used to supply the City of Chicago with drinking water from Lake Michigan. Water is collected and transported through tunnels located close to beneath the lake. The tunnels lead from the water cribs to one of two water purification plants located onshore, where the water is then treated before being pumped to all parts of the city as well as well as well as 118 suburbs."}}, {"question": "Who wrote the song the girl is mine?", "passages": [["The Girl Is Mine", "The Girl Is Mine\n\n\"The Girl Is Mine\" is a song recorded by Michael Jackson and Paul McCartney.", "The track was written by Jackson and produced by Jackson and Quincy Jones.", "It was released as the first single for Jackson's sixth solo album, \"Thriller\" (1982).", "The song was recorded at Westlake Studios, Los Angeles, from April 14 to 16, 1982.", "The year before, Jackson and McCartney had recorded \"Say Say Say\" and \"The Man\" for the latter's fifth solo album, \"Pipes of Peace\" (1983).", "Although \"The Girl Is Mine\" was released as a single, Jackson never performed the song live.", "\"The Girl Is Mine\" achieved success in the music charts.", "Aside from topping the R&B singles chart, the single peaked at number two on the \"Billboard\" Hot 100 and number eight in the UK.", "By 1985, it had sold 1.3 million copies, and was eventually certified platinum by the Recording Industry Association of America, for shipments of at least one million units.", "Despite the song's success, it received generally mixed reviews from critics who consider it to be the weakest song on \"Thriller\".", "\"The Girl Is Mine\" has been the subject of two plagiarism lawsuits, the first in 1984 and the latter in 1993."]], "gold": "There are multiple songs titled, \"The Girl is Mine\". Michael Jackson released the song as the first single for his sixth solo album, Thriller (1982). There is also a song by 99 Souls that features multiple artists: Angela Beyince, Beyonce Knowles, Brandy Norwood, Donald Davis, Edward Robinson, Fred Jerkins III, Kelendria Rowland, LaShawn Daniels, Patrick Douthit, Rodney Jerkins, Tejeda Japhe, Tenitra Williams.", "prediction 1": "\"The Girl Is Mine\" is a song recorded by Michael Jackson and Paul McCartney. The track was written by Jackson and produced by Jackson and Quincy Jones. It was released as the first single for Jackson's sixth solo album, Thriller.\n", "prediction 2": "The track, The Girl Is Mine, was written by Michael Jackson and produced by Jackson and Quincy Jones. It was released as the first single for Jackson's sixth solo album, Thriller (1982).", "prediction 3": "\"The Girl Is Mine\" is a song recorded by Michael Jackson and Paul McCartney. The track was written by Jackson and produced by Jackson and Quincy Jones. It was released as the first single for Jackson's sixth solo album, \"Thriller\". Through various songs, the track has been the subject of plagiarism lawsuits, both of which was filed in 1984 and 1993.", "prediction 4": "\"The Girl Is Mine\" is a song recorded by Michael Jackson and Paul McCartney. The track was written by Jackson and produced by Jackson and Quincy Jones. It was released as the first single for Jackson's sixth solo album, Thriller (1982). The song was written and produced by Jackson and Quincy Jones.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 152, "end": 229}], "missing-info": [], "corrected-prediction": "\"The Girl Is Mine\" is a song recorded by Michael Jackson and Paul McCartney. The track was written by Jackson and produced by Jackson and Quincy Jones."}, "preference": [1, 1, 0, 1, 2, 2], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - The Girl Is Mine\nS1. The Girl Is Mine  \"The Girl Is Mine\" is a song recorded by Michael Jackson and Paul McCartney.\nS2. The track was written by Jackson and produced by Jackson and Quincy Jones.\nS3. It was released as the first single for Jackson's sixth solo album, \"Thriller\" (1982).\nS4. The song was recorded at Westlake Studios, Los Angeles, from April 14 to 16, 1982.\nS5. The year before, Jackson and McCartney had recorded \"Say Say Say\" and \"The Man\" for the latter's fifth solo album, \"Pipes of Peace\" (1983).\nS6. Although \"The Girl Is Mine\" was released as a single, Jackson never performed the song live.\nS7. \"The Girl Is Mine\" achieved success in the music charts.\nS8. Aside from topping the R&B singles chart, the single peaked at number two on the \"Billboard\" Hot 100 and number eight in the UK.\nS9. By 1985, it had sold 1.3 million copies, and was eventually certified platinum by the Recording Industry Association of America, for shipments of at least one million units.\nS10. Despite the song's success, it received generally mixed reviews from critics who consider it to be the weakest song on \"Thriller\".\nS11. \"The Girl Is Mine\" has been the subject of two plagiarism lawsuits, the first in 1984 and the latter in 1993.\n    \nInput Question:\nWho wrote the song the girl is mine?\n\nCorrect Response:\nThere are multiple songs titled, \"The Girl is Mine\". Michael Jackson released the song as the first single for his sixth solo album, Thriller (1982). There is also a song by 99 Souls that features multiple artists: Angela Beyince, Beyonce Knowles, Brandy Norwood, Donald Davis, Edward Robinson, Fred Jerkins III, Kelendria Rowland, LaShawn Daniels, Patrick Douthit, Rodney Jerkins, Tejeda Japhe, Tenitra Williams.\n\nModel Prediction:\n\"The Girl Is Mine\" is a song recorded by Michael Jackson and Paul McCartney. The track was written by Jackson and produced by Jackson and Quincy Jones. It was released as the first single for Jackson's sixth solo album, Thriller.\n\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "\"The Girl Is Mine\" is a song recorded by Michael Jackson and Paul McCartney. The track was written by Jackson and produced by Jackson and Quincy Jones. [It was released as the first single for Jackson's sixth solo album, Thriller.]\n\nExplanation:\n1. The third sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\"."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. \"The Girl Is Mine\" is a song recorded by Michael Jackson and Paul McCartney.\nS2. The track was written by Jackson and produced by Jackson and Quincy Jones.\nS3. It was released as the first single for Jackson's sixth solo album, Thriller.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation:\nAll the facts in the model prediction are consistent with the provided passages and can be verified."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "None\n\nExplanation:\nThe model prediction contains all the necessary information to answer the question. It correctly states that \"The Girl Is Mine\" was written by Michael Jackson. There is no missing information in the model prediction."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "\"The Girl Is Mine\" is a song recorded by Michael Jackson and Paul McCartney. The track was written by Jackson and produced by Jackson and Quincy Jones."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 29, "end": 76}, {"error type": "Irrelevant", "explanation": "", "start": 114, "end": 151}], "missing-info": [{"error type": "Missing-Minor-Auxiliary", "passage_id": 1, "sentence_id": [3]}], "corrected-prediction": "\"The Girl Is Mine\" is a song written by Michael Jackson. It was released as the first single for Jackson's sixth solo album, \"Thriller\" (1982).\n"}}, {"question": "What was the first cartoon walt disney made?", "passages": [["Walt Disney", "By 1926 Winkler's role in the distribution of the \"Alice\" series had been handed over to her husband, the film producer Charles Mintz, although the relationship between him and Disney was sometimes strained.", "The series ran until July 1927, by which time Disney had begun to tire of it and wanted to move away from the mixed format to all animation.", "After Mintz requested new material to distribute through Universal Pictures, Disney and Iwerks created Oswald the Lucky Rabbit, a character Disney wanted to be \"peppy, alert, saucy and venturesome, keeping him also neat and trim\".", "In February 1928, Disney hoped to negotiate a larger fee for producing the \"Oswald\" series, but found Mintz wanting to reduce the payments.", "Mintz had also persuaded many of the artists involved to work directly for him, including Harman, Ising, Carman Maxwell and Friz Freleng.", "Disney also found out that Universal owned the intellectual property rights to Oswald.", "Mintz threatened to start his own studio and produce the series himself if Disney refused to accept the reductions.", "Disney declined Mintz's ultimatum and lost most of his animation staff, except Iwerks, who chose to remain with him."], ["Oswald the Lucky Rabbit", "Disney, together with Iwerks, decided to create a second cartoon titled \"Trolley Troubles\" featuring a much younger, neater Oswald.", "The short, released on September 5, 1927, officially launched the series and proved to be Disney's greatest success to date.", "The storyline for Poor Papa was reused in a Mickey Mouse short six years later, in \"Mickey's Nightmare\", 1932.", "Oswald the Lucky Rabbit became Disney's first major hit in 1927, rivaling other popular cartoon characters, such as Felix the Cat and Koko the Clown.", "The success of the Oswald series allowed the Walt Disney Studio to grow to a staff of nearly twenty.", "Walt's weekly salary from the series was $100 while Roy Disney's was $65.", "The Disney brothers earned $500 per Oswald short and split the year-end profits, with Walt receiving 60% ($5,361), and Roy receiving 40% ($3,574).", "With income gained from the Oswald series, Walt and Roy purchased ten acres of land in the desert.", "They also invested in an oil-drilling venture.", "Iwerks also invested his income in several stone mills to crush paint pigment he used to make paint formulas that were utilized by animators for decades."], ["Alice Comedies", "Alice Comedies\n\nThe Alice Comedies are a series of animated cartoons\ncreated by Walt Disney in the 1920s, in which a live action little girl named Alice (originally played by Virginia Davis) and an animated cat named Julius have adventures in an animated landscape.", "Disney, Ub Iwerks, and their staff made the first \"Alice Comedy\", a one-reel (ten-minute) short subject titled \"Alice's Wonderland\", while still heading the failing Laugh-O-Gram Studio in Kansas City, Missouri.", "\"Alice's Wonderland\" begins with Alice entering a cartoon studio to witness cartoons being created.", "Alice is amazed by what she sees: the cartoon characters come to life and play around.", "After heading to bed that night, she dreams of being in the cartoon world, welcomed by all of the characters.", "Alice plays with them until a group of lions break free from a cage and chase her.", "Though never released, this short helped set the stage for what was to come in the later \"Alice Comedies\", as it established the world as a playful dream and also introduced the elements which would soon define the series.", "The idea of setting a real-world girl in an animated world was at this point in film history still unique.", "The design and voice of the later series were all set by this original film.", "After completing the film, the studio went bankrupt and was forced to shut down."]], "gold": "For years, Walt Disney worked on the Alice Comedies, a series of animated/live actions shorts of which Disney grew tired, deciding to move away from the mixed format to all animation and crating his overall first cartoon, Oswald the Lucky Rabbit, in 1927. After losing the rights to this character, Disney developed Mickey Mouse as a replacement, which debuted in the animated short Steamboat Willie on November 18th, 1928, notable for being the first cartoon made with synchronized sound. By 1934, Disney had become dissatisfied with producing formulaic cartoon shorts and believed a feature-length cartoon would be more profitable, beginning the four-year production of Snow White and the Seven Dwarfs. The film was Disney's first animated feature film, releasing in 1937 to critical and commercial success.", "prediction 1": "Walt Disney, together with Ub Iwerks, and their staff made the first \"Alice Comedy\", a one-reel (ten-minute) short subject titled \"Alice's Wonderland\", while still heading the failing Laugh-O-Gram Studio in Kansas City, Missouri. The storyline for Poor Papa was reused in a Mickey Mouse short six years later, in \"Mickey's Nightmare\", 1932.", "prediction 2": "Disney, together with Iwerks, decided to create a second cartoon titled Trolley Troubles featuring a much younger, neater Oswald. The short, released on September 5, 1927, officially launched the series and proved to be Disney's greatest success to date. The first one-reel (ten-minute) short subject titled \"Alice's Wonderland\", was made while still heading the failing Laugh-O-Gram Studio in Kansas City, Missouri. It set the stage for what would come later series as it would set the scene for what would soon define the character voice and design and voice would later characters. It was the first \"Alice Comedy\", a one-reel (reeland), which was completed and was forced to shut down after completing the film.", "prediction 3": "Walt Disney made his first cartoon in 1926 with Ub Iwerks, under the direction of Charles Mintz, named Alice's Wonderland. The short was a one reel, ten minute film, titled Alice's Comedy, which set the stage for the later Alice Comedies. The film's director, Mickey Mouse, was Walt Disney's son. Walt Disney, who had been working with Iwerks, created the first \"Alice Comedy\", a one reel, ten minute film, titled Alie's Wonderland, which was released on September 5, 1927.", "prediction 4": "Disney, together with Iwerks, decided to create a second cartoon titled \"Trolley Troubles\" featuring a much younger, neater Oswald. The short, released on September 5, 1927, officially launched the series and proved to be Disney's greatest success to date. The first two Disney cartoons were the Alice Comedy and the Alice Comedies 2. Walt Disney was a film producer at that time.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 230, "end": 340}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 1, "sentence_id": [3]}], "corrected-prediction": "Walt Disney, together with Ub Iwerks, and their staff made the first \"Alice Comedy\", a one-reel (ten-minute) short subject titled \"Alice's Wonderland\", while still heading the failing Laugh-O-Gram Studio in Kansas City, Missouri. After growing tired of the mixed format of the Alice Comedies, Disney and Iwerks created Oswald the Lucky Rabbit, a character Disney wanted to be \"peppy, alert, saucy and venturesome, keeping him also neat and trim\". However, when Disney hoped to negotiate a larger fee for producing the \"Oswald\" series, he found Mintz wanting to reduce the payments. Disney also found out that Universal owned the intellectual property rights to Oswald. When Mintz threatened to start his own studio and produce the series himself if Disney refused to accept the reductions, Disney declined Mintz's ultimatum and lost most of his animation staff, except Iwerks, who chose to remain with him."}, "preference": [1, 1, 1, 2, 2, 2], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Walt Disney\nS1. By 1926 Winkler's role in the distribution of the \"Alice\" series had been handed over to her husband, the film producer Charles Mintz, although the relationship between him and Disney was sometimes strained.\nS2. The series ran until July 1927, by which time Disney had begun to tire of it and wanted to move away from the mixed format to all animation.\nS3. After Mintz requested new material to distribute through Universal Pictures, Disney and Iwerks created Oswald the Lucky Rabbit, a character Disney wanted to be \"peppy, alert, saucy and venturesome, keeping him also neat and trim\".\nS4. In February 1928, Disney hoped to negotiate a larger fee for producing the \"Oswald\" series, but found Mintz wanting to reduce the payments.\nS5. Mintz had also persuaded many of the artists involved to work directly for him, including Harman, Ising, Carman Maxwell and Friz Freleng.\nS6. Disney also found out that Universal owned the intellectual property rights to Oswald.\nS7. Mintz threatened to start his own studio and produce the series himself if Disney refused to accept the reductions.\nS8. Disney declined Mintz's ultimatum and lost most of his animation staff, except Iwerks, who chose to remain with him.\n\nPassage 2: Title (S0) - Oswald the Lucky Rabbit\nS1. Disney, together with Iwerks, decided to create a second cartoon titled \"Trolley Troubles\" featuring a much younger, neater Oswald.\nS2. The short, released on September 5, 1927, officially launched the series and proved to be Disney's greatest success to date.\nS3. The storyline for Poor Papa was reused in a Mickey Mouse short six years later, in \"Mickey's Nightmare\", 1932.\nS4. Oswald the Lucky Rabbit became Disney's first major hit in 1927, rivaling other popular cartoon characters, such as Felix the Cat and Koko the Clown.\nS5. The success of the Oswald series allowed the Walt Disney Studio to grow to a staff of nearly twenty.\nS6. Walt's weekly salary from the series was $100 while Roy Disney's was $65.\nS7. The Disney brothers earned $500 per Oswald short and split the year-end profits, with Walt receiving 60% ($5,361), and Roy receiving 40% ($3,574).\nS8. With income gained from the Oswald series, Walt and Roy purchased ten acres of land in the desert.\nS9. They also invested in an oil-drilling venture.\nS10. Iwerks also invested his income in several stone mills to crush paint pigment he used to make paint formulas that were utilized by animators for decades.\n\nPassage 3: Title (S0) - Alice Comedies\nS1. Alice Comedies  The Alice Comedies are a series of animated cartoons created by Walt Disney in the 1920s, in which a live action little girl named Alice (originally played by Virginia Davis) and an animated cat named Julius have adventures in an animated landscape.\nS2. Disney, Ub Iwerks, and their staff made the first \"Alice Comedy\", a one-reel (ten-minute) short subject titled \"Alice's Wonderland\", while still heading the failing Laugh-O-Gram Studio in Kansas City, Missouri.\nS3. \"Alice's Wonderland\" begins with Alice entering a cartoon studio to witness cartoons being created.\nS4. Alice is amazed by what she sees: the cartoon characters come to life and play around.\nS5. After heading to bed that night, she dreams of being in the cartoon world, welcomed by all of the characters.\nS6. Alice plays with them until a group of lions break free from a cage and chase her.\nS7. Though never released, this short helped set the stage for what was to come in the later \"Alice Comedies\", as it established the world as a playful dream and also introduced the elements which would soon define the series.\nS8. The idea of setting a real-world girl in an animated world was at this point in film history still unique.\nS9. The design and voice of the later series were all set by this original film.\nS10. After completing the film, the studio went bankrupt and was forced to shut down.\n    \nInput Question:\nWhat was the first cartoon walt disney made?\n\nCorrect Response:\nFor years, Walt Disney worked on the Alice Comedies, a series of animated/live actions shorts of which Disney grew tired, deciding to move away from the mixed format to all animation and crating his overall first cartoon, Oswald the Lucky Rabbit, in 1927. After losing the rights to this character, Disney developed Mickey Mouse as a replacement, which debuted in the animated short Steamboat Willie on November 18th, 1928, notable for being the first cartoon made with synchronized sound. By 1934, Disney had become dissatisfied with producing formulaic cartoon shorts and believed a feature-length cartoon would be more profitable, beginning the four-year production of Snow White and the Seven Dwarfs. The film was Disney's first animated feature film, releasing in 1937 to critical and commercial success.\n\nModel Prediction:\nWalt Disney, together with Ub Iwerks, and their staff made the first \"Alice Comedy\", a one-reel (ten-minute) short subject titled \"Alice's Wonderland\", while still heading the failing Laugh-O-Gram Studio in Kansas City, Missouri. The storyline for Poor Papa was reused in a Mickey Mouse short six years later, in \"Mickey's Nightmare\", 1932.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "Walt Disney, together with Ub Iwerks, and their staff made the first \"Alice Comedy\", a one-reel (ten-minute) short subject titled \"Alice's Wonderland\", while still heading the failing Laugh-O-Gram Studio in Kansas City, Missouri. [The storyline for Poor Papa was reused in a Mickey Mouse short six years later, in \"Mickey's Nightmare\", 1932.]\n\nExplanation:\nThe second sentence in the model prediction is irrelevant. It does not provide any information that directly answers the question or serves as crucial auxiliary information. The reuse of the storyline for Poor Papa in a Mickey Mouse short does not contribute to understanding what the first cartoon Walt Disney made was."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. Walt Disney, together with Ub Iwerks, and their staff made the first \"Alice Comedy\", a one-reel (ten-minute) short subject titled \"Alice's Wonderland\", while still heading the failing Laugh-O-Gram Studio in Kansas City, Missouri.\nS2. The storyline for Poor Papa was reused in a Mickey Mouse short six years later, in \"Mickey's Nightmare\", 1932.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation:\nThere are no factual inconsistencies or unverifiable facts in the model prediction. All the information provided can be verified from the passages."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 3 [Missing Answer]\n2. Passage 1, sentence 4 [Missing Major Auxiliary Information]\n3. Passage 1, sentence 6 [Missing Major Auxiliary Information]\n4. Passage 1, sentence 8 [Missing Major Auxiliary Information]\n\nExplanation:\n1. The model prediction does not mention that Disney and Iwerks created Oswald the Lucky Rabbit, which is the first all-animation cartoon that Disney made after the Alice Comedies. This is a direct answer to the question and is missing in the model prediction.\n2. The model prediction does not mention that Disney hoped to negotiate a larger fee for producing the \"Oswald\" series, but found Mintz wanting to reduce the payments. This is a major auxiliary information that provides context to why Disney lost the rights to Oswald the Lucky Rabbit.\n3. The model prediction does not mention that Disney found out that Universal owned the intellectual property rights to Oswald. This is a major auxiliary information that provides context to why Disney lost the rights to Oswald the Lucky Rabbit.\n4. The model prediction does not mention that Disney declined Mintz's ultimatum and lost most of his animation staff, except Iwerks, who chose to remain with him. This is a major auxiliary information that provides context to why Disney lost the rights to Oswald the Lucky Rabbit and had to create a new character, Mickey Mouse."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "Walt Disney, together with Ub Iwerks, and their staff made the first \"Alice Comedy\", a one-reel (ten-minute) short subject titled \"Alice's Wonderland\", while still heading the failing Laugh-O-Gram Studio in Kansas City, Missouri. After growing tired of the mixed format of the Alice Comedies, Disney and Iwerks created Oswald the Lucky Rabbit, a character Disney wanted to be \"peppy, alert, saucy and venturesome, keeping him also neat and trim\". However, when Disney hoped to negotiate a larger fee for producing the \"Oswald\" series, he found Mintz wanting to reduce the payments. Disney also found out that Universal owned the intellectual property rights to Oswald. When Mintz threatened to start his own studio and produce the series himself if Disney refused to accept the reductions, Disney declined Mintz's ultimatum and lost most of his animation staff, except Iwerks, who chose to remain with him."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 85, "end": 229}, {"error type": "Irrelevant", "explanation": "", "start": 230, "end": 340}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 3, "sentence_id": [1]}, {"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [2]}, {"error type": "Missing-Major-Auxiliary", "passage_id": 2, "sentence_id": [4]}], "corrected-prediction": "Walt Disney, together with Ub Iwerks, and their staff made the first \"Alice Comedy\", which turned into a series of animated cartoons. Disney had begun to tire of it and wanted to move away from the mixed format to all animation. Oswald the Lucky Rabbit became Disney's first major hit in 1927."}}, {"question": "Who played the professor in gilligan's island?", "passages": [["The Professor (Gilligan's Island)", "The Professor (Gilligan's Island)\n\nRoy Hinkley, referred to as the Professor, is one of the seven castaways from the television series \"Gilligan's Island\" (1964\u201367); he was played by Russell Johnson.", "The character was originally played by John Gabriel in the pilot episode, but the network thought he looked too young to have all the degrees attributed to the Professor.", "The Professor's backstory identifies him as Roy Hinkley (though his actual name is rarely mentioned during the series), a high-school science teacher who was born in Cleveland, Ohio.", "His principal expertise was as a botanist, whose purpose in joining the ill-fated voyage that stranded the castaways was to write a book to be titled \"Fun With Ferns\".", "His main function on the show was to devise many ways for the castaways to live more comfortably on the island.", "Many of his inventions (including a method for recharging the batteries in the ubiquitous radio) used coconuts and bamboo, both of which were in plentiful supply.", "Aside from his proficiency in science, he was also adept and well-versed in law, literature, social sciences, and the arts."], ["Gilligan's Island", "Gilligan's Island\n\nGilligan's Island is an American sitcom created and produced by Sherwood Schwartz.", "The show had an ensemble cast that featured Bob Denver, Alan Hale Jr., Jim Backus, Natalie Schafer, Russell Johnson, Tina Louise, and Dawn Wells.", "It aired for three seasons on the CBS network from September 26, 1964, to April 17, 1967.", "The series followed the comic adventures of seven castaways as they attempted to survive the island on which they had been shipwrecked.", "Most episodes revolve around the dissimilar castaways' conflicts and their unsuccessful attempts, for whose failure Gilligan was frequently responsible, to escape their plight.", "\"Gilligan's Island\" ran for a total of 98 episodes.", "The first season, consisting of 36 episodes, was filmed in black and white.", "These episodes were later colorized for syndication.", "The show's second and third seasons (62 episodes) and the three television movie sequels (aired between 1978 and 1982) were filmed in color.", "The show received solid ratings during its original run, then grew in popularity during decades of syndication, especially in the 1970s and 1980s when many markets ran the show in the late afternoon.", "Today, the title character of Gilligan is widely recognized as an American cultural icon."]], "gold": "The Gilligan's Island character Ron Hinkley, referred to as the Professor, was played by John Gabriel in the show's 1963 pilot episode. However, CBS thought he looked too young to have all the degrees attributed to the Professor. He was replaced by Russell Johnson, who played the Professor from 1964 until 1983.", "prediction 1": "The character of the Professor in the television series Gilligan's Island was played by several actors. John Gabriel played the character in the pilot episode, but the network thought he looked too young to have all the degrees attributed to the Professor. Russell Johnson played the character in the second and third seasons of the show.\n", "prediction 2": "The character of Professor Roy Hinkley in Gilligan's Island was played by several actors. John Gabriel played the role of the scientist Professor in the pilot episode. Russell Johnson played the role during the second and third seasons of the show.", "prediction 3": "The character of Professor Gilligan in the television sitcom Gilligan's Island is played by a number of actors. The first person to play the character was John Gabriel, who played the character for two seasons in an episode of the pilot. Russell Johnson played the character for three seasons and a total of 118 episodes.", "prediction 4": "Roy Hinkley, referred to as the Professor, is one of the seven castaways from the television series Gilligan's Island (1964\u201367) and was played by Russell Johnson. The character was originally played by John Gabriel in the pilot episode, but the network thought he looked too young to have all the degrees attributed to the Professor. The Professor's backstory identifies him as Roy Hinkley, a high-school science teacher, born in Cleveland, Ohio. His principal expertise was as a botanist, whose purpose in joining the ill-fated voyage that stranded the castaway was to write a book to be titled \"Fun With Ferns\". His main function on the show was to devise many ways for the castaways to live more comfortably on the Island.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 257, "end": 338}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 1, "sentence_id": [1]}], "corrected-prediction": "The character of the Professor in the television series Gilligan's Island was played by several actors. John Gabriel played the character in the pilot episode, but the network thought he looked too young to have all the degrees attributed to the Professor. Russell Johnson then took over the role and played the Professor throughout the entire series from 1964 to 1967."}, "preference": [1, 1, 1, 1, 1, 2], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - The Professor (Gilligan's Island)\nS1. The Professor (Gilligan's Island)  Roy Hinkley, referred to as the Professor, is one of the seven castaways from the television series \"Gilligan's Island\" (1964\u201367); he was played by Russell Johnson.\nS2. The character was originally played by John Gabriel in the pilot episode, but the network thought he looked too young to have all the degrees attributed to the Professor.\nS3. The Professor's backstory identifies him as Roy Hinkley (though his actual name is rarely mentioned during the series), a high-school science teacher who was born in Cleveland, Ohio.\nS4. His principal expertise was as a botanist, whose purpose in joining the ill-fated voyage that stranded the castaways was to write a book to be titled \"Fun With Ferns\".\nS5. His main function on the show was to devise many ways for the castaways to live more comfortably on the island.\nS6. Many of his inventions (including a method for recharging the batteries in the ubiquitous radio) used coconuts and bamboo, both of which were in plentiful supply.\nS7. Aside from his proficiency in science, he was also adept and well-versed in law, literature, social sciences, and the arts.\n\nPassage 2: Title (S0) - Gilligan's Island\nS1. Gilligan's Island  Gilligan's Island is an American sitcom created and produced by Sherwood Schwartz.\nS2. The show had an ensemble cast that featured Bob Denver, Alan Hale Jr., Jim Backus, Natalie Schafer, Russell Johnson, Tina Louise, and Dawn Wells.\nS3. It aired for three seasons on the CBS network from September 26, 1964, to April 17, 1967.\nS4. The series followed the comic adventures of seven castaways as they attempted to survive the island on which they had been shipwrecked.\nS5. Most episodes revolve around the dissimilar castaways' conflicts and their unsuccessful attempts, for whose failure Gilligan was frequently responsible, to escape their plight.\nS6. \"Gilligan's Island\" ran for a total of 98 episodes.\nS7. The first season, consisting of 36 episodes, was filmed in black and white.\nS8. These episodes were later colorized for syndication.\nS9. The show's second and third seasons (62 episodes) and the three television movie sequels (aired between 1978 and 1982) were filmed in color.\nS10. The show received solid ratings during its original run, then grew in popularity during decades of syndication, especially in the 1970s and 1980s when many markets ran the show in the late afternoon.\nS11. Today, the title character of Gilligan is widely recognized as an American cultural icon.\n    \nInput Question:\nWho played the professor in gilligan's island?\n\nCorrect Response:\nThe Gilligan's Island character Ron Hinkley, referred to as the Professor, was played by John Gabriel in the show's 1963 pilot episode. However, CBS thought he looked too young to have all the degrees attributed to the Professor. He was replaced by Russell Johnson, who played the Professor from 1964 until 1983.\n\nModel Prediction:\nThe character of the Professor in the television series Gilligan's Island was played by several actors. John Gabriel played the character in the pilot episode, but the network thought he looked too young to have all the degrees attributed to the Professor. Russell Johnson played the character in the second and third seasons of the show.\n\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "The character of the Professor in the television series Gilligan's Island was played by several actors. John Gabriel played the character in the pilot episode, but the network thought he looked too young to have all the degrees attributed to the Professor. [Russell Johnson played the character in the second and third seasons of the show.]\n\nExplanation:\n1. The phrase \"Russell Johnson played the character in the second and third seasons of the show\" is incorrect. Russell Johnson played the character throughout the entire series, not just the second and third seasons. This is an \"Inconsistent Fact\"."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The character of the Professor in the television series Gilligan's Island was played by several actors.\nS2. John Gabriel played the character in the pilot episode, but the network thought he looked too young to have all the degrees attributed to the Professor.\nS3. Russell Johnson played the character in the second and third seasons of the show.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "Inconsistent or Unverifiable Sentences:\n1. S3\n\nExplanation:\n1. The statement \"Russell Johnson played the character in the second and third seasons of the show\" in sentence S3 is inconsistent with the information provided in the passages. The passages clearly state that Russell Johnson played the character of the Professor throughout the entire series, not just in the second and third seasons."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 1 [Missing Answer]\n\nExplanation:\n1. The model prediction does not mention that Russell Johnson played the Professor for the entire series from 1964-67, as stated in Passage 1, sentence 1. This is a critical piece of information that directly answers the question and is thus labeled as [Missing Answer]."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The character of the Professor in the television series Gilligan's Island was played by several actors. John Gabriel played the character in the pilot episode, but the network thought he looked too young to have all the degrees attributed to the Professor. Russell Johnson then took over the role and played the Professor throughout the entire series from 1964 to 1967."}], "feedback_human": {"errors": [{"error type": "Wrong-Grounding", "explanation": "{\"passage_id\":1,\"sentence_id\":[1]}", "start": 294, "end": 325}], "missing-info": [], "corrected-prediction": "The character of the Professor, in the television series Gilligan's Island, was played by two actors. John Gabriel played the character in the pilot episode, but the network thought he looked too young to have all the degrees attributed to the Professor. Russell Johnson played the character afterwards from 1964 to 1967.\n"}}, {"question": "When did the way you look tonight come out?", "passages": [["The Way You Look Tonight", "The Way You Look Tonight\n\n\"The Way You Look Tonight\" is a song from the film \"Swing Time\" that was performed by Fred Astaire and written by Dorothy Fields and Jerome Kern.", "It won the Academy Award for Best Original Song in 1936.", "Fields remarked, \"The first time Jerry played that melody for me I went out and started to cry.", "The release absolutely killed me.", "I couldn't stop, it was so beautiful.\"", "In the movie, Astaire sang \"The Way You Look Tonight\" to Ginger Rogers while she was washing her hair in an adjacent room.", "His recording reached the top of the charts in 1936.", "Other versions that year were by Guy Lombardo and by Teddy Wilson with Billie Holiday.", "To take advantage of the success of the song, pianist Teddy Wilson brought Billie Holiday into a studio ten weeks after the movie was released.", "Holiday was twenty-one when she recorded \"The Way You Look Tonight\" as a duet with Wilson in October 1936.", "Six years passed before the song appeared on the charts again, this time in a version by Benny Goodman with Peggy Lee on vocals and Mel Powell on celeste.", "The most popular and imitated version was recorded by Frank Sinatra with the Nelson Riddle orchestra in 1964.", "Versions were also recorded by Clifford Brown, Tina Brooks, Johnny Griffin (with John Coltrane), and Charlie Parker."], ["The Way You Look Tonight", "Bing Crosby and his wife Dixie Lee recorded it as a duet on August 19, 1936.", "The Lettermen found their first hit when their version reached No. 14 on the \"Billboard\" magazine Hot 100 singles chart and No. 36 on the UK Singles Chart.", "Sonny Rollins and Thelonious Monk recorded it in 1954."], ["It Had to Be You: The Great American Songbook", "It Had to Be You: The Great American Songbook\n\nIt Had to Be You: The Great American Songbook is the first album of American pop standards recorded by British musician Rod Stewart.", "It was released on 22 October 2002, and became the first in a five-volume series.", "The album was Stewart's first release for Sony Music imprint J Records.", "It included his second recording of \"Every Time We Say Goodbye.\"", "A live DVD of the same title was released on 4 February 2003, which featured performances of material from the studio album as well as Stewart's earlier material.", "Stiefel at Stiefel Entertainment."], ["Hey, Good Lookin' (song)", "Hey, Good Lookin' (song)\n\n\"Hey, Good Lookin'\" is a 1951 song written and recorded by Hank Williams, and his version was inducted into the Grammy Hall of Fame in 2001.", "Since its original 1951 recording it has been covered by a variety of artists.", "The Hank Williams song was inspired by another song by the same title, which was written by Cole Porter in 1942.", "The lyrics for the Williams version begin as a come on using double entendres related to food preparation (\"How's about cookin' somethin' up with me?\").", "By the third and fourth verses, the singer is promising the object of his affection that they can become an exclusive couple (\"How's about keepin' steady company?\" and \"I'm gonna throw my date book over the fence\").", "Williams was friendly with musician Jimmy Dickens.", "Having told Dickens that Dickens needed a hit record if he was going to become a star, Williams said he'd write it, and penned \"Hey Good Lookin'\" in only 20 minutes while on a plane with Dickens, Minnie Pearl, and Pearl's husband Henry Cannon.", "A week later Williams recorded it himself, jokingly telling Dickens, \"That song's too good for you!\""]], "gold": "\"The Way You Look Tonight\" is a song from the film \"Swing Time\" that was performed by Fred Astaire and composed by Jerome Kern with lyrics written by Dorothy Fields. It won the Academy Award for Best Original Song in 1936. Bing Crosby and his wife Dixie Lee recorded it as a duet on August 19, 1936. To take advantage of the success of the song, pianist Teddy Wilson brought Billie Holiday into a studio ten weeks after the movie was released and when Holiday was twenty-one when she recorded \"The Way You Look Tonight\" as a duet with Wilson in October 1936. In 1942, the song appeared on the charts again, this time in a version by Benny Goodman with Peggy Lee on vocals and Mel Powell on celeste. The most popular and imitated version was recorded by Frank Sinatra with the Nelson Riddle orchestra in 1964. Versions were also recorded by Clifford Brown, Tina Brooks, Johnny Griffin (with John Coltrane), and Charlie Parker, and Tony Bennett. Rod Stewart included it on the album \"Great American Songbook\" in 2002.", "prediction 1": "\"The Way You Look Tonight\" is a song from the film Swing Time that was performed by Fred Astaire and written by Dorothy Fields and Jerome Kern. It won the Academy Award for Best Original Song in 1936. It was also the title of a song that was recorded by Bing Crosby and his wife Dixie Lee on August 19, 1936. The song was also the title of an album, It Had to Be You: The Great American Songbook, which was released on October 22, 2002.", "prediction 2": "\"The Way You Look Tonight\" is a song from the film Swing Time that was performed by Fred Astaire and written by Dorothy Fields and Jerome Kern. It won the Academy Award for Best Original Song in 1936. The song was recorded and released by Bing Crosby and his wife Dixie Lee on August 19, 1936. The song came out on the charts again in a version by Benny Goodman with Peggy Lee on vocals and Mel Powell on celeste.", "prediction 3": "\"The Way You Look Tonight\" is a song from the film Swing Time. It was performed by Fred Astaire and written by Dorothy Fields and Jerome Kern. It won the Academy Award for Best Original Song in 1936. It was also recorded in 1936 by Teddy Wilson and Billie Holiday, and was first released on November 6, 1936. It was also featured on Rod Stewart's album It Had to Be You: The Great American Songbook on October 22, 2002.", "prediction 4": "The way you look tonight is a song from the movie \"Swing Time\" that was performed by Fred Astaire and written by Dorothy Fields and Jerome Kern. It won the Academy Award for Best Original Song in 1936. Hey, Good Lookin' is a 1951 song written and recorded by Hank Williams. His version was inducted into the Grammy Hall of Fame in 2001.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 309, "end": 436}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [6]}], "corrected-prediction": "\"The Way You Look Tonight\" is a song from the film Swing Time that was performed by Fred Astaire and written by Dorothy Fields and Jerome Kern. It won the Academy Award for Best Original Song in 1936. In the movie, Astaire sang the song to Ginger Rogers while she was washing her hair in an adjacent room. His recording reached the top of the charts in 1936. The song was also recorded by Bing Crosby and his wife Dixie Lee on August 19, 1936. Pianist Teddy Wilson brought Billie Holiday into a studio ten weeks after the movie was released, and Holiday was twenty-one when she recorded \"The Way You Look Tonight\" as a duet with Wilson in October 1936. The song appeared on the charts again in 1942 in a version by Benny Goodman with Peggy Lee on vocals and Mel Powell on celeste. The most popular and imitated version was recorded by Frank Sinatra with the Nelson Riddle orchestra in 1964. Versions were also recorded by Clifford Brown, Tina Brooks, Johnny Griffin (with John Coltrane), and Charlie Parker."}, "preference": [1, 0, 1, 2, 2, 1], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - The Way You Look Tonight\nS1. The Way You Look Tonight  \"The Way You Look Tonight\" is a song from the film \"Swing Time\" that was performed by Fred Astaire and written by Dorothy Fields and Jerome Kern.\nS2. It won the Academy Award for Best Original Song in 1936.\nS3. Fields remarked, \"The first time Jerry played that melody for me I went out and started to cry.\nS4. The release absolutely killed me.\nS5. I couldn't stop, it was so beautiful.\"\nS6. In the movie, Astaire sang \"The Way You Look Tonight\" to Ginger Rogers while she was washing her hair in an adjacent room.\nS7. His recording reached the top of the charts in 1936.\nS8. Other versions that year were by Guy Lombardo and by Teddy Wilson with Billie Holiday.\nS9. To take advantage of the success of the song, pianist Teddy Wilson brought Billie Holiday into a studio ten weeks after the movie was released.\nS10. Holiday was twenty-one when she recorded \"The Way You Look Tonight\" as a duet with Wilson in October 1936.\nS11. Six years passed before the song appeared on the charts again, this time in a version by Benny Goodman with Peggy Lee on vocals and Mel Powell on celeste.\nS12. The most popular and imitated version was recorded by Frank Sinatra with the Nelson Riddle orchestra in 1964.\nS13. Versions were also recorded by Clifford Brown, Tina Brooks, Johnny Griffin (with John Coltrane), and Charlie Parker.\n\nPassage 2: Title (S0) - The Way You Look Tonight\nS1. Bing Crosby and his wife Dixie Lee recorded it as a duet on August 19, 1936.\nS2. The Lettermen found their first hit when their version reached No. 14 on the \"Billboard\" magazine Hot 100 singles chart and No. 36 on the UK Singles Chart.\nS3. Sonny Rollins and Thelonious Monk recorded it in 1954.\n\nPassage 3: Title (S0) - It Had to Be You: The Great American Songbook\nS1. It Had to Be You: The Great American Songbook  It Had to Be You: The Great American Songbook is the first album of American pop standards recorded by British musician Rod Stewart.\nS2. It was released on 22 October 2002, and became the first in a five-volume series.\nS3. The album was Stewart's first release for Sony Music imprint J Records.\nS4. It included his second recording of \"Every Time We Say Goodbye.\"\nS5. A live DVD of the same title was released on 4 February 2003, which featured performances of material from the studio album as well as Stewart's earlier material.\nS6. Stiefel at Stiefel Entertainment.\n\nPassage 4: Title (S0) - Hey, Good Lookin' (song)\nS1. Hey, Good Lookin' (song)  \"Hey, Good Lookin'\" is a 1951 song written and recorded by Hank Williams, and his version was inducted into the Grammy Hall of Fame in 2001.\nS2. Since its original 1951 recording it has been covered by a variety of artists.\nS3. The Hank Williams song was inspired by another song by the same title, which was written by Cole Porter in 1942.\nS4. The lyrics for the Williams version begin as a come on using double entendres related to food preparation (\"How's about cookin' somethin' up with me?\").\nS5. By the third and fourth verses, the singer is promising the object of his affection that they can become an exclusive couple (\"How's about keepin' steady company?\" and \"I'm gonna throw my date book over the fence\").\nS6. Williams was friendly with musician Jimmy Dickens.\nS7. Having told Dickens that Dickens needed a hit record if he was going to become a star, Williams said he'd write it, and penned \"Hey Good Lookin'\" in only 20 minutes while on a plane with Dickens, Minnie Pearl, and Pearl's husband Henry Cannon.\nS8. A week later Williams recorded it himself, jokingly telling Dickens, \"That song's too good for you!\"\n    \nInput Question:\nWhen did the way you look tonight come out?\n\nCorrect Response:\n\"The Way You Look Tonight\" is a song from the film \"Swing Time\" that was performed by Fred Astaire and composed by Jerome Kern with lyrics written by Dorothy Fields. It won the Academy Award for Best Original Song in 1936. Bing Crosby and his wife Dixie Lee recorded it as a duet on August 19, 1936. To take advantage of the success of the song, pianist Teddy Wilson brought Billie Holiday into a studio ten weeks after the movie was released and when Holiday was twenty-one when she recorded \"The Way You Look Tonight\" as a duet with Wilson in October 1936. In 1942, the song appeared on the charts again, this time in a version by Benny Goodman with Peggy Lee on vocals and Mel Powell on celeste. The most popular and imitated version was recorded by Frank Sinatra with the Nelson Riddle orchestra in 1964. Versions were also recorded by Clifford Brown, Tina Brooks, Johnny Griffin (with John Coltrane), and Charlie Parker, and Tony Bennett. Rod Stewart included it on the album \"Great American Songbook\" in 2002.\n\nModel Prediction:\n\"The Way You Look Tonight\" is a song from the film Swing Time that was performed by Fred Astaire and written by Dorothy Fields and Jerome Kern. It won the Academy Award for Best Original Song in 1936. It was also the title of a song that was recorded by Bing Crosby and his wife Dixie Lee on August 19, 1936. The song was also the title of an album, It Had to Be You: The Great American Songbook, which was released on October 22, 2002.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "\"The Way You Look Tonight\" is a song from the film Swing Time that was performed by Fred Astaire and written by Dorothy Fields and Jerome Kern. It won the Academy Award for Best Original Song in 1936. It was also the title of a song that was recorded by Bing Crosby and his wife Dixie Lee on August 19, 1936. [The song was also the title of an album, It Had to Be You: The Great American Songbook, which was released on October 22, 2002.]\n\nExplanation:\n1. The last sentence in the model prediction is irrelevant. The song \"The Way You Look Tonight\" was not the title of the album \"It Had to Be You: The Great American Songbook\". This information is not related to the question nor is it found in the reference response. Therefore, it should be marked as \"Irrelevant\"."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. \"The Way You Look Tonight\" is a song from the film Swing Time that was performed by Fred Astaire and written by Dorothy Fields and Jerome Kern.\nS2. It won the Academy Award for Best Original Song in 1936.\nS3. It was also the title of a song that was recorded by Bing Crosby and his wife Dixie Lee on August 19, 1936.\nS4. The song was also the title of an album, It Had to Be You: The Great American Songbook, which was released on October 22, 2002.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "Inconsistent or Unverifiable Sentences:\n1. S4\n\nExplanation:\n1. The statement in sentence 4 that \"The Way You Look Tonight\" was the title of the album \"It Had to Be You: The Great American Songbook\" is factually inconsistent with the passages. The song was included in the album, but it was not the title of the album (Passage 3, sentence 1). Therefore, this sentence should be marked as \"Inconsistent Fact\"."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 6 [Missing Major Auxiliary Information]\n2. Passage 1, sentence 7 [Missing Major Auxiliary Information]\n3. Passage 1, sentence 10 [Missing Major Auxiliary Information]\n4. Passage 1, sentence 11 [Missing Major Auxiliary Information]\n5. Passage 1, sentence 12 [Missing Major Auxiliary Information]\n6. Passage 1, sentence 13 [Missing Major Auxiliary Information]\n7. Passage 2, sentence 1 [Missing Major Auxiliary Information]\n8. Passage 2, sentence 2 [Missing Major Auxiliary Information]\n9. Passage 2, sentence 3 [Missing Major Auxiliary Information]\n\nExplanation:\n1. The model prediction does not mention that in the movie, Astaire sang \"The Way You Look Tonight\" to Ginger Rogers while she was washing her hair in an adjacent room (Passage 1, sentence 6). This is a major auxiliary information that provides context to the song's origin.\n2. The model prediction does not mention that Astaire's recording of the song reached the top of the charts in 1936 (Passage 1, sentence 7). This is a major auxiliary information that indicates the song's success.\n3. The model prediction does not mention that Billie Holiday recorded \"The Way You Look Tonight\" as a duet with Teddy Wilson in October 1936 (Passage 1, sentence 10). This is a major auxiliary information that provides additional context to the song's history.\n4. The model prediction does not mention that the song appeared on the charts again in 1942 in a version by Benny Goodman with Peggy Lee on vocals and Mel Powell on celeste (Passage 1, sentence 11). This is a major auxiliary information that provides additional context to the song's history.\n5. The model prediction does not mention that the most popular and imitated version was recorded by Frank Sinatra with the Nelson Riddle orchestra in 1964 (Passage 1, sentence 12). This is a major auxiliary information that provides additional context to the song's history.\n6. The model prediction does not mention that versions were also recorded by Clifford Brown, Tina Brooks, Johnny Griffin (with John Coltrane), and Charlie Parker (Passage 1, sentence 13). This is a major auxiliary information that provides additional context to the song's history.\n7. The model prediction does not mention that Bing Crosby and his wife Dixie Lee recorded it as a duet on August 19,"}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "\"The Way You Look Tonight\" is a song from the film Swing Time that was performed by Fred Astaire and written by Dorothy Fields and Jerome Kern. It won the Academy Award for Best Original Song in 1936. In the movie, Astaire sang the song to Ginger Rogers while she was washing her hair in an adjacent room. His recording reached the top of the charts in 1936. The song was also recorded by Bing Crosby and his wife Dixie Lee on August 19, 1936. Pianist Teddy Wilson brought Billie Holiday into a studio ten weeks after the movie was released, and Holiday was twenty-one when she recorded \"The Way You Look Tonight\" as a duet with Wilson in October 1936. The song appeared on the charts again in 1942 in a version by Benny Goodman with Peggy Lee on vocals and Mel Powell on celeste. The most popular and imitated version was recorded by Frank Sinatra with the Nelson Riddle orchestra in 1964. Versions were also recorded by Clifford Brown, Tina Brooks, Johnny Griffin (with John Coltrane), and Charlie Parker."}], "feedback_human": {"errors": [], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [9]}, {"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [10]}, {"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [11]}, {"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [12]}, {"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [13]}], "corrected-prediction": "\"The Way You Look Tonight\" is a song from the film Swing Time that was performed by Fred Astaire and written by Dorothy Fields and Jerome Kern. It won the Academy Award for Best Original Song in 1936. It was also the title of a song that was recorded by Bing Crosby and his wife Dixie Lee on August 19, 1936. To take advantage of the success of the song, pianist Teddy Wilson brought Billie Holiday into a studio ten weeks after the movie was released. Holiday was twenty-one when she recorded \"The Way You Look Tonight\" as a duet with Wilson in October 1936. Six years passed before the song appeared on the charts again, this time in a version by Benny Goodman with Peggy Lee on vocals and Mel Powell on celeste. The most popular and imitated version was recorded by Frank Sinatra with the Nelson Riddle orchestra in 1964. Versions were also recorded by Clifford Brown, Tina Brooks, Johnny Griffin (with John Coltrane), and Charlie Parker. The song was also the title of an album, It Had to Be You: The Great American Songbook, which was released on October 22, 2002."}}, {"question": "Who writes the headlines to a news story?", "passages": [["Headline", "Headline\n\nThe headline is the text indicating the nature of the article below it.", "The large type \"front page headline\" did not come into use until the late 19th century when increased competition between newspapers led to the use of attention-getting headlines.", "It is sometimes termed a news \"hed\", a deliberate misspelling that dates from production flow during hot type days, to notify the composing room that a written note from an editor concerned a headline and should not be set in type.", "Headlines in English often use a set of grammatical rules known as headlinese, designed to meet stringent space requirements by, for example, leaving out forms of the verb \"to be\" and choosing short verbs like \"eye\" over longer synonyms like \"consider\".", "A headline's purpose is to quickly and briefly draw attention to the story.", "It is generally written by a copy editor, but may also be written by the writer, the page layout designer, or other editors.", "The most important story on the front page above the fold may have a larger headline if the story is unusually important.", "\"The New York Times\"'s 21 July 1969 front page stated, for example, that \"MEN WALK ON MOON\", with the four words in gigantic size spread from the left to right edges of the page."]], "gold": "The headline of an article is the text that indicates the article's nature and its purpose is to quickly and briefly draw attention to the story. The headline of a news story is generally written by a copy editor, but when the copy editor doesn't write it, it may instead be written by the writer, the page layout designer, or other editors.", "prediction 1": "The headline is the text indicating the nature of the article below it. The large type \"front page headline\" did not come into use until the late 19th century when increased competition between newspapers led to the use of attention-getting headlines. It is sometimes termed a news \"hed\", a deliberate misspelling that dates from production flow during hot type days, to notify the composing room that a written note from an editor concerned a headline and should not be set in type.", "prediction 2": "The headline is the text indicating the nature of the article below it. It is usually written by a copy editor, but may also be written by the writer, the page layout designer, or other editors. The headlines to news stories are usually written by the writer, the page layout designer, or other editors. In magazines, the headlines are often written by the writer, the page layout designer, or other editors.", "prediction 3": "The headline is the text indicating the nature of the article below it. It is sometimes termed a news \"hed\", a deliberate misspelling that dates from production flow during hot type days, to notify the composing room that a written note from an editor concerned a headline and should not be set in type. A copy editor generally writes the headlines to a news story, but it may also be written by the writer, the page layout designer, or other editors.", "prediction 4": "The headline is the text indicating the nature of the article below it. The large type \"front page headline\" did not come into use until the late 19th century when increased competition between newspapers led to the use of attention-getting headlines. A headline's purpose is to quickly and briefly draw attention to the story. It is generally written by a copy editor, but may also be written by the writer, the page layout designer, or other editors.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 72, "end": 483}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 1, "sentence_id": [6]}], "corrected-prediction": "The headline of a news story is generally written by a copy editor. However, it may also be written by the writer, the page layout designer, or other editors."}, "preference": [1, 1, 1, 0, 0, 0], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Headline\nS1. Headline  The headline is the text indicating the nature of the article below it.\nS2. The large type \"front page headline\" did not come into use until the late 19th century when increased competition between newspapers led to the use of attention-getting headlines.\nS3. It is sometimes termed a news \"hed\", a deliberate misspelling that dates from production flow during hot type days, to notify the composing room that a written note from an editor concerned a headline and should not be set in type.\nS4. Headlines in English often use a set of grammatical rules known as headlinese, designed to meet stringent space requirements by, for example, leaving out forms of the verb \"to be\" and choosing short verbs like \"eye\" over longer synonyms like \"consider\".\nS5. A headline's purpose is to quickly and briefly draw attention to the story.\nS6. It is generally written by a copy editor, but may also be written by the writer, the page layout designer, or other editors.\nS7. The most important story on the front page above the fold may have a larger headline if the story is unusually important.\nS8. \"The New York Times\"'s 21 July 1969 front page stated, for example, that \"MEN WALK ON MOON\", with the four words in gigantic size spread from the left to right edges of the page.\n    \nInput Question:\nWho writes the headlines to a news story?\n\nCorrect Response:\nThe headline of an article is the text that indicates the article's nature and its purpose is to quickly and briefly draw attention to the story. The headline of a news story is generally written by a copy editor, but when the copy editor doesn't write it, it may instead be written by the writer, the page layout designer, or other editors.\n\nModel Prediction:\nThe headline is the text indicating the nature of the article below it. The large type \"front page headline\" did not come into use until the late 19th century when increased competition between newspapers led to the use of attention-getting headlines. It is sometimes termed a news \"hed\", a deliberate misspelling that dates from production flow during hot type days, to notify the composing room that a written note from an editor concerned a headline and should not be set in type.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "The headline is the text indicating the nature of the article below it. [The large type \"front page headline\" did not come into use until the late 19th century when increased competition between newspapers led to the use of attention-getting headlines. It is sometimes termed a news \"hed\", a deliberate misspelling that dates from production flow during hot type days, to notify the composing room that a written note from an editor concerned a headline and should not be set in type.]\n\nExplanation:\nThe second and third sentences in the model prediction are irrelevant to the question asked. The question is about who writes the headlines, not about the history or terminology of headlines. Therefore, these sentences should be marked as \"Irrelevant\"."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The headline is the text indicating the nature of the article below it.\nS2. The large type \"front page headline\" did not come into use until the late 19th century when increased competition between newspapers led to the use of attention-getting headlines.\nS3. It is sometimes termed a news \"hed\", a deliberate misspelling that dates from production flow during hot type days, to notify the composing room that a written note from an editor concerned a headline and should not be set in type.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation:\nAll the facts presented in the model prediction are consistent with the passages and can be verified. However, they are irrelevant to the question asked."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 6 [Missing Answer]\n\nExplanation:\nThe model prediction does not include the information from Passage 1, sentence 6, which directly answers the question about who writes the headlines for a news story. This is a missing answer."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The headline of a news story is generally written by a copy editor. However, it may also be written by the writer, the page layout designer, or other editors."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 72, "end": 251}, {"error type": "Irrelevant", "explanation": "", "start": 252, "end": 483}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [5]}, {"error type": "Missing-Answer", "passage_id": 1, "sentence_id": [6]}], "corrected-prediction": "The headline is the text indicating the nature of the article below it, and its purpose is to quickly and briefly draw attention to the story.  It is generally written by a copy editor, but may also be written by the writer, the page layout designer, or other editors."}}, {"question": "Who wants to be a millionaire american winner?", "passages": [["Who Wants to Be a Millionaire? (UK game show)", "Although the Defence provided evidence claiming Whittock's coughing was a result of dust allergies and a hay fever he was suffering from, and Whittock himself testified against the accusations, the Prosecution refuted these claims with their evidence, including footage that showed Whittock stopped coughing when he became a contestant after Ingram.", "On 7 April 2003, the group were found guilty, with all three given suspended prison sentences and fines, with the Ingrams later ordered to pay legal costs within two months of the trial's conclusion.", "On 24 July 2003, the British Army ordered Charles Ingram to resign his commission as a Major, in the wake of the trial.", "In the aftermath of the trial, the scandal became the subject of a documentary entitled \"Millionaire: A Major Fraud\", presented by Martin Bashir and broadcast on 21 April 2003, with a follow-up two weeks later entitled \"Millionaire: The Final Answer\".", "The documentary featured excerpts from the recording that had been enhanced for the Ingrams' trial, footage of the actions made by Ingram's wife in the audience, and interviews with production staff and some of the contestants who had been present during the recording."], ["Who Wants to Be a Millionaire (U.S. game show)", "On November 11, Murray was asked approximately how many people had lived on Earth in its history and correctly guessed 100 billion.", "Murray was still atop the leaderboard entering the November 20 finale as he remained the only contestant to even attempt to answer his or her question.", "The only person who could defeat him was top seed and $250,000 winner Jehan Shamsid-Deen, who was asked a question regarding the Blorenge, cited as \"a rare example of a word that rhymes with orange\".", "Shamsid-Deen considered taking the risk, believing (correctly) that the name belonged to a mountain in Wales.", "However, she decided that the potential of losing $225,000 did not justify the risk and elected to walk away from the question, giving Murray the win and the million dollar prize.", "Since its introduction to the United States, GSN credited \"Who Wants to Be a Millionaire\" with not only single-handedly reviving the game show genre, but also breaking new ground for it.", "The series revolutionized the look and feel of game shows with its unique lighting system, dramatic music cues, and futuristic set."], ["Who Wants to Be a Millionaire (U.S. game show)", "Who Wants to Be a Millionaire (U.S. game show)\n\nWho Wants to Be a Millionaire (often informally called Millionaire) is an American television game show based on the same-titled British program and developed for the United States by Michael Davies.", "The show features a quiz competition in which contestants attempt to win a top prize of $1,000,000 by answering a series of multiple-choice questions of increasing difficulty (although, for a time, most of the questions were of random difficulty).", "The program has endured as one of the longest-running and most successful international variants in the \"Who Wants to Be a Millionaire?\" franchise.", "The original U.S. version aired on ABC from August 16, 1999, to June 27, 2002, and was hosted by Regis Philbin.", "The daily syndicated version of the show began airing on September 16, 2002, and was hosted for eleven seasons by Meredith Vieira until May 31, 2013.", "Later hosts included Cedric the Entertainer in the 2013\u201314 season, Terry Crews in the following season (2014\u201315), and Chris Harrison, who began hosting on September 14, 2015.", "As the first U.S. network game show to offer a million-dollar top prize, the show made television history by becoming one of the highest-rated game shows in the history of American television."]], "gold": "Who Wants to Be a Millionaire is an American television game show adapted from the same-titled British program that features a quiz competition with contestants attempting to win a top prize of $1,000,000 by answering a series of multiple-choice questions, usually of increasing difficulty. Many people have won the show throughout the years. John Carpenter became the first top prize winner in the show on November 19, 1999, while Kevin Smith was the first to do so during the syndicated version of the program on February 18, 2003. Nancy Christy is the most recent winner of a regular episode, also being the first and only woman to get the $1,000,000 prize, while Sam Murray was the winner during the Tournament of Ten edition.", "prediction 1": "Who Wants to Be a Millionaire is an American television game show that aired on ABC from August 16, 1999, to June 27, 2002. The show features a quiz competition in which contestants attempt to win a top prize of $1,000,000 by answering a series of multiple-choice questions of increasing difficulty. The first American winner was Jehan Shamsid-Deen, who was asked a question regarding the Blorenge, cited as \"a rare example of a word that rhymes with orange\".", "prediction 2": "Who Wants to Be a Millionaire is an American television game show based on the same-titled British program and developed for the United States by Michael Davies. The program features a quiz competition in which contestants attempt to win a top prize of $1,000,000 by answering a series of multiple-choice questions of increasing difficulty. The show made television history by becoming one of the highest-rated game shows in the history of American television.", "prediction 3": "Who Wants to Be a Millionaire is an American television game show based on the same-titled British program and developed for the United States by Michael Davies. The show features a quiz competition in which contestants attempt to win a top prize of $1,000,000 by answering a series of multiple-choice questions of increasing difficulty. The original U.S. version aired on ABC from August 16, 1999, to June 27, 2002, and was hosted by Regis Philbin.", "prediction 4": "Who Wants to Be a Millionaire is an American game show based on the same-titled British program and developed for the United States by Michael Davies. The show features a quiz competition in which contestants attempt to win a top prize of $1,000,000 by answering a series of multiple-choice questions of increasing difficulty. The first U.S. network game show to offer a million-dollar top prize, the show made television history by becoming one of the highest-rated game shows in the history of American television. The second year the game show aire winner was Jehan Shamsid-Deen. Ingram had won $250,000 prize when he had a million dollar win.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 300, "end": 459}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 2, "sentence_id": [5]}], "corrected-prediction": "Who Wants to Be a Millionaire is an American television game show that aired on ABC from August 16, 1999, to June 27, 2002. The show features a quiz competition in which contestants attempt to win a top prize of $1,000,000 by answering a series of multiple-choice questions of increasing difficulty. The winner during the Tournament of Ten edition was Sam Murray."}, "preference": [1, 1, 1, 1, 1, 1], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Who Wants to Be a Millionaire? (UK game show)\nS1. Although the Defence provided evidence claiming Whittock's coughing was a result of dust allergies and a hay fever he was suffering from, and Whittock himself testified against the accusations, the Prosecution refuted these claims with their evidence, including footage that showed Whittock stopped coughing when he became a contestant after Ingram.\nS2. On 7 April 2003, the group were found guilty, with all three given suspended prison sentences and fines, with the Ingrams later ordered to pay legal costs within two months of the trial's conclusion.\nS3. On 24 July 2003, the British Army ordered Charles Ingram to resign his commission as a Major, in the wake of the trial.\nS4. In the aftermath of the trial, the scandal became the subject of a documentary entitled \"Millionaire: A Major Fraud\", presented by Martin Bashir and broadcast on 21 April 2003, with a follow-up two weeks later entitled \"Millionaire: The Final Answer\".\nS5. The documentary featured excerpts from the recording that had been enhanced for the Ingrams' trial, footage of the actions made by Ingram's wife in the audience, and interviews with production staff and some of the contestants who had been present during the recording.\n\nPassage 2: Title (S0) - Who Wants to Be a Millionaire (U.S. game show)\nS1. On November 11, Murray was asked approximately how many people had lived on Earth in its history and correctly guessed 100 billion.\nS2. Murray was still atop the leaderboard entering the November 20 finale as he remained the only contestant to even attempt to answer his or her question.\nS3. The only person who could defeat him was top seed and $250,000 winner Jehan Shamsid-Deen, who was asked a question regarding the Blorenge, cited as \"a rare example of a word that rhymes with orange\".\nS4. Shamsid-Deen considered taking the risk, believing (correctly) that the name belonged to a mountain in Wales.\nS5. However, she decided that the potential of losing $225,000 did not justify the risk and elected to walk away from the question, giving Murray the win and the million dollar prize.\nS6. Since its introduction to the United States, GSN credited \"Who Wants to Be a Millionaire\" with not only single-handedly reviving the game show genre, but also breaking new ground for it.\nS7. The series revolutionized the look and feel of game shows with its unique lighting system, dramatic music cues, and futuristic set.\n\nPassage 3: Title (S0) - Who Wants to Be a Millionaire (U.S. game show)\nS1. Who Wants to Be a Millionaire (U.S. game show)  Who Wants to Be a Millionaire (often informally called Millionaire) is an American television game show based on the same-titled British program and developed for the United States by Michael Davies.\nS2. The show features a quiz competition in which contestants attempt to win a top prize of $1,000,000 by answering a series of multiple-choice questions of increasing difficulty (although, for a time, most of the questions were of random difficulty).\nS3. The program has endured as one of the longest-running and most successful international variants in the \"Who Wants to Be a Millionaire?\" franchise.\nS4. The original U.S. version aired on ABC from August 16, 1999, to June 27, 2002, and was hosted by Regis Philbin.\nS5. The daily syndicated version of the show began airing on September 16, 2002, and was hosted for eleven seasons by Meredith Vieira until May 31, 2013.\nS6. Later hosts included Cedric the Entertainer in the 2013\u201314 season, Terry Crews in the following season (2014\u201315), and Chris Harrison, who began hosting on September 14, 2015.\nS7. As the first U.S. network game show to offer a million-dollar top prize, the show made television history by becoming one of the highest-rated game shows in the history of American television.\n    \nInput Question:\nWho wants to be a millionaire american winner?\n\nCorrect Response:\nWho Wants to Be a Millionaire is an American television game show adapted from the same-titled British program that features a quiz competition with contestants attempting to win a top prize of $1,000,000 by answering a series of multiple-choice questions, usually of increasing difficulty. Many people have won the show throughout the years. John Carpenter became the first top prize winner in the show on November 19, 1999, while Kevin Smith was the first to do so during the syndicated version of the program on February 18, 2003. Nancy Christy is the most recent winner of a regular episode, also being the first and only woman to get the $1,000,000 prize, while Sam Murray was the winner during the Tournament of Ten edition.\n\nModel Prediction:\nWho Wants to Be a Millionaire is an American television game show that aired on ABC from August 16, 1999, to June 27, 2002. The show features a quiz competition in which contestants attempt to win a top prize of $1,000,000 by answering a series of multiple-choice questions of increasing difficulty. The first American winner was Jehan Shamsid-Deen, who was asked a question regarding the Blorenge, cited as \"a rare example of a word that rhymes with orange\".\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "Who Wants to Be a Millionaire is an American television game show that aired on ABC from August 16, 1999, to June 27, 2002. The show features a quiz competition in which contestants attempt to win a top prize of $1,000,000 by answering a series of multiple-choice questions of increasing difficulty. [The first American winner was Jehan Shamsid-Deen, who was asked a question regarding the Blorenge, cited as \"a rare example of a word that rhymes with orange\".]\n\nExplanation:\nThe last sentence in the model prediction is factually incorrect. Jehan Shamsid-Deen did not win the game show, but rather decided to walk away from the question, as stated in Passage 2, sentence 5. Therefore, it should be marked as \"Inconsistent Fact\"."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. Who Wants to Be a Millionaire is an American television game show that aired on ABC from August 16, 1999, to June 27, 2002.\nS2. The show features a quiz competition in which contestants attempt to win a top prize of $1,000,000 by answering a series of multiple-choice questions of increasing difficulty.\nS3. The first American winner was Jehan Shamsid-Deen, who was asked a question regarding the Blorenge, cited as \"a rare example of a word that rhymes with orange\".\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "Inconsistent or Unverifiable Sentences:\n1. S3\n\nExplanation:\n1. The third sentence is factually incorrect. Jehan Shamsid-Deen did not win the game show, but rather decided to walk away from the question, as stated in Passage 2, sentence 5. Therefore, it should be marked as \"Inconsistent Fact\"."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 2, sentence 5 [Missing Answer]\n\nExplanation:\n1. The model prediction fails to mention that Sam Murray was the winner of the game show during the Tournament of Ten edition, as stated in Passage 2, sentence 5. This is a \"Missing Answer\"."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "Who Wants to Be a Millionaire is an American television game show that aired on ABC from August 16, 1999, to June 27, 2002. The show features a quiz competition in which contestants attempt to win a top prize of $1,000,000 by answering a series of multiple-choice questions of increasing difficulty. The winner during the Tournament of Ten edition was Sam Murray."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 66, "end": 123}, {"error type": "Unverifiable", "explanation": "", "start": 300, "end": 349}, {"error type": "Irrelevant", "explanation": "", "start": 350, "end": 459}], "missing-info": [{"error type": "Missing-Minor-Auxiliary", "passage_id": 3, "sentence_id": [1]}, {"error type": "Missing-Answer", "passage_id": 2, "sentence_id": [5]}], "corrected-prediction": "Who Wants to Be a Millionaire is an American television game show based on the same-titled British program. The show features a quiz competition in which contestants attempt to win a top prize of $1,000,000 by answering a series of multiple-choice questions of increasing difficulty. Sam Murray was the winner.                "}}, {"question": "When was the last time australia held the commonwealth games?", "passages": [["Commonwealth Games", "Commonwealth Games\n\nThe Commonwealth Games are an international multi-sport event involving athletes from the Commonwealth of Nations.", "The event was first held in 1930, and has taken place every four years since then.", "The Commonwealth Games were known as the British Empire Games from 1930 to 1950, the British Empire and Commonwealth Games from 1954 to 1966, and British Commonwealth Games from 1970 to 1974.", "It is the world's first multi-sport event which inducted equal number of women\u2019s and men\u2019s medal events and was implemented recently in the 2018 Commonwealth Games.", "Their creation was inspired by the Inter-Empire Championships, as a part of the Festival of Empire, which were held in London, United Kingdom in 1911.", "Melville Marks Robinson founded the games as the British Empire Games which were first hosted in Hamilton in 1930.", "During the 20th and 21st centuries, the evolution of the games movement has resulted in several changes to the Commonwealth Games.", "Some of these adjustments include the creation of the Commonwealth Winter Games for snow and ice sports for the commonwealth athletes, the Commonwealth Paraplegic Games for commonwealth athletes with a disability and the Commonwealth Youth Games for commonwealth athletes aged 14 to 18.", "The first edition of the winter games and paraplegic games were held in 1958 and 1962 respectively, with their last edition held in 1966 and 1974 respectively and the first youth games were held in 2000."], ["Commonwealth Games", "The 1942 and 1946 Commonwealth Games were cancelled because of the second world war.", "The Commonwealth Games are overseen by the Commonwealth Games Federation (CGF), which also controls the sporting programme and selects the host cities.", "The games movement consists of international sports federations (IFs), (CGAs), and organising committees for each specific Commonwealth Games.", "There are several rituals and symbols, such as the Commonwealth Games flag and Queen's Baton, as well as the opening and closing ceremonies.", "Over 5,000 athletes compete at the Commonwealth Games in more than 15 different sports and more than 250 events.", "The first, second, and third-place finishers in each event receive Commonwealth Games medals: gold, silver, and bronze, respectively.", "Apart from many Olympic sports, the games also include some sports that are played predominantly in Commonwealth countries but which are not part of the Olympic programme, such as lawn bowls, netball and squash.", "Although there are currently 53 members of the Commonwealth of Nations, 71 teams currently participate in the Commonwealth Games, as a number of dependent territories compete under their own flags.", "The four Home Nations of the United Kingdom\u2014England, Scotland, Wales, and Northern Ireland\u2014also send separate teams.", "Nineteen cities in nine countries (counting England, Wales, and Scotland separately) have hosted the event."]], "gold": "The Commonwealth Games is an international multi-sport event involving athletes from the Commonwealth of Nations. The event was first held in 1930, and, with the exception of 1942 and 1946, has taken place every four years since then. Although there are currently 54 members of the Commonwealth of Nations, 72 teams currently participate in the Commonwealth Games, as a number of dependent territories compete under their own flags. Australia has held the Commonwealth Games several times. The last time they held the games in Sydney was on 5 February - 12 February 1938. The last time they held the games in Perth was on 22 November - 1 December 1962. The last time they held the games in Brisbane was on 30 September - 9 October 1982. The last time they held the games in Melbourne was on 15 March - 26 March 2006. The last time they held the games in Gold Coast was on 4 April - 15 April 2018.", "prediction 1": "The Commonwealth Games are an international multi-sport event involving athletes from the Commonwealth of Nations. The event was first held in 1930, and has taken place every four years since then. The last time Australia held the commonwealth games was in 2018.", "prediction 2": "The Commonwealth Games are an international multi-sport event involving athletes from the Commonwealth of Nations. The event was first held in 1930, and has taken place every four years since then. In the 20th and 21st centuries, the evolution of the games movement has resulted in several changes to the Commonwealth Games. Some of these adjustments include the creation of the Commonwealth Winter Games for snow and ice sports for the commonwealth athletes, the Commonwealth Paraplegic Games for commonwealth athletes with a disability and the first Youth Games for commonwealth athletes aged 14 to 18.", "prediction 3": "The Commonwealth Games are an international multi-sport event involving athletes from the Commonwealth of Nations. The event was first held in 1930, and has taken place every four years since then. During the 20th and 21st centuries, the evolution of the games movement has resulted in several changes to the Commonwealth Games, including the creation of the Commonwealth Winter Games for snow and ice sports for the commonwealth athletes, the Commonwealth Paraplegic Games for commonwealth athletes with a disability and the Commonwealth Youth Games for commonwealth athletes aged 14 to 18.", "prediction 4": "The Commonwealth Games are an international multi-sport event involving athletes from the Commonwealth of Nations. The event was first held in 1930, and has taken place every four years since then. The Commonwealth Games were known as the British Empire Games from 1930 to 1950, the British Empire and Commonwealth Games from 1954 to 1966, and British Commonwealth Games from 1970 to 1974. The 2018 Commonwealth Games were the first time that Australia held the commonwealth games.", "feedback": {"errors": [], "missing-info": [], "corrected-prediction": "The Commonwealth Games are an international multi-sport event involving athletes from the Commonwealth of Nations. The event was first held in 1930, and has taken place every four years since then. The last time Australia held the commonwealth games was in 2018."}, "preference": [2, 2, 2, 1, 1, 1], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Commonwealth Games\nS1. Commonwealth Games  The Commonwealth Games are an international multi-sport event involving athletes from the Commonwealth of Nations.\nS2. The event was first held in 1930, and has taken place every four years since then.\nS3. The Commonwealth Games were known as the British Empire Games from 1930 to 1950, the British Empire and Commonwealth Games from 1954 to 1966, and British Commonwealth Games from 1970 to 1974.\nS4. It is the world's first multi-sport event which inducted equal number of women\u2019s and men\u2019s medal events and was implemented recently in the 2018 Commonwealth Games.\nS5. Their creation was inspired by the Inter-Empire Championships, as a part of the Festival of Empire, which were held in London, United Kingdom in 1911.\nS6. Melville Marks Robinson founded the games as the British Empire Games which were first hosted in Hamilton in 1930.\nS7. During the 20th and 21st centuries, the evolution of the games movement has resulted in several changes to the Commonwealth Games.\nS8. Some of these adjustments include the creation of the Commonwealth Winter Games for snow and ice sports for the commonwealth athletes, the Commonwealth Paraplegic Games for commonwealth athletes with a disability and the Commonwealth Youth Games for commonwealth athletes aged 14 to 18.\nS9. The first edition of the winter games and paraplegic games were held in 1958 and 1962 respectively, with their last edition held in 1966 and 1974 respectively and the first youth games were held in 2000.\n\nPassage 2: Title (S0) - Commonwealth Games\nS1. The 1942 and 1946 Commonwealth Games were cancelled because of the second world war.\nS2. The Commonwealth Games are overseen by the Commonwealth Games Federation (CGF), which also controls the sporting programme and selects the host cities.\nS3. The games movement consists of international sports federations (IFs), (CGAs), and organising committees for each specific Commonwealth Games.\nS4. There are several rituals and symbols, such as the Commonwealth Games flag and Queen's Baton, as well as the opening and closing ceremonies.\nS5. Over 5,000 athletes compete at the Commonwealth Games in more than 15 different sports and more than 250 events.\nS6. The first, second, and third-place finishers in each event receive Commonwealth Games medals: gold, silver, and bronze, respectively.\nS7. Apart from many Olympic sports, the games also include some sports that are played predominantly in Commonwealth countries but which are not part of the Olympic programme, such as lawn bowls, netball and squash.\nS8. Although there are currently 53 members of the Commonwealth of Nations, 71 teams currently participate in the Commonwealth Games, as a number of dependent territories compete under their own flags.\nS9. The four Home Nations of the United Kingdom\u2014England, Scotland, Wales, and Northern Ireland\u2014also send separate teams.\nS10. Nineteen cities in nine countries (counting England, Wales, and Scotland separately) have hosted the event.\n    \nInput Question:\nWhen was the last time australia held the commonwealth games?\n\nCorrect Response:\nThe Commonwealth Games is an international multi-sport event involving athletes from the Commonwealth of Nations. The event was first held in 1930, and, with the exception of 1942 and 1946, has taken place every four years since then. Although there are currently 54 members of the Commonwealth of Nations, 72 teams currently participate in the Commonwealth Games, as a number of dependent territories compete under their own flags. Australia has held the Commonwealth Games several times. The last time they held the games in Sydney was on 5 February - 12 February 1938. The last time they held the games in Perth was on 22 November - 1 December 1962. The last time they held the games in Brisbane was on 30 September - 9 October 1982. The last time they held the games in Melbourne was on 15 March - 26 March 2006. The last time they held the games in Gold Coast was on 4 April - 15 April 2018.\n\nModel Prediction:\nThe Commonwealth Games are an international multi-sport event involving athletes from the Commonwealth of Nations. The event was first held in 1930, and has taken place every four years since then. The last time Australia held the commonwealth games was in 2018.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "The Commonwealth Games are an international multi-sport event involving athletes from the Commonwealth of Nations. The event was first held in 1930, and has taken place every four years since then. The last time Australia held the commonwealth games was in 2018.\n\nExplanation: There are no irrelevant, incoherent or repetitive spans in the model prediction. The information provided is relevant to the question, coherent, and not repetitive."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The Commonwealth Games are an international multi-sport event involving athletes from the Commonwealth of Nations.\nS2. The event was first held in 1930, and has taken place every four years since then.\nS3. The last time Australia held the commonwealth games was in 2018.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "There are no inconsistent or unverifiable facts in the model prediction. All the information provided in the model prediction is consistent with the passages and can be verified from the passages."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "There is no missing information in the model prediction. The model correctly identifies that the last time Australia hosted the Commonwealth Games was in 2018, which is the main information asked for in the question."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The Commonwealth Games are an international multi-sport event involving athletes from the Commonwealth of Nations. The event was first held in 1930, and has taken place every four years since then. The last time Australia held the commonwealth games was in 2018."}], "feedback_human": {"errors": [{"error type": "Unverifiable", "explanation": "", "start": 198, "end": 262}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 2, "sentence_id": [8]}], "corrected-prediction": "The Commonwealth Games is an international multi-sport event involving athletes from the Commonwealth of Nations. The event was first held in 1930, and, with the exception of 1942 and 1946, has taken place every four years since then. Although there are currently 53 members of the Commonwealth of Nations, 71 teams currently participate in the Commonwealth Games, as a number of dependent territories compete under their own flags.                "}}, {"question": "When is the nba first regular season game?", "passages": [["2016\u201317 NBA season", "This was the first time since the 1963\u201364 NBA season that there was no in-season coaching changes, the fourth time this happened in league history.", "The preseason began on October 1, 2016 and ended on October 21, 2016.", "The regular season began on Tuesday, October 25, 2016.", "Christmas Day games were played on Sunday, December 25, 2016.", "The regular season ended on Wednesday, April 12, 2017.", "The schedule was released at 6:00\u00a0p.m. ET on August 11, 2016.", "Notes\n\n\n\nThe 2017 NBA Playoffs began on April 15, 2017.", "In May 2017, ESPN aired the Western Conference Finals and TNT aired the Eastern Conference Finals.", "The season ended with the 2017 NBA Finals which began on June 1, 2017 and ended on June 12, 2017 on ABC.", "Awards were presented at the NBA Awards ceremony, which were held on June 26.", "Finalists for voted awards were announced during the playoffs and winners were presented at the award ceremony.", "The All-NBA Team was announced in advance in order for teams to have all the necessary information to make offseason preparations.", "The following players were named the Eastern and Western Conference Players of the Week.", "The following players were named the Eastern and Western Conference Players of the Month.", "The following players were named the Eastern and Western Conference Rookies of the Month.", "The following coaches were named the Eastern and Western Conference Coaches of the Month."], ["2015\u201316 Cleveland Cavaliers season", "However, despite having the best record in their conference, the team fired head coach David Blatt on January 22, 2016.", "Assistant coach Tyronn Lue took over for the remainder of the season.", "The Cavaliers finished the regular season with a 57\u201325 record and obtained the number one seed in the Eastern Conference for the first time since 2010.", "In the first two rounds of the 2016 NBA playoffs, the Cavaliers swept the Detroit Pistons and the Atlanta Hawks, respectively.", "In the Eastern Conference Finals, the Cavaliers beat the Toronto Raptors in six games.", "The Cavaliers lost three of the first four games of the 2016 NBA Finals to the Golden State Warriors, who had defeated Cleveland in the finals the year before.", "In turn, the Cavaliers won Games 5 and 6 of the series to bring about a climactic Game 7 at Oracle Arena.", "With Game 7 tied at 89\u201389, LeBron James chased down and blocked Andre Iguodala's attempted lay-up in a play that became known as \"The Block.\"", "The Cavaliers ultimately won Game 7, 93\u201389, for the first NBA championship in franchise history.", "No team had ever before recovered from a 3\u20131 deficit in an NBA Finals series.", "James was named the unanimous NBA Finals MVP, receiving the award for the third time in his career."], ["National Basketball Association", "National Basketball Association\n\nThe National Basketball Association (NBA) is a men's professional basketball league in North America; composed of 30 teams (29 in the United States and 1 in Canada).", "It is widely considered to be the premier men's professional basketball league in the world.", "The NBA is an active member of USA Basketball (USAB), which is recognized by FIBA (also known as the International Basketball Federation) as the national governing body for basketball in the United States.", "The NBA is one of the four major professional sports leagues in the United States and Canada.", "NBA players are the world's best paid athletes by average annual salary per player.", "The league was founded in New York City on June 6, 1946, as the Basketball Association of America (BAA).", "The league adopted the name National Basketball Association on August 3, 1949, after merging with the competing National Basketball League (NBL).", "The league's several international as well as individual team offices are directed out of its head offices located in the Olympic Tower at 645 Fifth Avenue in Manhattan.", "NBA Entertainment and NBA TV studios are directed out of offices located in Secaucus, New Jersey.", "The Basketball Association of America was founded in 1946 by owners of the major ice hockey arenas in the Northeastern and Midwestern United States and Canada."], ["2016\u201317 NBA season", "2016\u201317 NBA season\n\nThe 2016\u201317 NBA season was the 71st season of the National Basketball Association.", "The regular season began on October 25, 2016, with the 2016 NBA champion Cleveland Cavaliers hosting a game against the New York Knicks.", "The 2017 NBA All-Star Game was played at the Smoothie King Center in New Orleans, Louisiana, on February 19, 2017, with the West defeating the East 192\u2013182.", "Anthony Davis of the New Orleans Pelicans was named the All Star Game MVP after breaking Wilt Chamberlain's record by scoring 52 points in the All Star Game.", "The original host of the game, Charlotte's Spectrum Center, was removed as the host on July 21, 2016 due to the league's opposition against North Carolina's Public Facilities Privacy & Security Act.", "The regular season ended on April 12, 2017, and the playoffs began on April 15, 2017 and ended on June 12, 2017, with the Golden State Warriors going 16-1 in the playoffs and beating the Cleveland Cavaliers in five games during their third consecutive matchup in the NBA Finals.", "Free agency negotiations began on Friday, July 1, 2016 at 12:01\u00a0a.m.", "e.t.", "Players can sign starting on July 6, after the July moratorium ended.", "There were no head coaching changes during the regular season."], ["2015\u201316 NBA season", "2015\u201316 NBA season\n\nThe 2015\u201316 NBA season was the 70th season of the National Basketball Association.", "The regular season began on Tuesday, October 27, 2015 at the United Center, home of the Chicago Bulls, with their game against the Cleveland Cavaliers.", "The 2016 NBA All-Star Game was played at the Air Canada Centre in Toronto, Ontario, Canada on February 14, 2016.", "The regular season ended on April 13, 2016.", "The playoffs started on April 16, 2016 and ended with the 2016 NBA Finals on June 19, 2016, with the Cleveland Cavaliers becoming NBA Champions for the first time in franchise history after defeating the Golden State Warriors in seven games.", "Free agency negotiations began on Friday, July 1, 2015 while players will begin to sign starting on July 7, after the July moratorium ended.", "The preseason began on Friday, October 2, 2015 and ended on Friday, October 23, 2015.", "The regular season began on Tuesday, October 27, 2015 at the United Center, home of the Chicago Bulls, who hosted a game against the Cleveland Cavaliers at 8:00\u00a0p.m. EDT, then the Atlanta Hawks hosted the Detroit Pistons at 8:00\u00a0p.m. EDT.", "Finally, the defending NBA champion Golden State Warriors hosted the New Orleans Pelicans at 10:30\u00a0p.m. EDT at the Oracle Arena."]], "gold": "Usually, the first regular game of the each NBA season has been played in the month of October, with the exception of the 2020-21 edition, which, due to COVID-19 restrictions, began in December. For the 2015-16 Season, the opening game was on October 27, 2015. The event was held on October 25, 2016 for the 2016-17 Season and on October 17, 2017 for the 2017-18 edition.", "prediction 1": "The National Basketball Association (NBA) is a men's professional basketball league in North America, composed of 30 teams, with 30 members, based in the United States and Canada. The league began its 71st season on August 3, 1949, when the NBA champion Cleveland Cavaliers hosted a game against the New York Knicks. The NBA regular season began on Tuesday, October 25, 2016, with the 2016 NBA champion Cleveland Cavaliers hosting a game against the New York Knicks. Christmas Day games were played on Sunday, December 25, 2016. The NBA first regular season began on Wednesday, April 12, 2017.\n", "prediction 2": "The National Basketball Association is a men's professional basketball league in North America, composed of 30 teams, with 30 teams in the United States and one team in Canada. The league's first regular season game was on October 25, 2016 against the New York Knicks. The NBA is widely considered to be the premier men's professional basketball league in the world, with more than 10,000 players, with a total population of over 30 million. It was founded on June 6, 1946, as the Basketball Association of America and adopted the name National Basketball Association on August 3, 1949. The first regular season game began on October 25, 2016, with the Cleveland Cavaliers hosting a game against the New Orleans Pelicans. The league's first regular season game was held on February 19, 2017, with the New Orleans Pelicans hosting a game against the New York Knicks.", "prediction 3": "The National Basketball Association (NBA) is a men's professional basketball league in North America. The league began its 71st season on August 3, 1949, and played its first regular season game on October 25, 2016. The first regular season game was played February 19, 1917, against the Philadelphia 76ers.", "prediction 4": "The NBA, officially the National Basketball Association, is a men's professional basketball league in North America composed of 30 teams and is widely considered the premier men's professional basketball league in the world. The league began in 1946 as the Basketball Association of America, before adopting the name National Basketball Association on August 3, 1949, after merging with the competing National Basketball League (NBL). The NBA regular season began on October 25, 2016, with the 2015\u201316 Cleveland Cavaliers hosting a game against the New York Knicks. Christmas Day games were played on Sunday, December 25, 2016. The NBA began its 2017 NBA playoffs ended on April 12, 2017. A few years later on January 15, 2018, the Houston Rockets had played against the Chicago Bulls.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 317, "end": 466}, {"error type": "Irrelevant", "explanation": "", "start": 467, "end": 528}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 1, "sentence_id": [3]}], "corrected-prediction": "The National Basketball Association (NBA) is a men's professional basketball league in North America, composed of 30 teams, based in the United States and Canada. The 2015-16 NBA season began on Tuesday, October 27, 2015. The following season, the 2016-17 NBA season, began on Tuesday, October 25, 2016, with the 2016 NBA champion Cleveland Cavaliers hosting a game against the New York Knicks."}, "preference": [1, 1, 1, 2, 2, 2], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - 2016\u201317 NBA season\nS1. This was the first time since the 1963\u201364 NBA season that there was no in-season coaching changes, the fourth time this happened in league history.\nS2. The preseason began on October 1, 2016 and ended on October 21, 2016.\nS3. The regular season began on Tuesday, October 25, 2016.\nS4. Christmas Day games were played on Sunday, December 25, 2016.\nS5. The regular season ended on Wednesday, April 12, 2017.\nS6. The schedule was released at 6:00\u00a0p.m. ET on August 11, 2016.\nS7. Notes    The 2017 NBA Playoffs began on April 15, 2017.\nS8. In May 2017, ESPN aired the Western Conference Finals and TNT aired the Eastern Conference Finals.\nS9. The season ended with the 2017 NBA Finals which began on June 1, 2017 and ended on June 12, 2017 on ABC.\nS10. Awards were presented at the NBA Awards ceremony, which were held on June 26.\nS11. Finalists for voted awards were announced during the playoffs and winners were presented at the award ceremony.\nS12. The All-NBA Team was announced in advance in order for teams to have all the necessary information to make offseason preparations.\nS13. The following players were named the Eastern and Western Conference Players of the Week.\nS14. The following players were named the Eastern and Western Conference Players of the Month.\nS15. The following players were named the Eastern and Western Conference Rookies of the Month.\nS16. The following coaches were named the Eastern and Western Conference Coaches of the Month.\n\nPassage 2: Title (S0) - 2015\u201316 Cleveland Cavaliers season\nS1. However, despite having the best record in their conference, the team fired head coach David Blatt on January 22, 2016.\nS2. Assistant coach Tyronn Lue took over for the remainder of the season.\nS3. The Cavaliers finished the regular season with a 57\u201325 record and obtained the number one seed in the Eastern Conference for the first time since 2010.\nS4. In the first two rounds of the 2016 NBA playoffs, the Cavaliers swept the Detroit Pistons and the Atlanta Hawks, respectively.\nS5. In the Eastern Conference Finals, the Cavaliers beat the Toronto Raptors in six games.\nS6. The Cavaliers lost three of the first four games of the 2016 NBA Finals to the Golden State Warriors, who had defeated Cleveland in the finals the year before.\nS7. In turn, the Cavaliers won Games 5 and 6 of the series to bring about a climactic Game 7 at Oracle Arena.\nS8. With Game 7 tied at 89\u201389, LeBron James chased down and blocked Andre Iguodala's attempted lay-up in a play that became known as \"The Block.\"\nS9. The Cavaliers ultimately won Game 7, 93\u201389, for the first NBA championship in franchise history.\nS10. No team had ever before recovered from a 3\u20131 deficit in an NBA Finals series.\nS11. James was named the unanimous NBA Finals MVP, receiving the award for the third time in his career.\n\nPassage 3: Title (S0) - National Basketball Association\nS1. National Basketball Association  The National Basketball Association (NBA) is a men's professional basketball league in North America; composed of 30 teams (29 in the United States and 1 in Canada).\nS2. It is widely considered to be the premier men's professional basketball league in the world.\nS3. The NBA is an active member of USA Basketball (USAB), which is recognized by FIBA (also known as the International Basketball Federation) as the national governing body for basketball in the United States.\nS4. The NBA is one of the four major professional sports leagues in the United States and Canada.\nS5. NBA players are the world's best paid athletes by average annual salary per player.\nS6. The league was founded in New York City on June 6, 1946, as the Basketball Association of America (BAA).\nS7. The league adopted the name National Basketball Association on August 3, 1949, after merging with the competing National Basketball League (NBL).\nS8. The league's several international as well as individual team offices are directed out of its head offices located in the Olympic Tower at 645 Fifth Avenue in Manhattan.\nS9. NBA Entertainment and NBA TV studios are directed out of offices located in Secaucus, New Jersey.\nS10. The Basketball Association of America was founded in 1946 by owners of the major ice hockey arenas in the Northeastern and Midwestern United States and Canada.\n\nPassage 4: Title (S0) - 2016\u201317 NBA season\nS1. 2016\u201317 NBA season  The 2016\u201317 NBA season was the 71st season of the National Basketball Association.\nS2. The regular season began on October 25, 2016, with the 2016 NBA champion Cleveland Cavaliers hosting a game against the New York Knicks.\nS3. The 2017 NBA All-Star Game was played at the Smoothie King Center in New Orleans, Louisiana, on February 19, 2017, with the West defeating the East 192\u2013182.\nS4. Anthony Davis of the New Orleans Pelicans was named the All Star Game MVP after breaking Wilt Chamberlain's record by scoring 52 points in the All Star Game.\nS5. The original host of the game, Charlotte's Spectrum Center, was removed as the host on July 21, 2016 due to the league's opposition against North Carolina's Public Facilities Privacy & Security Act.\nS6. The regular season ended on April 12, 2017, and the playoffs began on April 15, 2017 and ended on June 12, 2017, with the Golden State Warriors going 16-1 in the playoffs and beating the Cleveland Cavaliers in five games during their third consecutive matchup in the NBA Finals.\nS7. Free agency negotiations began on Friday, July 1, 2016 at 12:01\u00a0a.m.\nS8. e.t.\nS9. Players can sign starting on July 6, after the July moratorium ended.\nS10. There were no head coaching changes during the regular season.\n\nPassage 5: Title (S0) - 2015\u201316 NBA season\nS1. 2015\u201316 NBA season  The 2015\u201316 NBA season was the 70th season of the National Basketball Association.\nS2. The regular season began on Tuesday, October 27, 2015 at the United Center, home of the Chicago Bulls, with their game against the Cleveland Cavaliers.\nS3. The 2016 NBA All-Star Game was played at the Air Canada Centre in Toronto, Ontario, Canada on February 14, 2016.\nS4. The regular season ended on April 13, 2016.\nS5. The playoffs started on April 16, 2016 and ended with the 2016 NBA Finals on June 19, 2016, with the Cleveland Cavaliers becoming NBA Champions for the first time in franchise history after defeating the Golden State Warriors in seven games.\nS6. Free agency negotiations began on Friday, July 1, 2015 while players will begin to sign starting on July 7, after the July moratorium ended.\nS7. The preseason began on Friday, October 2, 2015 and ended on Friday, October 23, 2015.\nS8. The regular season began on Tuesday, October 27, 2015 at the United Center, home of the Chicago Bulls, who hosted a game against the Cleveland Cavaliers at 8:00\u00a0p.m. EDT, then the Atlanta Hawks hosted the Detroit Pistons at 8:00\u00a0p.m. EDT.\nS9. Finally, the defending NBA champion Golden State Warriors hosted the New Orleans Pelicans at 10:30\u00a0p.m. EDT at the Oracle Arena.\n    \nInput Question:\nWhen is the nba first regular season game?\n\nCorrect Response:\nUsually, the first regular game of the each NBA season has been played in the month of October, with the exception of the 2020-21 edition, which, due to COVID-19 restrictions, began in December. For the 2015-16 Season, the opening game was on October 27, 2015. The event was held on October 25, 2016 for the 2016-17 Season and on October 17, 2017 for the 2017-18 edition.\n\nModel Prediction:\nThe National Basketball Association (NBA) is a men's professional basketball league in North America, composed of 30 teams, with 30 members, based in the United States and Canada. The league began its 71st season on August 3, 1949, when the NBA champion Cleveland Cavaliers hosted a game against the New York Knicks. The NBA regular season began on Tuesday, October 25, 2016, with the 2016 NBA champion Cleveland Cavaliers hosting a game against the New York Knicks. Christmas Day games were played on Sunday, December 25, 2016. The NBA first regular season began on Wednesday, April 12, 2017.\n\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "The National Basketball Association (NBA) is a men's professional basketball league in North America, composed of 30 teams, with 30 members, based in the United States and Canada. The league began its 71st season on August 3, 1949, when the NBA champion Cleveland Cavaliers hosted a game against the New York Knicks. [The NBA regular season began on Tuesday, October 25, 2016, with the 2016 NBA champion Cleveland Cavaliers hosting a game against the New York Knicks.] [Christmas Day games were played on Sunday, December 25, 2016.] The NBA first regular season began on Wednesday, April 12, 2017.\n\nExplanation:\n1. The third sentence is repetitive as it repeats the information about the start of the 2016 NBA season and the game between the Cleveland Cavaliers and the New York Knicks.\n2. The fourth sentence is irrelevant as it mentions the Christmas Day games which are not related to the question about the first regular season game.\n3. The last sentence is incoherent as it incorrectly states that the NBA first regular season began on April 12, 2017, which is actually the end date of the 2016-2017 regular season."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The National Basketball Association (NBA) is a men's professional basketball league in North America, composed of 30 teams, with 30 members, based in the United States and Canada.\nS2. The league began its 71st season on August 3, 1949, when the NBA champion Cleveland Cavaliers hosted a game against the New York Knicks.\nS3. The NBA regular season began on Tuesday, October 25, 2016, with the 2016 NBA champion Cleveland Cavaliers hosting a game against the New York Knicks.\nS4. Christmas Day games were played on Sunday, December 25, 2016.\nS5. The NBA first regular season began on Wednesday, April 12, 2017.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "Inconsistent or Unverifiable Sentences:\n1. S2\n2. S5\n\nExplanation:\n1. The second sentence is factually inconsistent. The 71st season of the NBA did not begin on August 3, 1949. This date is actually when the league adopted the name National Basketball Association (Passage 3, S7). The 71st season began on October 25, 2016 (Passage 1, S3).\n2. The fifth sentence is also factually inconsistent. The NBA's first regular season did not begin on April 12, 2017. This is actually the end date of the 2016-2017 regular season (Passage 1, S5)."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 3 [Missing Answer]\n2. Passage 5, sentence 2 [Missing Answer]\n3. Passage 4, sentence 2 [Missing Answer]\n\nExplanation:\n1. The model prediction misses the information about the start of the 2016-17 NBA season on October 25, 2016 (Passage 1, S3).\n2. The model prediction also misses the information about the start of the 2015-16 NBA season on October 27, 2015 (Passage 5, S2).\n3. The model prediction does not mention the start of the 2017-18 NBA season on October 17, 2017, which is not provided in the passages but is mentioned in the reference response."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The National Basketball Association (NBA) is a men's professional basketball league in North America, composed of 30 teams, based in the United States and Canada. The 2015-16 NBA season began on Tuesday, October 27, 2015. The following season, the 2016-17 NBA season, began on Tuesday, October 25, 2016, with the 2016 NBA champion Cleveland Cavaliers hosting a game against the New York Knicks."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 0, "end": 179}, {"error type": "Wrong-Grounding", "explanation": "{\"passage_id\":4,\"sentence_id\":[2]}", "start": 216, "end": 231}, {"error type": "Irrelevant", "explanation": "", "start": 232, "end": 316}, {"error type": "Redundant", "explanation": " The league began its 71st season on August 3, 1949, when the NBA champion Cleveland Cavaliers hosted a game against the New York Knicks. ", "start": 317, "end": 466}, {"error type": "Irrelevant", "explanation": "", "start": 467, "end": 528}, {"error type": "Wrong-Grounding", "explanation": "{\"passage_id\":5,\"sentence_id\":[2]}", "start": 578, "end": 594}], "missing-info": [{"error type": "Missing-Minor-Auxiliary", "passage_id": 4, "sentence_id": [1]}, {"error type": "Missing-Minor-Auxiliary", "passage_id": 5, "sentence_id": [1]}], "corrected-prediction": "The league began its 71st (2016-2017) season on October 25, 2016. For the 2015-16 Season, the opening game was on October 27, 2015. "}}, {"question": "Who played eddie on the tv show frasier?", "passages": [["Minor characters on Frasier", "Her traditionally minded, prudish mother lives in Spokane, Washington.", "Claire (Patricia Clarkson) is a friend of Frasier's old date / high school prom queen.", "She appears in season 8.", "The following are significant members of the Crane family excluding Frasier, Martin, Niles, and Daphne Crane.", "Although most of the series revolves around Frasier Crane and his immediate family, occasionally members of Frasier's extended family appear.", "These are listed below.", "David is Niles' and Daphne's son.", "He was born in the two-part episode \"Goodnight, Seattle\".", "During Daphne's pregnancy, it is implied he takes after his low-brow uncles (Daphne's brothers); for example, he kicks away classical music and jumps at the mention of a pub.", "He was born in a veterinary clinic and is named after show's creator David Angell, who died along with his wife Lynn aboard American Airlines Flight 11 during the September 11, 2001 attacks.", "Eddie (born May 1990) is a Parson Russell Terrier.", "Eddie was originally played by Moose, and later by Moose's son Enzo.", "Eddie is known for responding to Martin and Daphne with human-like understanding, but often seems to taunt Frasier."], ["Frasier", "Frasier\n\nFrasier is an American sitcom that was broadcast on NBC for 11 seasons, premiering on September 16, 1993, and concluding on May 13, 2004.", "The program was created and produced by David Angell, Peter Casey, and David Lee (as Grub Street Productions) in association with Grammnet (2004) and Paramount Network Television.", "The series was created as a spin-off of \"Cheers\", continuing the story of psychiatrist Frasier Crane as he returned to his hometown of Seattle and started building a new life as a radio advice show host while reconnecting with his father and brother.", "\"Frasier\" stars Kelsey Grammer, Jane Leeves, David Hyde Pierce, Peri Gilpin, and John Mahoney.", "The show was critically acclaimed, with the show itself and the cast winning thirty-seven Emmy Awards, a record at the time for a scripted series.", "It also won the Emmy for Outstanding Comedy Series for five consecutive years.", "Psychiatrist Dr. Frasier Crane (Grammer) returns to his home town of Seattle, Washington, following the end of his marriage and his life in Boston (as seen in \"Cheers\")."]], "gold": "Frasier is an American television sitcom that was broadcast on NBC for 11 seasons. The character, Eddie, was a Parson Russell Terrier. He was originally played by Moose, and later by Moose's son Enzo.", "prediction 1": "Eddie is a parson Russell Terrier who is played by Moose, and later by Moose's son Enzo, on the tv show Frasier. Eddie was originally played by Moose, and later by Moose's son Enzo.", "prediction 2": "Eddie was originally played by Moose, and later by Moose's son Enzo. Eddie is known for responding to Martin and Daphne with human-like understanding, but often seems to taunt Frasier. On the sitcom Frasier, the character of Eddie was played by Kelsey Grammer, Jane Leeves, David Hyde Pierce, Peri Gilpin, and John Mahoney.", "prediction 3": "Eddie was originally played by Moose, and later by Moose's son Enzo. Eddie is known for responding to Martin and Daphne with human-like understanding, but often seems to taunt Frasier. The show had a runaway success as a sitcom, with the final season starring Kelsey Grammer.", "prediction 4": "Frasier is an American sitcom that was broadcast on NBC for 11 seasons. Eddie was originally played by Moose, and later by Moose's son Enzo. Enzo was a puppy. The character was played by Kelsey Grammer in season 1 and by Jonathan R. Davidson in season 11.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 113, "end": 181}], "missing-info": [], "corrected-prediction": "Eddie is a parson Russell Terrier who is played by Moose, and later by Moose's son Enzo, on the TV show Frasier."}, "preference": [2, 2, 2, 1, 1, 1], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Minor characters on Frasier\nS1. Her traditionally minded, prudish mother lives in Spokane, Washington.\nS2. Claire (Patricia Clarkson) is a friend of Frasier's old date / high school prom queen.\nS3. She appears in season 8.\nS4. The following are significant members of the Crane family excluding Frasier, Martin, Niles, and Daphne Crane.\nS5. Although most of the series revolves around Frasier Crane and his immediate family, occasionally members of Frasier's extended family appear.\nS6. These are listed below.\nS7. David is Niles' and Daphne's son.\nS8. He was born in the two-part episode \"Goodnight, Seattle\".\nS9. During Daphne's pregnancy, it is implied he takes after his low-brow uncles (Daphne's brothers); for example, he kicks away classical music and jumps at the mention of a pub.\nS10. He was born in a veterinary clinic and is named after show's creator David Angell, who died along with his wife Lynn aboard American Airlines Flight 11 during the September 11, 2001 attacks.\nS11. Eddie (born May 1990) is a Parson Russell Terrier.\nS12. Eddie was originally played by Moose, and later by Moose's son Enzo.\nS13. Eddie is known for responding to Martin and Daphne with human-like understanding, but often seems to taunt Frasier.\n\nPassage 2: Title (S0) - Frasier\nS1. Frasier  Frasier is an American sitcom that was broadcast on NBC for 11 seasons, premiering on September 16, 1993, and concluding on May 13, 2004.\nS2. The program was created and produced by David Angell, Peter Casey, and David Lee (as Grub Street Productions) in association with Grammnet (2004) and Paramount Network Television.\nS3. The series was created as a spin-off of \"Cheers\", continuing the story of psychiatrist Frasier Crane as he returned to his hometown of Seattle and started building a new life as a radio advice show host while reconnecting with his father and brother.\nS4. \"Frasier\" stars Kelsey Grammer, Jane Leeves, David Hyde Pierce, Peri Gilpin, and John Mahoney.\nS5. The show was critically acclaimed, with the show itself and the cast winning thirty-seven Emmy Awards, a record at the time for a scripted series.\nS6. It also won the Emmy for Outstanding Comedy Series for five consecutive years.\nS7. Psychiatrist Dr. Frasier Crane (Grammer) returns to his home town of Seattle, Washington, following the end of his marriage and his life in Boston (as seen in \"Cheers\").\n    \nInput Question:\nWho played eddie on the tv show frasier?\n\nCorrect Response:\nFrasier is an American television sitcom that was broadcast on NBC for 11 seasons. The character, Eddie, was a Parson Russell Terrier. He was originally played by Moose, and later by Moose's son Enzo.\n\nModel Prediction:\nEddie is a parson Russell Terrier who is played by Moose, and later by Moose's son Enzo, on the tv show Frasier. Eddie was originally played by Moose, and later by Moose's son Enzo.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "Eddie is a parson Russell Terrier who is played by Moose, and later by Moose's son Enzo, on the tv show Frasier. [Eddie was originally played by Moose, and later by Moose's son Enzo.]\n\nExplanation:\nThe second sentence in the model prediction is repetitive as it repeats the information that Eddie was played by Moose and later by Moose's son Enzo."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. Eddie is a parson Russell Terrier who is played by Moose, and later by Moose's son Enzo, on the tv show Frasier.\nS2. Eddie was originally played by Moose, and later by Moose's son Enzo.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation:\nAll the facts in the model prediction are consistent with the information provided in the passages."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "None\n\nExplanation:\nThe model prediction contains all the necessary information to answer the question. It correctly identifies that Eddie, a character from the TV show Frasier, was played by a Parson Russell Terrier named Moose and later by Moose's son, Enzo."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "Eddie is a parson Russell Terrier who is played by Moose, and later by Moose's son Enzo, on the TV show Frasier."}], "feedback_human": {"errors": [{"error type": "Redundant", "explanation": "Eddie is a parson Russell Terrier who is played by Moose, and later by Moose's son Enzo", "start": 113, "end": 181}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 2, "sentence_id": [1]}], "corrected-prediction": "Frasier Frasier is an American sitcom that was broadcast on NBC for 11 seasons. Eddie is a parson Russell Terrier who is played by Moose, and later by Moose's son Enzo."}}, {"question": "How many months are in the roman calendar?", "passages": [["Roman calendar", "In order to avoid interfering with Rome's religious ceremonies, the reform added all its days towards the ends of months and did not adjust any nones or ides, even in months which came to have 31 days.", "The Julian calendar was supposed to have a single leap day on 24 February (a doubled \") every fourth year but following Caesar's assassination the priests figured this using inclusive counting and mistakenly added the bissextile day every three years.", "In order to bring the calendar back to its proper place, Augustus was obliged to suspend intercalation for one or two decades.", "The revised calendar remaining slightly longer than the solar year, the date of Easter shifted far enough away from the vernal equinox that Pope Gregory\u00a0XIII ordered its adjustment in the 16th century.", "The original Roman calendar is believed to have been an observational lunar calendar whose months began from the first signs of a new crescent moon.", "Because a lunar cycle is about days long, such months would have varied between 29 and 30 days.", "Twelve such months would have fallen 10 or 11 days short of the solar year; without adjustment, such a year would have quickly rotated out of alignment with the seasons in the manner of the Islamic calendar.", "Given the seasonal aspects of the later calendar and its associated religious festivals, this was presumably avoided through some form of intercalation or through the suspension of the calendar during winter."], ["Roman calendar", "Rome's 8-day week, the nundinal cycle, was shared with the Etruscans, who used it as the schedule of royal audiences.", "It was presumably a part of the early calendar and was credited in Roman legend variously to Romulus and Servius Tullius.", "The Romans themselves described their first organized year as one with ten fixed months, each of 30 or 31 days.", "Such a decimal division fitted general Roman practice.", "The four 31-day months were called \"full\" (') and the others \"hollow\" (').", "Its 304 days made up exactly 38 nundinal cycles.", "The system is usually said to have left the remaining 50-odd days of the year as an unorganized \"winter\", although Licinius Macer's lost history apparently stated the earliest Roman calendar employed intercalation instead and Macrobius claims the 10-month calendar was allowed to shift until the summer and winter months were completely misplaced, at which time additional days belonging to no month were simply inserted into the calendar until it seemed things were restored to their proper place.", "Later Roman writers credited this calendar to Romulus, their legendary first king and culture hero, although this was common with other practices and traditions whose origin had been lost to them."], ["Roman calendar", "Some scholars doubt the existence of this calendar at all, as it is only attested in late Republican and Imperial sources and apparently supported only by the misplaced names of the months from September to December.", "R\u00fcpke also finds the coincidence of the length of the supposed \"Romulan\" year with the length of the first ten months of the Julian calendar to be suspicious.", "Other traditions existed alongside this one, however.", "Plutarch's \"Parallel Lives\" recounts that Romulus's calendar had been solar but adhered to the general principle that the year should last for 360 days.", "Months were employed secondarily and haphazardly, with some counted as 20 days and others as 35 or more.", "The attested calendar of the Roman Republic was quite different.", "It followed Greek calendars in assuming a lunar cycle of days and a solar year of synodic months ( days), which align every fourth year after the addition of two intercalary months.", "The additional two months of the year were January and February; the intercalary month was sometimes known as Mercedonius.", "The Romans did not follow the usual Greek practice in alternating 29- and 30-day months and a 29- or 30-day intercalary month every other year."]], "gold": "The Roman Calendar went through different revisions throughout history. The original one is believed to have been an observational lunar calendar with twelve months that would have fallen 10 or 11 days short of the solar year. Nonetheless, their first organized calendar was one with ten fixed months, each of 30 or 31 days named \"hollow\" or \"full\" respectively. The later Roman Republican Calendar was quite different from previous iterations as it followed Greek calendars in assuming a lunar cycle of 29 1\u20442 days and a solar year of 12 1\u20442 synodic months.", "prediction 1": "The original Roman calendar is believed to have been an observational lunar calendar whose months began from the first signs of a new crescent moon. Because a lunar cycle is about days long, such months would have varied between 29 and 30 days. Twelve such months would have fallen 10 or 11 days short of the solar year. Later Roman writers credited this calendar to Romulus, their legendary first king and culture hero, although this was common with other practices and traditions whose origin had been lost to them. The attested calendar of the attested Roman Republic was quite different. It followed Greek calendars in assuming a lunar cycle of days and a solar year of synodic months, which align every fourth year after the addition of two intercalary months.", "prediction 2": "The original Roman calendar is believed to have been an observational lunar calendar whose months began from the first signs of a new crescent moon. Because a lunar cycle is about days long, such months would have varied between 29 and 30 days. Twelve such months would have fallen 10 or 11 days short of the solar year. Additionally, the Romans themselves described their first organized year as one with ten fixed months, each of 30 or 31 days. Such a decimal division fitted general Roman practice, especially during winter, when additional days belonging to no month were simply inserted into the calendar until it seemed things were restored to their proper place.", "prediction 3": "The original Roman calendar is believed to have been an observational lunar calendar whose months began from the first signs of a new crescent moon. Because a lunar cycle is about days long, such months would have varied between 29 and 30 days. The Romans themselves described their first organized year as one with ten fixed months, each of 30 or 31 days. However, the 10-month system was later credited to Romulus, the legendary first king and culture hero of Rome.", "prediction 4": "There are several different versions of the Roman calendar. The original Roman calendar is believed to have been an observational lunar calendar, whose months began from the first signs of a new crescent moon. According to the Romans, the first organized year was one with ten fixed months, each of 30 or 31 days, while the rest of the year was an unorganized winter. The earliest Roman calendar employed intercalation, at which time additional days belonging to no month were simply inserted into the calendar until it seemed things were restored to their proper place.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 321, "end": 517}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 2, "sentence_id": [3]}], "corrected-prediction": "The original Roman calendar is believed to have been an observational lunar calendar whose months began from the first signs of a new crescent moon. Because a lunar cycle is about days long, such months would have varied between 29 and 30 days. Twelve such months would have fallen 10 or 11 days short of the solar year. The first organized Roman calendar had ten fixed months, each of 30 or 31 days, named \"hollow\" or \"full\" respectively. The attested calendar of the Roman Republic was quite different. It followed Greek calendars in assuming a lunar cycle of days and a solar year of synodic months, which align every fourth year after the addition of two intercalary months."}, "preference": [1, 1, 1, 2, 2, 1], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Roman calendar\nS1. In order to avoid interfering with Rome's religious ceremonies, the reform added all its days towards the ends of months and did not adjust any nones or ides, even in months which came to have 31 days.\nS2. The Julian calendar was supposed to have a single leap day on 24 February (a doubled \") every fourth year but following Caesar's assassination the priests figured this using inclusive counting and mistakenly added the bissextile day every three years.\nS3. In order to bring the calendar back to its proper place, Augustus was obliged to suspend intercalation for one or two decades.\nS4. The revised calendar remaining slightly longer than the solar year, the date of Easter shifted far enough away from the vernal equinox that Pope Gregory\u00a0XIII ordered its adjustment in the 16th century.\nS5. The original Roman calendar is believed to have been an observational lunar calendar whose months began from the first signs of a new crescent moon.\nS6. Because a lunar cycle is about days long, such months would have varied between 29 and 30 days.\nS7. Twelve such months would have fallen 10 or 11 days short of the solar year; without adjustment, such a year would have quickly rotated out of alignment with the seasons in the manner of the Islamic calendar.\nS8. Given the seasonal aspects of the later calendar and its associated religious festivals, this was presumably avoided through some form of intercalation or through the suspension of the calendar during winter.\n\nPassage 2: Title (S0) - Roman calendar\nS1. Rome's 8-day week, the nundinal cycle, was shared with the Etruscans, who used it as the schedule of royal audiences.\nS2. It was presumably a part of the early calendar and was credited in Roman legend variously to Romulus and Servius Tullius.\nS3. The Romans themselves described their first organized year as one with ten fixed months, each of 30 or 31 days.\nS4. Such a decimal division fitted general Roman practice.\nS5. The four 31-day months were called \"full\" (') and the others \"hollow\" (').\nS6. Its 304 days made up exactly 38 nundinal cycles.\nS7. The system is usually said to have left the remaining 50-odd days of the year as an unorganized \"winter\", although Licinius Macer's lost history apparently stated the earliest Roman calendar employed intercalation instead and Macrobius claims the 10-month calendar was allowed to shift until the summer and winter months were completely misplaced, at which time additional days belonging to no month were simply inserted into the calendar until it seemed things were restored to their proper place.\nS8. Later Roman writers credited this calendar to Romulus, their legendary first king and culture hero, although this was common with other practices and traditions whose origin had been lost to them.\n\nPassage 3: Title (S0) - Roman calendar\nS1. Some scholars doubt the existence of this calendar at all, as it is only attested in late Republican and Imperial sources and apparently supported only by the misplaced names of the months from September to December.\nS2. R\u00fcpke also finds the coincidence of the length of the supposed \"Romulan\" year with the length of the first ten months of the Julian calendar to be suspicious.\nS3. Other traditions existed alongside this one, however.\nS4. Plutarch's \"Parallel Lives\" recounts that Romulus's calendar had been solar but adhered to the general principle that the year should last for 360 days.\nS5. Months were employed secondarily and haphazardly, with some counted as 20 days and others as 35 or more.\nS6. The attested calendar of the Roman Republic was quite different.\nS7. It followed Greek calendars in assuming a lunar cycle of days and a solar year of synodic months ( days), which align every fourth year after the addition of two intercalary months.\nS8. The additional two months of the year were January and February; the intercalary month was sometimes known as Mercedonius.\nS9. The Romans did not follow the usual Greek practice in alternating 29- and 30-day months and a 29- or 30-day intercalary month every other year.\n    \nInput Question:\nHow many months are in the roman calendar?\n\nCorrect Response:\nThe Roman Calendar went through different revisions throughout history. The original one is believed to have been an observational lunar calendar with twelve months that would have fallen 10 or 11 days short of the solar year. Nonetheless, their first organized calendar was one with ten fixed months, each of 30 or 31 days named \"hollow\" or \"full\" respectively. The later Roman Republican Calendar was quite different from previous iterations as it followed Greek calendars in assuming a lunar cycle of 29 1\u20442 days and a solar year of 12 1\u20442 synodic months.\n\nModel Prediction:\nThe original Roman calendar is believed to have been an observational lunar calendar whose months began from the first signs of a new crescent moon. Because a lunar cycle is about days long, such months would have varied between 29 and 30 days. Twelve such months would have fallen 10 or 11 days short of the solar year. Later Roman writers credited this calendar to Romulus, their legendary first king and culture hero, although this was common with other practices and traditions whose origin had been lost to them. The attested calendar of the attested Roman Republic was quite different. It followed Greek calendars in assuming a lunar cycle of days and a solar year of synodic months, which align every fourth year after the addition of two intercalary months.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "The original Roman calendar is believed to have been an observational lunar calendar whose months began from the first signs of a new crescent moon. Because a lunar cycle is about days long, such months would have varied between 29 and 30 days. Twelve such months would have fallen 10 or 11 days short of the solar year. [Later Roman writers credited this calendar to Romulus, their legendary first king and culture hero, although this was common with other practices and traditions whose origin had been lost to them.] The attested calendar of the attested Roman Republic was quite different. It followed Greek calendars in assuming a lunar cycle of days and a solar year of synodic months, which align every fourth year after the addition of two intercalary months.\n\nExplanation:\nThe information about Romulus and the cultural traditions is irrelevant to the question about the number of months in the Roman calendar. It does not provide an answer or crucial auxiliary information. Therefore, it should be marked as \"Irrelevant\"."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The original Roman calendar is believed to have been an observational lunar calendar whose months began from the first signs of a new crescent moon.\nS2. Because a lunar cycle is about days long, such months would have varied between 29 and 30 days.\nS3. Twelve such months would have fallen 10 or 11 days short of the solar year.\nS4. Later Roman writers credited this calendar to Romulus, their legendary first king and culture hero, although this was common with other practices and traditions whose origin had been lost to them.\nS5. The attested calendar of the attested Roman Republic was quite different.\nS6. It followed Greek calendars in assuming a lunar cycle of days and a solar year of synodic months, which align every fourth year after the addition of two intercalary months.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation:\nAll the facts mentioned in the model prediction are consistent with the provided passages and can be verified from them."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 2, sentence 3 [Missing Answer]\n2. Passage 2, sentence 5 [Missing Major Auxiliary Information]\n\nExplanation:\n1. The model prediction does not mention the ten fixed months of the first organized Roman calendar, which is a missing answer found in Passage 2, sentence 3.\n2. The model prediction also omits the information about the months being named \"hollow\" or \"full\", which is a major auxiliary information that helps in understanding the structure of the Roman calendar. This information can be found in Passage 2, sentence 5."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The original Roman calendar is believed to have been an observational lunar calendar whose months began from the first signs of a new crescent moon. Because a lunar cycle is about days long, such months would have varied between 29 and 30 days. Twelve such months would have fallen 10 or 11 days short of the solar year. The first organized Roman calendar had ten fixed months, each of 30 or 31 days, named \"hollow\" or \"full\" respectively. The attested calendar of the Roman Republic was quite different. It followed Greek calendars in assuming a lunar cycle of days and a solar year of synodic months, which align every fourth year after the addition of two intercalary months."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 149, "end": 244}, {"error type": "Irrelevant", "explanation": "", "start": 690, "end": 765}, {"error type": "Irrelevant", "explanation": "", "start": 327, "end": 517}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 2, "sentence_id": [3]}], "corrected-prediction": "The original Roman calendar is believed to have been an observational lunar calendar whose months began from the first signs of a new crescent moon. Twelve such months would have fallen 10 or 11 days short of the solar year.  The Romans themselves described their first organized year as one with ten fixed months, each of 30 or 31 days. Later,  the attested calendar of the attested Roman Republic was quite different. It followed Greek calendars in assuming a lunar cycle of days and a solar year of synodic months. "}}, {"question": "Who owns the rights to texas chainsaw massacre?", "passages": [["The Texas Chainsaw Massacre (franchise)", "When comparing \"The Texas Chainsaw Massacre\" to the other top-grossing horror film series \u2013 \"A Nightmare on Elm Street\", \"Child's Play\", \"Friday the 13th\", \"Halloween\", the \"Hannibal Lecter\" series, \"Psycho\", \"Saw\", and \"Scream\" \u2013 and adjusting for the 2011 inflation, \"The Texas Chainsaw Massacre\" is the eighth highest grossing horror film series in the United States, with a combined gross of $304.6 million, only outperforming the \"Chucky\" film series with approximately $203\u00a0million.", "The series is led by \"Friday the 13th\" at $687.1\u00a0million, \"A Nightmare on Elm Street\" with $592.8\u00a0million, the Hannibal Lecter film series with $588.7\u00a0million, \"Halloween\" with $557.5\u00a0million, \"Saw\" with $457.4\u00a0million, \"Scream\" with $442.9\u00a0million, and the \"Psycho\" film series, with $376.3\u00a0million.", "Following the release of \"Leatherface\", the producers had the rights to make five more \"Texas Chainsaw Massacre\" films.", "In April 2015, producer Christa Campbell stated that the fate of the potential films would largely depend on the financial reception and perceived fan reactions regarding the 2017 prequel."], ["The Texas Chainsaw Massacre (franchise)", "Campbell clarified in December 2017 that Lionsgate and Millennium Films had lost the franchise rights due to the time it took to release it.", "On August 24, 2018, Legendary Pictures had bought the rights to the franchise, with a new film and a television series in development.", "Several comic books based on \"The Texas Chainsaw Massacre\" films were published in 1991 by Northstar Comics entitled \"Leatherface\".", "They were licensed as \"The Texas Chainsaw Massacre\" to Avatar Press for use in new comic book stories, the first of which was published in 2005.", "In 2006, Avatar Press lost the license to DC Comics imprint, Wildstorm, which has published new stories based on the films.", "However, in June 2007, Wildstorm changed a number of horror comics, including \"The Texas Chainsaw Massacre\", from monthly issues to specials and miniseries.", "The series of comics featured none of the main characters seen in the original film (Topps Comics \"Jason vs. Leatherface\" series is exempt) with the exception of Leatherface, however, the 1991 \"Leatherface\" miniseries was loosely based on the third \"Texas Chainsaw Massacre\" film.", "The writer of the miniseries, Mort Castle said, \"The series was very loosely based on \"Texas Chainsaw Massacre III\"."], ["Texas Chainsaw 3D", "In March 2015 Hollywood Collectibles released a 20-inch Leatherface action figure, based on Dan Yeager portrayed figure.", "In January 2013, it was revealed that due to the film's financial success, Millennium Films began planning a sequel film to be called \"Texas Chainsaw 4\" which was expected to begin filming later in 2013 in the state of Louisiana.", "Millennium Films Chairman Avi Lerner stated that the project was brought to him by Christa Campbell and Lati Grobman and that Millennium had signed on to produce, with Lionsgate distributing the finished product.", "Executive producer Mark Burg clarified that the sequel was prematurely announced and had not been authorised, \"The rights are controlled by Carl [Mazzocone] and Main Line Pictures, no matter what Millennium says.", "Millennium simply sold the foreign rights and they will not tell us when a sequel is ready to be made.", "The script was developed by Carl, myself and writer/director John Luessenhop.", "Maybe they're looking for something to sell at Berlin, but they have no right to announce this sequel.\"", "Ultimately, a prequel titled \"Leatherface\" was released by Lionsgate and Millennium Films in October 2017, from a pitch by writer Seth M. Sherwood focusing on the origin of the eponymous killer."]], "gold": "Lionsgate and Millennium Films owned the rights to Texas Chainsaw Massacre in 2013 but lost the rights in 2017 due to the time it took to release more Texas Chainsaw Massacre films. On August 24, 2018, Legendary Pictures had bought the rights to the franchise, with a new film and a television series in development.", "prediction 1": "Legendary Pictures bought the rights to the Texas Chainsaw Massacre franchise in 2018 and plans to develop a new film based on the franchise.", "prediction 2": "Legendary Pictures has bought the rights to the Texas Chainsaw Massacre franchise for a reported $120 million. Legendary Pictures has produced a new film and a television series in development. The rights to the Texas Chainsaw Massacre comic book series were licensed as \"The Texas Chainsaw Massacre\" to Avatar Press for use in new comic book stories. In 2017, a prequel to the original film was released by Lionsgate and Millennium Films. In 2018, Legendary Pictures acquired the rights to the original film and the prequel.", "prediction 3": "The Texas Chainsaw Massacre franchise is a horror film franchise that has been produced by several studios. As of 2017, Lionsgate and Millennium Films owned the rights to the franchise. In 2018, Legendary Pictures bought the rights to the franchise, with a new film in development.", "prediction 4": "Several film and comic book series based on The Texas Chainsaw Massacre have been published since the 1991 film's release in 1991. The Texas Chainsaw Massacre films are a horror film franchise which has been produced by several companies. The first two films, Texas Chainsaw Massacre III and the 2017 prequel, were produced by Lionsgate and Millennium Films. The rights to the Texas Chainsaw Massacre franchise were owned by Carl Mazzocone and Main Line Pictures. Legendary Pictures bought the rights to the franchise on August 24, 2018, and a new film and a television series in development.", "feedback": {"errors": [], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 2, "sentence_id": [1]}], "corrected-prediction": "Lionsgate and Millennium Films had previously owned the rights to the Texas Chainsaw Massacre franchise but lost them in 2017 due to the time it took to release more films. Legendary Pictures then bought the rights to the franchise in 2018 and has plans to develop a new film and a television series based on the franchise."}, "preference": [1, 1, 1, 2, 1, 1], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - The Texas Chainsaw Massacre (franchise)\nS1. When comparing \"The Texas Chainsaw Massacre\" to the other top-grossing horror film series \u2013 \"A Nightmare on Elm Street\", \"Child's Play\", \"Friday the 13th\", \"Halloween\", the \"Hannibal Lecter\" series, \"Psycho\", \"Saw\", and \"Scream\" \u2013 and adjusting for the 2011 inflation, \"The Texas Chainsaw Massacre\" is the eighth highest grossing horror film series in the United States, with a combined gross of $304.6 million, only outperforming the \"Chucky\" film series with approximately $203\u00a0million.\nS2. The series is led by \"Friday the 13th\" at $687.1\u00a0million, \"A Nightmare on Elm Street\" with $592.8\u00a0million, the Hannibal Lecter film series with $588.7\u00a0million, \"Halloween\" with $557.5\u00a0million, \"Saw\" with $457.4\u00a0million, \"Scream\" with $442.9\u00a0million, and the \"Psycho\" film series, with $376.3\u00a0million.\nS3. Following the release of \"Leatherface\", the producers had the rights to make five more \"Texas Chainsaw Massacre\" films.\nS4. In April 2015, producer Christa Campbell stated that the fate of the potential films would largely depend on the financial reception and perceived fan reactions regarding the 2017 prequel.\n\nPassage 2: Title (S0) - The Texas Chainsaw Massacre (franchise)\nS1. Campbell clarified in December 2017 that Lionsgate and Millennium Films had lost the franchise rights due to the time it took to release it.\nS2. On August 24, 2018, Legendary Pictures had bought the rights to the franchise, with a new film and a television series in development.\nS3. Several comic books based on \"The Texas Chainsaw Massacre\" films were published in 1991 by Northstar Comics entitled \"Leatherface\".\nS4. They were licensed as \"The Texas Chainsaw Massacre\" to Avatar Press for use in new comic book stories, the first of which was published in 2005.\nS5. In 2006, Avatar Press lost the license to DC Comics imprint, Wildstorm, which has published new stories based on the films.\nS6. However, in June 2007, Wildstorm changed a number of horror comics, including \"The Texas Chainsaw Massacre\", from monthly issues to specials and miniseries.\nS7. The series of comics featured none of the main characters seen in the original film (Topps Comics \"Jason vs. Leatherface\" series is exempt) with the exception of Leatherface, however, the 1991 \"Leatherface\" miniseries was loosely based on the third \"Texas Chainsaw Massacre\" film.\nS8. The writer of the miniseries, Mort Castle said, \"The series was very loosely based on \"Texas Chainsaw Massacre III\".\n\nPassage 3: Title (S0) - Texas Chainsaw 3D\nS1. In March 2015 Hollywood Collectibles released a 20-inch Leatherface action figure, based on Dan Yeager portrayed figure.\nS2. In January 2013, it was revealed that due to the film's financial success, Millennium Films began planning a sequel film to be called \"Texas Chainsaw 4\" which was expected to begin filming later in 2013 in the state of Louisiana.\nS3. Millennium Films Chairman Avi Lerner stated that the project was brought to him by Christa Campbell and Lati Grobman and that Millennium had signed on to produce, with Lionsgate distributing the finished product.\nS4. Executive producer Mark Burg clarified that the sequel was prematurely announced and had not been authorised, \"The rights are controlled by Carl [Mazzocone] and Main Line Pictures, no matter what Millennium says.\nS5. Millennium simply sold the foreign rights and they will not tell us when a sequel is ready to be made.\nS6. The script was developed by Carl, myself and writer/director John Luessenhop.\nS7. Maybe they're looking for something to sell at Berlin, but they have no right to announce this sequel.\"\nS8. Ultimately, a prequel titled \"Leatherface\" was released by Lionsgate and Millennium Films in October 2017, from a pitch by writer Seth M. Sherwood focusing on the origin of the eponymous killer.\n    \nInput Question:\nWho owns the rights to texas chainsaw massacre?\n\nCorrect Response:\nLionsgate and Millennium Films owned the rights to Texas Chainsaw Massacre in 2013 but lost the rights in 2017 due to the time it took to release more Texas Chainsaw Massacre films. On August 24, 2018, Legendary Pictures had bought the rights to the franchise, with a new film and a television series in development.\n\nModel Prediction:\nLegendary Pictures bought the rights to the Texas Chainsaw Massacre franchise in 2018 and plans to develop a new film based on the franchise.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "Legendary Pictures bought the rights to the Texas Chainsaw Massacre franchise in 2018 and plans to develop a new film based on the franchise.\n\nExplanation: There are no irrelevant, incoherent or repetitive spans in the model prediction. The information provided is relevant to the question, is coherent and does not repeat any information."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. Legendary Pictures bought the rights to the Texas Chainsaw Massacre franchise in 2018 and plans to develop a new film based on the franchise.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation: The model prediction does not contain any factual inconsistencies or unverifiable facts. The information provided in the prediction is consistent with the information provided in the passages."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 2, sentence 1 [Missing Major Auxiliary Information]\n2. Passage 2, sentence 2 [Missing Major Auxiliary Information]\n\nExplanation:\n1. The model prediction does not mention that Lionsgate and Millennium Films had previously owned the rights to the Texas Chainsaw Massacre franchise but lost them in 2017 due to the time it took to release more films. This is a significant piece of information that provides context to the ownership of the franchise rights.\n2. The model prediction also omits the information that Legendary Pictures is planning to develop not only a new film but also a television series based on the franchise. This is important auxiliary information that gives a fuller picture of Legendary Pictures' plans for the franchise."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "Lionsgate and Millennium Films had previously owned the rights to the Texas Chainsaw Massacre franchise but lost them in 2017 due to the time it took to release more films. Legendary Pictures then bought the rights to the franchise in 2018 and has plans to develop a new film and a television series based on the franchise."}], "feedback_human": {"errors": [], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 2, "sentence_id": [1]}, {"error type": "Missing-Major-Auxiliary", "passage_id": 2, "sentence_id": [2]}], "corrected-prediction": "Lionsgate and Millennium Films owned the rights to Texas Chainsaw Massacre, but lost them due to the time it took to release it. Legendary Pictures bought the rights to the Texas Chainsaw Massacre franchise in 2018 and plans to develop a new film and television series based on the franchise."}}, {"question": "When was the original story of beauty and the beast written?", "passages": [["Beauty and the Beast", "Beauty and the Beast\n\nBeauty and the Beast () is a fairy tale written by French novelist Gabrielle-Suzanne Barbot de Villeneuve and published in 1740 in \"La Jeune Am\u00e9ricaine et les contes marins\" (\"The Young American and Marine Tales\").", "Her lengthy version was abridged, rewritten, and published first by Jeanne-Marie Leprince de Beaumont in 1756 in \"Magasin des enfants\" (\"Children's Collection\") and by Andrew Lang in the \"Blue Fairy Book\" of his \"Fairy Book\" series in 1889, to produce the version(s) most commonly retold.", "It was influenced by some earlier stories, such as \"Cupid and Psyche\", \"The Golden Ass\" written by Lucius Apuleius Madaurensis in the 2nd century AD, and \"The Pig King\", an Italian fairytale published by Giovanni Francesco Straparola in \"The Facetious Nights of Straparola\".", "Variants of the tale are known across Europe.", "In France, for example, \"Z\u00e9mire and Azor\" is an operatic version of the story, written by Marmontel and composed by Gr\u00e9try in 1771, which had enormous success well into the 19th century; it is based on the second version of the tale."]], "gold": "Beauty and the Beast is a fairy tale written by French novelist Gabrielle-Suzanne Barbot de Villeneuve and published in 1740. Her lengthy version was later abridged, rewritten, and published by Jeanne-Marie Leprince de Beaumont in 1756 in Magasin des enfants to produce the version most commonly retold.", "prediction 1": "The original story of Beauty and the Beast was written by Gabrielle-Suzanne Barbot de Villeneuve in 1740 and published in 1740 in La Jeune Am\u00e9ricaine et les contes marins. It was abridged, rewritten, and published first by Jeanne-Marie Leprin de Beaumont in 1756 in Magasin des enfants (\"Children's Collection\") and by Andrew Lang in the Blue Fairy Book of his Fairy Book series in 1889, to produce the version(s) most commonly retold. Variants of the story are known across Europe.", "prediction 2": "Beauty and the Beast is a fairy tale written by Gabrielle-Suzanne Barbot de Villeneuve and published in 1740 in La Jeune Am\u00e9ricaine et les contes marins. Her lengthy version was abridged, rewritten, and published first by Jeanne-Marie Leprin de Beaumont in 1756 in Magasin des enfants (\"Children's Collection\") and by Andrew Lang in the Blue Fairy Book of his Fairy Book series in 1889, to produce the version(s) most commonly retold. Variants of the story are known across Europe.", "prediction 3": "Beauty and the Beast is a fairy tale written by French novelist Gabrielle-Suzanne Barbot de Villeneuve and published in 1740 in La Jeune Am\u00e9ricaine et les contes marins. Her lengthy version was abridged, rewritten, and published first by Jeanne-Marie Leprin de Beaumont in 1756 in Magasin des enfants (\"Children's Collection\") and by Andrew Lang in the Blue Fairy Book of his Fairy Book series in 1889, to produce the version(s) most commonly retold. Variants of the tale are known across Europe.", "prediction 4": "The original story of Beauty and the Beast was written by Gabrielle-Suzanne Barbot de Villeneuve and published in 1740. It was abridged, rewritten, and published by Jeanne-Marie Leprin de Beaumont in 1756 in Magasin des enfants and by Andrew Lang in the Blue Fairy Book of his Fairy Book series in 1889, to produce the version(s) most commonly retold.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 436, "end": 482}], "missing-info": [], "corrected-prediction": "The original story of Beauty and the Beast was written by Gabrielle-Suzanne Barbot de Villeneuve in 1740 and published in 1740 in La Jeune Am\u00e9ricaine et les contes marins. It was abridged, rewritten, and published first by Jeanne-Marie Leprin de Beaumont in 1756 in Magasin des enfants (\"Children's Collection\") and by Andrew Lang in the Blue Fairy Book of his Fairy Book series in 1889, to produce the version(s) most commonly retold."}, "preference": [1, 1, 1, 1, 1, 1], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Beauty and the Beast\nS1. Beauty and the Beast  Beauty and the Beast () is a fairy tale written by French novelist Gabrielle-Suzanne Barbot de Villeneuve and published in 1740 in \"La Jeune Am\u00e9ricaine et les contes marins\" (\"The Young American and Marine Tales\").\nS2. Her lengthy version was abridged, rewritten, and published first by Jeanne-Marie Leprince de Beaumont in 1756 in \"Magasin des enfants\" (\"Children's Collection\") and by Andrew Lang in the \"Blue Fairy Book\" of his \"Fairy Book\" series in 1889, to produce the version(s) most commonly retold.\nS3. It was influenced by some earlier stories, such as \"Cupid and Psyche\", \"The Golden Ass\" written by Lucius Apuleius Madaurensis in the 2nd century AD, and \"The Pig King\", an Italian fairytale published by Giovanni Francesco Straparola in \"The Facetious Nights of Straparola\".\nS4. Variants of the tale are known across Europe.\nS5. In France, for example, \"Z\u00e9mire and Azor\" is an operatic version of the story, written by Marmontel and composed by Gr\u00e9try in 1771, which had enormous success well into the 19th century; it is based on the second version of the tale.\n    \nInput Question:\nWhen was the original story of beauty and the beast written?\n\nCorrect Response:\nBeauty and the Beast is a fairy tale written by French novelist Gabrielle-Suzanne Barbot de Villeneuve and published in 1740. Her lengthy version was later abridged, rewritten, and published by Jeanne-Marie Leprince de Beaumont in 1756 in Magasin des enfants to produce the version most commonly retold.\n\nModel Prediction:\nThe original story of Beauty and the Beast was written by Gabrielle-Suzanne Barbot de Villeneuve in 1740 and published in 1740 in La Jeune Am\u00e9ricaine et les contes marins. It was abridged, rewritten, and published first by Jeanne-Marie Leprin de Beaumont in 1756 in Magasin des enfants (\"Children's Collection\") and by Andrew Lang in the Blue Fairy Book of his Fairy Book series in 1889, to produce the version(s) most commonly retold. Variants of the story are known across Europe.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "The original story of Beauty and the Beast was written by Gabrielle-Suzanne Barbot de Villeneuve in 1740 and published in 1740 in La Jeune Am\u00e9ricaine et les contes marins. It was abridged, rewritten, and published first by Jeanne-Marie Leprin de Beaumont in 1756 in Magasin des enfants (\"Children's Collection\") and by Andrew Lang in the Blue Fairy Book of his Fairy Book series in 1889, to produce the version(s) most commonly retold. [Variants of the story are known across Europe.]\n\nExplanation:\nThe last sentence in the model prediction is irrelevant as it does not provide a direct answer to the question nor is it crucial auxiliary information. It is not found in the reference response and does not contribute to the understanding of when the original story of Beauty and the Beast was written. Therefore, it should be marked as \"Irrelevant\"."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The original story of Beauty and the Beast was written by Gabrielle-Suzanne Barbot de Villeneuve in 1740 and published in 1740 in La Jeune Am\u00e9ricaine et les contes marins.\nS2. It was abridged, rewritten, and published first by Jeanne-Marie Leprin de Beaumont in 1756 in Magasin des enfants (\"Children's Collection\") and by Andrew Lang in the Blue Fairy Book of his Fairy Book series in 1889, to produce the version(s) most commonly retold.\nS3. Variants of the story are known across Europe.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation:\nAll the facts in the model prediction are consistent with the provided passages and verifiable. Therefore, there are no spans that contain inconsistent or unverifiable facts."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "None\n\nExplanation:\nThe model prediction contains all the necessary information to answer the question. It correctly states that the original story of Beauty and the Beast was written by Gabrielle-Suzanne Barbot de Villeneuve and published in 1740, and that it was later abridged and rewritten by Jeanne-Marie Leprince de Beaumont in 1756. Therefore, there is no missing information."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The original story of Beauty and the Beast was written by Gabrielle-Suzanne Barbot de Villeneuve in 1740 and published in 1740 in La Jeune Am\u00e9ricaine et les contes marins. It was abridged, rewritten, and published first by Jeanne-Marie Leprin de Beaumont in 1756 in Magasin des enfants (\"Children's Collection\") and by Andrew Lang in the Blue Fairy Book of his Fairy Book series in 1889, to produce the version(s) most commonly retold."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 127, "end": 171}, {"error type": "Irrelevant", "explanation": "", "start": 286, "end": 387}, {"error type": "Irrelevant", "explanation": "", "start": 436, "end": 482}], "missing-info": [], "corrected-prediction": "The original story of Beauty and the Beast was written by Gabrielle-Suzanne Barbot de Villeneuve in 1740 and published in 1740. It was abridged, rewritten, and published first by Jeanne-Marie Leprin de Beaumont in 1756 in Magasin des enfants  to produce the version(s) most commonly retold. Variants of the story are known across Europe."}}, {"question": "When was the american war of independence fought?", "passages": [["American Revolutionary War", "American Revolutionary War\n\nThe American Revolutionary War (17751783), also known as the American War of Independence, was an 18th-century war between Great Britain and its Thirteen Colonies (allied with France) which declared independence as the United States of America.", "After 1765, growing philosophical and political differences strained the relationship between Great Britain and its colonies.", "Patriot protests against taxation without representation followed the Stamp Act and escalated into boycotts, which culminated in 1773 with the Sons of Liberty destroying a shipment of tea in Boston Harbor.", "Britain responded by closing Boston Harbor and passing a series of punitive measures against Massachusetts Bay Colony.", "Massachusetts colonists responded with the Suffolk Resolves, and they established a shadow government which wrested control of the countryside from the Crown.", "Twelve colonies formed a Continental Congress to coordinate their resistance, establishing committees and conventions that effectively seized power.", "British attempts to disarm the Massachusetts militia in Concord led to open combat on April 19, 1775.", "Militia forces then besieged Boston, forcing a British evacuation in March 1776, and Congress appointed George Washington to command the Continental Army.", "Concurrently, the Americans failed decisively in an attempt to invade Quebec and raise insurrection against the British.", "On July 2, 1776, the Second Continental Congress voted for independence, issuing its declaration on July\u00a04.", "Sir William Howe launched a British counter-offensive, capturing New York City and leaving American morale at a low ebb."], ["American Revolutionary War", "In early 1782, Parliament voted to end all offensive operations in North America, but the war continued in Europe, India and the Caribbean.", "In the latter the British scored a major victory over the French navy, and then later defeated Spanish and French attempts to seize Gibraltar.", "On September 3, 1783, the belligerent parties signed the Treaty of Paris in which Great Britain agreed to recognize the sovereignty of the United States and formally end the war.", "French involvement had proven decisive, but France made few gains and incurred crippling debts.", "Spain made some territorial gains but failed in its primary aim of recovering Gibraltar.", "The Dutch were defeated on all counts and were compelled to cede territory to Great Britain.", "In India, the war against Mysore and its allies concluded in 1784 without any territorial changes.", "Parliament passed the Stamp Act in 1765.", "Colonists condemned the tax because their rights as Englishmen protected them from being taxed by a Parliament in which they had no elected representatives.", "Parliament argued that the colonies were \"represented virtually\", an idea that was criticized throughout the Empire.", "Parliament did repeal the act in 1766; however, it also affirmed its right to pass laws that were binding on the colonies.", "From 1767, Parliament began passing legislation to raise revenue for the salaries of civil officials, ensuring their loyalty while inadvertently increasing resentment among the colonists, and opposition soon became widespread.", "Enforcing the acts proved difficult."]], "gold": "The American war of independence began April 19, 1775 and ended on September 3, 1783.", "prediction 1": "The American Revolutionary War was fought between Great Britain and its Thirteen Colonies (allied with France) on July 2, 1776, and July 4, 1783. The war was fought over the issue of independence from Great Britain on July 2, 1776 and the issue of independence on July 4, 1783. The war continued over the rest of the 18th century, with major victories recorded in Europe, India, and the Caribbean. On September 3, 1783, the belligerent parties signed the Treaty of Paris in which Great Britain agreed to recognize the sovereignty of the United States of America and formally ended the war on September 3, 1783.", "prediction 2": "The American Revolutionary War was an 18th-century war between Great Britain and its Thirteen Colonies (allied with France) which declared independence as the United States of America. It started on April 19, 1775 and lasted until July 4, 1783, when the belligerent parties signed the Treaty of Paris, in which Great Britain agreed to recognize the sovereignty of the United States and formally end the war.", "prediction 3": "The American Revolutionary War was an 18th-century war between Great Britain and its Thirteen Colonies (allied with France) which declared independence as the United States of America. The war started on April 19, 1775 and was completed on July 4, 1783. The American Revolutionary War was also known as the American War of Independence.", "prediction 4": "The American Revolutionary War, also known as the American War of Independence, was an 18th-century war between Great Britain and its Thirteen Colonies (allied with France) which declared independence as the United States of America. The war started on April 19, 1775, which led to open combat on April 19, 1775, and lasted until July 4, 1783, when Parliament voted to end all offensive operations in North America, but the war continued in Europe, India and the Caribbean.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 146, "end": 277}, {"error type": "Irrelevant", "explanation": "", "start": 278, "end": 397}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 1, "sentence_id": [7]}], "corrected-prediction": "The American Revolutionary War, also known as the American War of Independence, was fought between Great Britain and its Thirteen Colonies (allied with France) from April 19, 1775 to September 3, 1783. On September 3, 1783, the belligerent parties signed the Treaty of Paris in which Great Britain agreed to recognize the sovereignty of the United States of America and formally ended the war."}, "preference": [2, 2, 2, 2, 1, 1], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - American Revolutionary War\nS1. American Revolutionary War  The American Revolutionary War (17751783), also known as the American War of Independence, was an 18th-century war between Great Britain and its Thirteen Colonies (allied with France) which declared independence as the United States of America.\nS2. After 1765, growing philosophical and political differences strained the relationship between Great Britain and its colonies.\nS3. Patriot protests against taxation without representation followed the Stamp Act and escalated into boycotts, which culminated in 1773 with the Sons of Liberty destroying a shipment of tea in Boston Harbor.\nS4. Britain responded by closing Boston Harbor and passing a series of punitive measures against Massachusetts Bay Colony.\nS5. Massachusetts colonists responded with the Suffolk Resolves, and they established a shadow government which wrested control of the countryside from the Crown.\nS6. Twelve colonies formed a Continental Congress to coordinate their resistance, establishing committees and conventions that effectively seized power.\nS7. British attempts to disarm the Massachusetts militia in Concord led to open combat on April 19, 1775.\nS8. Militia forces then besieged Boston, forcing a British evacuation in March 1776, and Congress appointed George Washington to command the Continental Army.\nS9. Concurrently, the Americans failed decisively in an attempt to invade Quebec and raise insurrection against the British.\nS10. On July 2, 1776, the Second Continental Congress voted for independence, issuing its declaration on July\u00a04.\nS11. Sir William Howe launched a British counter-offensive, capturing New York City and leaving American morale at a low ebb.\n\nPassage 2: Title (S0) - American Revolutionary War\nS1. In early 1782, Parliament voted to end all offensive operations in North America, but the war continued in Europe, India and the Caribbean.\nS2. In the latter the British scored a major victory over the French navy, and then later defeated Spanish and French attempts to seize Gibraltar.\nS3. On September 3, 1783, the belligerent parties signed the Treaty of Paris in which Great Britain agreed to recognize the sovereignty of the United States and formally end the war.\nS4. French involvement had proven decisive, but France made few gains and incurred crippling debts.\nS5. Spain made some territorial gains but failed in its primary aim of recovering Gibraltar.\nS6. The Dutch were defeated on all counts and were compelled to cede territory to Great Britain.\nS7. In India, the war against Mysore and its allies concluded in 1784 without any territorial changes.\nS8. Parliament passed the Stamp Act in 1765.\nS9. Colonists condemned the tax because their rights as Englishmen protected them from being taxed by a Parliament in which they had no elected representatives.\nS10. Parliament argued that the colonies were \"represented virtually\", an idea that was criticized throughout the Empire.\nS11. Parliament did repeal the act in 1766; however, it also affirmed its right to pass laws that were binding on the colonies.\nS12. From 1767, Parliament began passing legislation to raise revenue for the salaries of civil officials, ensuring their loyalty while inadvertently increasing resentment among the colonists, and opposition soon became widespread.\nS13. Enforcing the acts proved difficult.\n    \nInput Question:\nWhen was the american war of independence fought?\n\nCorrect Response:\nThe American war of independence began April 19, 1775 and ended on September 3, 1783.\n\nModel Prediction:\nThe American Revolutionary War was fought between Great Britain and its Thirteen Colonies (allied with France) on July 2, 1776, and July 4, 1783. The war was fought over the issue of independence from Great Britain on July 2, 1776 and the issue of independence on July 4, 1783. The war continued over the rest of the 18th century, with major victories recorded in Europe, India, and the Caribbean. On September 3, 1783, the belligerent parties signed the Treaty of Paris in which Great Britain agreed to recognize the sovereignty of the United States of America and formally ended the war on September 3, 1783.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "The American Revolutionary War was fought between Great Britain and its Thirteen Colonies (allied with France) on July 2, 1776, and July 4, 1783. [The war was fought over the issue of independence from Great Britain on July 2, 1776 and the issue of independence on July 4, 1783.] [The war continued over the rest of the 18th century, with major victories recorded in Europe, India, and the Caribbean.] On September 3, 1783, the belligerent parties signed the Treaty of Paris in which Great Britain agreed to recognize the sovereignty of the United States of America and formally ended the war on September 3, 1783.\n\nExplanation:\n1. The span \"The war was fought over the issue of independence from Great Britain on July 2, 1776 and the issue of independence on July 4, 1783.\" is irrelevant because it does not provide any new or necessary information about the dates of the war. It is also repetitive because it repeats the dates already mentioned in the previous sentence.\n2. The span \"The war continued over the rest of the 18th century, with major victories recorded in Europe, India, and the Caribbean.\" is irrelevant because it does not directly answer the question about when the American Revolutionary War was fought. It also includes information about other conflicts that are not directly related to the American Revolutionary War."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The American Revolutionary War was fought between Great Britain and its Thirteen Colonies (allied with France) on July 2, 1776, and July 4, 1783.\nS2. The war was fought over the issue of independence from Great Britain on July 2, 1776 and the issue of independence on July 4, 1783.\nS3. The war continued over the rest of the 18th century, with major victories recorded in Europe, India, and the Caribbean.\nS4. On September 3, 1783, the belligerent parties signed the Treaty of Paris in which Great Britain agreed to recognize the sovereignty of the United States of America and formally ended the war on September 3, 1783.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "Inconsistent or Unverifiable Sentences:\n1. S1\n2. S2\n\nExplanation:\n1. The first sentence is factually inconsistent with the passages. According to Passage 1, sentence 7, the war began on April 19, 1775, not July 2, 1776. Also, the war did not end on July 4, 1783, as stated in the sentence. According to Passage 2, sentence 3, the war ended on September 3, 1783.\n2. The second sentence is also factually inconsistent. The dates mentioned (July 2, 1776 and July 4, 1783) do not correspond to the start and end dates of the war."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 7 [Missing Answer]\n2. Passage 2, sentence 3 [Missing Answer]\n\nExplanation:\n1. The model prediction does not mention the correct start date of the war, which is April 19, 1775, as stated in Passage 1, sentence 7. This is a missing answer.\n2. The model prediction also does not mention the correct end date of the war, which is September 3, 1783, as stated in Passage 2, sentence 3. This is another missing answer."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The American Revolutionary War, also known as the American War of Independence, was fought between Great Britain and its Thirteen Colonies (allied with France) from April 19, 1775 to September 3, 1783. On September 3, 1783, the belligerent parties signed the Treaty of Paris in which Great Britain agreed to recognize the sovereignty of the United States of America and formally ended the war."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 0, "end": 110}, {"error type": "Incoherent", "explanation": "", "start": 215, "end": 277}, {"error type": "Irrelevant", "explanation": "", "start": 146, "end": 214}, {"error type": "Irrelevant", "explanation": "", "start": 278, "end": 397}, {"error type": "Redundant", "explanation": "On September 3, 1783, ", "start": 589, "end": 610}, {"error type": "Unverifiable", "explanation": "", "start": 111, "end": 145}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 1, "sentence_id": [7]}], "corrected-prediction": "The war started when British attempts to disarm the Massachusetts militia in Concord led to open combat on April 19, 1775. On September 3, 1783, the belligerent parties signed the Treaty of Paris in which Great Britain agreed to recognize the sovereignty of the United States of America and formally ended the war."}}, {"question": "How much of india's population is muslim?", "passages": [["Religion in India", "Christianity in India has different denominations, like Roman Catholicism, Oriental Orthodox, and Protestantism.", "Most Christians reside in South India, particularly in Kerala, Tamil Nadu and Goa.", "There are also large Christian populations in the North-east Indian states.", "Christianity in India was expanded in the 16th century by Catholic Portuguese expeditions and by Protestant British and US missionaries in the 18th century.", "Though Islam came to India in the early 7th century with the advent of Arab traders in Malabar coast, Kerala, it started to become a major religion during the Muslim rule in the Indian subcontinent.", "Islam's spread in India mostly took place under the Delhi Sultanate (1206\u20131526) and the Mughal Empire (1526\u20131858), greatly aided by the mystic Sufi tradition.", "Islam is the second largest religion in India, with 14.2% of the country's population or roughly 172 million people identifying as adherents of Islam (2011 census).", "There are six religions in India which have been awarded \"National minority\" status\u2014Muslims, Christians, Sikhs, Jains, Buddhists and Zoroastrians."], ["Religion in Asia", "Islam is a monotheistic and Abrahamic religion articulated by the Qur'an, a book considered by its adherents to be the verbatim word of God (Arabic: \u0627\u0644\u0644\u0647 All\u0101h) and by the teachings and normative example (called the Sunnah and composed of hadith) of Muhammad, considered by them to be the last prophet of God.", "South Asia and Southeast Asia are home of the most populous Muslim countries, with Indonesia, Pakistan, India, and Bangladesh having more than 100 million adherents each.", "According to U.S. government figures, in 2006 there were 20 million Muslims in China.", "In the Western Asia, the non-Arab countries of Iran and Turkey are the largest Muslim-majority countries.", "In South Asia, Pakistan and Bangladesh are the countries with the largest Muslim-majority.", "In Central Asia, Afghanistan and Uzbekistan are the countries with the largest Muslim-majority.", "Indonesia is 87 percent Muslim and is the country with the largest Muslim population in the world, Pakistan is 97 percent Muslim, Bangladesh is 90 percent Muslim.", "India's Muslim population is 14.2% of the total, approximately 190 million people.", "Around 6-11 percent, some 6 - 12 million people in the Philippines are Muslim.", "Thailand's Muslims make up 4.6 percent of the population, or approximately 3 million people."], ["Religion in India", "Punjab is the spiritual home of Sikhs, and is the only state in India where Sikhs form a majority.", "There are also significant populations of Sikhs in neighbouring Chandigarh, Delhi and Haryana, which were historically part of Punjab.", "Islam is a monotheistic religion centered on the belief in one God and following the example of Muhammad; It is the largest minority religion in India.", "According to the 2011 census, India is home to 172 million Muslims, the world's third-largest Muslim population after those in Indonesia (210 million) and Pakistan (195 million).", "Muslims compose 14.23% of the Indian population.", "Muslims are a majority in states Jammu and Kashmir and Lakshadweep, and live in high concentrations in Uttar Pradesh, Bihar, West Bengal, Assam, and Kerala.", "There has been no particular census conducted in India with regards to sects, but sources suggest the largest denomination is Sunni Islam with a substantial minority of Shiite Muslims and Ahmadi Muslims.", "Indian sources like Times of India and DNA reported the Indian Shiite population in mid-2005\u20132006 to be between 25% and 31% of entire Muslim population of India, which accounts them in numbers between 40 to 50 million of a total of 172 million Muslims in India.", "Christianity is a monotheistic religion centred on the life and teachings of Jesus as presented in the New Testament."]], "gold": "Islam is the second-largest religion in India. It makes India the country with the largest Muslim population outside Muslim-majority countries. 195 million people in India are Muslim, which is 14.9% of the population.", "prediction 1": "Islam is the second largest religion in India, with 14.2% of the country's population or roughly 172 million people identifying as adherents of Islam. According to the 2011 census, India is home to 172 million Muslims, the world's third-largest Muslim population after those in Indonesia (210 million) and Pakistan (195 million). Muslims compose 14.23% of the Indian population.", "prediction 2": "Islam is the second largest religion in India, with 14.2% of the country's population or roughly 172 million people identifying as adherents of Islam (2011 census). According to the 2011 census, India is home to 172 million Muslims, the world's third-largest Muslim population after those in Indonesia (210 million) and Pakistan (195 million).", "prediction 3": "India is home to 172 million Muslims, the world's third-largest Muslim population after those in Indonesia (210 million) and Pakistan (195 million). According to the 2011 census, Muslims compose 14.23% of the Indian population.", "prediction 4": "In the 2011 census, 172 million people were estimated to be Muslims. In 2012, Muslims accounted for 14.23% of the population, and in 2013 they accounted for 17.1 percent. In 2014, Muslims accounted for 17.1 percent.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 151, "end": 329}], "missing-info": [], "corrected-prediction": "Islam is the second largest religion in India, with 14.2% of the country's population or roughly 172 million people identifying as adherents of Islam. Muslims compose 14.23% of the Indian population."}, "preference": [1, 1, 1, 1, 1, 1], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Religion in India\nS1. Christianity in India has different denominations, like Roman Catholicism, Oriental Orthodox, and Protestantism.\nS2. Most Christians reside in South India, particularly in Kerala, Tamil Nadu and Goa.\nS3. There are also large Christian populations in the North-east Indian states.\nS4. Christianity in India was expanded in the 16th century by Catholic Portuguese expeditions and by Protestant British and US missionaries in the 18th century.\nS5. Though Islam came to India in the early 7th century with the advent of Arab traders in Malabar coast, Kerala, it started to become a major religion during the Muslim rule in the Indian subcontinent.\nS6. Islam's spread in India mostly took place under the Delhi Sultanate (1206\u20131526) and the Mughal Empire (1526\u20131858), greatly aided by the mystic Sufi tradition.\nS7. Islam is the second largest religion in India, with 14.2% of the country's population or roughly 172 million people identifying as adherents of Islam (2011 census).\nS8. There are six religions in India which have been awarded \"National minority\" status\u2014Muslims, Christians, Sikhs, Jains, Buddhists and Zoroastrians.\n\nPassage 2: Title (S0) - Religion in Asia\nS1. Islam is a monotheistic and Abrahamic religion articulated by the Qur'an, a book considered by its adherents to be the verbatim word of God (Arabic: \u0627\u0644\u0644\u0647 All\u0101h) and by the teachings and normative example (called the Sunnah and composed of hadith) of Muhammad, considered by them to be the last prophet of God.\nS2. South Asia and Southeast Asia are home of the most populous Muslim countries, with Indonesia, Pakistan, India, and Bangladesh having more than 100 million adherents each.\nS3. According to U.S. government figures, in 2006 there were 20 million Muslims in China.\nS4. In the Western Asia, the non-Arab countries of Iran and Turkey are the largest Muslim-majority countries.\nS5. In South Asia, Pakistan and Bangladesh are the countries with the largest Muslim-majority.\nS6. In Central Asia, Afghanistan and Uzbekistan are the countries with the largest Muslim-majority.\nS7. Indonesia is 87 percent Muslim and is the country with the largest Muslim population in the world, Pakistan is 97 percent Muslim, Bangladesh is 90 percent Muslim.\nS8. India's Muslim population is 14.2% of the total, approximately 190 million people.\nS9. Around 6-11 percent, some 6 - 12 million people in the Philippines are Muslim.\nS10. Thailand's Muslims make up 4.6 percent of the population, or approximately 3 million people.\n\nPassage 3: Title (S0) - Religion in India\nS1. Punjab is the spiritual home of Sikhs, and is the only state in India where Sikhs form a majority.\nS2. There are also significant populations of Sikhs in neighbouring Chandigarh, Delhi and Haryana, which were historically part of Punjab.\nS3. Islam is a monotheistic religion centered on the belief in one God and following the example of Muhammad; It is the largest minority religion in India.\nS4. According to the 2011 census, India is home to 172 million Muslims, the world's third-largest Muslim population after those in Indonesia (210 million) and Pakistan (195 million).\nS5. Muslims compose 14.23% of the Indian population.\nS6. Muslims are a majority in states Jammu and Kashmir and Lakshadweep, and live in high concentrations in Uttar Pradesh, Bihar, West Bengal, Assam, and Kerala.\nS7. There has been no particular census conducted in India with regards to sects, but sources suggest the largest denomination is Sunni Islam with a substantial minority of Shiite Muslims and Ahmadi Muslims.\nS8. Indian sources like Times of India and DNA reported the Indian Shiite population in mid-2005\u20132006 to be between 25% and 31% of entire Muslim population of India, which accounts them in numbers between 40 to 50 million of a total of 172 million Muslims in India.\nS9. Christianity is a monotheistic religion centred on the life and teachings of Jesus as presented in the New Testament.\n    \nInput Question:\nHow much of india's population is muslim?\n\nCorrect Response:\nIslam is the second-largest religion in India. It makes India the country with the largest Muslim population outside Muslim-majority countries. 195 million people in India are Muslim, which is 14.9% of the population.\n\nModel Prediction:\nIslam is the second largest religion in India, with 14.2% of the country's population or roughly 172 million people identifying as adherents of Islam. According to the 2011 census, India is home to 172 million Muslims, the world's third-largest Muslim population after those in Indonesia (210 million) and Pakistan (195 million). Muslims compose 14.23% of the Indian population.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "Islam is the second largest religion in India, with 14.2% of the country's population or roughly 172 million people identifying as adherents of Islam. [According to the 2011 census, India is home to 172 million Muslims, the world's third-largest Muslim population after those in Indonesia (210 million) and Pakistan (195 million).] Muslims compose 14.23% of the Indian population.\n\nExplanation:\nThe second sentence in the model prediction is repetitive as it repeats the information about the number of Muslims in India and their percentage of the total population, which was already mentioned in the first sentence. Therefore, it should be marked as \"Repetitive\"."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. Islam is the second largest religion in India, with 14.2% of the country's population or roughly 172 million people identifying as adherents of Islam.\nS2. According to the 2011 census, India is home to 172 million Muslims, the world's third-largest Muslim population after those in Indonesia (210 million) and Pakistan (195 million).\nS3. Muslims compose 14.23% of the Indian population.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation:\nAll the facts in the model prediction are consistent with the information provided in the passages."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "None\n\nExplanation:\nThe model prediction includes all the necessary information to answer the question. It correctly states the percentage of India's population that is Muslim and the number of Muslims in India. There is no missing information in the model prediction."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "Islam is the second largest religion in India, with 14.2% of the country's population or roughly 172 million people identifying as adherents of Islam. Muslims compose 14.23% of the Indian population."}], "feedback_human": {"errors": [{"error type": "Redundant", "explanation": " with 14.2% of the country's population ", "start": 330, "end": 378}, {"error type": "Redundant", "explanation": " roughly 172 million people identifying as adherents of Islam", "start": 195, "end": 218}, {"error type": "Irrelevant", "explanation": "", "start": 263, "end": 329}], "missing-info": [], "corrected-prediction": "Islam is the second largest religion in India, with 14.2% of the country's population or roughly 172 million people identifying as adherents of Islam. According to the 2011 census, India is home  the world's third-largest Muslim population."}}, {"question": "Who played the cowbell on don't fear the reaper?", "passages": [["(Don't Fear) The Reaper", "\u2018The legendary once-in-a-lifetime groove!\u2019", "\u2026 What evolved in the studio was the extended solo section; it took them nearly as long to edit the five-minute track down to manageable length as it did to record it.\"", "The song features prominent use of the cowbell percussion instrument, overdubbed on the original recording.", "Bassist Joe Bouchard remembered the producer requesting his brother, drummer Albert Bouchard, play the cowbell: \"Albert thought he was crazy.", "But he put all this tape around a cowbell and played it.", "It really pulled the track together.\"", "However, producer David Lucas says that he played it, a claim supported by bandmember Eric Bloom.", "The song was on the \"Billboard\" Hot 100 chart for 20 weeks, reaching number 12 for the weeks beginning November 6 and November 13 in 1976.", "It was B\u00d6C's highest-charting U.S. song and helped \"Agents of Fortune\" reach number 29 on the \"Billboard\" 200.", "\"(Don't Fear)", "The Reaper\" charted even higher in Canada, peaking at number 7.", "The single edit was released in the UK in July 1976 (CBS 4483) but failed to chart."], ["(Don't Fear) The Reaper", "(Don't Fear)", "The Reaper\n\n\"(Don't Fear)", "The Reaper\" is a song by American rock band Blue \u00d6yster Cult from the band's 1976 album \"Agents of Fortune.\"", "The song, written and sung by lead guitarist Donald \"Buck Dharma\" Roeser, deals with eternal love and the inevitability of death.", "Dharma wrote the song while picturing an early death for himself.", "Released as an edited single (omitting the slow building interlude in the original), the song was Blue \u00d6yster Cult's highest chart success, reaching #7 in \"Cash Box\" and #12 on the \"Billboard\" Hot 100 in late 1976.", "Critical reception was mainly positive, and in 2004, \"(Don't Fear)", "The Reaper\" was listed at number 405 on the \"Rolling Stone\" list of the top 500 songs of all time.", "The song is about the inevitability of death and the foolishness of fearing it, and was written when Dharma was thinking about what would happen if he died at a young age.", "Lyrics such as \"Romeo and Juliet are together in eternity\" have led many listeners to interpret the song to be about a murder-suicide pact, but Dharma says the song is about eternal love, rather than suicide."], ["(Don't Fear) The Reaper", "In 1997 \"Mojo\" listed the song as the 80th best single of all time, while \"Q\" ranked \"(Don't Fear)", "The Reaper\" number 404 in its 2003 countdown of the \"1001 Best Songs Ever.\"", "When \"The Guardian\" released its unranked list of the \"1000 Songs Everyone Must Hear\" in 2009, the song was included.", "The publication wrote that the song's charm \"lies in the disjuncture between its gothic storyline and the sprightly, Byrdsian guitar line that carries it.\"", "In his book \"The Heart of Rock and Soul: The 1001 Greatest Singles Ever Made,\" rock critic Dave Marsh ranked the song at number 997.", "Blue \u00d6yster Cult performed a live version of \"(Don't Fear) The Reaper\" on the band's 1978 album \"Some Enchanted Evening\".", "A live version appears on their 1982 album \"Extraterrestrial Live\".", "Blue \u00d6yster Cult's 1991 live album \"Live 1976\" features \"(Don't Fear)", "The Reaper\".", "A live version appears on their 2002 album \"A Long Day's Night\".", "Buck Dharma released an acoustic version of the song on the 1994 various artists compilation album \"Guitar Practicing Musicians 3\".", "Gus Black covered the song in 1996 for the \"Scream\" soundtrack."]], "gold": "There is some dispute among members of American rock band Blue \u00d6yster Cult as to who played the cowbell overdubbed on their original recording of the 1976 song \"(Don't Fear) The Reaper\". Bassist Joe Bouchard remembered his brother, drummer Albert Bouchard playing the instrument, while produced David Lucas and guitarist Eric Bloom remember Lucas doing it instead.", "prediction 1": "(Don't Fear) The Reaper is a song by American rock band Blue yster Cult from the band's 1976 album Agents of Fortune. The song features prominent use of the cowbell percussion instrument, overdubbed on the original recording. Producer David Lucas says he played it, a claim supported by bandmember Eric Bloom.", "prediction 2": "Blue yster Cult's song \"(Don't Fear) The Reaper\" features prominent use of the cowbell percussion instrument, overdubbed on the original recording. Producer David Lucas says that he played the cowbell, a claim supported by bandmember Eric Bloom. Blue yster Cult performed a live version of \"(Don't Fear) The Reaper\" on their 1978 album \"Some Enchanted Evening\". A live version appears on their 1982 album \"Extraterrestrial Live.\"", "prediction 3": "The 1976 song (Don't Fear) The Reaper features prominent use of the cowbell percussion instrument, overdubbed on the original recording. Bassist Joe Bouchard remembered the producer requesting his brother, drummer Albert Bouchard, play the cowbell. However, producer David Lucas says that he played it, a claim supported by bandmember Eric Bloom. Blue yster Cult performed a live version of ((Don't Fear) The Reaper) on their 1978 album Some Enchanted Evening.", "prediction 4": "(Don't Fear) The Reaper is a song by American rock band Blue yster Cult from the band's 1976 album Agents of Fortune. The song features prominent use of the cowbell percussion instrument, overdubbed on the original recording. Producer David Lucas says that he played the cowbell, a claim supported by bandmember Eric Bloom.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 0, "end": 117}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [4]}], "corrected-prediction": "The song \"(Don't Fear) The Reaper\" by American rock band Blue \u00d6yster Cult features prominent use of the cowbell percussion instrument, overdubbed on the original recording. There is some dispute about who played it. Producer David Lucas says he played it, a claim supported by bandmember Eric Bloom. However, bassist Joe Bouchard remembered his brother, drummer Albert Bouchard, playing the cowbell."}, "preference": [1, 1, 0, 1, 2, 2], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - (Don't Fear) The Reaper\nS1. \u2018The legendary once-in-a-lifetime groove!\u2019\nS2. \u2026 What evolved in the studio was the extended solo section; it took them nearly as long to edit the five-minute track down to manageable length as it did to record it.\"\nS3. The song features prominent use of the cowbell percussion instrument, overdubbed on the original recording.\nS4. Bassist Joe Bouchard remembered the producer requesting his brother, drummer Albert Bouchard, play the cowbell: \"Albert thought he was crazy.\nS5. But he put all this tape around a cowbell and played it.\nS6. It really pulled the track together.\"\nS7. However, producer David Lucas says that he played it, a claim supported by bandmember Eric Bloom.\nS8. The song was on the \"Billboard\" Hot 100 chart for 20 weeks, reaching number 12 for the weeks beginning November 6 and November 13 in 1976.\nS9. It was B\u00d6C's highest-charting U.S. song and helped \"Agents of Fortune\" reach number 29 on the \"Billboard\" 200.\nS10. \"(Don't Fear)\nS11. The Reaper\" charted even higher in Canada, peaking at number 7.\nS12. The single edit was released in the UK in July 1976 (CBS 4483) but failed to chart.\n\nPassage 2: Title (S0) - (Don't Fear) The Reaper\nS1. (Don't Fear)\nS2. The Reaper  \"(Don't Fear)\nS3. The Reaper\" is a song by American rock band Blue \u00d6yster Cult from the band's 1976 album \"Agents of Fortune.\"\nS4. The song, written and sung by lead guitarist Donald \"Buck Dharma\" Roeser, deals with eternal love and the inevitability of death.\nS5. Dharma wrote the song while picturing an early death for himself.\nS6. Released as an edited single (omitting the slow building interlude in the original), the song was Blue \u00d6yster Cult's highest chart success, reaching #7 in \"Cash Box\" and #12 on the \"Billboard\" Hot 100 in late 1976.\nS7. Critical reception was mainly positive, and in 2004, \"(Don't Fear)\nS8. The Reaper\" was listed at number 405 on the \"Rolling Stone\" list of the top 500 songs of all time.\nS9. The song is about the inevitability of death and the foolishness of fearing it, and was written when Dharma was thinking about what would happen if he died at a young age.\nS10. Lyrics such as \"Romeo and Juliet are together in eternity\" have led many listeners to interpret the song to be about a murder-suicide pact, but Dharma says the song is about eternal love, rather than suicide.\n\nPassage 3: Title (S0) - (Don't Fear) The Reaper\nS1. In 1997 \"Mojo\" listed the song as the 80th best single of all time, while \"Q\" ranked \"(Don't Fear)\nS2. The Reaper\" number 404 in its 2003 countdown of the \"1001 Best Songs Ever.\"\nS3. When \"The Guardian\" released its unranked list of the \"1000 Songs Everyone Must Hear\" in 2009, the song was included.\nS4. The publication wrote that the song's charm \"lies in the disjuncture between its gothic storyline and the sprightly, Byrdsian guitar line that carries it.\"\nS5. In his book \"The Heart of Rock and Soul: The 1001 Greatest Singles Ever Made,\" rock critic Dave Marsh ranked the song at number 997.\nS6. Blue \u00d6yster Cult performed a live version of \"(Don't Fear) The Reaper\" on the band's 1978 album \"Some Enchanted Evening\".\nS7. A live version appears on their 1982 album \"Extraterrestrial Live\".\nS8. Blue \u00d6yster Cult's 1991 live album \"Live 1976\" features \"(Don't Fear)\nS9. The Reaper\".\nS10. A live version appears on their 2002 album \"A Long Day's Night\".\nS11. Buck Dharma released an acoustic version of the song on the 1994 various artists compilation album \"Guitar Practicing Musicians 3\".\nS12. Gus Black covered the song in 1996 for the \"Scream\" soundtrack.\n    \nInput Question:\nWho played the cowbell on don't fear the reaper?\n\nCorrect Response:\nThere is some dispute among members of American rock band Blue \u00d6yster Cult as to who played the cowbell overdubbed on their original recording of the 1976 song \"(Don't Fear) The Reaper\". Bassist Joe Bouchard remembered his brother, drummer Albert Bouchard playing the instrument, while produced David Lucas and guitarist Eric Bloom remember Lucas doing it instead.\n\nModel Prediction:\n(Don't Fear) The Reaper is a song by American rock band Blue yster Cult from the band's 1976 album Agents of Fortune. The song features prominent use of the cowbell percussion instrument, overdubbed on the original recording. Producer David Lucas says he played it, a claim supported by bandmember Eric Bloom.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "[(Don't Fear) The Reaper is a song by American rock band Blue yster Cult from the band's 1976 album Agents of Fortune.] The song features prominent use of the cowbell percussion instrument, overdubbed on the original recording. Producer David Lucas says he played it, a claim supported by bandmember Eric Bloom.\n\nExplanation:\n1. The first sentence in the model prediction is irrelevant as it does not directly answer the question nor provide crucial auxiliary information. The question is about who played the cowbell in the song, not about the song's general information."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. (Don't Fear) The Reaper is a song by American rock band Blue yster Cult from the band's 1976 album Agents of Fortune.\nS2. The song features prominent use of the cowbell percussion instrument, overdubbed on the original recording.\nS3. Producer David Lucas says he played it, a claim supported by bandmember Eric Bloom.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation:\nAll the facts in the model prediction are consistent with the provided passages and can be verified."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 4 [Missing Major Auxiliary Information]\n\nExplanation:\n1. The model prediction fails to mention that there is a dispute about who played the cowbell. Bassist Joe Bouchard remembered his brother, drummer Albert Bouchard, playing the cowbell, which is a crucial piece of information for understanding the full context of the answer."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The song \"(Don't Fear) The Reaper\" by American rock band Blue \u00d6yster Cult features prominent use of the cowbell percussion instrument, overdubbed on the original recording. There is some dispute about who played it. Producer David Lucas says he played it, a claim supported by bandmember Eric Bloom. However, bassist Joe Bouchard remembered his brother, drummer Albert Bouchard, playing the cowbell."}], "feedback_human": {"errors": [], "missing-info": [{"error type": "Missing-Answer", "passage_id": 1, "sentence_id": [4]}], "corrected-prediction": "(Don't Fear) The Reaper is a song by American rock band Blue \u00d6yster Cult from the band's 1976 album Agents of Fortune. The song features prominent use of the cowbell percussion instrument, overdubbed on the original recording. Producer David Lucas says he played it, a claim supported by bandmember Eric Bloom. Bassist Joe Bouchard remembered the producer requesting his brother, drummer Albert Bouchard, play the cowbell. "}}, {"question": "Who had a hit with love is in the air?", "passages": [["Love Is in the Air (song)", "Love Is in the Air (song)\n\n", "\"Love Is in the Air\" is a 1977 disco song sung by John Paul Young.", "The song was written by George Young and Harry Vanda and it became a worldwide hit in 1978, peaking at No. 3 on the Australian charts and No. 5 in the UK Singles Chart.", "In the United States, the song peaked at No. 7 on the pop chart and spent two weeks at No. 1 on the adult contemporary chart, his only US top 40 hit.", "The song was released as the lead single from Young's fourth studio album, \"Love Is in the Air\" (1978).", "A Spanish version has been recorded under the name, \"El Amor Est\u00e1 En El Aire\".", "In 2017, the song was selected for preservation in the National Film and Sound Archive's Sounds of Australia collection.", "John Paul Young said of the recording, \"We actually did 'Love Is in the Air' because we needed something for the German market.", "'Standing in the Rain' became a hit in the clubs over there and then on the charts, so we needed a follow-up.", "I'd been to Germany and heard the music.", "It was electronic mania, all clicks and electronic buzzes.", "So George and Harry gave it the treatment.\""], ["Thomas Anders", "Thomas Anders\n\nBernd Weidung (born 1 March 1963 in Koblenz, Rhineland-Palatinate), better known by his stage name Thomas Anders, is a German singer, best known as the lead singer of German duo Modern Talking.", "Starting his singing career while still in school, Anders unsuccessfully attempted to establish himself as a schlager artist for several years.", "After forming the Eurodisco duo Modern Talking with Dieter Bohlen in 1984, they became a worldwide sensation with their hit \"You're My Heart, You're My Soul\".", "They followed up with a string of other worldwide hits, namely \"You Can Win If You Want\", \"Cheri, Cheri Lady\", \"Brother Louie\", \"Atlantis Is Calling (S.O.S. for Love)\", \"Geronimo's Cadillac\", and \"Jet Airliner\", before dissolving in 1987."]], "gold": "There are several song by the title \"Love Is in the Air\". \"Love Is in the Air\" is a 1977 disco song by Australian singer John Paul Young. Tom Jones had a hit with \"Love Is in the Air\" in 1979. Bernd Weidung, known by his stage name Thomas Anders, who is a German singer, songwriter and record producer, had a hit with \"Love Is in the Air\" in 2016.", "prediction 1": "\"Love Is in the Air\" is a 1977 disco song sung by John Paul Young. The song was written by George Young and Harry Vanda and it became a worldwide hit in 1978, peaking at No. 3 on the Australian charts and No. 5 in the UK Singles Chart. In the United States, the song peaked at No. 7 on the pop chart and spent two weeks at No. 1 on the adult contemporary chart, his only US top 40 hit. There is also a Spanish version that was recorded under the name El Amor Est\u00e1 En El Aire.", "prediction 2": "Love Is in the Air is a 1977 disco song sung by John Paul Young. The song was written by George Young and Harry Vanda and became a worldwide hit in 1978, peaking at No. 3 on the Australian charts and No. 5 in the UK Singles Chart.", "prediction 3": "The 1977 disco song Love Is in the Air was sung by John Paul Young. The song was written by George Young and Harry Vanda and it became a worldwide hit in 1978, peaking at No. 3 on the Australian charts and No. 5 in the UK Singles Chart. A Spanish version of the song was released under the name El Amor Est\u00e1 En El Aire. Anders, better known by his stage name Thomas Anders, is the lead singer of German duo Modern Talking.", "prediction 4": "Love Is in the Air is a 1977 disco song sung by John Paul Young. The song was written by George Young and Harry Vanda and it became a worldwide hit in 1978, peaking at No. 3 on the Australian charts and No. 5 in the UK Singles Chart. In the United States, the song peaked at No. 7 on the pop chart and spent two weeks at No. 1 on the adult contemporary chart, his only US top 40 hit. In 2017, the song was selected for preservation in the National Film and Sound Archive's Sounds of Australia collection.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 386, "end": 475}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 2, "sentence_id": [1]}], "corrected-prediction": "\"Love Is in the Air\" is a 1977 disco song sung by John Paul Young. The song was written by George Young and Harry Vanda and it became a worldwide hit in 1978, peaking at No. 3 on the Australian charts and No. 5 in the UK Singles Chart. In the United States, the song peaked at No. 7 on the pop chart and spent two weeks at No. 1 on the adult contemporary chart, his only US top 40 hit. Thomas Anders, a German singer, also had a hit with \"Love Is in the Air\"."}, "preference": [1, 1, 0, 2, 2, 2], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Love Is in the Air (song)\nS1. Love Is in the Air (song)  \nS2. \"Love Is in the Air\" is a 1977 disco song sung by John Paul Young.\nS3. The song was written by George Young and Harry Vanda and it became a worldwide hit in 1978, peaking at No. 3 on the Australian charts and No. 5 in the UK Singles Chart.\nS4. In the United States, the song peaked at No. 7 on the pop chart and spent two weeks at No. 1 on the adult contemporary chart, his only US top 40 hit.\nS5. The song was released as the lead single from Young's fourth studio album, \"Love Is in the Air\" (1978).\nS6. A Spanish version has been recorded under the name, \"El Amor Est\u00e1 En El Aire\".\nS7. In 2017, the song was selected for preservation in the National Film and Sound Archive's Sounds of Australia collection.\nS8. John Paul Young said of the recording, \"We actually did 'Love Is in the Air' because we needed something for the German market.\nS9. 'Standing in the Rain' became a hit in the clubs over there and then on the charts, so we needed a follow-up.\nS10. I'd been to Germany and heard the music.\nS11. It was electronic mania, all clicks and electronic buzzes.\nS12. So George and Harry gave it the treatment.\"\n\nPassage 2: Title (S0) - Thomas Anders\nS1. Thomas Anders  Bernd Weidung (born 1 March 1963 in Koblenz, Rhineland-Palatinate), better known by his stage name Thomas Anders, is a German singer, best known as the lead singer of German duo Modern Talking.\nS2. Starting his singing career while still in school, Anders unsuccessfully attempted to establish himself as a schlager artist for several years.\nS3. After forming the Eurodisco duo Modern Talking with Dieter Bohlen in 1984, they became a worldwide sensation with their hit \"You're My Heart, You're My Soul\".\nS4. They followed up with a string of other worldwide hits, namely \"You Can Win If You Want\", \"Cheri, Cheri Lady\", \"Brother Louie\", \"Atlantis Is Calling (S.O.S. for Love)\", \"Geronimo's Cadillac\", and \"Jet Airliner\", before dissolving in 1987.\n    \nInput Question:\nWho had a hit with love is in the air?\n\nCorrect Response:\nThere are several song by the title \"Love Is in the Air\". \"Love Is in the Air\" is a 1977 disco song by Australian singer John Paul Young. Tom Jones had a hit with \"Love Is in the Air\" in 1979. Bernd Weidung, known by his stage name Thomas Anders, who is a German singer, songwriter and record producer, had a hit with \"Love Is in the Air\" in 2016.\n\nModel Prediction:\n\"Love Is in the Air\" is a 1977 disco song sung by John Paul Young. The song was written by George Young and Harry Vanda and it became a worldwide hit in 1978, peaking at No. 3 on the Australian charts and No. 5 in the UK Singles Chart. In the United States, the song peaked at No. 7 on the pop chart and spent two weeks at No. 1 on the adult contemporary chart, his only US top 40 hit. There is also a Spanish version that was recorded under the name El Amor Est\u00e1 En El Aire.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "\"Love Is in the Air\" is a 1977 disco song sung by John Paul Young. The song was written by George Young and Harry Vanda and it became a worldwide hit in 1978, peaking at No. 3 on the Australian charts and No. 5 in the UK Singles Chart. In the United States, the song peaked at No. 7 on the pop chart and spent two weeks at No. 1 on the adult contemporary chart, his only US top 40 hit. [There is also a Spanish version that was recorded under the name El Amor Est\u00e1 En El Aire.]\n\nExplanation:\nThe last sentence about the Spanish version of the song is irrelevant to the question about who had a hit with the song \"Love Is in the Air\". It does not provide any information about the artists who had a hit with the song. Therefore, it is marked as [Irrelevant]."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. \"Love Is in the Air\" is a 1977 disco song sung by John Paul Young.\nS2. The song was written by George Young and Harry Vanda and it became a worldwide hit in 1978, peaking at No.\nS3. 3 on the Australian charts and No.\nS4. 5 in the UK Singles Chart.\nS5. In the United States, the song peaked at No.\nS6. 7 on the pop chart and spent two weeks at No.\nS7. 1 on the adult contemporary chart, his only US top 40 hit.\nS8. There is also a Spanish version that was recorded under the name El Amor Est\u00e1 En El Aire.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation:\nAll the facts presented in the model prediction are consistent with the information provided in the passages. Therefore, there are no spans that contain inconsistent or unverifiable facts."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 2, sentence 1 [Missing Answer]\n\nExplanation:\n1. The model prediction does not mention that Thomas Anders also had a hit with \"Love Is in the Air\", which is a missing answer from Passage 2, sentence 1."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "\"Love Is in the Air\" is a 1977 disco song sung by John Paul Young. The song was written by George Young and Harry Vanda and it became a worldwide hit in 1978, peaking at No. 3 on the Australian charts and No. 5 in the UK Singles Chart. In the United States, the song peaked at No. 7 on the pop chart and spent two weeks at No. 1 on the adult contemporary chart, his only US top 40 hit. Thomas Anders, a German singer, also had a hit with \"Love Is in the Air\"."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 67, "end": 235}, {"error type": "Irrelevant", "explanation": "", "start": 236, "end": 385}, {"error type": "Irrelevant", "explanation": "", "start": 386, "end": 475}], "missing-info": [], "corrected-prediction": "\"Love Is in the Air\" is a 1977 disco song sung by John Paul Young. "}}, {"question": "How many countries are members of security council?", "passages": [["United Nations Security Council", "United Nations Security Council\n\nThe United Nations Security Council (UNSC) is one of the six principal organs of the United Nations (UN), charged with the maintenance of international peace and security as well as accepting new members to the United Nations and approving any changes to its United Nations Charter.", "Its powers include the establishment of peacekeeping operations, the establishment of international sanctions, and the authorization of military action through Security Council resolutions; it is the only UN body with the authority to issue binding resolutions to member states.", "The Security Council held its first session on 17 January 1946.", "Like the UN as a whole, the Security Council was created following World War II to address the failings of a previous international organization, the League of Nations, in maintaining world peace.", "In its early decades, the Security Council was largely paralyzed by the Cold War division between the US and USSR and their respective allies, though it authorized interventions in the Korean War and the Congo Crisis and peacekeeping missions in the Suez Crisis, Cyprus, and West New Guinea.", "With the collapse of the Soviet Union, UN peacekeeping efforts increased dramatically in scale, and the Security Council authorized major military and peacekeeping missions in Kuwait, Namibia, Cambodia, Bosnia, Rwanda, Somalia, Sudan, and the Democratic Republic of Congo.", "The Security Council consists of fifteen members."], ["Permanent members of the United Nations Security Council", "Permanent members of the United Nations Security Council\n\nThe permanent members of the United Nations Security Council (also known as the Permanent Five, Big Five, or P5) are the five states which the UN Charter of 1945 grants a permanent seat on the UN Security Council: China (formerly the Republic of China), France, Russia (formerly the Soviet Union), the United Kingdom, and the United States.", "These countries were all allies in World War II, which they won.", "They are also all nuclear weapons states.", "A total of 15 UN member states serve on the UNSC, the remainder of which are elected.", "Any one of the five permanent members have the power of veto, which enables them to prevent the adoption of any \"substantive\" draft Council resolution, regardless of its level of international support.", "At the UN's founding in 1945, the five permanent members of the Security Council were the French Republic, the Republic of China, the Soviet Union, the United Kingdom, and the United States.", "There have been two seat changes since then, although not reflected in of the United Nations Charter as it has not been accordingly amended:\n\n\nAdditionally, France reformed its provisional government into the French Fourth Republic in 1946 and later into the French Fifth Republic in 1958, both under the leadership of Charles de Gaulle."], ["United Nations Security Council", "The great powers that were the victors of World War II\u2014the Soviet Union (now represented by the Russian Federation), the United Kingdom, France, the Republic of China (now represented by the People's Republic of China), and the United States\u2014serve as the body's five permanent members.", "These permanent members can veto any substantive Security Council resolution, including those on the admission of new member states or candidates for Secretary-General.", "The Security Council also has 10 non-permanent members, elected on a regional basis to serve two-year terms.", "The body's presidency rotates monthly among its members.", "Security Council resolutions are typically enforced by UN peacekeepers, military forces voluntarily provided by member states and funded independently of the main UN budget.", ", 103,510 peacekeepers and 16,471 civilians were deployed on sixteen peacekeeping operations and one special political mission.", "In the century prior to the UN's creation, several international treaty organizations and conferences had been formed to regulate conflicts between nations, such as the International Committee of the Red Cross and the Hague Conventions of 1899 and 1907.", "Following the catastrophic loss of life in World War I, the Paris Peace Conference established the League of Nations to maintain harmony between the nations."]], "gold": "The United Nations Security Council (UNSC) is one of the six principal organs of the United Nations (UN), charged with ensuring international peace and security recommending the admission of new UN members to the General Assembly, and approving any changes to the UN Charter. After 1966, permanent membership on the Council is held by 5 countries, and non-permanent membership by 10 countries. Prior to 1966, there were six elected members, while the permanent members have in essence not changed since the creation of the United Nations in 1945, apart from the representation of China.", "prediction 1": "The United Nations Security Council consists of 15 members, including 10 non-permanent members and 10 members elected by the Security Council's President. China is one of the five permanent members of the Security Council, while the Soviet Union is also a permanent member.", "prediction 2": "The Security Council of the United Nations is composed of 15 states. There are five permanent members, the other permanent members are China, the Republic of China, the Soviet Union, and the United Kingdom. The Security Council consists of 10 non-permanent members, elected on a regional basis to serve two-year terms, and 10 non-permanent members are members who are appointed by the President.", "prediction 3": "The United Nations Security Council is one of the six principal organs of the United Nations, charged with the maintenance of international peace and security as well as accepting new members to the United Nations and approving any changes to its United Nations Charter. The Security Council consists of 15 members, of which 5 are permanent members.", "prediction 4": "The United Nations Security Council is one of the six principal organs of the United Nations, charged with the maintenance of international peace and security as well as accepting new members to the United Nations and approving any changes to its United Nations Charter. The Security Council consists of 15 members, of which 15 are permanent and the remaining 4 are elected.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 70, "end": 153}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 1, "sentence_id": [7]}], "corrected-prediction": "The United Nations Security Council consists of 15 members, including 5 permanent members and 10 non-permanent members. China is one of the five permanent members of the Security Council, while Russia, formerly the Soviet Union, is also a permanent member."}, "preference": [2, 2, 2, 1, 1, 1], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - United Nations Security Council\nS1. United Nations Security Council  The United Nations Security Council (UNSC) is one of the six principal organs of the United Nations (UN), charged with the maintenance of international peace and security as well as accepting new members to the United Nations and approving any changes to its United Nations Charter.\nS2. Its powers include the establishment of peacekeeping operations, the establishment of international sanctions, and the authorization of military action through Security Council resolutions; it is the only UN body with the authority to issue binding resolutions to member states.\nS3. The Security Council held its first session on 17 January 1946.\nS4. Like the UN as a whole, the Security Council was created following World War II to address the failings of a previous international organization, the League of Nations, in maintaining world peace.\nS5. In its early decades, the Security Council was largely paralyzed by the Cold War division between the US and USSR and their respective allies, though it authorized interventions in the Korean War and the Congo Crisis and peacekeeping missions in the Suez Crisis, Cyprus, and West New Guinea.\nS6. With the collapse of the Soviet Union, UN peacekeeping efforts increased dramatically in scale, and the Security Council authorized major military and peacekeeping missions in Kuwait, Namibia, Cambodia, Bosnia, Rwanda, Somalia, Sudan, and the Democratic Republic of Congo.\nS7. The Security Council consists of fifteen members.\n\nPassage 2: Title (S0) - Permanent members of the United Nations Security Council\nS1. Permanent members of the United Nations Security Council  The permanent members of the United Nations Security Council (also known as the Permanent Five, Big Five, or P5) are the five states which the UN Charter of 1945 grants a permanent seat on the UN Security Council: China (formerly the Republic of China), France, Russia (formerly the Soviet Union), the United Kingdom, and the United States.\nS2. These countries were all allies in World War II, which they won.\nS3. They are also all nuclear weapons states.\nS4. A total of 15 UN member states serve on the UNSC, the remainder of which are elected.\nS5. Any one of the five permanent members have the power of veto, which enables them to prevent the adoption of any \"substantive\" draft Council resolution, regardless of its level of international support.\nS6. At the UN's founding in 1945, the five permanent members of the Security Council were the French Republic, the Republic of China, the Soviet Union, the United Kingdom, and the United States.\nS7. There have been two seat changes since then, although not reflected in of the United Nations Charter as it has not been accordingly amended:   Additionally, France reformed its provisional government into the French Fourth Republic in 1946 and later into the French Fifth Republic in 1958, both under the leadership of Charles de Gaulle.\n\nPassage 3: Title (S0) - United Nations Security Council\nS1. The great powers that were the victors of World War II\u2014the Soviet Union (now represented by the Russian Federation), the United Kingdom, France, the Republic of China (now represented by the People's Republic of China), and the United States\u2014serve as the body's five permanent members.\nS2. These permanent members can veto any substantive Security Council resolution, including those on the admission of new member states or candidates for Secretary-General.\nS3. The Security Council also has 10 non-permanent members, elected on a regional basis to serve two-year terms.\nS4. The body's presidency rotates monthly among its members.\nS5. Security Council resolutions are typically enforced by UN peacekeepers, military forces voluntarily provided by member states and funded independently of the main UN budget.\nS6. , 103,510 peacekeepers and 16,471 civilians were deployed on sixteen peacekeeping operations and one special political mission.\nS7. In the century prior to the UN's creation, several international treaty organizations and conferences had been formed to regulate conflicts between nations, such as the International Committee of the Red Cross and the Hague Conventions of 1899 and 1907.\nS8. Following the catastrophic loss of life in World War I, the Paris Peace Conference established the League of Nations to maintain harmony between the nations.\n    \nInput Question:\nHow many countries are members of security council?\n\nCorrect Response:\nThe United Nations Security Council (UNSC) is one of the six principal organs of the United Nations (UN), charged with ensuring international peace and security recommending the admission of new UN members to the General Assembly, and approving any changes to the UN Charter. After 1966, permanent membership on the Council is held by 5 countries, and non-permanent membership by 10 countries. Prior to 1966, there were six elected members, while the permanent members have in essence not changed since the creation of the United Nations in 1945, apart from the representation of China.\n\nModel Prediction:\nThe United Nations Security Council consists of 15 members, including 10 non-permanent members and 10 members elected by the Security Council's President. China is one of the five permanent members of the Security Council, while the Soviet Union is also a permanent member.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "The United Nations Security Council consists of 15 members, including [10 non-permanent members and 10 members elected by the Security Council's President]. China is one of the five permanent members of the Security Council, while the Soviet Union is also a permanent member.\n\nExplanation:\n1. The phrase \"10 non-permanent members and 10 members elected by the Security Council's President\" is incorrect and incoherent. The Security Council consists of 15 members, 5 of which are permanent and 10 are non-permanent. The President of the Security Council does not elect members."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The United Nations Security Council consists of 15 members, including 10 non-permanent members and 10 members elected by the Security Council's President.\nS2. China is one of the five permanent members of the Security Council, while the Soviet Union is also a permanent member.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "Inconsistent or Unverifiable Sentences:\n1. S1\n2. S2\n\nExplanation:\n1. Sentence 1 is factually inconsistent with the passages. The Security Council consists of 15 members, 5 of which are permanent and 10 are non-permanent. The President of the Security Council does not elect members (Passage 1, S7 and Passage 3, S3).\n2. Sentence 2 is factually inconsistent with the passages. The Soviet Union is no longer a member of the Security Council; it is now represented by the Russian Federation (Passage 2, S1 and Passage 3, S1)."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 7 [Missing Answer]\n2. Passage 3, sentence 3 [Missing Answer]\n\nExplanation:\n1. The model prediction does not mention the total number of members in the Security Council, which is 15 (Passage 1, sentence 7).\n2. The model prediction also fails to mention that there are 10 non-permanent members in the Security Council (Passage 3, sentence 3)."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The United Nations Security Council consists of 15 members, including 5 permanent members and 10 non-permanent members. China is one of the five permanent members of the Security Council, while Russia, formerly the Soviet Union, is also a permanent member."}], "feedback_human": {"errors": [{"error type": "Wrong-Grounding", "explanation": "{\"passage_id\":2,\"sentence_id\":[1,4]}", "start": 99, "end": 154}, {"error type": "Irrelevant", "explanation": "", "start": 155, "end": 273}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [1]}], "corrected-prediction": "The United Nations Security Council (UNSC) is one of the six principal organs of the United Nations (UN), charged with the maintenance of international peace and security as well as accepting new members to the United Nations and approving any changes to its United Nations Charter. The United Nations Security Council consists of 15 members, including 10 non-permanent members and 5 permanent members."}}, {"question": "Who wrote the score for 2001 a space odyssey?", "passages": [["2001: A Space Odyssey (score)", "2001:", "A Space Odyssey (score)\n\nThe \"2001: A Space Odyssey\" score is an unused film score composed by Alex North for Stanley Kubrick's 1968 film, \".\"", "In the early stages of production, Kubrick had commissioned noted Hollywood composer Alex North, who had written the score for \"Spartacus\" and also worked on \"Dr. Strangelove\", to write the score of his upcoming film \"\".", "However, during post-production, Kubrick chose to abandon North's music in favor of the now-familiar classical music pieces he had earlier chosen as \"guide pieces\" for the soundtrack.", "North did not know of the abandonment of the score until after he saw the film's premiere screening.", "The world's first exposure to North's unused music was in 1993 via Telarc's issue of the main theme on \"Hollywood's Greatest Hits, Vol. 2\", a compilation album by Erich Kunzel and the Cincinnati Pops Orchestra.", "All the music North originally wrote was recorded commercially by North's friend and colleague Jerry Goldsmith with the National Philharmonic Orchestra and was released on Var\u00e8se Sarabande CDs shortly after Telarc's first theme release but before North's death."]], "gold": "In the early stages of production, Kubrick had commissioned noted Hollywood composer Alex North, who had written the score for Spartacus and also worked on Dr. Strangelove, to write the score of his upcoming film 2001: A Space Odyssey. However, during post-production, Kubrick chose to abandon North's music in favor of classical music pieces he had earlier chosen as \"guide pieces\" for the soundtrack. North did not know of the abandonment of the score until after he saw the film's premiere screening. Richard Strauss, Johann Strauss, and Aram Khachaturian wrote the music that was used in 2001: A Space Odyssey.", "prediction 1": "The 2001: A Space Odyssey score is an unused film score composed by Alex North for Stanley Kubrick's 1968 film, \". In the early stages of production, Kubrick had commissioned noted Hollywood composer Alex North, who had written the score for Spartacus, Dr. Strangelove, and Spartacus II, to write the score of his upcoming film. However, during post-production, Kubrick chose to abandon North's music in favor of the now-familiar classical music pieces he had earlier chosen as \"guide pieces\" for the film's soundtrack. North did not know of the abandonment of the score until after he saw the film's premiere screening.", "prediction 2": "The 2001: A Space Odyssey score is an unused film score composed by Alex North for Stanley Kubrick's 1968 film. In the early stages of production, Kubrick had commissioned noted Hollywood composer Alex North, who had written the score for Spartacus and also worked on Dr. Strangelove, to write the score of his upcoming film. However, during post-production, Kubrick chose to abandon North's music in favor of the now-familiar classical music pieces he had earlier chosen as \"guide pieces\" for the film's soundtrack. North did not know of the abandonment of the score until after he saw the film's premiere screening.", "prediction 3": "The 2001: A Space Odyssey score is an unused film score composed by Alex North for Stanley Kubrick's 1968 film, \".\" In the early stages of production, Kubrick had commissioned noted Hollywood composer Alex North, who had written the score for Spartacus and also worked on \"Dr. Strangelove\", to write the score of his upcoming film \".\" However, during post-production, Kubrick chose to abandon North's music in favor of the now-familiar classical music pieces he had earlier chosen as \"guide pieces\" for the soundtrack.", "prediction 4": "The \"2001: A Space Odyssey\" score is an unused film score composed by Alex North for Stanley Kubrick's 1968 film, \". Kubrick had commissioned noted Hollywood composer Alex North, who had written the score for Spartacus and also worked on \"Dr. Strangelove\", to write the score of his upcoming film. However, during post-production, Kubrick chose to abandon North's music in favor of the now-familiar classical music pieces he had earlier chosen as \"guide pieces\" for the soundtrack. North did not know of the abandonment of the score until after he saw the film's premiere screening. Kubrick chose to abandon North's music in favor of the now-familiar classical music pieces he had earlier chosen as \"guide pieces\" for the soundtrack.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 253, "end": 287}], "missing-info": [], "corrected-prediction": "The 2001: A Space Odyssey score is an unused film score composed by Alex North for Stanley Kubrick's 1968 film. In the early stages of production, Kubrick had commissioned noted Hollywood composer Alex North, who had written the score for Spartacus and Dr. Strangelove, to write the score of his upcoming film. However, during post-production, Kubrick chose to abandon North's music in favor of the now-familiar classical music pieces he had earlier chosen as \"guide pieces\" for the film's soundtrack. North did not know of the abandonment of the score until after he saw the film's premiere screening."}, "preference": [0, 2, 1, 2, 1, 1], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - 2001: A Space Odyssey (score)\nS1. 2001:\nS2. A Space Odyssey (score)  The \"2001: A Space Odyssey\" score is an unused film score composed by Alex North for Stanley Kubrick's 1968 film, \".\"\nS3. In the early stages of production, Kubrick had commissioned noted Hollywood composer Alex North, who had written the score for \"Spartacus\" and also worked on \"Dr. Strangelove\", to write the score of his upcoming film \"\".\nS4. However, during post-production, Kubrick chose to abandon North's music in favor of the now-familiar classical music pieces he had earlier chosen as \"guide pieces\" for the soundtrack.\nS5. North did not know of the abandonment of the score until after he saw the film's premiere screening.\nS6. The world's first exposure to North's unused music was in 1993 via Telarc's issue of the main theme on \"Hollywood's Greatest Hits, Vol. 2\", a compilation album by Erich Kunzel and the Cincinnati Pops Orchestra.\nS7. All the music North originally wrote was recorded commercially by North's friend and colleague Jerry Goldsmith with the National Philharmonic Orchestra and was released on Var\u00e8se Sarabande CDs shortly after Telarc's first theme release but before North's death.\n    \nInput Question:\nWho wrote the score for 2001 a space odyssey?\n\nCorrect Response:\nIn the early stages of production, Kubrick had commissioned noted Hollywood composer Alex North, who had written the score for Spartacus and also worked on Dr. Strangelove, to write the score of his upcoming film 2001: A Space Odyssey. However, during post-production, Kubrick chose to abandon North's music in favor of classical music pieces he had earlier chosen as \"guide pieces\" for the soundtrack. North did not know of the abandonment of the score until after he saw the film's premiere screening. Richard Strauss, Johann Strauss, and Aram Khachaturian wrote the music that was used in 2001: A Space Odyssey.\n\nModel Prediction:\nThe 2001: A Space Odyssey score is an unused film score composed by Alex North for Stanley Kubrick's 1968 film, \". In the early stages of production, Kubrick had commissioned noted Hollywood composer Alex North, who had written the score for Spartacus, Dr. Strangelove, and Spartacus II, to write the score of his upcoming film. However, during post-production, Kubrick chose to abandon North's music in favor of the now-familiar classical music pieces he had earlier chosen as \"guide pieces\" for the film's soundtrack. North did not know of the abandonment of the score until after he saw the film's premiere screening.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "The 2001: A Space Odyssey score is an unused film score composed by Alex North for Stanley Kubrick's 1968 film, \". In the early stages of production, Kubrick had commissioned noted Hollywood composer Alex North, who had written the score for Spartacus, [Dr. Strangelove, and Spartacus II,] to write the score of his upcoming film. However, during post-production, Kubrick chose to abandon North's music in favor of the now-familiar classical music pieces he had earlier chosen as \"guide pieces\" for the film's soundtrack. North did not know of the abandonment of the score until after he saw the film's premiere screening.\n\nExplanation:\nThe span \"Dr. Strangelove, and Spartacus II,\" is irrelevant because it does not directly answer the question or provide crucial auxiliary information. The information about Alex North writing the score for \"Dr. Strangelove\" is already mentioned earlier in the sentence, making it repetitive. The mention of \"Spartacus II\" is not found in the passages or the reference response, making it irrelevant."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001: A Space Odyssey score is an unused film score composed by Alex North for Stanley Kubrick's 1968 film, \".\nS2. In the early stages of production, Kubrick had commissioned noted Hollywood composer Alex North, who had written the score for Spartacus, Dr. Strangelove, and Spartacus II, to write the score of his upcoming film.\nS3. However, during post-production, Kubrick chose to abandon North's music in favor of the now-familiar classical music pieces he had earlier chosen as \"guide pieces\" for the film's soundtrack.\nS4. North did not know of the abandonment of the score until after he saw the film's premiere screening.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "S2\n\nExplanation:\nThe mention of \"Spartacus II\" in sentence 2 is an unverifiable fact as it is not mentioned in any of the provided passages."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "None\n\nExplanation:\nThe model prediction includes all the necessary information from the passages to answer the question. There is no missing information."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The 2001: A Space Odyssey score is an unused film score composed by Alex North for Stanley Kubrick's 1968 film. In the early stages of production, Kubrick had commissioned noted Hollywood composer Alex North, who had written the score for Spartacus and Dr. Strangelove, to write the score of his upcoming film. However, during post-production, Kubrick chose to abandon North's music in favor of the now-familiar classical music pieces he had earlier chosen as \"guide pieces\" for the film's soundtrack. North did not know of the abandonment of the score until after he saw the film's premiere screening."}], "feedback_human": {"errors": [], "missing-info": [], "corrected-prediction": "The 2001: A Space Odyssey score is an unused film score composed by Alex North for Stanley Kubrick's 1968 film, \". In the early stages of production, Kubrick had commissioned noted Hollywood composer Alex North, who had written the score for Spartacus, Dr. Strangelove, and Spartacus II, to write the score of his upcoming film. However, during post-production, Kubrick chose to abandon North's music in favor of the now-familiar classical music pieces he had earlier chosen as \"guide pieces\" for the film's soundtrack. North did not know of the abandonment of the score until after he saw the film's premiere screening."}}, {"question": "Who established mission san francisco de la espada?", "passages": [["Espada Acequia", "Espada Acequia\n\nThe Espada Acequia, or Piedras Creek Aqueduct, was built by Franciscan friars in 1731 in what is now San Antonio, Texas, United States.", "It was built to supply irrigation water to the lands near Mission San Francisco de la Espada, today part of San Antonio Missions National Historical Park.", "The acequia is still in use today and is an Historic Civil Engineering Landmark and a National Historic Landmark.", "Mission Espada's \"acequia\" (irrigation) system can still be seen today.", "The main ditch, or \"acequia madre\", continues to carry water to the mission and its former farmlands.", "This water is still used by residents living on these neighboring lands.", "The initial survival of a new mission depended upon the planting and harvesting of crops.", "In south central Texas, intermittent rainfall and the need for a reliable water source made the design and installation of an acequia system a high priority.", "Irrigation was so important to Spanish colonial settlers that they measured cropland in \"suertes\" -the amount of land that could be watered in one day.", "The use of acequias was originally brought to the arid regions of Spain by the Romans and the Moors.", "When Franciscan missionaries arrived in the desert Southwest they found the system worked well in the hot, dry environment."], ["Spanish missions in Texas", "It was completed near the Hasinai village of Nabedaches in late May, and its first mass was conducted on June 1, 1690.", "In its first two years of existence, the mission faced much hardship, as floodwaters and then drought destroyed their crops.", "After an epidemic killed half of the local population, the Hasinai became convinced that the missionaries had caused the deaths.", "Fearing an attack, on October 25, 1693 the missionaries buried the mission bell, set the building ablaze, and retreated to Mexico.", "The mission was reestablished on July 3, 1716, as Nuestro Padre San Francisco de los Tejas.", "In 1721, it was renamed Mission San Francisco de los Neches.", "It was moved in 1731 to San Antonio where it was named Mission San Francisco de la Espada.", "The surviving structure is now part of San Antonio Missions National Historical Park operated by the National Park Service.", "A commemorative representation of Mission San Francisco de los Tejas, is located in Weches at Mission Tejas State Park.", "Mission Sant\u00edsimo Nombre de Mar\u00eda was the second mission established by the Spanish in East Texas.", "Built for the native Neches population, the mission opened in September 1690 northeast of Mission San Francisco.", "The mission consisted of a straw chapel and a house for the priest.", "It was destroyed by a flood in 1692."]], "gold": "Mission San Francisco de la Espada (also Mission Espada) is a Roman Rite Catholic mission established in 1690 by Spain and relocated in 1731 to present-day San Antonio, Texas, in what was then known as northern New Spain. The mission was built in order to convert local Native Americans to Christianity and solidify Spanish territorial claims in the New World against encroachment from France. Founded in 1690 as San Francisco de los Tejas near Weches, Texas and southwest of present-day Alto, Texas, Mission San Francisco de la Espada was the second mission established in Texas. Three priests, three soldiers and supplies were left among the Nabedache Indians.", "prediction 1": "The first Spanish mission in Texas was San Francisco de los Tejas, established in 1690, and renamed on July 3, 1716, as Nuestro Padre San Francisco de los Tejas. In 1731, the mission was moved to San Antonio, where it was renamed Mission San Francisco de la Espada. The surviving structure is now part of San Antonio Missions National Historical Park operated by the National Park Service.", "prediction 2": "The Spanish established Mission San Francisco de la Espada in 1690. The mission was reestablished in 1716 as Nuestro Padre San Francisco de los Tejas. In 1721, it was renamed Mission San Francisco de los Neches. It was moved in 1731 to San Antonio where it was named Mission San Francisco de la Espada.", "prediction 3": "The Spanish established Mission San Francisco de la Espada in 1690. The mission was reestablished on July 3, 1716, as Nuestro Padre San Francisco de los Tejas and was renamed Mission San Francisco de los Neches. In 1731, it was moved to San Antonio where it was named Mission San Francisco de la Espada.", "prediction 4": "The Espada Acequia, or Piedras Creek Aqueduct, was built by Franciscan friars in 1731 in what is now San Antonio, Texas, United States. It was built to supply irrigation water to the lands near Mission San Francisco de la Espada. The mission was reestablished on July 3, 1716, as Nuestro Padre San Francisco de los Tejas. In 1721, it was renamed Mission San Francisco de los Neches. It was moved in 1731 to San Antonio where it was named Mission San Francisco de la Espada.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 266, "end": 389}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 2, "sentence_id": [1]}], "corrected-prediction": "The first Spanish mission in Texas was San Francisco de los Tejas, established in 1690, and its first mass was conducted on June 1, 1690. It was renamed on July 3, 1716, as Nuestro Padre San Francisco de los Tejas. In 1731, the mission was moved to San Antonio, where it was renamed Mission San Francisco de la Espada."}, "preference": [1, 1, 2, 0, 2, 2], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Espada Acequia\nS1. Espada Acequia  The Espada Acequia, or Piedras Creek Aqueduct, was built by Franciscan friars in 1731 in what is now San Antonio, Texas, United States.\nS2. It was built to supply irrigation water to the lands near Mission San Francisco de la Espada, today part of San Antonio Missions National Historical Park.\nS3. The acequia is still in use today and is an Historic Civil Engineering Landmark and a National Historic Landmark.\nS4. Mission Espada's \"acequia\" (irrigation) system can still be seen today.\nS5. The main ditch, or \"acequia madre\", continues to carry water to the mission and its former farmlands.\nS6. This water is still used by residents living on these neighboring lands.\nS7. The initial survival of a new mission depended upon the planting and harvesting of crops.\nS8. In south central Texas, intermittent rainfall and the need for a reliable water source made the design and installation of an acequia system a high priority.\nS9. Irrigation was so important to Spanish colonial settlers that they measured cropland in \"suertes\" -the amount of land that could be watered in one day.\nS10. The use of acequias was originally brought to the arid regions of Spain by the Romans and the Moors.\nS11. When Franciscan missionaries arrived in the desert Southwest they found the system worked well in the hot, dry environment.\n\nPassage 2: Title (S0) - Spanish missions in Texas\nS1. It was completed near the Hasinai village of Nabedaches in late May, and its first mass was conducted on June 1, 1690.\nS2. In its first two years of existence, the mission faced much hardship, as floodwaters and then drought destroyed their crops.\nS3. After an epidemic killed half of the local population, the Hasinai became convinced that the missionaries had caused the deaths.\nS4. Fearing an attack, on October 25, 1693 the missionaries buried the mission bell, set the building ablaze, and retreated to Mexico.\nS5. The mission was reestablished on July 3, 1716, as Nuestro Padre San Francisco de los Tejas.\nS6. In 1721, it was renamed Mission San Francisco de los Neches.\nS7. It was moved in 1731 to San Antonio where it was named Mission San Francisco de la Espada.\nS8. The surviving structure is now part of San Antonio Missions National Historical Park operated by the National Park Service.\nS9. A commemorative representation of Mission San Francisco de los Tejas, is located in Weches at Mission Tejas State Park.\nS10. Mission Sant\u00edsimo Nombre de Mar\u00eda was the second mission established by the Spanish in East Texas.\nS11. Built for the native Neches population, the mission opened in September 1690 northeast of Mission San Francisco.\nS12. The mission consisted of a straw chapel and a house for the priest.\nS13. It was destroyed by a flood in 1692.\n    \nInput Question:\nWho established mission san francisco de la espada?\n\nCorrect Response:\nMission San Francisco de la Espada (also Mission Espada) is a Roman Rite Catholic mission established in 1690 by Spain and relocated in 1731 to present-day San Antonio, Texas, in what was then known as northern New Spain. The mission was built in order to convert local Native Americans to Christianity and solidify Spanish territorial claims in the New World against encroachment from France. Founded in 1690 as San Francisco de los Tejas near Weches, Texas and southwest of present-day Alto, Texas, Mission San Francisco de la Espada was the second mission established in Texas. Three priests, three soldiers and supplies were left among the Nabedache Indians.\n\nModel Prediction:\nThe first Spanish mission in Texas was San Francisco de los Tejas, established in 1690, and renamed on July 3, 1716, as Nuestro Padre San Francisco de los Tejas. In 1731, the mission was moved to San Antonio, where it was renamed Mission San Francisco de la Espada. The surviving structure is now part of San Antonio Missions National Historical Park operated by the National Park Service.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "The first Spanish mission in Texas was San Francisco de los Tejas, established in 1690, and renamed on July 3, 1716, as Nuestro Padre San Francisco de los Tejas. In 1731, the mission was moved to San Antonio, where it was renamed Mission San Francisco de la Espada. [The surviving structure is now part of San Antonio Missions National Historical Park operated by the National Park Service.]\n\nExplanation:\n1. The last sentence in the model prediction is not directly answering the question nor is it crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the factual consistency of this sentence, as you only need to label one error type for each span by following the order in the list of erroneous spans above."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The first Spanish mission in Texas was San Francisco de los Tejas, established in 1690, and renamed on July 3, 1716, as Nuestro Padre San Francisco de los Tejas.\nS2. In 1731, the mission was moved to San Antonio, where it was renamed Mission San Francisco de la Espada.\nS3. The surviving structure is now part of San Antonio Missions National Historical Park operated by the National Park Service.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation:\nAll the facts in the model prediction are consistent with the information provided in the passages. Therefore, there are no spans that contain inconsistent or unverifiable facts."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 2, sentence 1 [Missing Major Auxiliary Information]\n\nExplanation:\n1. The model prediction does not mention that the mission's first mass was conducted on June 1, 1690. This is a significant event in the establishment of the mission and provides important context, making it a major piece of missing auxiliary information."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The first Spanish mission in Texas was San Francisco de los Tejas, established in 1690, and its first mass was conducted on June 1, 1690. It was renamed on July 3, 1716, as Nuestro Padre San Francisco de los Tejas. In 1731, the mission was moved to San Antonio, where it was renamed Mission San Francisco de la Espada."}], "feedback_human": {"errors": [{"error type": "Wrong-Grounding", "explanation": "{\"passage_id\":2,\"sentence_id\":[5]}", "start": 39, "end": 66}, {"error type": "Wrong-Grounding", "explanation": "{\"passage_id\":2,\"sentence_id\":[6]}", "start": 120, "end": 161}, {"error type": "Irrelevant", "explanation": "", "start": 266, "end": 389}, {"error type": "Wrong-Grounding", "explanation": "{\"passage_id\":2,\"sentence_id\":[5,6]}", "start": 103, "end": 116}], "missing-info": [], "corrected-prediction": "The first Spanish mission in Texas was Nuestro Padre San Francisco de los Tejas, established in 1690, and reestablished on July 3, 1716. In 1721 it was renamed as Mission San Francisco de los Neches.. In 1731, the mission was moved to San Antonio, where it was renamed Mission San Francisco de la Espada. "}}, {"question": "Who's the lead singer of the doobie brothers?", "passages": [["The Doobie Brothers", "The Doobie Brothers\n\nThe Doobie Brothers are an American rock band from San Jose, California.", "The group has sold more than 40 million albums worldwide.", "It has been active for five decades, with its greatest success in the 1970s.", "The band's history can be roughly divided into three eras.", "From 1970 to 1975 it featured lead vocalist Tom Johnston and a mainstream rock and roll sound with elements of folk, country and R&B. Johnston quit the group in 1975, and was replaced by Michael McDonald, whose interest in soul music changed the band's sound until it broke up in 1982.", "The Doobie Brothers reformed in 1987 with Johnston back in the fold and are still active, with occasional contributions from McDonald.", "Every incarnation of the group emphasized vocal harmonies.", "The Doobie Brothers were inducted into the Vocal Group Hall of Fame in 2004.", "Drummer John Hartman arrived in California determined to meet Skip Spence of Moby Grape and join an aborted Grape reunion.", "Spence introduced Hartman to singer, guitarist, and songwriter Tom Johnston and the two proceeded to form the nucleus of what would become the Doobie Brothers.", "Johnston and Hartman called their fledgling group \"Pud\" and experimented with lineups (occasionally including Spence) and styles as they performed in and around San Jose.", "They were mostly a power trio (along with bassist Greg Murphy) but briefly worked with a horn section."]], "gold": "The Doobie Brothers are an American rock band from San Jose, California, known for their flexibility in performing across numerous genres and their vocal harmonies. At some point, drummer John Hartman arrived in California determined to meet Skip Spence of Moby Grape and join an aborted Grape reunion. Spence introduced Hartman to singer, guitarist, and songwriter Tom Johnston and the two proceeded to form the nucleus of what would become the Doobie Brothers. Johnston quit the group in 1975, and was replaced by Michael McDonald.", "prediction 1": "The Doobie Brothers are an American rock band from San Jose, California. It has sold more than 40 million albums worldwide. The band's history can be roughly divided into three eras. From 1970 to 1975 it featured lead vocalist Tom Johnston and a mainstream rock and roll sound with elements of folk, country and R&B. Johnston quit the group in 1975, and was replaced by Michael McDonald, whose interest in soul music changed the band's sound until it broke up in 1982. The Doobie Brothers reformed in 1987 with Johnston back in the fold and are still active, with occasional contributions from McDonald.", "prediction 2": "The Doobie Brothers are an American rock band from San Jose, California. It has sold more than 40 million albums worldwide. From 1970 to 1975 the lead singer of the Doobies was Tom Johnston. Johnston quit the group in 1975, and was replaced by Michael McDonald, whose interest in soul music changed the band's sound until it broke up in 1982. The Doobie Brothers reformed in 1987 with Johnston back in the fold and are still active, with occasional contributions from McDonald.", "prediction 3": "The Doobie Brothers are an American rock band from San Jose, California. Their lead singer was Tom Johnston from 1970 to 1975. Johnston quit the group in 1975 and was replaced by Michael McDonald. McDonald's interest in soul music changed the band's sound until it broke up in 1982. The Doobie Brothers reformed in 1987 with Johnston back in the fold and are still active, with occasional contributions from McDonald.", "prediction 4": "The Doobie Brothers are an American rock band from San Jose, California. They have sold more than 40 million albums worldwide. From 1970 to 1975 it featured lead vocalist Tom Johnston and a mainstream rock and roll sound with elements of folk, country and R&B. Johnston quit the group in 1975, and was replaced by Michael McDonald, whose interest in soul music changed the band's sound until it broke up in 1982. The Doobie Brothers reformed in 1987 with Johnston back in the fold and are still active, with occasional contributions from McDonald.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 73, "end": 123}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [9]}], "corrected-prediction": "The Doobie Brothers are an American rock band from San Jose, California. The band's history can be roughly divided into three eras. Drummer John Hartman arrived in California determined to meet Skip Spence of Moby Grape and join an aborted Grape reunion. Spence introduced Hartman to singer, guitarist, and songwriter Tom Johnston and the two proceeded to form the nucleus of what would become the Doobie Brothers. From 1970 to 1975 it featured lead vocalist Tom Johnston and a mainstream rock and roll sound with elements of folk, country and R&B. Johnston quit the group in 1975, and was replaced by Michael McDonald, whose interest in soul music changed the band's sound until it broke up in 1982. The Doobie Brothers reformed in 1987 with Johnston back in the fold and are still active, with occasional contributions from McDonald."}, "preference": [1, 1, 1, 0, 0, 0], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - The Doobie Brothers\nS1. The Doobie Brothers  The Doobie Brothers are an American rock band from San Jose, California.\nS2. The group has sold more than 40 million albums worldwide.\nS3. It has been active for five decades, with its greatest success in the 1970s.\nS4. The band's history can be roughly divided into three eras.\nS5. From 1970 to 1975 it featured lead vocalist Tom Johnston and a mainstream rock and roll sound with elements of folk, country and R&B. Johnston quit the group in 1975, and was replaced by Michael McDonald, whose interest in soul music changed the band's sound until it broke up in 1982.\nS6. The Doobie Brothers reformed in 1987 with Johnston back in the fold and are still active, with occasional contributions from McDonald.\nS7. Every incarnation of the group emphasized vocal harmonies.\nS8. The Doobie Brothers were inducted into the Vocal Group Hall of Fame in 2004.\nS9. Drummer John Hartman arrived in California determined to meet Skip Spence of Moby Grape and join an aborted Grape reunion.\nS10. Spence introduced Hartman to singer, guitarist, and songwriter Tom Johnston and the two proceeded to form the nucleus of what would become the Doobie Brothers.\nS11. Johnston and Hartman called their fledgling group \"Pud\" and experimented with lineups (occasionally including Spence) and styles as they performed in and around San Jose.\nS12. They were mostly a power trio (along with bassist Greg Murphy) but briefly worked with a horn section.\n    \nInput Question:\nWho's the lead singer of the doobie brothers?\n\nCorrect Response:\nThe Doobie Brothers are an American rock band from San Jose, California, known for their flexibility in performing across numerous genres and their vocal harmonies. At some point, drummer John Hartman arrived in California determined to meet Skip Spence of Moby Grape and join an aborted Grape reunion. Spence introduced Hartman to singer, guitarist, and songwriter Tom Johnston and the two proceeded to form the nucleus of what would become the Doobie Brothers. Johnston quit the group in 1975, and was replaced by Michael McDonald.\n\nModel Prediction:\nThe Doobie Brothers are an American rock band from San Jose, California. It has sold more than 40 million albums worldwide. The band's history can be roughly divided into three eras. From 1970 to 1975 it featured lead vocalist Tom Johnston and a mainstream rock and roll sound with elements of folk, country and R&B. Johnston quit the group in 1975, and was replaced by Michael McDonald, whose interest in soul music changed the band's sound until it broke up in 1982. The Doobie Brothers reformed in 1987 with Johnston back in the fold and are still active, with occasional contributions from McDonald.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "The Doobie Brothers are an American rock band from San Jose, California. [It has sold more than 40 million albums worldwide.] The band's history can be roughly divided into three eras. From 1970 to 1975 it featured lead vocalist Tom Johnston and a mainstream rock and roll sound with elements of folk, country and R&B. Johnston quit the group in 1975, and was replaced by Michael McDonald, whose interest in soul music changed the band's sound until it broke up in 1982. The Doobie Brothers reformed in 1987 with Johnston back in the fold and are still active, with occasional contributions from McDonald.\n\nExplanation:\nThe second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The Doobie Brothers are an American rock band from San Jose, California.\nS2. It has sold more than 40 million albums worldwide.\nS3. The band's history can be roughly divided into three eras.\nS4. From 1970 to 1975 it featured lead vocalist Tom Johnston and a mainstream rock and roll sound with elements of folk, country and R&B.\nS5. Johnston quit the group in 1975, and was replaced by Michael McDonald, whose interest in soul music changed the band's sound until it broke up in 1982.\nS6. The Doobie Brothers reformed in 1987 with Johnston back in the fold and are still active, with occasional contributions from McDonald.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation:\nAll the facts mentioned in the model prediction are consistent with the provided passages and none of them are unverifiable."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 9 [Missing Major Auxiliary Information]\n2. Passage 1, sentence 10 [Missing Major Auxiliary Information]\n\nExplanation:\n1. The model prediction does not include the information about how drummer John Hartman arrived in California with the intention to meet Skip Spence of Moby Grape and join an aborted Grape reunion. This information is crucial to understanding the formation of the Doobie Brothers and the role of Tom Johnston in the band.\n2. The model prediction also misses the information about how Skip Spence introduced Hartman to Tom Johnston, which led to the formation of the Doobie Brothers. This is a significant detail that provides context to the band's formation and the role of the lead singers."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The Doobie Brothers are an American rock band from San Jose, California. The band's history can be roughly divided into three eras. Drummer John Hartman arrived in California determined to meet Skip Spence of Moby Grape and join an aborted Grape reunion. Spence introduced Hartman to singer, guitarist, and songwriter Tom Johnston and the two proceeded to form the nucleus of what would become the Doobie Brothers. From 1970 to 1975 it featured lead vocalist Tom Johnston and a mainstream rock and roll sound with elements of folk, country and R&B. Johnston quit the group in 1975, and was replaced by Michael McDonald, whose interest in soul music changed the band's sound until it broke up in 1982. The Doobie Brothers reformed in 1987 with Johnston back in the fold and are still active, with occasional contributions from McDonald."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 73, "end": 123}, {"error type": "Irrelevant", "explanation": "", "start": 124, "end": 182}, {"error type": "Irrelevant", "explanation": "", "start": 183, "end": 316}, {"error type": "Irrelevant", "explanation": "", "start": 388, "end": 468}, {"error type": "Irrelevant", "explanation": "", "start": 469, "end": 603}], "missing-info": [{"error type": "Missing-Minor-Auxiliary", "passage_id": 1, "sentence_id": [7]}, {"error type": "Missing-Minor-Auxiliary", "passage_id": 1, "sentence_id": [9]}, {"error type": "Missing-Minor-Auxiliary", "passage_id": 1, "sentence_id": [10]}], "corrected-prediction": "The Doobie Brothers are an American rock band from San Jose, California, known for their vocal harmonies. At some point, drummer John Hartman arrived in California determined to meet Skip Spence of Moby Grape and join an aborted Grape reunion. Spence introduced Hartman to singer, guitarist, and songwriter Tom Johnston and the two proceeded to form the nucleus of what would become the Doobie Brothers. Johnston quit the group in 1975, and was replaced by Michael McDonald. "}}, {"question": "Who played the young tom riddle in harry potter?", "passages": [["Lord Voldemort", "Voldemort appears in seven \"Harry Potter\" films, namely \"Harry Potter and the Philosopher's Stone\", \"Harry Potter and the Chamber of Secrets\", \"Harry Potter and the Goblet of Fire\", \"Harry Potter and the Order of the Phoenix\", \"Harry Potter and the Half-Blood Prince\", \"Harry Potter and the Deathly Hallows \u2013 Part 1\" and \"Harry Potter and the Deathly Hallows \u2013 Part 2\".", "Several actors have portrayed him in his varying incarnations and ages.", "In \"Harry Potter and the Philosopher's Stone\", Voldemort's manifestation is as a face on the back of Quirrell's head, an effect achieved by computer generated imagery.", "Ian Hart, the actor who played Quirrell in the same film, provided the voice and the facial source for this character.", "Voldemort also appears in a scene in the Forbidden Forest where he is seen drinking the blood of a unicorn.", "As Voldemort's face was altered enough by CG work, and Hart's voice was affected enough, there was no confusion by Hart's playing of the two roles.", "In that film, he was also shown in a flashback sequence when he arrived at the home of James and Lily Potter to kill them."], ["Lord Voldemort", "Fiennes's nephew, Hero Fiennes-Tiffin, portrayed Tom Riddle as a child in \"Harry Potter and the Half-Blood Prince\".", "By the time filming arrived Christian Coulson was 29, and not considered suitable to return as the adolescent Riddle.", "Thomas James Longley was originally scheduled to take over the role, but last minute renegotiations saw Frank Dillane cast instead.", "After he regains his body in the fourth book, Rowling describes Voldemort as having pale skin, a chalk-white, skull-like face, snake-like slits for nostrils, red eyes and cat-like slits for pupils, a skeletally thin body and long, thin hands with unnaturally long fingers.", "As mentioned in the first chapter of the seventh book, he also has no hair or lips.", "Earlier in life, as seen through flashbacks contained in the second and sixth books, Tom Marvolo Riddle was handsome and tall with pale skin, jet black hair, and dark brown eyes.", "He could charm many people with his looks.", "The transformation into his monstrous state is believed to have been the result of creating his Horcruxes and becoming less human as he continued to divide his soul.", "In the films, Voldemort's eyes are blue with round pupils."], ["Lord Voldemort", "In Alan Moore's \"\", a young Tom Marvolo Riddle (introduced as \"Tom\", whose middle name is a \"marvel\" and last name is a \"conundrum\") appears, and becomes the new avatar of Oliver Haddo at the story's conclusion.", "In \"A Very Potter Musical\", Voldemort is played by actor Joe Walker.", "Voldemort also appeared in the 2012 Summer Olympics opening ceremony in London as an inflatable representation of children's literature villains, alongside The Queen of Hearts, Captain Hook, and Cruella de Vil.", "Voldemort appears in \"The Lego Batman Movie\" as one of the prisoners in the Phantom Zone that Joker recruits to take over Gotham City.", "Though Ralph Fiennes is featured in this movie as the voice of Alfred Pennyworth, he does not reprise his role.", "Instead, Voldemort is voiced by Eddie Izzard\n\nOutside of the \"Harry Potter\" video games, Voldemort is also playable in \"Lego Dimensions\", with archive audio of Ralph Fiennes's portrayal in the films used for his voiceovers.", "In \"The Lego Batman Movie\" pack for the game, Voldemort is voiced by Liam O'Brien\".", "A 2018 Italian fan film titled \"\" depicts the story of Tom Riddle's rise to power."]], "gold": "Christian Coulson played 16-year-old Tom Riddle in the film Harry Potter and the Chamber of Secrets. Then, in Harry Potter and the Half-Blood Prince, two actors played young Tom Riddle. The nephew of Ralph Fiennes, Hero Fiennes-Tiffin, portrayed 11-year-old Tom Riddle in the film, while Frank Dillane played 16-year-old Tom Riddle. Christian Coulson, who played Tom Riddle in Harry Potter and the Chamber of Secrets, was now 29 years old. Therefore, he was not considered suitable to return to the adolescent role of Tom Riddle in Harry Potter and the Half-Blood Prince.", "prediction 1": "Hero Fiennes-Tiffin, the nephew of Ralph Fiennes, played Tom Riddle as a child in Harry Potter and the Chamber of Secrets. By the time filming arrived Christian Coulson was 29, and not considered suitable to return as the adolescent Riddle. Thomas James Longley was originally scheduled to take over the role, but last minute renegotiations saw Frank Dillane cast instead. In Harry Potter and the Half Blood Prince, Ralph Fiennes' nephew, portrayed Tom Riddle as a young Tom Riddle as a child. By the time filming arrived Christian Coulson was 29, and not considered suitable to return as the adolescent Riddle. By the time filming arrived Christian Coulson was not considered suitable to return as the adolescent Riddle.", "prediction 2": "Hero Fiennes-Tiffin, played the young Tom Riddle in Harry Potter and the Chamber of Secrets and Harry Potter and the Half Blood Prince. Christian Coulson, played the young Tom Riddle in Harry Potter and the Goblet of Fire. Thomas James Longley was originally scheduled to take over the role, but last minute renegotiations saw Frank Dillane cast instead. In Harry Potter and the Half Blood Prince, Ralph Fiennes' nephew, portrayed the young Tom Riddle as a child, an adolooo. In Harry Potter and the Half Blood Prince, Hero Fiennes's nephew, Hero Fiennes-Tiffin, Hero Fiennes's nephew, portrayed the child Tom Marvolodle in Harry Potter and the LEGO Movie. In the Harry Potter and the Very Potter Musical, Voldemort is played by Joe Walker. In Harry Potter and", "prediction 3": "Hero Fiennes-Tiffin, played the young Tom Riddle in Harry Potter and the Chamber of Secrets, and Christian Coulson played the adult Tom Riddle. In Harry Potter and the Half Blood Prince, Hero Fiennes-Tiffin plays Tom Riddle as a child. In Harry Potter and the Chamber of Secrets, Christian Coulson plays Tom Riddle as an adolescent. In Harry Potter and the Order of the Phoenix, Thomas James Longley plays Tom Riddle as an adolooman, and Joe Walker plays Lord Voldemort as a young Tom Marvolo Riddle.", "prediction 4": "Hero Fiennes-Tiffin played the young Tom Riddle in Harry Potter and the Chamber of Secrets and Harry Potter and the Goblet of Fire. In Harry Potter and the Half Blood Prince, Hero Fiennes-Tiffin played the young Tom Riddle. In Harry Potter and the Deathly Hallows, Frank Dillane played the young Tom Riddle. In Harry Potter and the Deathly Hallows: Parts 1 and 2, Hero Fiennes-Tiffin played the young Tom Riddle.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 373, "end": 721}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 2, "sentence_id": [2]}], "corrected-prediction": "Hero Fiennes-Tiffin, the nephew of Ralph Fiennes, played Tom Riddle as a child in Harry Potter and the Half-Blood Prince. By the time filming arrived for the same movie, Christian Coulson, who had played a 16-year-old Tom Riddle in Harry Potter and the Chamber of Secrets, was 29 and not considered suitable to return as the adolescent Riddle. Thomas James Longley was originally scheduled to take over the role, but last minute renegotiations saw Frank Dillane cast instead."}, "preference": [1, 1, 1, 2, 2, 1], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Lord Voldemort\nS1. Voldemort appears in seven \"Harry Potter\" films, namely \"Harry Potter and the Philosopher's Stone\", \"Harry Potter and the Chamber of Secrets\", \"Harry Potter and the Goblet of Fire\", \"Harry Potter and the Order of the Phoenix\", \"Harry Potter and the Half-Blood Prince\", \"Harry Potter and the Deathly Hallows \u2013 Part 1\" and \"Harry Potter and the Deathly Hallows \u2013 Part 2\".\nS2. Several actors have portrayed him in his varying incarnations and ages.\nS3. In \"Harry Potter and the Philosopher's Stone\", Voldemort's manifestation is as a face on the back of Quirrell's head, an effect achieved by computer generated imagery.\nS4. Ian Hart, the actor who played Quirrell in the same film, provided the voice and the facial source for this character.\nS5. Voldemort also appears in a scene in the Forbidden Forest where he is seen drinking the blood of a unicorn.\nS6. As Voldemort's face was altered enough by CG work, and Hart's voice was affected enough, there was no confusion by Hart's playing of the two roles.\nS7. In that film, he was also shown in a flashback sequence when he arrived at the home of James and Lily Potter to kill them.\n\nPassage 2: Title (S0) - Lord Voldemort\nS1. Fiennes's nephew, Hero Fiennes-Tiffin, portrayed Tom Riddle as a child in \"Harry Potter and the Half-Blood Prince\".\nS2. By the time filming arrived Christian Coulson was 29, and not considered suitable to return as the adolescent Riddle.\nS3. Thomas James Longley was originally scheduled to take over the role, but last minute renegotiations saw Frank Dillane cast instead.\nS4. After he regains his body in the fourth book, Rowling describes Voldemort as having pale skin, a chalk-white, skull-like face, snake-like slits for nostrils, red eyes and cat-like slits for pupils, a skeletally thin body and long, thin hands with unnaturally long fingers.\nS5. As mentioned in the first chapter of the seventh book, he also has no hair or lips.\nS6. Earlier in life, as seen through flashbacks contained in the second and sixth books, Tom Marvolo Riddle was handsome and tall with pale skin, jet black hair, and dark brown eyes.\nS7. He could charm many people with his looks.\nS8. The transformation into his monstrous state is believed to have been the result of creating his Horcruxes and becoming less human as he continued to divide his soul.\nS9. In the films, Voldemort's eyes are blue with round pupils.\n\nPassage 3: Title (S0) - Lord Voldemort\nS1. In Alan Moore's \"\", a young Tom Marvolo Riddle (introduced as \"Tom\", whose middle name is a \"marvel\" and last name is a \"conundrum\") appears, and becomes the new avatar of Oliver Haddo at the story's conclusion.\nS2. In \"A Very Potter Musical\", Voldemort is played by actor Joe Walker.\nS3. Voldemort also appeared in the 2012 Summer Olympics opening ceremony in London as an inflatable representation of children's literature villains, alongside The Queen of Hearts, Captain Hook, and Cruella de Vil.\nS4. Voldemort appears in \"The Lego Batman Movie\" as one of the prisoners in the Phantom Zone that Joker recruits to take over Gotham City.\nS5. Though Ralph Fiennes is featured in this movie as the voice of Alfred Pennyworth, he does not reprise his role.\nS6. Instead, Voldemort is voiced by Eddie Izzard  Outside of the \"Harry Potter\" video games, Voldemort is also playable in \"Lego Dimensions\", with archive audio of Ralph Fiennes's portrayal in the films used for his voiceovers.\nS7. In \"The Lego Batman Movie\" pack for the game, Voldemort is voiced by Liam O'Brien\".\nS8. A 2018 Italian fan film titled \"\" depicts the story of Tom Riddle's rise to power.\n    \nInput Question:\nWho played the young tom riddle in harry potter?\n\nCorrect Response:\nChristian Coulson played 16-year-old Tom Riddle in the film Harry Potter and the Chamber of Secrets. Then, in Harry Potter and the Half-Blood Prince, two actors played young Tom Riddle. The nephew of Ralph Fiennes, Hero Fiennes-Tiffin, portrayed 11-year-old Tom Riddle in the film, while Frank Dillane played 16-year-old Tom Riddle. Christian Coulson, who played Tom Riddle in Harry Potter and the Chamber of Secrets, was now 29 years old. Therefore, he was not considered suitable to return to the adolescent role of Tom Riddle in Harry Potter and the Half-Blood Prince.\n\nModel Prediction:\nHero Fiennes-Tiffin, the nephew of Ralph Fiennes, played Tom Riddle as a child in Harry Potter and the Chamber of Secrets. By the time filming arrived Christian Coulson was 29, and not considered suitable to return as the adolescent Riddle. Thomas James Longley was originally scheduled to take over the role, but last minute renegotiations saw Frank Dillane cast instead. In Harry Potter and the Half Blood Prince, Ralph Fiennes' nephew, portrayed Tom Riddle as a young Tom Riddle as a child. By the time filming arrived Christian Coulson was 29, and not considered suitable to return as the adolescent Riddle. By the time filming arrived Christian Coulson was not considered suitable to return as the adolescent Riddle.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "Hero Fiennes-Tiffin, the nephew of Ralph Fiennes, played Tom Riddle as a child in Harry Potter and the Chamber of Secrets. By the time filming arrived Christian Coulson was 29, and not considered suitable to return as the adolescent Riddle. Thomas James Longley was originally scheduled to take over the role, but last minute renegotiations saw Frank Dillane cast instead. [In Harry Potter and the Half Blood Prince, Ralph Fiennes' nephew, portrayed Tom Riddle as a young Tom Riddle as a child. By the time filming arrived Christian Coulson was 29, and not considered suitable to return as the adolescent Riddle. By the time filming arrived Christian Coulson was not considered suitable to return as the adolescent Riddle.]\n\nExplanation:\n1. The information about Hero Fiennes-Tiffin playing Tom Riddle as a child in Harry Potter and the Chamber of Secrets is incorrect. He played the role in Harry Potter and the Half-Blood Prince. This makes the information irrelevant.\n2. The information about Christian Coulson being 29 and not suitable to return as the adolescent Riddle is repeated three times in the model prediction. This makes the repeated information repetitive."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. Hero Fiennes-Tiffin, the nephew of Ralph Fiennes, played Tom Riddle as a child in Harry Potter and the Chamber of Secrets.\nS2. By the time filming arrived Christian Coulson was 29, and not considered suitable to return as the adolescent Riddle.\nS3. Thomas James Longley was originally scheduled to take over the role, but last minute renegotiations saw Frank Dillane cast instead.\nS4. In Harry Potter and the Half Blood Prince, Ralph Fiennes' nephew, portrayed Tom Riddle as a young Tom Riddle as a child.\nS5. By the time filming arrived Christian Coulson was 29, and not considered suitable to return as the adolescent Riddle.\nS6. By the time filming arrived Christian Coulson was not considered suitable to return as the adolescent Riddle.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "Inconsistent or Unverifiable Sentences:\n1. S1\n2. S4\n\nExplanation:\n1. The first sentence is incorrect. Hero Fiennes-Tiffin did not play Tom Riddle in Harry Potter and the Chamber of Secrets. He played the role in Harry Potter and the Half-Blood Prince. This makes the information in the sentence factually inconsistent with the passages.\n2. The fourth sentence is also incorrect. It repeats the incorrect information from the first sentence about Hero Fiennes-Tiffin playing Tom Riddle in Harry Potter and the Chamber of Secrets. This makes the information in the sentence factually inconsistent with the passages."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 2, sentence 2 [Missing Answer]\n2. Passage 2, sentence 3 [Missing Answer]\n\nExplanation:\n1. The model prediction does not mention that Christian Coulson played 16-year-old Tom Riddle in the film Harry Potter and the Chamber of Secrets. This information is present in Passage 2, sentence 2.\n2. The model prediction does not mention that Frank Dillane played 16-year-old Tom Riddle in Harry Potter and the Half-Blood Prince. This information is present in Passage 2, sentence 3."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "Hero Fiennes-Tiffin, the nephew of Ralph Fiennes, played Tom Riddle as a child in Harry Potter and the Half-Blood Prince. By the time filming arrived for the same movie, Christian Coulson, who had played a 16-year-old Tom Riddle in Harry Potter and the Chamber of Secrets, was 29 and not considered suitable to return as the adolescent Riddle. Thomas James Longley was originally scheduled to take over the role, but last minute renegotiations saw Frank Dillane cast instead."}], "feedback_human": {"errors": [{"error type": "Wrong-Grounding", "explanation": "{\"passage_id\":2,\"sentence_id\":[1]}", "start": 95, "end": 122}, {"error type": "Redundant", "explanation": "Hero Fiennes-Tiffin, the nephew of Ralph Fiennes, played Tom Riddle as a child in Harry Potter and the Chamber of Secrets. ", "start": 373, "end": 493}, {"error type": "Redundant", "explanation": "By the time filming arrived Christian Coulson was 29, and not considered suitable to return as the adolescent Riddle. ", "start": 494, "end": 721}, {"error type": "Irrelevant", "explanation": "", "start": 241, "end": 344}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 2, "sentence_id": [2]}], "corrected-prediction": "Hero Fiennes-Tiffin, the nephew of Ralph Fiennes, played Tom Riddle as a child in Harry Potter and the Half-Blood Prince. By the time filming arrived Christian Coulson was 29, and not considered suitable to return as the adolescent Riddle. Frank Dillane was also cast as adolescent Riddle. "}}, {"question": "Where does the novel call me by your name take place?", "passages": [["Call Me by Your Name (novel)", "Call Me by Your Name (novel)\n\nCall Me by Your Name is a 2007 novel by American writer Andr\u00e9 Aciman that centers on a blossoming romantic relationship between an intellectually precocious and curious 17-year-old American-Italian Jewish boy named Elio Perlman and a visiting 24-year-old American Jewish scholar named Oliver in 1980s Italy.", "The novel chronicles their summer romance and the 20 years that follow.", "The narrator, Elio Perlman, recalls the events of the summer of about 1983, when he was seventeen and living with his parents in Italy.", "Each summer, his parents would take in a doctoral student as a house guest for six weeks, who would revise a book manuscript while assisting his father with academic paperwork.", "Elio resents the tradition, as it requires him to vacate his bedroom so the guest can use it for the duration of their stay.", "Oliver, the guest for the summer, is carefree and detached\u2014a stark contrast to Elio\u2019s introversion.", "Elio selected Oliver as a guest in the hopes of \"instant affinities\" between them and acts as his tour guide, though Elio's attempts to impress Oliver are met with indifference.", "When Oliver grabs Elio's arm after a tennis match, Elio retracts in fear."], ["Call Me by Your Name (novel)", "Elio visits Marzia\u2019s house, and the two have sex; in the afternoon he masturbates with a cut peach, and ejaculates inside of it.", "Oliver later visits Elio\u2019s room, eats the peach and its contents, and again has sex with Elio.", "Before returning to the United States, Oliver decides to spend three days in Rome, where he is accompanied by Elio.", "Upon returning from the trip, Elio is saddened to find that his belongings have already been returned to his original bedroom, and that all traces of Oliver\u2019s visit have vanished.", "Elio has a discussion with his father, who says that he approves of the friendship (and relationship) between Elio and Oliver.", "That Christmas, Oliver again visits the Perlman family, and announces that he intends to marry next summer.", "Oliver and Elio fall out of touch, and do not communicate with each other for many years.", "Fifteen years later, Elio visits Oliver in the United States, where Oliver is now a professor.", "Elio is unwilling to meet Oliver\u2019s wife and children, admitting that he still feels attraction towards Oliver and jealousy towards his new family.", "Oliver admits that he has followed Elio\u2019s academic career, and shows him a postcard that he brought with him when he left Italy and has kept over the years."], ["Italy", "The election was characterized by a strong showing of the Five Star Movement and the League and the university professor Giuseppe Conte became the Prime Minister at the head of a populist coalition.", "Italy is located in Southern Europe, between latitudes 35\u00b0 and 47\u00b0 N, and longitudes 6\u00b0 and 19\u00b0 E. To the north, Italy borders France, Switzerland, Austria and Slovenia, and is roughly delimited by the Alpine watershed, enclosing the Po Valley and the Venetian Plain.", "To the south, it consists of the entirety of the Italian Peninsula and the two Mediterranean islands of Sicily and Sardinia, in addition to many smaller islands.", "The sovereign states of San Marino and the Vatican City are enclaves within Italy, while Campione d'Italia is an Italian exclave in Switzerland.", "The country's total area is , of which is land and is water.", "Including the islands, Italy has a coastline and border of on the Adriatic, Ionian, Tyrrhenian seas (), and borders shared with France (), Austria (), Slovenia () and Switzerland ().", "San Marino () and Vatican City (), both enclaves, account for the remainder.", "The Apennine Mountains form the peninsula's backbone and the Alps form most of its northern boundary, where Italy's highest point is located on Monte Bianco ()."]], "gold": "The 2007 Andr\u00e9 Aciman novel Call Me by Your Name takes place in several countries, including Italy and the United States. The early part of the novel takes place in Italy in Southern Europe, where the narrator recalls the events of the summer of 1987. Also, Oliver, with whom the narrator has a romantic relationship, returns to the United States in North America in the novel.", "prediction 1": "Call Me by Your Name is a 2007 novel by American writer Andr\u00e9 Aciman that centers on a blossoming romantic relationship between an intellectually precocious and curious 17-year-old American-Italian Jewish boy named Elio Perlman and a visiting 24-year-old American Jewish scholar named Oliver in 1980s Italy. The novel chronicles their summer romance and the 20 years that follow. The narrator, Elio Perlman, recalls the events of the summer of 1983, when he was seventeen and living with his parents in Italy.", "prediction 2": "Call Me by Your Name is a 2007 novel by American writer Andr\u00e9 Aciman that centers on a blossoming romantic relationship between an intellectually precocious and curious 17-year-old American-Italian Jewish boy named Elio Perlman and a visiting 24-year-old American Jewish scholar named Oliver in 1980s Italy. The novel chronicles their summer romance and the 20 years that follow.", "prediction 3": "Call Me by Your Name is a 2007 novel written by American writer Andr\u00e9 Aciman that centers on a blossoming romantic relationship between an intellectually precocious and curious 17-year-old American-Italian Jewish boy named Elio Perlman and a visiting 24-year-old American Jewish scholar named Oliver in 1980s Italy. The novel chronicles their summer romance and the 20 years that follow. The narrator, Elio Perlman, recalls the events of the summer of about 1983, when he was seventeen and living with his parents in Italy. The narrator, Elio Perlman, recalls the events of the summer romance between them.", "prediction 4": "Call Me by Your Name is a 2007 novel by American writer Andr\u00e9 Aciman that centers on a blossoming romantic relationship between an intellectually precocious and curious 17-year-old American-Italian Jewish boy named Elio Perlman and a visiting 24-year-old American Jewish scholar named Oliver in 1980s Italy. The narrator, Elio Perlman, recalls the events of the summer of about 1983, when he was seventeen and living with his parents in Italy. The novel chronicles their summer romance and the 20 years that follow.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 308, "end": 509}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 2, "sentence_id": [8]}], "corrected-prediction": "The novel Call Me by Your Name by Andr\u00e9 Aciman takes place in Italy during the 1980s, where the main characters Elio Perlman and Oliver spend a summer. The story also extends to the United States, where Elio visits Oliver years later."}, "preference": [2, 1, 1, 1, 1, 2], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Call Me by Your Name (novel)\nS1. Call Me by Your Name (novel)  Call Me by Your Name is a 2007 novel by American writer Andr\u00e9 Aciman that centers on a blossoming romantic relationship between an intellectually precocious and curious 17-year-old American-Italian Jewish boy named Elio Perlman and a visiting 24-year-old American Jewish scholar named Oliver in 1980s Italy.\nS2. The novel chronicles their summer romance and the 20 years that follow.\nS3. The narrator, Elio Perlman, recalls the events of the summer of about 1983, when he was seventeen and living with his parents in Italy.\nS4. Each summer, his parents would take in a doctoral student as a house guest for six weeks, who would revise a book manuscript while assisting his father with academic paperwork.\nS5. Elio resents the tradition, as it requires him to vacate his bedroom so the guest can use it for the duration of their stay.\nS6. Oliver, the guest for the summer, is carefree and detached\u2014a stark contrast to Elio\u2019s introversion.\nS7. Elio selected Oliver as a guest in the hopes of \"instant affinities\" between them and acts as his tour guide, though Elio's attempts to impress Oliver are met with indifference.\nS8. When Oliver grabs Elio's arm after a tennis match, Elio retracts in fear.\n\nPassage 2: Title (S0) - Call Me by Your Name (novel)\nS1. Elio visits Marzia\u2019s house, and the two have sex; in the afternoon he masturbates with a cut peach, and ejaculates inside of it.\nS2. Oliver later visits Elio\u2019s room, eats the peach and its contents, and again has sex with Elio.\nS3. Before returning to the United States, Oliver decides to spend three days in Rome, where he is accompanied by Elio.\nS4. Upon returning from the trip, Elio is saddened to find that his belongings have already been returned to his original bedroom, and that all traces of Oliver\u2019s visit have vanished.\nS5. Elio has a discussion with his father, who says that he approves of the friendship (and relationship) between Elio and Oliver.\nS6. That Christmas, Oliver again visits the Perlman family, and announces that he intends to marry next summer.\nS7. Oliver and Elio fall out of touch, and do not communicate with each other for many years.\nS8. Fifteen years later, Elio visits Oliver in the United States, where Oliver is now a professor.\nS9. Elio is unwilling to meet Oliver\u2019s wife and children, admitting that he still feels attraction towards Oliver and jealousy towards his new family.\nS10. Oliver admits that he has followed Elio\u2019s academic career, and shows him a postcard that he brought with him when he left Italy and has kept over the years.\n\nPassage 3: Title (S0) - Italy\nS1. The election was characterized by a strong showing of the Five Star Movement and the League and the university professor Giuseppe Conte became the Prime Minister at the head of a populist coalition.\nS2. Italy is located in Southern Europe, between latitudes 35\u00b0 and 47\u00b0 N, and longitudes 6\u00b0 and 19\u00b0 E. To the north, Italy borders France, Switzerland, Austria and Slovenia, and is roughly delimited by the Alpine watershed, enclosing the Po Valley and the Venetian Plain.\nS3. To the south, it consists of the entirety of the Italian Peninsula and the two Mediterranean islands of Sicily and Sardinia, in addition to many smaller islands.\nS4. The sovereign states of San Marino and the Vatican City are enclaves within Italy, while Campione d'Italia is an Italian exclave in Switzerland.\nS5. The country's total area is , of which is land and is water.\nS6. Including the islands, Italy has a coastline and border of on the Adriatic, Ionian, Tyrrhenian seas (), and borders shared with France (), Austria (), Slovenia () and Switzerland ().\nS7. San Marino () and Vatican City (), both enclaves, account for the remainder.\nS8. The Apennine Mountains form the peninsula's backbone and the Alps form most of its northern boundary, where Italy's highest point is located on Monte Bianco ().\n    \nInput Question:\nWhere does the novel call me by your name take place?\n\nCorrect Response:\nThe 2007 Andr\u00e9 Aciman novel Call Me by Your Name takes place in several countries, including Italy and the United States. The early part of the novel takes place in Italy in Southern Europe, where the narrator recalls the events of the summer of 1987. Also, Oliver, with whom the narrator has a romantic relationship, returns to the United States in North America in the novel.\n\nModel Prediction:\nCall Me by Your Name is a 2007 novel by American writer Andr\u00e9 Aciman that centers on a blossoming romantic relationship between an intellectually precocious and curious 17-year-old American-Italian Jewish boy named Elio Perlman and a visiting 24-year-old American Jewish scholar named Oliver in 1980s Italy. The novel chronicles their summer romance and the 20 years that follow. The narrator, Elio Perlman, recalls the events of the summer of 1983, when he was seventeen and living with his parents in Italy.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "Call Me by Your Name is a 2007 novel by American writer Andr\u00e9 Aciman that centers on a blossoming romantic relationship between an intellectually precocious and curious 17-year-old American-Italian Jewish boy named Elio Perlman and a visiting 24-year-old American Jewish scholar named Oliver in 1980s Italy. [The novel chronicles their summer romance and the 20 years that follow. The narrator, Elio Perlman, recalls the events of the summer of 1983, when he was seventeen and living with his parents in Italy.]\n\nExplanation:\n1. The second and third sentences in the model prediction are neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, they should be marked as \"Irrelevant\". \n2. The first sentence is not marked as it provides the necessary context for the setting of the novel."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. Call Me by Your Name is a 2007 novel by American writer Andr\u00e9 Aciman that centers on a blossoming romantic relationship between an intellectually precocious and curious 17-year-old American-Italian Jewish boy named Elio Perlman and a visiting 24-year-old American Jewish scholar named Oliver in 1980s Italy.\nS2. The novel chronicles their summer romance and the 20 years that follow.\nS3. The narrator, Elio Perlman, recalls the events of the summer of 1983, when he was seventeen and living with his parents in Italy.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation:\nAll the facts in the model prediction are consistent with the passages and verifiable."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 2, sentence 8 [Missing Answer]\n\nExplanation:\n1. The model prediction does not mention that part of the novel also takes place in the United States, where Elio visits Oliver 15 years later. This information is found in Passage 2, sentence 8 and is also included in the reference response. Therefore, it should be marked as \"Missing Answer\"."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The novel Call Me by Your Name by Andr\u00e9 Aciman takes place in Italy during the 1980s, where the main characters Elio Perlman and Oliver spend a summer. The story also extends to the United States, where Elio visits Oliver years later."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 40, "end": 55}, {"error type": "Irrelevant", "explanation": "", "start": 87, "end": 97}, {"error type": "Irrelevant", "explanation": "", "start": 128, "end": 227}, {"error type": "Irrelevant", "explanation": "", "start": 232, "end": 284}, {"error type": "Irrelevant", "explanation": "", "start": 295, "end": 300}, {"error type": "Irrelevant", "explanation": "", "start": 308, "end": 379}, {"error type": "Irrelevant", "explanation": "", "start": 394, "end": 407}, {"error type": "Wrong-Grounding", "explanation": "{\"passage_id\":1,\"sentence_id\":[3]}", "start": 444, "end": 449}, {"error type": "Irrelevant", "explanation": "", "start": 450, "end": 509}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 2, "sentence_id": [3]}], "corrected-prediction": "The 2007 Andr\u00e9 Aciman novel Call Me by Your Name takes place in Italy and the United States.  The early part of the novel takes place in Italy in Southern Europe, where the narrator recalls the events of the summer of about 1983. Additionally, Oliver, with whom the narrator has a romantic relationship, returns to the United States in the novel after spending three days in Rome."}}, {"question": "When is harry potter and cursed child coming out?", "passages": [["Wizarding World", "In November 2016, Rowling confirmed that the series' story would consist of a sequence of events that occurred between the years of 1926 and 1945.", "In December 2013, J. K. Rowling announced that she was working on a \"Harry Potter\"\u2013based play, and in June 2015 it was officially titled \"Harry Potter and the Cursed Child\".", "The two-part, West End stage play, written by British playwright Jack Thorne is based on an original story by Thorne, John Tiffany and Rowling.", "It is directed by Tiffany with choreography by Steven Hoggett, set design by Christine Jones, costume design by Katrina Lindsay, lighting design by Neil Austin, music by Imogen Heap, and sound design by Gareth Fry.", "The story begins nineteen years after the events of \"Deathly Hallows\" and follows Harry Potter, now a Ministry of Magic employee, and his younger son Albus Severus Potter, who is about to attend Hogwarts.", "On 20 December 2015, it was announced that Jamie Parker, Noma Dumezweni and Paul Thornley would play Harry Potter, Hermione Granger and Ron Weasley.", "The play debuted at the Palace Theatre, London on 7 June 2016 in previews, with the official opening on 30 July.", "The script was released in book form the day after the play's world premiere."], ["Harry Potter and the Cursed Child", "Harry Potter and the Cursed Child\n\nHarry Potter and the Cursed Child is a two-part stage play written by Jack Thorne based on an original story by Thorne, J. K. Rowling and John Tiffany.", "Previews of the play began at the Palace Theatre, London on 7 June 2016, and it premiered on 30 July 2016.", "The play opened on Broadway on 22 April 2018 at the Lyric Theatre, with previews starting on 16 March 2018.", "Its cast is similar to that of the first year on West End, with returning actors Anthony Boyle, Sam Clemmett, Noma Dumezweni, Poppy Miller, Jamie Parker, Alex Price, and Paul Thornley.", "The story begins nineteen years after the events of \"Harry Potter and the Deathly Hallows\" and follows Harry Potter, now a Ministry of Magic employee, and his younger son Albus Severus Potter, who is about to attend Hogwarts School of Witchcraft and Wizardry.", "At the 2017 Laurence Olivier Awards, the London production received a record-breaking eleven nominations and an again record-breaking nine awards, including Best New Play, Best Actor, Best Actor in a Supporting Role, Best Actress in a Supporting Role and Best Director.", "At the 2018 Tony Awards, the Broadway production won six awards, including Best Play."], ["Harry Potter and the Cursed Child", "In mid-July\u00a02016, the theatre began holding a ticket lottery at 1\u00a0pm each Friday, releasing 40 for sale on their website for \"some of the best seats\" in the theatre for the lowest price, advertised at \u00a320\u00a0per part.", "For example, the \"Friday Forty\" tickets sold on 29\u00a0July 2016 were for performances on 3, 5, 6, and 7\u00a0August.", "On 20\u00a0December 2015, initial casting was announced with Jamie Parker playing Harry Potter, Noma Dumezweni playing Hermione Granger and Paul Thornley playing Ron Weasley.", "The casting of the dark-skinned Noma Dumezweni as Hermione sparked fervent discussion, to which Rowling responded that Hermione's skin was never specified as white.", "Further notable casting includes Poppy Miller as Ginny Potter, Alex Price as Draco Malfoy, Sam Clemmett as Albus Severus Potter and Anthony Boyle as Scorpius Malfoy.", "The production features an overall cast of 42.", "The production began previews on 16 March 2018, officially opening on 22 April at the Lyric Theatre.", "Clemmett, Boyle, Dumezweni, Miller, Parker, Price and Thornley reprised their roles, from the West End.", "The theatre removed 400 seats from the auditorium and moved the entrance to 43rd Street."]], "gold": "Harry Potter and the Cursed Child is a two part British play written by Jack Thorne based on an original story by J. K. Rowling, John Tiffany, and Thorne.  It began previews June 7,2016 at the Palace Theater,  London, it premiered July 30,2016. Previews for the Broadway production began at the Lyric Theater, March 16,2018. It premiered April 22,2018. The cast was similar to that of the first year in the West End.", "prediction 1": "Harry Potter and the Cursed Child is a 2016-based British stage play written by British playwright Jack Thorne based on an original story by Thorne, J. K. Rowling, John Tiffany, and Rowling. It was first performed on April 22, 2018 at the Lyric Theatre in Brooklyn, New York. The London production debuted on June 7, 2016, with previews starting on March 16, 2018 and it opened on July 30, 2016. The play opened on Broadway on April 22, 2018 at the Lyric Theatre in Brooklyn, New York City on June 22, 2018 at the Lyric Theatre, Brooklyn Theatre in Philadelphia on April 22, 2018. The play opened on June 22, 2018 at the Palace Theatre, with previews starting on March 16, with previews starting on March 22, 2018 at the Lyric Theatre in New York City Center in New York City.", "prediction 2": "Harry Potter and the Cursed Child is a 2016 British stage play written by Jack Thorne based on an original story by Thorne, John Tiffany and Rowling. The two-part, West End stage play was released on 7 June 2016 and its premiere was on 30 July 2016. It opened on Broadway on 22 April 2018 at the Lyric Theatre.", "prediction 3": "Harry Potter and the Cursed Child is a two-part stage play written by British playwright Jack Thorne based on an original story by Thorne, John Tiffany and Rowling. The West End play, written by Thorne, opened in previews on 7 June 2016 in London and opened on 30 July 2016. The Broadway production opened in New York City on 22 April 2018 beginning previews on 16 March 2018.", "prediction 4": "Harry Potter and the Cursed Child is a two-part stage play written by British playwright Jack Thorne based on an original story by Thorne, John Tiffany and Rowling. The two-part, West End stage play, written by British playwright Jack Thorne, debuted at the Palace Theatre, London on 7 June 2016 in previews, with the official opening on 30 July 2016. The play opened on Broadway on 22 April 2018 at the Lyric Theatre, with previews starting on 16 March 2018.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 396, "end": 776}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 2, "sentence_id": [2]}], "corrected-prediction": "Harry Potter and the Cursed Child is a British stage play written by Jack Thorne based on an original story by Thorne, J. K. Rowling, John Tiffany, and Rowling. The London production debuted with previews starting on June 7, 2016 and it officially opened on July 30, 2016. The play opened on Broadway at the Lyric Theatre, with previews starting on March 16, 2018 and it officially premiered on April 22, 2018."}, "preference": [2, 2, 2, 1, 1, 0], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Wizarding World\nS1. In November 2016, Rowling confirmed that the series' story would consist of a sequence of events that occurred between the years of 1926 and 1945.\nS2. In December 2013, J. K. Rowling announced that she was working on a \"Harry Potter\"\u2013based play, and in June 2015 it was officially titled \"Harry Potter and the Cursed Child\".\nS3. The two-part, West End stage play, written by British playwright Jack Thorne is based on an original story by Thorne, John Tiffany and Rowling.\nS4. It is directed by Tiffany with choreography by Steven Hoggett, set design by Christine Jones, costume design by Katrina Lindsay, lighting design by Neil Austin, music by Imogen Heap, and sound design by Gareth Fry.\nS5. The story begins nineteen years after the events of \"Deathly Hallows\" and follows Harry Potter, now a Ministry of Magic employee, and his younger son Albus Severus Potter, who is about to attend Hogwarts.\nS6. On 20 December 2015, it was announced that Jamie Parker, Noma Dumezweni and Paul Thornley would play Harry Potter, Hermione Granger and Ron Weasley.\nS7. The play debuted at the Palace Theatre, London on 7 June 2016 in previews, with the official opening on 30 July.\nS8. The script was released in book form the day after the play's world premiere.\n\nPassage 2: Title (S0) - Harry Potter and the Cursed Child\nS1. Harry Potter and the Cursed Child  Harry Potter and the Cursed Child is a two-part stage play written by Jack Thorne based on an original story by Thorne, J. K. Rowling and John Tiffany.\nS2. Previews of the play began at the Palace Theatre, London on 7 June 2016, and it premiered on 30 July 2016.\nS3. The play opened on Broadway on 22 April 2018 at the Lyric Theatre, with previews starting on 16 March 2018.\nS4. Its cast is similar to that of the first year on West End, with returning actors Anthony Boyle, Sam Clemmett, Noma Dumezweni, Poppy Miller, Jamie Parker, Alex Price, and Paul Thornley.\nS5. The story begins nineteen years after the events of \"Harry Potter and the Deathly Hallows\" and follows Harry Potter, now a Ministry of Magic employee, and his younger son Albus Severus Potter, who is about to attend Hogwarts School of Witchcraft and Wizardry.\nS6. At the 2017 Laurence Olivier Awards, the London production received a record-breaking eleven nominations and an again record-breaking nine awards, including Best New Play, Best Actor, Best Actor in a Supporting Role, Best Actress in a Supporting Role and Best Director.\nS7. At the 2018 Tony Awards, the Broadway production won six awards, including Best Play.\n\nPassage 3: Title (S0) - Harry Potter and the Cursed Child\nS1. In mid-July\u00a02016, the theatre began holding a ticket lottery at 1\u00a0pm each Friday, releasing 40 for sale on their website for \"some of the best seats\" in the theatre for the lowest price, advertised at \u00a320\u00a0per part.\nS2. For example, the \"Friday Forty\" tickets sold on 29\u00a0July 2016 were for performances on 3, 5, 6, and 7\u00a0August.\nS3. On 20\u00a0December 2015, initial casting was announced with Jamie Parker playing Harry Potter, Noma Dumezweni playing Hermione Granger and Paul Thornley playing Ron Weasley.\nS4. The casting of the dark-skinned Noma Dumezweni as Hermione sparked fervent discussion, to which Rowling responded that Hermione's skin was never specified as white.\nS5. Further notable casting includes Poppy Miller as Ginny Potter, Alex Price as Draco Malfoy, Sam Clemmett as Albus Severus Potter and Anthony Boyle as Scorpius Malfoy.\nS6. The production features an overall cast of 42.\nS7. The production began previews on 16 March 2018, officially opening on 22 April at the Lyric Theatre.\nS8. Clemmett, Boyle, Dumezweni, Miller, Parker, Price and Thornley reprised their roles, from the West End.\nS9. The theatre removed 400 seats from the auditorium and moved the entrance to 43rd Street.\n    \nInput Question:\nWhen is harry potter and cursed child coming out?\n\nCorrect Response:\nHarry Potter and the Cursed Child is a two part British play written by Jack Thorne based on an original story by J. K. Rowling, John Tiffany, and Thorne.  It began previews June 7,2016 at the Palace Theater,  London, it premiered July 30,2016. Previews for the Broadway production began at the Lyric Theater, March 16,2018. It premiered April 22,2018. The cast was similar to that of the first year in the West End.\n\nModel Prediction:\nHarry Potter and the Cursed Child is a 2016-based British stage play written by British playwright Jack Thorne based on an original story by Thorne, J. K. Rowling, John Tiffany, and Rowling. It was first performed on April 22, 2018 at the Lyric Theatre in Brooklyn, New York. The London production debuted on June 7, 2016, with previews starting on March 16, 2018 and it opened on July 30, 2016. The play opened on Broadway on April 22, 2018 at the Lyric Theatre in Brooklyn, New York City on June 22, 2018 at the Lyric Theatre, Brooklyn Theatre in Philadelphia on April 22, 2018. The play opened on June 22, 2018 at the Palace Theatre, with previews starting on March 16, with previews starting on March 22, 2018 at the Lyric Theatre in New York City Center in New York City.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "Harry Potter and the Cursed Child is a 2016-based British stage play written by British playwright Jack Thorne based on an original story by Thorne, J. K. Rowling, John Tiffany, and Rowling. It was first performed on April 22, 2018 at the Lyric Theatre in Brooklyn, New York. The London production debuted on June 7, 2016, with previews starting on March 16, 2018 and it opened on July 30, 2016. [The play opened on Broadway on April 22, 2018 at the Lyric Theatre in Brooklyn, New York City on June 22, 2018 at the Lyric Theatre, Brooklyn Theatre in Philadelphia on April 22, 2018. The play opened on June 22, 2018 at the Palace Theatre, with previews starting on March 16, with previews starting on March 22, 2018 at the Lyric Theatre in New York City Center in New York City.]\n\nExplanation:\nThe last two sentences in the model prediction are repetitive and contain irrelevant information. The repeated information is about the play opening on Broadway on April 22, 2018 at the Lyric Theatre. The irrelevant information includes the incorrect dates and locations such as \"June 22, 2018 at the Lyric Theatre, Brooklyn Theatre in Philadelphia on April 22, 2018\" and \"June 22, 2018 at the Palace Theatre, with previews starting on March 16, with previews starting on March 22, 2018 at the Lyric Theatre in New York City Center in New York City.\" which are not mentioned in the passages."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. Harry Potter and the Cursed Child is a 2016-based British stage play written by British playwright Jack Thorne based on an original story by Thorne, J. K. Rowling, John Tiffany, and Rowling.\nS2. It was first performed on April 22, 2018 at the Lyric Theatre in Brooklyn, New York.\nS3. The London production debuted on June 7, 2016, with previews starting on March 16, 2018 and it opened on July 30, 2016.\nS4. The play opened on Broadway on April 22, 2018 at the Lyric Theatre in Brooklyn, New York City on June 22, 2018 at the Lyric Theatre, Brooklyn Theatre in Philadelphia on April 22, 2018.\nS5. The play opened on June 22, 2018 at the Palace Theatre, with previews starting on March 16, with previews starting on March 22, 2018 at the Lyric Theatre in New York City Center in New York City.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "Inconsistent or Unverifiable Sentences:\n1. S2\n2. S3\n3. S4\n4. S5\n\nExplanation:\n1. The second sentence is factually inconsistent with the passages. The play was not performed at the Lyric Theatre in Brooklyn, New York, but at the Lyric Theatre on Broadway (Passage 2, sentence 3).\n2. The third sentence is factually inconsistent. The London production did not start previews on March 16, 2018. It started previews on June 7, 2016 (Passage 1, sentence 7).\n3. The fourth sentence contains unverifiable facts. The play did not open at the Lyric Theatre in Brooklyn, New York City on June 22, 2018, nor at the Lyric Theatre, Brooklyn Theatre in Philadelphia on April 22, 2018. These facts are not mentioned in any of the passages.\n4. The fifth sentence contains unverifiable facts. The play did not open on June 22, 2018 at the Palace Theatre, nor did previews start on March 22, 2018 at the Lyric Theatre in New York City Center in New York City. These facts are not mentioned in any of the passages."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 2, sentence 2 [Missing Answer]\n2. Passage 2, sentence 3 [Missing Answer]\n\nExplanation:\n1. The model prediction does not mention the exact premiere date of the play in London, which is July 30, 2016 (Passage 2, sentence 2). This is a missing answer.\n2. The model prediction also does not mention the exact premiere date of the play on Broadway, which is April 22, 2018 (Passage 2, sentence 3). This is another missing answer."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "Harry Potter and the Cursed Child is a British stage play written by Jack Thorne based on an original story by Thorne, J. K. Rowling, John Tiffany, and Rowling. The London production debuted with previews starting on June 7, 2016 and it officially opened on July 30, 2016. The play opened on Broadway at the Lyric Theatre, with previews starting on March 16, 2018 and it officially premiered on April 22, 2018."}], "feedback_human": {"errors": [{"error type": "Redundant", "explanation": "Harry Potter and the Cursed Child is a 2016-based British stage play written by British playwright Jack Thorne based on an original story by Thorne, J. K. Rowling, John Tiffany, ", "start": 178, "end": 190}, {"error type": "Irrelevant", "explanation": "", "start": 80, "end": 98}, {"error type": "Wrong-Grounding", "explanation": "{\"passage_id\":1,\"sentence_id\":[7]}", "start": 217, "end": 275}, {"error type": "Wrong-Grounding", "explanation": "{\"passage_id\":1,\"sentence_id\":[7]}", "start": 349, "end": 363}, {"error type": "Redundant", "explanation": " The play opened on Broadway on April 22, 2018 at the Lyric Theatre in Brooklyn, New York City ", "start": 490, "end": 545}, {"error type": "Unverifiable", "explanation": "", "start": 549, "end": 561}, {"error type": "Unverifiable", "explanation": "", "start": 476, "end": 489}, {"error type": "Unverifiable", "explanation": "", "start": 738, "end": 751}, {"error type": "Redundant", "explanation": "The play opened on June 22, 2018 at the Palace Theatre, with previews starting on March 16, with previews starting on March 22, 2018 at the Lyric Theatre in New York City ", "start": 752, "end": 776}, {"error type": "Redundant", "explanation": "The play opened on Broadway on April 22, 2018 at the Lyric Theatre in Brooklyn, New York City on June 22, 2018 at the Lyric Theatre, Brooklyn Theatre in Philadelphia on April 22, 2018. ", "start": 581, "end": 636}, {"error type": "Redundant", "explanation": "The play opened on June 22, 2018 at the Palace Theatre, with previews starting on March 16, ", "start": 673, "end": 698}, {"error type": "Wrong-Grounding", "explanation": "{\"passage_id\":2,\"sentence_id\":[3]}", "start": 699, "end": 708}], "missing-info": [{"error type": "Missing-Minor-Auxiliary", "passage_id": 2, "sentence_id": [4]}], "corrected-prediction": "Harry Potter and the Cursed Child is a 2016-based British stage play written by Jack Thorne based on an original story by Thorne, J. K. Rowling, John Tiffany, and Rowling. The play debuted at the Palace Theatre, London on 7 June 2016 in previews, with the official opening on 30 July. The play opened on Broadway on 22 April 2018 at the Lyric Theatre, with previews starting on 16 March 2018. Its cast is similar to that of the first year on West End."}}, {"question": "How much did titanic make at the box office?", "passages": [["Titanic (1953 film)", "Titanic (1953 film)\n\n", "Titanic is a 1953 American drama film directed by Jean Negulesco.", "Its plot centers on an estranged couple sailing on the ill-fated maiden voyage of the , which took place in April 1912.", "The film was released a day after the 41st anniversary of the sinking of the ocean liner.", "At the last minute, a wealthy American expatriate in Europe, Richard Sturges (Clifton Webb), buys a steerage-class ticket (the lowest class) for the maiden voyage of the RMS \"Titanic\" from a Basque immigrant.", "Once aboard he seeks out his runaway wife, Julia (Barbara Stanwyck).", "He discovers she is trying to take their two unsuspecting children, 18-year-old Annette (Audrey Dalton) and ten-year-old Norman (Harper Carter), to her hometown of Mackinac, Michigan, to raise as down-to-earth Americans rather than rootless elitists like Richard himself.", "As the ship prepares for departure, her captain, E. J. Smith (Brian Aherne), receives a hint from the shipping company representative that a record-setting speedy passage would be welcomed."], ["Titanic (1997 film)", "Titanic (1997 film)\n\n", "Titanic is a 1997 American epic romance and disaster film directed, written, co-produced and co-edited by James Cameron.", "A fictionalized account of the sinking of the RMS \"Titanic\", it stars Leonardo DiCaprio and Kate Winslet as members of different social classes who fall in love aboard the ship during its ill-fated maiden voyage.", "Cameron's inspiration for the film came from his fascination with shipwrecks; he felt a love story interspersed with the human loss would be essential to convey the emotional impact of the disaster.", "Production began in 1995, when Cameron shot footage of the actual \"Titanic\" wreck.", "The modern scenes on the research vessel\" \"were shot on board the \"Akademik Mstislav Keldysh\", which Cameron had used as a base when filming the wreck.", "Scale models, computer-generated imagery, and a reconstruction of the \"Titanic\" built at Baja Studios, at Playas de Rosarito in Baja California were used to re-create the sinking.", "The film was partially funded by Paramount Pictures and 20th Century Fox; the former handled distribution in North America while Fox released the film internationally.", "It was the most expensive film ever made at the time, with a production budget of $200\u00a0million.", "Upon its release on December 19, 1997, \"Titanic\" achieved critical and commercial success."], ["Titanic (1997 film)", "20th Century Fox and Paramount Pictures co-financed \"Titanic\", with Paramount handling the North American distribution and Fox handling the international release.", "They expected Cameron to complete the film for a release on July 2, 1997.", "The film was to be released on this date \"in order to exploit the lucrative summer season ticket sales when blockbuster films usually do better\".", "In April, Cameron said the film's special effects were too complicated and that releasing the film for summer would not be possible.", "With production delays, Paramount pushed back the release date to December 19, 1997.", "\"This fueled speculation that the film itself was a disaster.\"", "A preview screening in Minneapolis on July 14 \"generated positive reviews\" and \"[c]hatter on the internet was responsible for more favorable word of mouth about the [film]\".", "This eventually led to more positive media coverage.", "The film premiered on November 1, 1997, at the Tokyo International Film Festival, where reaction was described as \"tepid\" by \"The New York Times\".", "Positive reviews started to appear back in the United States; the official Hollywood premiere occurred on December 14, 1997, where \"the big movie stars who attended the opening were enthusiastically gushing about the film to the world media\"."]], "gold": "There are several movies based on the ill-fated maiden voyage of the RMS Titanic and named after the ship. One of them was directed by Jean Negulesco, starred Clifton Webb and Barbara Stanwyck and was released in 1953, making a total of $2,250,000 at the box office. In 1997, James Cameron directed an epic romance and disaster film starring Leonardo DiCaprio and Kate Winslet as members of different social classes who fall in love aboard the ship. The film premiered on November 1, 1997, at the Tokyo International Film Festival and received a steady attendance after opening in North America, where, by the end of that same weekend, theaters were beginning to sell out, ultimately leading to the movie making a grand total of $2.187 billion on the box office throughout its original release.", "prediction 1": "Titanic is a 1953 American drama film directed by Jean Negulesco. Its plot centers on an estranged couple sailing on the ill-fated maiden voyage of the RMS Titanic, which took place in April 1912. The film was released a day after the 41st anniversary of the sinking of the ocean liner. It was the most expensive film ever made at the time, with a production budget of $200 million. The 1997 American epic romance film Titanic achieved critical and commercial success.", "prediction 2": "Titanic was a 1953 American drama film directed by Jean Negulesco, whose plot centers on an estranged couple sailing on the ill-fated maiden voyage of the RMS Titanic. The film was released on the 41st anniversary of the sinking of the ocean liner, and made $80 million in North America. The 1997 American epic romance and disaster film, Titanic, was released on December 19, 1997, and made $85 million worldwide.", "prediction 3": "Titanic is a 1953 American drama film directed by Jean Negulesco. Its plot centers on an estranged couple sailing on the ill-fated maiden voyage of the RMS Titanic, which took place in April 1912. The film was released a day after the 41st anniversary of the sinking of the ocean liner. In 1997, James Cameron directed the epic romance and disaster film, Titanic, which was the most expensive film ever made at the time, with a production budget of $200 million. The film made over $800 million at the worldwide box office. In the United States, it grossed $800 million at the domestic box office.", "prediction 4": "Titanic is a 1953 American drama film directed by Jean Negulesco. The film's plot centers on an estranged couple sailing on the ill-fated maiden voyage of the RMS Titanic. The 1997 American epic romance and disaster film Titanic was released on December 19, 1997. It was the most expensive film ever made at the time, with a production budget of $200 million.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 287, "end": 382}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 1, "sentence_id": [4]}], "corrected-prediction": "The 1953 American drama film Titanic, directed by Jean Negulesco, centered on an estranged couple sailing on the ill-fated maiden voyage of the RMS Titanic. The film was released a day after the 41st anniversary of the sinking of the ocean liner. The 1997 American epic romance film Titanic, directed by James Cameron, achieved critical and commercial success. However, the box office earnings for both films are not mentioned in the provided passages."}, "preference": [0, 1, 0, 1, 0, 2], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Titanic (1953 film)\nS1. Titanic (1953 film)  \nS2. Titanic is a 1953 American drama film directed by Jean Negulesco.\nS3. Its plot centers on an estranged couple sailing on the ill-fated maiden voyage of the , which took place in April 1912.\nS4. The film was released a day after the 41st anniversary of the sinking of the ocean liner.\nS5. At the last minute, a wealthy American expatriate in Europe, Richard Sturges (Clifton Webb), buys a steerage-class ticket (the lowest class) for the maiden voyage of the RMS \"Titanic\" from a Basque immigrant.\nS6. Once aboard he seeks out his runaway wife, Julia (Barbara Stanwyck).\nS7. He discovers she is trying to take their two unsuspecting children, 18-year-old Annette (Audrey Dalton) and ten-year-old Norman (Harper Carter), to her hometown of Mackinac, Michigan, to raise as down-to-earth Americans rather than rootless elitists like Richard himself.\nS8. As the ship prepares for departure, her captain, E. J. Smith (Brian Aherne), receives a hint from the shipping company representative that a record-setting speedy passage would be welcomed.\n\nPassage 2: Title (S0) - Titanic (1997 film)\nS1. Titanic (1997 film)  \nS2. Titanic is a 1997 American epic romance and disaster film directed, written, co-produced and co-edited by James Cameron.\nS3. A fictionalized account of the sinking of the RMS \"Titanic\", it stars Leonardo DiCaprio and Kate Winslet as members of different social classes who fall in love aboard the ship during its ill-fated maiden voyage.\nS4. Cameron's inspiration for the film came from his fascination with shipwrecks; he felt a love story interspersed with the human loss would be essential to convey the emotional impact of the disaster.\nS5. Production began in 1995, when Cameron shot footage of the actual \"Titanic\" wreck.\nS6. The modern scenes on the research vessel\" \"were shot on board the \"Akademik Mstislav Keldysh\", which Cameron had used as a base when filming the wreck.\nS7. Scale models, computer-generated imagery, and a reconstruction of the \"Titanic\" built at Baja Studios, at Playas de Rosarito in Baja California were used to re-create the sinking.\nS8. The film was partially funded by Paramount Pictures and 20th Century Fox; the former handled distribution in North America while Fox released the film internationally.\nS9. It was the most expensive film ever made at the time, with a production budget of $200\u00a0million.\nS10. Upon its release on December 19, 1997, \"Titanic\" achieved critical and commercial success.\n\nPassage 3: Title (S0) - Titanic (1997 film)\nS1. 20th Century Fox and Paramount Pictures co-financed \"Titanic\", with Paramount handling the North American distribution and Fox handling the international release.\nS2. They expected Cameron to complete the film for a release on July 2, 1997.\nS3. The film was to be released on this date \"in order to exploit the lucrative summer season ticket sales when blockbuster films usually do better\".\nS4. In April, Cameron said the film's special effects were too complicated and that releasing the film for summer would not be possible.\nS5. With production delays, Paramount pushed back the release date to December 19, 1997.\nS6. \"This fueled speculation that the film itself was a disaster.\"\nS7. A preview screening in Minneapolis on July 14 \"generated positive reviews\" and \"[c]hatter on the internet was responsible for more favorable word of mouth about the [film]\".\nS8. This eventually led to more positive media coverage.\nS9. The film premiered on November 1, 1997, at the Tokyo International Film Festival, where reaction was described as \"tepid\" by \"The New York Times\".\nS10. Positive reviews started to appear back in the United States; the official Hollywood premiere occurred on December 14, 1997, where \"the big movie stars who attended the opening were enthusiastically gushing about the film to the world media\".\n    \nInput Question:\nHow much did titanic make at the box office?\n\nCorrect Response:\nThere are several movies based on the ill-fated maiden voyage of the RMS Titanic and named after the ship. One of them was directed by Jean Negulesco, starred Clifton Webb and Barbara Stanwyck and was released in 1953, making a total of $2,250,000 at the box office. In 1997, James Cameron directed an epic romance and disaster film starring Leonardo DiCaprio and Kate Winslet as members of different social classes who fall in love aboard the ship. The film premiered on November 1, 1997, at the Tokyo International Film Festival and received a steady attendance after opening in North America, where, by the end of that same weekend, theaters were beginning to sell out, ultimately leading to the movie making a grand total of $2.187 billion on the box office throughout its original release.\n\nModel Prediction:\nTitanic is a 1953 American drama film directed by Jean Negulesco. Its plot centers on an estranged couple sailing on the ill-fated maiden voyage of the RMS Titanic, which took place in April 1912. The film was released a day after the 41st anniversary of the sinking of the ocean liner. It was the most expensive film ever made at the time, with a production budget of $200 million. The 1997 American epic romance film Titanic achieved critical and commercial success.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "Titanic is a 1953 American drama film directed by Jean Negulesco. Its plot centers on an estranged couple sailing on the ill-fated maiden voyage of the RMS Titanic, which took place in April 1912. The film was released a day after the 41st anniversary of the sinking of the ocean liner. [It was the most expensive film ever made at the time, with a production budget of $200 million.] The 1997 American epic romance film Titanic achieved critical and commercial success.\n\nExplanation:\nThe information about the 1953 film being the most expensive film ever made at the time with a production budget of $200 million is irrelevant to the question asked. The question is about the box office earnings of the movie Titanic, not its production budget."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. Titanic is a 1953 American drama film directed by Jean Negulesco.\nS2. Its plot centers on an estranged couple sailing on the ill-fated maiden voyage of the RMS Titanic, which took place in April 1912.\nS3. The film was released a day after the 41st anniversary of the sinking of the ocean liner.\nS4. It was the most expensive film ever made at the time, with a production budget of $200 million.\nS5. The 1997 American epic romance film Titanic achieved critical and commercial success.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "S4\n\nExplanation:\nThe claim that the 1953 film Titanic was the most expensive film ever made at the time with a production budget of $200 million is inconsistent with the passages. The passages do not provide any information to support this claim. The $200 million budget is actually mentioned in the context of the 1997 film Titanic, not the 1953 version."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 4 [Missing Answer]\n2. Passage 2, sentence 9 [Missing Answer]\n3. Passage 3, sentence 5 [Missing Major Auxiliary Information]\n\nExplanation:\n1. The model prediction does not include the box office earnings of the 1953 film Titanic, which is a direct answer to the question.\n2. The model prediction also does not include the box office earnings of the 1997 film Titanic, which is another direct answer to the question.\n3. The model prediction does not mention the release date of the 1997 film Titanic, which is a major piece of auxiliary information that helps to understand the context of its box office success."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The 1953 American drama film Titanic, directed by Jean Negulesco, centered on an estranged couple sailing on the ill-fated maiden voyage of the RMS Titanic. The film was released a day after the 41st anniversary of the sinking of the ocean liner. The 1997 American epic romance film Titanic, directed by James Cameron, achieved critical and commercial success. However, the box office earnings for both films are not mentioned in the provided passages."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 165, "end": 196}, {"error type": "Irrelevant", "explanation": "", "start": 197, "end": 286}, {"error type": "Irrelevant", "explanation": "", "start": 287, "end": 382}], "missing-info": [{"error type": "Missing-Minor-Auxiliary", "passage_id": 1, "sentence_id": [5]}, {"error type": "Missing-Minor-Auxiliary", "passage_id": 1, "sentence_id": [6]}, {"error type": "Missing-Minor-Auxiliary", "passage_id": 2, "sentence_id": [2]}, {"error type": "Missing-Minor-Auxiliary", "passage_id": 2, "sentence_id": [3]}, {"error type": "Missing-Minor-Auxiliary", "passage_id": 3, "sentence_id": [9]}], "corrected-prediction": "Titanic is a 1953 American drama film directed by Jean Negulesco. Its plot centers on an estranged couple sailing on the ill-fated maiden voyage of the RMS Titanic, and starred Clifton Webb and Barbara Stanwyck.  The 1997 American epic romance film Titanic, directed by James Cameron, achieved critical and commercial success. A fictionalized account of the sinking of the RMS \"Titanic\", it stars Leonardo DiCaprio and Kate Winslet as members of different social classes who fall in love aboard the ship during its ill-fated maiden voyage. The film premiered on November 1, 1997, at the Tokyo International Film Festival."}}, {"question": "When was the last time the statue of liberty was cleaned?", "passages": [["Conservation-restoration of the Statue of Liberty", "Conservation-restoration of the Statue of Liberty\n\nA centennial conservation-restoration of the Statue of Liberty (\"Liberty Enlightening the World\") occurred between 1984 and 1986.", "The Statue of Liberty, by French sculptor Fr\u00e9d\u00e9ric Auguste Bartholdi, is a colossal artwork on Liberty Island in New York Harbor, and is a part of the Statue of Liberty National Monument.", "Much of the restoration effort was based on unprecedented restorative methods, as metallurgical repair work on such a large scale had never been attempted.", "Many scientists, engineers, government organizations, and professional consultants evaluated and dealt with the various problems and tasks facing the restoration effort.", "The restored statue was reopened during Liberty Weekend, its 100-year anniversary celebration held July 3\u20136, 1986.", "The preparations for the centennial celebration of the Statue of Liberty began in 1979.", "Formed by the National Park Service (NPS), the custodians of the statue since 1933, to investigate possible development alternatives[incomplete sentence].", "A report titled \"Analysis of Alternatives\", published in December 1980, proposed measures to remedy the certain conditions confronting visitors to the Statue of Liberty, such as the long lines and waiting time to enter the crown of the statue."], ["Effects of Hurricane Sandy in New York", "Governor Cuomo signed an executive order saying that displaced New Yorkers could vote in the 2012 United States elections at any polling place in the state.", "On November 7, Governor Cuomo fired Steven Kuhr, the head of the New York Office of Emergency Management, after Cuomo discovered that Kuhr had sent Suffolk County workers to clear a tree in his Long Island driveway as other victims needed help.", "A day later, Cuomo said that the estimated storm damage in New York state was $33 billion.", "New York City and the counties of Nassau and Suffolk imposed \"odd-even\" gasoline rationing, as New Jersey had, to ease congestion and frustration at filling stations.", "The system began on November 9 in the wake of a shortage.", "Cuomo also temporarily waived certain taxes and pollution restrictions on fuel deliveries.", "New York City schools remained closed through Friday, November 2 with classes resuming Monday for most students; but as many as 40,000 stayed home until November 7.", "Fifty-seven schools were still flooded as of that date.", "Many colleges and universities and K-12 schools in the tri-state area also cancelled classes.", "The Statue of Liberty was closed October 29, a day after its grand reopening.", "Both the statue and Ellis Island remained closed through 2012; the statue reopened July 4, 2013, while Ellis Island remained closed until 2014."]], "gold": "The Statue of Liberty has been cleaned on various occasions. The first was a centennial conservation-restoration of the Statue of Liberty which occurred between 1984-1986. During the Hurricane Sandy, the Statue of Liberty was closed October 29, a day after its grand reopening from a year-long renovation project. Both the statue and Ellis Island remained closed through 2012; the statue reopened July 4, 2013, thus the cleaning took place between 2012-2013.", "prediction 1": "The Statue of Liberty, by French sculptor Fr\u00e9d\u00e9ric Auguste Bartholdi, is a colossal artwork on Liberty Island in New York Harbor and is a part of the Statue of Liberty National Monument. A centennial conservation-restoration of the Statue of Liberty occurred between 1984 and 1986. The restored statue was reopened during Liberty Weekend, its 100-year anniversary celebration held July 3\u20136, 1986.", "prediction 2": "The last time the statue of liberty was cleaned was on September 14, 2013. The last time the statue of liberty was cleaned was on September 25, 2012.", "prediction 3": "The Statue of Liberty, by French sculptor Fr\u00e9d\u00e9ric Auguste Bartholdi, is a colossal artwork on Liberty Island in New York Harbor, and is part of the Statue of Liberty National Monument. A centennial conservation-restoration of the Statue of Liberty occurred between 1984 and 1986. The restored statue was reopened during Liberty Weekend, its 100-year anniversary celebration held July 3\u20136, 1986.", "prediction 4": "The last time the Statue of Liberty was cleaned was on July 1, 1987. In the year that followed, the statue was cleaned on July 7, 1988. In the year that followed, the statue was cleaned on July 13, 1988.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 0, "end": 186}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 2, "sentence_id": [10]}], "corrected-prediction": "A centennial conservation-restoration of the Statue of Liberty occurred between 1984 and 1986. The restored statue was reopened during Liberty Weekend, its 100-year anniversary celebration held July 3\u20136, 1986. Additionally, the Statue of Liberty was closed on October 29, a day after its grand reopening. Both the statue and Ellis Island remained closed through 2012; the statue reopened July 4, 2013, indicating another cleaning period."}, "preference": [1, 0, 1, 2, 2, 1], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Conservation-restoration of the Statue of Liberty\nS1. Conservation-restoration of the Statue of Liberty  A centennial conservation-restoration of the Statue of Liberty (\"Liberty Enlightening the World\") occurred between 1984 and 1986.\nS2. The Statue of Liberty, by French sculptor Fr\u00e9d\u00e9ric Auguste Bartholdi, is a colossal artwork on Liberty Island in New York Harbor, and is a part of the Statue of Liberty National Monument.\nS3. Much of the restoration effort was based on unprecedented restorative methods, as metallurgical repair work on such a large scale had never been attempted.\nS4. Many scientists, engineers, government organizations, and professional consultants evaluated and dealt with the various problems and tasks facing the restoration effort.\nS5. The restored statue was reopened during Liberty Weekend, its 100-year anniversary celebration held July 3\u20136, 1986.\nS6. The preparations for the centennial celebration of the Statue of Liberty began in 1979.\nS7. Formed by the National Park Service (NPS), the custodians of the statue since 1933, to investigate possible development alternatives[incomplete sentence].\nS8. A report titled \"Analysis of Alternatives\", published in December 1980, proposed measures to remedy the certain conditions confronting visitors to the Statue of Liberty, such as the long lines and waiting time to enter the crown of the statue.\n\nPassage 2: Title (S0) - Effects of Hurricane Sandy in New York\nS1. Governor Cuomo signed an executive order saying that displaced New Yorkers could vote in the 2012 United States elections at any polling place in the state.\nS2. On November 7, Governor Cuomo fired Steven Kuhr, the head of the New York Office of Emergency Management, after Cuomo discovered that Kuhr had sent Suffolk County workers to clear a tree in his Long Island driveway as other victims needed help.\nS3. A day later, Cuomo said that the estimated storm damage in New York state was $33 billion.\nS4. New York City and the counties of Nassau and Suffolk imposed \"odd-even\" gasoline rationing, as New Jersey had, to ease congestion and frustration at filling stations.\nS5. The system began on November 9 in the wake of a shortage.\nS6. Cuomo also temporarily waived certain taxes and pollution restrictions on fuel deliveries.\nS7. New York City schools remained closed through Friday, November 2 with classes resuming Monday for most students; but as many as 40,000 stayed home until November 7.\nS8. Fifty-seven schools were still flooded as of that date.\nS9. Many colleges and universities and K-12 schools in the tri-state area also cancelled classes.\nS10. The Statue of Liberty was closed October 29, a day after its grand reopening.\nS11. Both the statue and Ellis Island remained closed through 2012; the statue reopened July 4, 2013, while Ellis Island remained closed until 2014.\n    \nInput Question:\nWhen was the last time the statue of liberty was cleaned?\n\nCorrect Response:\nThe Statue of Liberty has been cleaned on various occasions. The first was a centennial conservation-restoration of the Statue of Liberty which occurred between 1984-1986. During the Hurricane Sandy, the Statue of Liberty was closed October 29, a day after its grand reopening from a year-long renovation project. Both the statue and Ellis Island remained closed through 2012; the statue reopened July 4, 2013, thus the cleaning took place between 2012-2013.\n\nModel Prediction:\nThe Statue of Liberty, by French sculptor Fr\u00e9d\u00e9ric Auguste Bartholdi, is a colossal artwork on Liberty Island in New York Harbor and is a part of the Statue of Liberty National Monument. A centennial conservation-restoration of the Statue of Liberty occurred between 1984 and 1986. The restored statue was reopened during Liberty Weekend, its 100-year anniversary celebration held July 3\u20136, 1986.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "[The Statue of Liberty, by French sculptor Fr\u00e9d\u00e9ric Auguste Bartholdi, is a colossal artwork on Liberty Island in New York Harbor and is a part of the Statue of Liberty National Monument.]\n\nExplanation:\n1. The first sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\"."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The Statue of Liberty, by French sculptor Fr\u00e9d\u00e9ric Auguste Bartholdi, is a colossal artwork on Liberty Island in New York Harbor and is a part of the Statue of Liberty National Monument.\nS2. A centennial conservation-restoration of the Statue of Liberty occurred between 1984 and 1986.\nS3. The restored statue was reopened during Liberty Weekend, its 100-year anniversary celebration held July 3\u20136, 1986.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation:\nAll the facts presented in the model prediction are consistent with the information provided in the passages."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 2, sentence 10 [Missing Answer]\n2. Passage 2, sentence 11 [Missing Answer]\n\nExplanation:\n1. The model prediction does not mention that the Statue of Liberty was closed on October 29, a day after its grand reopening, which is a crucial part of the answer to the question.\n2. The model prediction also misses the information that the statue and Ellis Island remained closed through 2012; the statue reopened July 4, 2013. This information is crucial to infer the last cleaning period of the statue."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "A centennial conservation-restoration of the Statue of Liberty occurred between 1984 and 1986. The restored statue was reopened during Liberty Weekend, its 100-year anniversary celebration held July 3\u20136, 1986. Additionally, the Statue of Liberty was closed on October 29, a day after its grand reopening. Both the statue and Ellis Island remained closed through 2012; the statue reopened July 4, 2013, indicating another cleaning period."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 0, "end": 186}, {"error type": "Irrelevant", "explanation": "", "start": 282, "end": 396}], "missing-info": [{"error type": "Missing-Minor-Auxiliary", "passage_id": 2, "sentence_id": [10]}, {"error type": "Missing-Minor-Auxiliary", "passage_id": 2, "sentence_id": [11]}], "corrected-prediction": "The Statue of Liberty, by French sculptor Fr\u00e9d\u00e9ric Auguste Bartholdi, is a colossal artwork on Liberty Island in New York Harbor and is a part of the Statue of Liberty National Monument. A centennial conservation-restoration of the Statue of Liberty occurred between 1984 and 1986. During the Hurricane Sandy, the Statue of Liberty was closed October 29, a day after its grand reopening. Both the statue and Ellis Island remained closed through 2012; the statue reopened July 4, 2013, while Ellis Island remained closed until 2014. "}}, {"question": "When did the packers play at camp randall?", "passages": [["Camp Randall Stadium", "When news surfaced on Monday, September 8, 2003, that this event was not a technical or human malfunction, but rather a decision by campus officials, the students launched a protest.", "Petitions circulated and students pushed back against administration.", "Structural engineers confirmed that the stadium would suffer no structural damage caused by the vibrations created by jumping.", "Two days later, Chancellor John D. Wiley announced that the \"Jump Around\" tradition would resume.", "The stadium is also used by the Wisconsin Interscholastic Athletic Association for its state football championships.", "The Green Bay Packers have played 12 exhibition games at Camp Randall, which, up until 2013, had a larger seating capacity than the Packers' home stadium, Lambeau Field.", "The series began in 1986, shortly after the Chicago Bears began to use nearby University of Wisconsin-Platteville as a training camp site.", "The most recent pre-season Packers game at Camp Randall was played in 1999.", "The University of Wisconsin men's and women's ice hockey teams each played an outdoor hockey game at Camp Randall Stadium on February 6, 2010, as part of the Culver's Camp Randall Hockey Classic.", "The Wisconsin women defeated Bemidji State 6\u20131, while the Badger men beat Michigan 3\u20132.", "Drum Corps International used the stadium as the site for its world championships in 1985, 1986, 1987, 1992, 1999, 2002, and 2006."]], "gold": "The Green Bay Packers first played at Camp Randall in 1986 and last played at Camp Randall, as of 2017, on August 23, 1999, the year of the most recent pre-season Packers game played at Camp Randall. The Green Bay Packers have played 12 exhibition games at Camp Randall.", "prediction 1": "The Green Bay Packers have played 12 exhibition games at Camp Randall, which, up until 1999, had a larger seating capacity than the Packers' home stadium, Lambeau Field. The series began in 1986, shortly after the Chicago Bears began using nearby University of Wisconsin-Platteville as a training camp site. The most recent pre-season Packers game at Camp Randall was played in 1999. The University of Wisconsin men's and women's ice hockey teams each played an outdoor hockey game at Camp Randall Stadium on February 6, 2010, as part of the Culver's Camp Randall Hockey Classic.\n", "prediction 2": "The Green Bay Packers last played at Camp Randall in September 1999.", "prediction 3": "The Green Bay Packers have played 12 exhibition games at Camp Randall, which, up until 1999, had a larger seating capacity than the Packers' home stadium, Lambeau Field. The most recent pre-season Packers game at Camp Randall was played in 1999.", "prediction 4": "The Green Bay Packers played in their first game at the Camp Randall Stadium on September 5, 1989. On February 6, 2010, the University of Wisconsin men's and women's ice hockey teams each played an outdoor hockey game at Camp Randall Stadium as part of the Culver's Camp Randall Hockey Classic. The Green Bay Packers have played 12 exhibition games at Camp Randall, which, up until 1999, had a larger seating capacity than the Packers' home stadium, Lambeau Field.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 384, "end": 579}], "missing-info": [], "corrected-prediction": "The Green Bay Packers have played 12 exhibition games at Camp Randall, which, up until 1999, had a larger seating capacity than the Packers' home stadium, Lambeau Field. The series began in 1986, shortly after the Chicago Bears began using nearby University of Wisconsin-Platteville as a training camp site. The most recent pre-season Packers game at Camp Randall was played in 1999."}, "preference": [1, 2, 1, 2, 2, 1], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Camp Randall Stadium\nS1. When news surfaced on Monday, September 8, 2003, that this event was not a technical or human malfunction, but rather a decision by campus officials, the students launched a protest.\nS2. Petitions circulated and students pushed back against administration.\nS3. Structural engineers confirmed that the stadium would suffer no structural damage caused by the vibrations created by jumping.\nS4. Two days later, Chancellor John D. Wiley announced that the \"Jump Around\" tradition would resume.\nS5. The stadium is also used by the Wisconsin Interscholastic Athletic Association for its state football championships.\nS6. The Green Bay Packers have played 12 exhibition games at Camp Randall, which, up until 2013, had a larger seating capacity than the Packers' home stadium, Lambeau Field.\nS7. The series began in 1986, shortly after the Chicago Bears began to use nearby University of Wisconsin-Platteville as a training camp site.\nS8. The most recent pre-season Packers game at Camp Randall was played in 1999.\nS9. The University of Wisconsin men's and women's ice hockey teams each played an outdoor hockey game at Camp Randall Stadium on February 6, 2010, as part of the Culver's Camp Randall Hockey Classic.\nS10. The Wisconsin women defeated Bemidji State 6\u20131, while the Badger men beat Michigan 3\u20132.\nS11. Drum Corps International used the stadium as the site for its world championships in 1985, 1986, 1987, 1992, 1999, 2002, and 2006.\n    \nInput Question:\nWhen did the packers play at camp randall?\n\nCorrect Response:\nThe Green Bay Packers first played at Camp Randall in 1986 and last played at Camp Randall, as of 2017, on August 23, 1999, the year of the most recent pre-season Packers game played at Camp Randall. The Green Bay Packers have played 12 exhibition games at Camp Randall.\n\nModel Prediction:\nThe Green Bay Packers have played 12 exhibition games at Camp Randall, which, up until 1999, had a larger seating capacity than the Packers' home stadium, Lambeau Field. The series began in 1986, shortly after the Chicago Bears began using nearby University of Wisconsin-Platteville as a training camp site. The most recent pre-season Packers game at Camp Randall was played in 1999. The University of Wisconsin men's and women's ice hockey teams each played an outdoor hockey game at Camp Randall Stadium on February 6, 2010, as part of the Culver's Camp Randall Hockey Classic.\n\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "The Green Bay Packers have played 12 exhibition games at Camp Randall, which, up until 1999, had a larger seating capacity than the Packers' home stadium, Lambeau Field. The series began in 1986, shortly after the Chicago Bears began using nearby University of Wisconsin-Platteville as a training camp site. The most recent pre-season Packers game at Camp Randall was played in 1999. [The University of Wisconsin men's and women's ice hockey teams each played an outdoor hockey game at Camp Randall Stadium on February 6, 2010, as part of the Culver's Camp Randall Hockey Classic.]\n\nExplanation:\nThe last sentence in the model prediction is irrelevant to the question asked as it does not provide any information about when the Packers played at Camp Randall. It instead provides information about a hockey game that took place at the stadium, which is not relevant to the question. Therefore, it should be marked as \"Irrelevant\"."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The Green Bay Packers have played 12 exhibition games at Camp Randall, which, up until 1999, had a larger seating capacity than the Packers' home stadium, Lambeau Field.\nS2. The series began in 1986, shortly after the Chicago Bears began using nearby University of Wisconsin-Platteville as a training camp site.\nS3. The most recent pre-season Packers game at Camp Randall was played in 1999.\nS4. The University of Wisconsin men's and women's ice hockey teams each played an outdoor hockey game at Camp Randall Stadium on February 6, 2010, as part of the Culver's Camp Randall Hockey Classic.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation:\nAll the facts presented in the model prediction are consistent with the information provided in the passages. There are no unverifiable or inconsistent facts present in the model prediction."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "None\n\nExplanation:\nThe model prediction does not miss any information that is expected to be there. It correctly mentions that the Green Bay Packers have played 12 exhibition games at Camp Randall, starting in 1986 and the most recent game being in 1999. These details are all present in the passages and are relevant to the question."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The Green Bay Packers have played 12 exhibition games at Camp Randall, which, up until 1999, had a larger seating capacity than the Packers' home stadium, Lambeau Field. The series began in 1986, shortly after the Chicago Bears began using nearby University of Wisconsin-Platteville as a training camp site. The most recent pre-season Packers game at Camp Randall was played in 1999."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 71, "end": 169}, {"error type": "Irrelevant", "explanation": "", "start": 196, "end": 307}, {"error type": "Irrelevant", "explanation": "", "start": 384, "end": 580}], "missing-info": [], "corrected-prediction": "The Green Bay Packers have played 12 exhibition games at Camp Randall, The series began in 1986. The most recent pre-season Packers game at Camp Randall was played in 1999.\n"}}, {"question": "Where does doctor strange go to get his powers?", "passages": [["Kamar-Taj", "Kamar-Taj\n\nKamar-Taj (Arabic/Persian: \u0642\u0645\u0631 \u062a\u0627\u062c \"Qamar-Taj\", meaning; \"Moon Crown\") is a fictional location appearing in American comic books published by Marvel Comics.", "It first appeared in \"Strange Tales\" #110 (July 1963) and was created by Stan Lee and Steve Ditko.", "The name \"Kamar-Taj\" does not appear in early Lee/Ditko Doctor Strange stories, but was created later as the country's backstory was fleshed out.", "Kamar-Taj is \"a hidden land high in the Himalayas\" and the homeland of Doctor Strange's mentor, the Ancient One, and of the evil sorcerer Kaluu.", "Strange's majordomo Wong also stems from a family of monks living in Kamar-Taj.", "Over 500 years ago, the man who would one day become the Ancient One was born in Kamar-Taj.", "With his friend Kaluu, he discovered the power of magic but the two friends disagreed on how to use it to protect their village.", "Kaluu sought to conquer neighboring villages and build a large empire."], ["Kamar-Taj", "The two cast a spell eliminating sickness, disease and age from Kamar-Taj and shortly afterwards Kaluu was crowned king by the villagers under Kaluu's mind-control spell.", "The Ancient One tried to stop Kaluu and in their battle the village of Kamar-Taj was wiped out.", "Kaluu was banished to an alternate dimension.", "The Ancient One left Kamar-Taj and traveled the Earth for centuries, battling evil creatures, gaining the Amulet of Agamotto and the Book of the Vishanti.", "He finally settled down in the Himalaya Mountains near Kamar-Taj, building a palace as his home with an order of monks to protect and assist him.", "In a tournament organized by the sorcerer Aged Genghis, the Ancient One won the title of Earth's Sorcerer Supreme.", "He took a student, who would one day become Mister Jip, but banned him from his home when he found out the student had been studying the forbidden books to increase his own power.", "Feeling himself getting older and weaker, the Ancient One set out to find a student.", "He taught such beings as Doctor Druid and Baron Mordo but found his true apprentice in Stephen Strange, claiming that this boy would become the new Sorcerer Supreme.", "Mordo began to plot against Strange, though the Ancient One kept protecting him."], ["Doctor Strange", "Depressed and still searching, Strange, while walking near the docks, overhears two sailors talking about a hermit called the Ancient One (who is actually the Earth's Sorcerer Supreme) in the Himalayas, who can cure any ailment.", "Strange uses the last of his funds to seek out the aged mystic.", "The Ancient One refuses to help Strange because of his arrogance, but senses a good side that he attempts to bring to the surface.", "He fails, but Strange's heroism appears when he discovers the Ancient One's disciple, Baron Mordo, attempting to kill the old man.", "After a confrontation with Mordo leads to him being shackled with restraining spells preventing him from either attacking Mordo or warning the Ancient One, Strange desperately and selflessly accepts the Ancient One's offer to become his apprentice to have some hope of helping the old man.", "The Ancient One, pleased at Strange's sincere change of heart, accepts the westerner and promptly frees him from the restraining spells while explaining he was aware of Mordo's treachery all along.", "Strange soon becomes Mordo's most enduring enemy, as the Ancient One teaches the doctor the mystic arts.", "After completing his training, Strange returns to New York City and takes up residence within the Sanctum Sanctorum, a townhouse located in Greenwich Village, and is soon assisted by his personal assistant Wong."]], "gold": "Kamar-Taj is a fictional location appearing in American comic books published by Marvel Comics. It first appeared in Strange Tales #110 and was created by Stan Lee and Steve Ditko. Kamar-Taj is \"a hidden land high in the Himalayas\" and the homeland of Doctor Strange's mentor, the Ancient One, from whom he gets his powers. At a time when he is broke and ostracized from his colleagues, Strange becomes a drifter and happens to overhear two sailors in a bar discussing a hermit called the Ancient One, who is actually the Earth's Sorcerer Supreme, in the Himalayas, who can heal any ailment. Despite not personally believing in magic, Strange uses the last of his money to track down the aged mystic, and, after Strange proves himself by committing a heroic act, the Ancient One accepts him as his new student and trains the doctor in the mystic arts.", "prediction 1": "Kamar-Taj is the homeland of Doctor Strange's mentor, the Ancient One, and of the evil sorcerer Kaluu. The Ancient One traveled the Earth for centuries, battling evil creatures, and gaining the Amulet of Agamotto and the Book of the Vishanti. He finally settled down in the Himalaya Mountains near Kamar-Taj, building a palace as his home with an order of monks to protect and assist him. Then, when Strange is depressed and still seeking, he overhear-Taj and overhear-Taj, the Ancient One promises that he would become his student. Strange then moves to New York City to take up residence within the Sanctorum Sanctorum Sanctorum Sanctorum Sanctorum Sanctorum Sanctorum, a townhouse located in Greenwich Village.", "prediction 2": "Doctor Strange went to the Himalayas to learn about the ancient mystic who is the Earth's Sorcerer Supreme. The Ancient One is a hermit who is in the mountains and teaches Strange the mystic arts. Strange is brought back to New York City to complete his training under the tutelage of the Ancient One.", "prediction 3": "The Doctor Strange story begins in Strange Tales #110 when Strange is walking near the docks and hears two sailors talking about a hermit called the Ancient One, the Earth's Sorcerer Supreme. The Ancient One traveled the Earth for centuries, fighting evil creatures, and gaining the Amulet of Agamotto and the Book of the Vishanti. He then settled down in the Himalaya Mountains near Kamar-Taj, building a palace as his home with an order of monks to protect him.", "prediction 4": "Doctor Strange visits the Himalayas to get his powers from a hermit called the Ancient One, who is actually the Earth's Sorcerer Supreme. The hermit also teaches the doctor the mystic arts and also gives him the ability to speak the language of the gods. Strange then returns to New York City to complete his training with the Ancient One.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 443, "end": 473}, {"error type": "Irrelevant", "explanation": "", "start": 601, "end": 671}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [1]}], "corrected-prediction": "Kamar-Taj, a fictional location appearing in American comic books published by Marvel Comics, is the homeland of Doctor Strange's mentor, the Ancient One, and of the evil sorcerer Kaluu. The Ancient One traveled the Earth for centuries, battling evil creatures, and gaining the Amulet of Agamotto and the Book of the Vishanti. He finally settled down in the Himalaya Mountains near Kamar-Taj, building a palace as his home with an order of monks to protect and assist him. When Strange is depressed and still searching, he overhears two sailors discussing a hermit in the Himalayas who can cure any ailment. This leads him to the Ancient One, who promises that he would become his student after Strange proves his heroism. Strange then moves to New York City to take up residence within the Sanctum Sanctorum, a townhouse located in Greenwich Village."}, "preference": [1, 1, 1, 2, 2, 1], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Kamar-Taj\nS1. Kamar-Taj  Kamar-Taj (Arabic/Persian: \u0642\u0645\u0631 \u062a\u0627\u062c \"Qamar-Taj\", meaning; \"Moon Crown\") is a fictional location appearing in American comic books published by Marvel Comics.\nS2. It first appeared in \"Strange Tales\" #110 (July 1963) and was created by Stan Lee and Steve Ditko.\nS3. The name \"Kamar-Taj\" does not appear in early Lee/Ditko Doctor Strange stories, but was created later as the country's backstory was fleshed out.\nS4. Kamar-Taj is \"a hidden land high in the Himalayas\" and the homeland of Doctor Strange's mentor, the Ancient One, and of the evil sorcerer Kaluu.\nS5. Strange's majordomo Wong also stems from a family of monks living in Kamar-Taj.\nS6. Over 500 years ago, the man who would one day become the Ancient One was born in Kamar-Taj.\nS7. With his friend Kaluu, he discovered the power of magic but the two friends disagreed on how to use it to protect their village.\nS8. Kaluu sought to conquer neighboring villages and build a large empire.\n\nPassage 2: Title (S0) - Kamar-Taj\nS1. The two cast a spell eliminating sickness, disease and age from Kamar-Taj and shortly afterwards Kaluu was crowned king by the villagers under Kaluu's mind-control spell.\nS2. The Ancient One tried to stop Kaluu and in their battle the village of Kamar-Taj was wiped out.\nS3. Kaluu was banished to an alternate dimension.\nS4. The Ancient One left Kamar-Taj and traveled the Earth for centuries, battling evil creatures, gaining the Amulet of Agamotto and the Book of the Vishanti.\nS5. He finally settled down in the Himalaya Mountains near Kamar-Taj, building a palace as his home with an order of monks to protect and assist him.\nS6. In a tournament organized by the sorcerer Aged Genghis, the Ancient One won the title of Earth's Sorcerer Supreme.\nS7. He took a student, who would one day become Mister Jip, but banned him from his home when he found out the student had been studying the forbidden books to increase his own power.\nS8. Feeling himself getting older and weaker, the Ancient One set out to find a student.\nS9. He taught such beings as Doctor Druid and Baron Mordo but found his true apprentice in Stephen Strange, claiming that this boy would become the new Sorcerer Supreme.\nS10. Mordo began to plot against Strange, though the Ancient One kept protecting him.\n\nPassage 3: Title (S0) - Doctor Strange\nS1. Depressed and still searching, Strange, while walking near the docks, overhears two sailors talking about a hermit called the Ancient One (who is actually the Earth's Sorcerer Supreme) in the Himalayas, who can cure any ailment.\nS2. Strange uses the last of his funds to seek out the aged mystic.\nS3. The Ancient One refuses to help Strange because of his arrogance, but senses a good side that he attempts to bring to the surface.\nS4. He fails, but Strange's heroism appears when he discovers the Ancient One's disciple, Baron Mordo, attempting to kill the old man.\nS5. After a confrontation with Mordo leads to him being shackled with restraining spells preventing him from either attacking Mordo or warning the Ancient One, Strange desperately and selflessly accepts the Ancient One's offer to become his apprentice to have some hope of helping the old man.\nS6. The Ancient One, pleased at Strange's sincere change of heart, accepts the westerner and promptly frees him from the restraining spells while explaining he was aware of Mordo's treachery all along.\nS7. Strange soon becomes Mordo's most enduring enemy, as the Ancient One teaches the doctor the mystic arts.\nS8. After completing his training, Strange returns to New York City and takes up residence within the Sanctum Sanctorum, a townhouse located in Greenwich Village, and is soon assisted by his personal assistant Wong.\n    \nInput Question:\nWhere does doctor strange go to get his powers?\n\nCorrect Response:\nKamar-Taj is a fictional location appearing in American comic books published by Marvel Comics. It first appeared in Strange Tales #110 and was created by Stan Lee and Steve Ditko. Kamar-Taj is \"a hidden land high in the Himalayas\" and the homeland of Doctor Strange's mentor, the Ancient One, from whom he gets his powers. At a time when he is broke and ostracized from his colleagues, Strange becomes a drifter and happens to overhear two sailors in a bar discussing a hermit called the Ancient One, who is actually the Earth's Sorcerer Supreme, in the Himalayas, who can heal any ailment. Despite not personally believing in magic, Strange uses the last of his money to track down the aged mystic, and, after Strange proves himself by committing a heroic act, the Ancient One accepts him as his new student and trains the doctor in the mystic arts.\n\nModel Prediction:\nKamar-Taj is the homeland of Doctor Strange's mentor, the Ancient One, and of the evil sorcerer Kaluu. The Ancient One traveled the Earth for centuries, battling evil creatures, and gaining the Amulet of Agamotto and the Book of the Vishanti. He finally settled down in the Himalaya Mountains near Kamar-Taj, building a palace as his home with an order of monks to protect and assist him. Then, when Strange is depressed and still seeking, he overhear-Taj and overhear-Taj, the Ancient One promises that he would become his student. Strange then moves to New York City to take up residence within the Sanctorum Sanctorum Sanctorum Sanctorum Sanctorum Sanctorum Sanctorum, a townhouse located in Greenwich Village.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "Kamar-Taj is the homeland of Doctor Strange's mentor, the Ancient One, and of the evil sorcerer Kaluu. The Ancient One traveled the Earth for centuries, battling evil creatures, and gaining the Amulet of Agamotto and the Book of the Vishanti. He finally settled down in the Himalaya Mountains near Kamar-Taj, building a palace as his home with an order of monks to protect and assist him. Then, when Strange is depressed and still seeking, he [overhear-Taj and overhear-Taj,] the Ancient One promises that he would become his student. Strange then moves to New York City to take up residence within the [Sanctorum Sanctorum Sanctorum Sanctorum Sanctorum Sanctorum Sanctorum,] a townhouse located in Greenwich Village.\n\nExplanation:\n1. The phrase \"overhear-Taj and overhear-Taj,\" is incoherent and doesn't make sense in the context of the sentence.\n2. The phrase \"Sanctorum Sanctorum Sanctorum Sanctorum Sanctorum Sanctorum Sanctorum,\" is repetitive and doesn't add any value to the sentence. It seems like a repetition error."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. Kamar-Taj is the homeland of Doctor Strange's mentor, the Ancient One, and of the evil sorcerer Kaluu.\nS2. The Ancient One traveled the Earth for centuries, battling evil creatures, and gaining the Amulet of Agamotto and the Book of the Vishanti.\nS3. He finally settled down in the Himalaya Mountains near Kamar-Taj, building a palace as his home with an order of monks to protect and assist him.\nS4. Then, when Strange is depressed and still seeking, he overhear-Taj and overhear-Taj, the Ancient One promises that he would become his student.\nS5. Strange then moves to New York City to take up residence within the Sanctorum Sanctorum Sanctorum Sanctorum Sanctorum Sanctorum Sanctorum, a townhouse located in Greenwich Village.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation:\nAll the facts mentioned in the model prediction are consistent with the information provided in the passages. There are no unverifiable or inconsistent facts."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 1 [Missing Major Auxiliary Information]\n2. Passage 3, sentence 1 [Missing Major Auxiliary Information]\n3. Passage 3, sentence 5 [Missing Major Auxiliary Information]\n\nExplanation:\n1. The model prediction does not mention that Kamar-Taj is a fictional location appearing in American comic books published by Marvel Comics, which is important context for understanding the origin of Doctor Strange's powers.\n2. The model prediction omits the information that Strange heard about the Ancient One from two sailors discussing a hermit in the Himalayas who could cure any ailment. This is a crucial part of the story of how Strange ended up in Kamar-Taj.\n3. The model prediction does not include the information that Strange accepted the Ancient One's offer to become his apprentice in order to help the old man, which is a key part of his journey to becoming Doctor Strange."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "Kamar-Taj, a fictional location appearing in American comic books published by Marvel Comics, is the homeland of Doctor Strange's mentor, the Ancient One, and of the evil sorcerer Kaluu. The Ancient One traveled the Earth for centuries, battling evil creatures, and gaining the Amulet of Agamotto and the Book of the Vishanti. He finally settled down in the Himalaya Mountains near Kamar-Taj, building a palace as his home with an order of monks to protect and assist him. When Strange is depressed and still searching, he overhears two sailors discussing a hermit in the Himalayas who can cure any ailment. This leads him to the Ancient One, who promises that he would become his student after Strange proves his heroism. Strange then moves to New York City to take up residence within the Sanctum Sanctorum, a townhouse located in Greenwich Village."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 389, "end": 532}, {"error type": "Irrelevant", "explanation": "", "start": 533, "end": 713}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [1]}, {"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [2]}, {"error type": "Missing-Minor-Auxiliary", "passage_id": 1, "sentence_id": [4]}, {"error type": "Missing-Major-Auxiliary", "passage_id": 2, "sentence_id": [6]}], "corrected-prediction": " Kamar-Taj is a fictional location appearing in American comic books published by Marvel Comics. It first appeared in Strange Tales #110 and was created by Stan Lee and Steve Ditko. Kamar-Taj is \"a hidden land high in the Himalayas\" and the homeland of Doctor Strange's mentor, the Ancient One, and of the evil sorcerer Kaluu. The Ancient One traveled the Earth for centuries, battling evil creatures, and gaining the Amulet of Agamotto and the Book of the Vishanti. He finally settled down in the Himalaya Mountains near Kamar-Taj, building a palace as his home with an order of monks to protect and assist him. In a tournament organized by the sorcerer Aged Genghis, the Ancient One won the title of Earth's Sorcerer Supreme."}}, {"question": "Who sang i only think of you on two occasions?", "passages": [["Two Occasions", "Two Occasions\n\n\"Two Occasions\" is an R&B song written by Babyface, Darnell Bristol and Sid Johnson (who was the former manager for Babyface's early group, Manchild) .", "It was produced by Babyface and L.A. Reid for The Deele's third studio album \"Eyes of a Stranger\" (1987).", "The ballad was released as the album's second single in 1988.", "It's the only song on the album that features Babyface on lead vocals, which alternate between himself, Bristol, and Carlos \"Satin\" Greene throughout the course of the song.", "It has since been remade into a live version with added vocals from Babyface with all original vocals from The Deele intact; this version appeared on the 12\" maxi single and also three years later on his album, \"A Closer Look\".", "The song and Babyface were later referenced by Mariah Carey in her 2005 hit song, \"We Belong Together.\"", "The song is also sampled in the 2009 hit song \"Want It, Need It\" by Plies featuring Ashanti.", "It was also sampled in the song \"I Still Love You\" by Next (group) on their \"Rated Next\" album.", "Rap/Hip Hop artist Charlie Manhattan, released his version of \"Two Occasions,\" in 2007, which was taken from his solo debut album, \"The Manhattan Project\"."], ["Two Occasions", "\"Faye Wong\" also sampled the song in \"Miss You Night and Day\" found in her 1992 album, \"Coming Home\".", "Craig Lytle, in his review of the album for AllMusic, called \"Two Occasions\" a \"quiet-storm classic\" with \"superb arrangement and production\", declaring the song \"worthy of a number-one ranking.\"", "In 1989, the song won a BMI Pop Award.", "Although the band's first hit \"Body Talk\" actually had a higher placement on the R&B chart, \"Two Occasions\" is widely considered The Deele's most successful single.", "It peaked at number ten on the U.S. \"Billboard\" Hot 100, number four on the Hot R&B and number twenty-one on the Adult Contemporary chart."], ["The Deele", "The Deele\n\nThe Deele (pronounced /deal/) is an American band from Cincinnati, Ohio who achieved success in the 1980s with such hit singles as \"Body Talk\" and \"Two Occasions.\"", "When the group began recording in the early 1980s, the lineup consisted of Indianapolis native Kenny \"Babyface\" Edmonds along with Cincinnati musicians Antonio \"L.A.\" Reid, Carlos \"Satin\" Greene, Darnell \"Dee\" Bristol, Stanley \"Stick\" Burke, and Kevin \"Kayo\" Roberson.", "In 2007, Bristol, Greene, Roberson & Burke reformed the group with several new members.", "A March 2016 BET Honors performance, featuring Babyface and Reid reuniting with their former bandmates on stage, led to a more permanent reunion of the classic Deele lineup that has continued to the present.", "The Deele was formed in 1981 and originally comprised local Cincinnati musicians drummer Antonio \"L.A.\" Reid, bassist Kevin \"Kayo\" Roberson, vocalist/percussionist Darnell \"Dee\" Bristol, lead vocalist Carlos \"Satin\" Greene, guitarist/keyboardist Stanley \"Stick\" Burke, and guitarist Steve \"Tuck\" Walters.", "Reid, Roberson, and Walters had been members of a previous Cincinnati-based band, Pure Essence."]], "gold": "The Deele, an American band from Cincinnati, Ohio who achieved success in the 1980s with such hit singles as \"Body Talk\" and \"Two Occasions,\" sang the song in 1987. The Whispers cut a version of the song that appeared on their 1997 album Songbook : Volume One - The Songs of Babyface. Faye Wong also covered the song in Cantonese, titled as \"Miss You Night and Day\" found in her 1992 album, Coming Home.", "prediction 1": "\"Two Occasions\" is an R&B song written by Babyface, Darnell Bristol and Sid Johnson. The song was produced by Babyface and L.A. Reid for The Deele's third studio album, Eyes of a Stranger. It was released as the album's second single in 1988. Rap/Hip Hop artist Charlie Manhattan, released his version of \"Two Occasions,\" in 2007, which was taken from his solo debut album, The Manhattan Project.", "prediction 2": "The Deele, an American R&B band from Cincinnati who achieved success in the 1980s with hit singles such as Body Talk and Two Occasions, sang the song. It was produced by Babyface and L.A. Reid for The Deele's third studio album Eyes of a Stranger in 1987. The song was released as the album's second single in 1988. Rap/Hip Hop artist Charlie Manhattan, released his version of Two Occasions in 2007, which was taken from his solo debut album, The Manhattan Project. The original vocals from Babyface were referenced by Mariah Carey in her 2005 hit song, We Belong Together. It has since been remade into a live version with added vocals from Babyface with all original vocals from The Deele intact.", "prediction 3": "\"Two Occasions\" is an R&B song written by Babyface, Darnell Bristol and Sid Johnson. It was produced by Babyface and L.A. Reid for The Deele's third studio album Eyes of a Stranger in 1987. The song was released as the album's second single in 1988. Rap/Hip Hop artist Charlie Manhattan released his version of \"Two Occasions,\" in 2007, which was taken from his solo debut album, The Manhattan Project.", "prediction 4": "The Deele, an American R&B band from Cincinnati, Ohio, sang \"I only think of you on two occasions\" in 1988. The Deele was formed in 1981 and originally comprised local Cincinnati musicians drummer Antonio \"L.A.\" Reid, lead vocalist Carlos \"Satin\" Greene, vocalist Darnell \"Dee\" Bristol, guitarist/keyboardist Stanley \"Stick\" Burke, and guitarist Steve \"Tuck\" Walters.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 243, "end": 396}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 3, "sentence_id": [1]}], "corrected-prediction": "\"Two Occasions\" is an R&B song written by Babyface, Darnell Bristol and Sid Johnson. The song was produced by Babyface and L.A. Reid for The Deele's third studio album, Eyes of a Stranger. It was released as the album's second single in 1988. The Deele, an American band from Cincinnati, Ohio, sang the song, with Babyface on lead vocals."}, "preference": [1, 1, 1, 2, 2, 1], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Two Occasions\nS1. Two Occasions  \"Two Occasions\" is an R&B song written by Babyface, Darnell Bristol and Sid Johnson (who was the former manager for Babyface's early group, Manchild) .\nS2. It was produced by Babyface and L.A. Reid for The Deele's third studio album \"Eyes of a Stranger\" (1987).\nS3. The ballad was released as the album's second single in 1988.\nS4. It's the only song on the album that features Babyface on lead vocals, which alternate between himself, Bristol, and Carlos \"Satin\" Greene throughout the course of the song.\nS5. It has since been remade into a live version with added vocals from Babyface with all original vocals from The Deele intact; this version appeared on the 12\" maxi single and also three years later on his album, \"A Closer Look\".\nS6. The song and Babyface were later referenced by Mariah Carey in her 2005 hit song, \"We Belong Together.\"\nS7. The song is also sampled in the 2009 hit song \"Want It, Need It\" by Plies featuring Ashanti.\nS8. It was also sampled in the song \"I Still Love You\" by Next (group) on their \"Rated Next\" album.\nS9. Rap/Hip Hop artist Charlie Manhattan, released his version of \"Two Occasions,\" in 2007, which was taken from his solo debut album, \"The Manhattan Project\".\n\nPassage 2: Title (S0) - Two Occasions\nS1. \"Faye Wong\" also sampled the song in \"Miss You Night and Day\" found in her 1992 album, \"Coming Home\".\nS2. Craig Lytle, in his review of the album for AllMusic, called \"Two Occasions\" a \"quiet-storm classic\" with \"superb arrangement and production\", declaring the song \"worthy of a number-one ranking.\"\nS3. In 1989, the song won a BMI Pop Award.\nS4. Although the band's first hit \"Body Talk\" actually had a higher placement on the R&B chart, \"Two Occasions\" is widely considered The Deele's most successful single.\nS5. It peaked at number ten on the U.S. \"Billboard\" Hot 100, number four on the Hot R&B and number twenty-one on the Adult Contemporary chart.\n\nPassage 3: Title (S0) - The Deele\nS1. The Deele  The Deele (pronounced /deal/) is an American band from Cincinnati, Ohio who achieved success in the 1980s with such hit singles as \"Body Talk\" and \"Two Occasions.\"\nS2. When the group began recording in the early 1980s, the lineup consisted of Indianapolis native Kenny \"Babyface\" Edmonds along with Cincinnati musicians Antonio \"L.A.\" Reid, Carlos \"Satin\" Greene, Darnell \"Dee\" Bristol, Stanley \"Stick\" Burke, and Kevin \"Kayo\" Roberson.\nS3. In 2007, Bristol, Greene, Roberson & Burke reformed the group with several new members.\nS4. A March 2016 BET Honors performance, featuring Babyface and Reid reuniting with their former bandmates on stage, led to a more permanent reunion of the classic Deele lineup that has continued to the present.\nS5. The Deele was formed in 1981 and originally comprised local Cincinnati musicians drummer Antonio \"L.A.\" Reid, bassist Kevin \"Kayo\" Roberson, vocalist/percussionist Darnell \"Dee\" Bristol, lead vocalist Carlos \"Satin\" Greene, guitarist/keyboardist Stanley \"Stick\" Burke, and guitarist Steve \"Tuck\" Walters.\nS6. Reid, Roberson, and Walters had been members of a previous Cincinnati-based band, Pure Essence.\n    \nInput Question:\nWho sang i only think of you on two occasions?\n\nCorrect Response:\nThe Deele, an American band from Cincinnati, Ohio who achieved success in the 1980s with such hit singles as \"Body Talk\" and \"Two Occasions,\" sang the song in 1987. The Whispers cut a version of the song that appeared on their 1997 album Songbook : Volume One - The Songs of Babyface. Faye Wong also covered the song in Cantonese, titled as \"Miss You Night and Day\" found in her 1992 album, Coming Home.\n\nModel Prediction:\n\"Two Occasions\" is an R&B song written by Babyface, Darnell Bristol and Sid Johnson. The song was produced by Babyface and L.A. Reid for The Deele's third studio album, Eyes of a Stranger. It was released as the album's second single in 1988. Rap/Hip Hop artist Charlie Manhattan, released his version of \"Two Occasions,\" in 2007, which was taken from his solo debut album, The Manhattan Project.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "\"Two Occasions\" is an R&B song written by Babyface, Darnell Bristol and Sid Johnson. The song was produced by Babyface and L.A. Reid for The Deele's third studio album, Eyes of a Stranger. It was released as the album's second single in 1988. [Rap/Hip Hop artist Charlie Manhattan, released his version of \"Two Occasions,\" in 2007, which was taken from his solo debut album, The Manhattan Project.]\n\nExplanation:\nThe information about Charlie Manhattan's version of \"Two Occasions\" is irrelevant to the question, which asks about the original singer of the song. Thus, it should be marked as \"Irrelevant\"."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. \"Two Occasions\" is an R&B song written by Babyface, Darnell Bristol and Sid Johnson.\nS2. The song was produced by Babyface and L.A. Reid for The Deele's third studio album, Eyes of a Stranger.\nS3. It was released as the album's second single in 1988.\nS4. Rap/Hip Hop artist Charlie Manhattan, released his version of \"Two Occasions,\" in 2007, which was taken from his solo debut album, The Manhattan Project.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation:\nAll the facts presented in the model prediction are consistent with the information provided in the passages. There are no factual inconsistencies or unverifiable facts in the model prediction."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 3, sentence 1 [Missing Answer]\n2. Passage 1, sentence 4 [Missing Major Auxiliary Information]\n\nExplanation:\n1. The model prediction does not mention that the song \"Two Occasions\" was sung by The Deele, which is the direct answer to the question. This information can be found in Passage 3, sentence 1.\n2. The model prediction also misses the crucial auxiliary information that Babyface was the lead vocalist for the song \"Two Occasions\". This information can be found in Passage 1, sentence 4."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "\"Two Occasions\" is an R&B song written by Babyface, Darnell Bristol and Sid Johnson. The song was produced by Babyface and L.A. Reid for The Deele's third studio album, Eyes of a Stranger. It was released as the album's second single in 1988. The Deele, an American band from Cincinnati, Ohio, sang the song, with Babyface on lead vocals."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 85, "end": 188}, {"error type": "Irrelevant", "explanation": "", "start": 189, "end": 242}, {"error type": "Irrelevant", "explanation": "", "start": 322, "end": 330}, {"error type": "Irrelevant", "explanation": "", "start": 331, "end": 396}, {"error type": "Irrelevant", "explanation": "", "start": 0, "end": 84}], "missing-info": [{"error type": "Missing-Minor-Auxiliary", "passage_id": 3, "sentence_id": [1]}, {"error type": "Missing-Answer", "passage_id": 1, "sentence_id": [4]}], "corrected-prediction": "The Deele is an American band from Cincinnati, Ohio who achieved success in the 1980s with such hit singles as \"Body Talk\" and \"Two Occasions.\"  Lead vocals on the latter alternate between Babyface, Bristol, and Carlos \"Satin\" Greene. Charlie Manhattan has also released a version of the song."}}, {"question": "Who played little ricky on the lucille ball show?", "passages": [["Ricky Ricardo Jr.", "Ricky Ricardo Jr.\n\nEnrique Alberto Ricardo IV, \"Little Ricky,\" is a fictional character from the American television series \"I Love Lucy\" (1951\u201357, with Ricky Jr. becoming a part of the show as of his birth in 1953) and \"The Lucy-Desi Comedy Hour\" (1957\u201360).", "Little Ricky was played by a number of actors, including James John Ganzer, twins Richard and Ronald Lee Simmons, twins Michael and Joseph Mayer and, most notably, Keith Thibodeaux, billed as Little Ricky.", "Although the \"I Love Lucy\" announcer and the opening credits of \"The Lucy-Desi Comedy Hour\" gave his stage name as \"Little Ricky\", in his post-\"Lucy\" acting career, particularly his four-year irregular stint on \"The Andy Griffith Show\", he was billed as Richard Keith.", "In the show, Little Ricky is the son of Lucy Ricardo and Ricky Ricardo.", "Little Ricky lives with his parents in a New York Brownstone apartment building, which is owned and run by his godparents; the family later moves to a large suburban house in Westport, Connecticut.", "Lucy finds out she was expecting Little Ricky on the Season 2 episode \"Lucy is Enceinte.\""], ["Richard Keith (actor)", "Richard Keith (actor)\n\nKeith Thibodeaux (born December 1, 1950) is a former American child actor and musician, best known for playing Little Ricky on the television sitcoms \"I Love Lucy\" and \"The Lucy-Desi Comedy Hour\".", "His last name, which was Cajun French, was changed by producer Desi Arnaz to \"Keith\" because \"Thibodeaux\" was too difficult to pronounce.", "He is the last living regular appearing cast member from \"I Love Lucy\".", "Thibodeaux showed skill on the drums at a young age, and was making $500 a week at the age of 3 while touring with the Horace Heidt Orchestra.", "His father took him to audition for the part of Little Ricky in 1955, \"I walked on the set and there was Lucy, she was standing there and she was looking at me,\" he said.", "\"She said 'OK he's cute, but what does he do?'", "My dad said, 'Well he plays the drums' and she said, 'Oh, come on--I can't believe that.'", "Then, she says 'Look, we have a drum set over there, go ahead and let him play.'"]], "gold": "Enrique Alberto Ricardo IV or \"Little Ricky,\" is a fictional character from the American television series I Love Lucy, which aired from 1951\u201357, and The Lucy-Desi Comedy Hour, which aired from 1957\u201360. In the show, Little Ricky is the son of Lucy Ricardo and Ricky Ricardo and lives with his parents in a New York Brownstone apartment building and then the family later moves to a large suburban house in Westport, Connecticut. Little Ricky was played by a number of actors, including James John Ganzer, who played Little Ricky in season 2, episode 16, twins Richard and Ronald Lee Simmons who played him season 2, episodes 22 and 24, and twins Joseph and Michael Mayer played the character in season 5. In season 6, Keith Thibodeaux played the character, with his stage name in the credits being shown as \"Little Ricky\", although in his post-Lucy acting career he was known as Richard Keith. ", "prediction 1": "\"Little Ricky\" is a fictional character from the American television series \"I Love Lucy\" and \"The Lucy-Desi Comedy Hour\". The character was played by a number of actors, including James John Ganzer, twins Richard and Ronald Lee Simmons, twins Michael and Joseph Mayer and, most notably, Keith Thibodeaux, billed as Little Ricky. Although the \"I Love Lucy\" announcer and the opening credits of \"The Lucy-Desi Comedy Hour\" gave his stage name as \"Little Ricky\", in his post-Lucy acting career, particularly his four-year irregular stint on The Andy Griffith Show, he was billed as Richard Keith.", "prediction 2": "There were many actors playing the character Little Ricky on the Lucille Ball show. A former child actor and musician, Keith Thibodeaux, billed as Little Ricky on the television sitcoms I Love Lucy and The Lucy-Desi Comedy Hour, played the character.", "prediction 3": "Ricky, the fictional character, was played by several actors on the Lucille Ball show, including James John Ganzer, Richard Keith Thibodeaux, Ronald Lee Simmons, Michael Mayer, and Joseph Mayer. Despite his stage name being Little Ricky, his professional career began with a four-year odd stint on The Andy Griffith Show.", "prediction 4": "Ricky Ricardo IV, \"Little Ricky,\" is a fictional character from the American television show \"I Love Lucy\" and \"The Lucy-Desi Comedy Hour\". Ricky was played by a number of actors, including James John Ganzer, twins Richard and Ronald Lee Simmons, twins Michael and Joseph Mayer and, most notably, Keith Thibodeaux, billed as Little Ricky.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 493, "end": 562}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [5]}], "corrected-prediction": "\"Little Ricky\" is a fictional character from the American television series \"I Love Lucy\" and \"The Lucy-Desi Comedy Hour\". The character was played by a number of actors, including James John Ganzer, twins Richard and Ronald Lee Simmons, twins Michael and Joseph Mayer and, most notably, Keith Thibodeaux, billed as Little Ricky. Although the \"I Love Lucy\" announcer and the opening credits of \"The Lucy-Desi Comedy Hour\" gave his stage name as \"Little Ricky\", in his post-Lucy acting career, he was billed as Richard Keith. In the show, Little Ricky lives with his parents in a New York Brownstone apartment building and later the family moves to a large suburban house in Westport, Connecticut."}, "preference": [1, 1, 1, 2, 2, 2], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Ricky Ricardo Jr.\nS1. Ricky Ricardo Jr.  Enrique Alberto Ricardo IV, \"Little Ricky,\" is a fictional character from the American television series \"I Love Lucy\" (1951\u201357, with Ricky Jr. becoming a part of the show as of his birth in 1953) and \"The Lucy-Desi Comedy Hour\" (1957\u201360).\nS2. Little Ricky was played by a number of actors, including James John Ganzer, twins Richard and Ronald Lee Simmons, twins Michael and Joseph Mayer and, most notably, Keith Thibodeaux, billed as Little Ricky.\nS3. Although the \"I Love Lucy\" announcer and the opening credits of \"The Lucy-Desi Comedy Hour\" gave his stage name as \"Little Ricky\", in his post-\"Lucy\" acting career, particularly his four-year irregular stint on \"The Andy Griffith Show\", he was billed as Richard Keith.\nS4. In the show, Little Ricky is the son of Lucy Ricardo and Ricky Ricardo.\nS5. Little Ricky lives with his parents in a New York Brownstone apartment building, which is owned and run by his godparents; the family later moves to a large suburban house in Westport, Connecticut.\nS6. Lucy finds out she was expecting Little Ricky on the Season 2 episode \"Lucy is Enceinte.\"\n\nPassage 2: Title (S0) - Richard Keith (actor)\nS1. Richard Keith (actor)  Keith Thibodeaux (born December 1, 1950) is a former American child actor and musician, best known for playing Little Ricky on the television sitcoms \"I Love Lucy\" and \"The Lucy-Desi Comedy Hour\".\nS2. His last name, which was Cajun French, was changed by producer Desi Arnaz to \"Keith\" because \"Thibodeaux\" was too difficult to pronounce.\nS3. He is the last living regular appearing cast member from \"I Love Lucy\".\nS4. Thibodeaux showed skill on the drums at a young age, and was making $500 a week at the age of 3 while touring with the Horace Heidt Orchestra.\nS5. His father took him to audition for the part of Little Ricky in 1955, \"I walked on the set and there was Lucy, she was standing there and she was looking at me,\" he said.\nS6. \"She said 'OK he's cute, but what does he do?'\nS7. My dad said, 'Well he plays the drums' and she said, 'Oh, come on--I can't believe that.'\nS8. Then, she says 'Look, we have a drum set over there, go ahead and let him play.'\n    \nInput Question:\nWho played little ricky on the lucille ball show?\n\nCorrect Response:\nEnrique Alberto Ricardo IV or \"Little Ricky,\" is a fictional character from the American television series I Love Lucy, which aired from 1951\u201357, and The Lucy-Desi Comedy Hour, which aired from 1957\u201360. In the show, Little Ricky is the son of Lucy Ricardo and Ricky Ricardo and lives with his parents in a New York Brownstone apartment building and then the family later moves to a large suburban house in Westport, Connecticut. Little Ricky was played by a number of actors, including James John Ganzer, who played Little Ricky in season 2, episode 16, twins Richard and Ronald Lee Simmons who played him season 2, episodes 22 and 24, and twins Joseph and Michael Mayer played the character in season 5. In season 6, Keith Thibodeaux played the character, with his stage name in the credits being shown as \"Little Ricky\", although in his post-Lucy acting career he was known as Richard Keith. \n\nModel Prediction:\n\"Little Ricky\" is a fictional character from the American television series \"I Love Lucy\" and \"The Lucy-Desi Comedy Hour\". The character was played by a number of actors, including James John Ganzer, twins Richard and Ronald Lee Simmons, twins Michael and Joseph Mayer and, most notably, Keith Thibodeaux, billed as Little Ricky. Although the \"I Love Lucy\" announcer and the opening credits of \"The Lucy-Desi Comedy Hour\" gave his stage name as \"Little Ricky\", in his post-Lucy acting career, particularly his four-year irregular stint on The Andy Griffith Show, he was billed as Richard Keith.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "\"Little Ricky\" is a fictional character from the American television series \"I Love Lucy\" and \"The Lucy-Desi Comedy Hour\". The character was played by a number of actors, including James John Ganzer, twins Richard and Ronald Lee Simmons, twins Michael and Joseph Mayer and, most notably, Keith Thibodeaux, billed as Little Ricky. Although the \"I Love Lucy\" announcer and the opening credits of \"The Lucy-Desi Comedy Hour\" gave his stage name as \"Little Ricky\", in his post-Lucy acting career, [particularly his four-year irregular stint on The Andy Griffith Show,] he was billed as Richard Keith.\n\nExplanation:\nThe information about Keith Thibodeaux's post-Lucy acting career in The Andy Griffith Show is irrelevant to the question asking who played Little Ricky on the Lucille Ball show. Therefore, it should be marked as \"Irrelevant\"."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. \"Little Ricky\" is a fictional character from the American television series \"I Love Lucy\" and \"The Lucy-Desi Comedy Hour\".\nS2. The character was played by a number of actors, including James John Ganzer, twins Richard and Ronald Lee Simmons, twins Michael and Joseph Mayer and, most notably, Keith Thibodeaux, billed as Little Ricky.\nS3. Although the \"I Love Lucy\" announcer and the opening credits of \"The Lucy-Desi Comedy Hour\" gave his stage name as \"Little Ricky\", in his post-Lucy acting career, particularly his four-year irregular stint on The Andy Griffith Show, he was billed as Richard Keith.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation:\nAll the facts in the model prediction are consistent with the information provided in the passages."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 5 [Missing Major Auxiliary Information]\n\nExplanation:\n1. The model prediction does not include the information about Little Ricky's living situation, which is a major part of his character's background. This information is found in Passage 1, sentence 5."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "\"Little Ricky\" is a fictional character from the American television series \"I Love Lucy\" and \"The Lucy-Desi Comedy Hour\". The character was played by a number of actors, including James John Ganzer, twins Richard and Ronald Lee Simmons, twins Michael and Joseph Mayer and, most notably, Keith Thibodeaux, billed as Little Ricky. Although the \"I Love Lucy\" announcer and the opening credits of \"The Lucy-Desi Comedy Hour\" gave his stage name as \"Little Ricky\", in his post-Lucy acting career, he was billed as Richard Keith. In the show, Little Ricky lives with his parents in a New York Brownstone apartment building and later the family moves to a large suburban house in Westport, Connecticut."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 493, "end": 562}, {"error type": "Irrelevant", "explanation": "", "start": 339, "end": 366}, {"error type": "Irrelevant", "explanation": "", "start": 391, "end": 421}], "missing-info": [{"error type": "Missing-Minor-Auxiliary", "passage_id": 1, "sentence_id": [1]}, {"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [5]}], "corrected-prediction": "Enrique Alberto Ricardo IV, \"Little Ricky\", is a fictional character from the American television series \"I Love Lucy\" ((1951\u201357) and \"The Lucy-Desi Comedy Hour\" (1957\u201360). Little Ricky lives with his parents in a New York Brownstone apartment building, the family later moves to a large suburban house in Westport, Connecticut. The character was played by a number of actors, including James John Ganzer, twins Richard and Ronald Lee Simmons, twins Michael and Joseph Mayer and, most notably, Keith Thibodeaux, billed as Little Ricky. Although the opening credits gave his stage name as \"Little Ricky\", in his post-Lucy acting career, he was billed as Richard Keith."}}, {"question": "Where does the perks of being a wallflower take place?", "passages": [["Mr. Mudd", "Mr. Mudd\n\nMr. Mudd is a film production company founded in 1998 by Lianne Halfon, John Malkovich, and Russell Smith.", "The production company is also well known for producing the films \"Ghost World\", \"Juno\" and \"The Perks of Being a Wallflower\", all three of which received critical acclaim.", "The company is named for a Thai man (and convicted murderer) named Mr. Mudd who acted as Malkovich's driver while he was making \"The Killing Fields\" in 1983.", "Malkovich met Russell Smith in high school, where Smith was a star basketball player for the Lanphier High School Lions in Springfield, Illinois.", "The two later became freshman roommates at Eastern Illinois University.", "Malkovich later co-founded the Steppenwolf Theater Company, and invited Smith to become a writer for the troupe.", "Smith later produced a number of Steppenwolf plays, then moved into film production.", "Malkovich and Smith formed the Smith-Malkovich film production company in 1994.", "Malkovich met Lianne Halfon in the late 1980s while she was an executive at A&M Films.", "Malkovich and Halfon were both bidding for the film rights to author Don DeLillo's 1988 novel about Lee Harvey Oswald, \"Libra\".", "A&M films won the auction, and Halfon asked Malkovich to help develop the property."], ["The Perks of Being a Wallflower", "The Perks of Being a Wallflower\n\nThe Perks of Being a Wallflower is a coming-of-age epistolary novel by American writer Stephen Chbosky, which was first published on February 1, 1999, by Pocket Books.", "Set in the early 1990s, the novel follows Charlie, an introverted teenager, through his freshman year of high school in a Pittsburgh suburb.", "The novel details Charlie\u2019s unconventional style of thinking as he navigates between the worlds of adolescence and adulthood, and attempts to deal with poignant questions spurred by his interactions with both his friends and family.", "Chbosky took five years to develop and publish \"The Perks of Being a Wallflower\" , creating the characters and other aspects of the story from his own memories.", "The novel addresses themes permeating adolescence, including introversion, sexuality, drug use, and mental health, while also making several references to other literary works, films, and pop culture in general.", "Because of the mentioned themes, it was banned in some American schools for its content.", "In 2012, Chbosky himself adapted and directed a film version starring Logan Lerman, Emma Watson and Ezra Miller.", "The film boosted the novel's sales, and the book reached \"The New York Times\" Best Seller list."], ["The Perks of Being a Wallflower (film)", "The Perks of Being a Wallflower (film)\n\nThe Perks of Being a Wallflower is a 2012 American coming-of-age drama film written and directed by Stephen Chbosky, based on Chbosky\u2019s 1999 novel of the same name.", "Logan Lerman stars as a teenager named Charlie who writes to an unnamed friend, and these epistles chronicle his trials, tribulations, and triumphs as he goes through his first year of high school.", "The film depicts his depression and anxiety as he goes through his journey in high school making new friends.", "The film's ensemble cast also features Emma Watson, Ezra Miller, Mae Whitman, Kate Walsh, Dylan McDermott, Nina Dobrev, Johnny Simmons, Erin Wilhelmi, Melanie Lynskey, Paul Rudd and Joan Cusack.", "John Hughes originally read the novel and attempted to write a screenplay after he got the rights from Chbosky; however, he never finished writing the screenplay.", "Mr. Mudd Productions wanted Chbosky to adapt his own novel; after he finished writing the screenplay, production was approved.", "Filming began in Pittsburgh, Pennsylvania on May 2011 and lasted approximately fifty days."]], "gold": "The Perks of Being a Wallflower is a young adult coming-of-age epistolary novel by American writer Stephen Chbosky, which was first published on February 1, 1999. Set in the early 1990s, the novel follows Charlie, an introverted observing teenager, through his freshman year of high school in a Pittsburgh suburb. The novel details Charlie's unconventional style of thinking as he navigates between the worlds of adolescence and adulthood, and attempts to deal with poignant questions spurred by his interactions with both his friends and family. Stephen Chbosky wrote and directed a film based on the novel in 2012, in which the story was set and filmed in Pittsburgh, Pennsylvania.", "prediction 1": "The Perks of Being a Wallflower is a coming-of-age epistolary novel by American writer Stephen Chbosky, set in the early 1990s, which follows Charlie, an introverted teenager, through his freshman year of high school in Pittsburgh, Pennsylvania. The film adaptation of the novel took place in San Francisco and Los Angeles in 2011. It took place in New York City in 2014, in San Francisco in 2015, and in New York City in 2016. The Perks of Being a Wallflower is an American coming-of-of-age drama film written and directed by Stephen Chbosky. It is set in San Francisco in the early 1990s, Pennsylvania.", "prediction 2": "The Perks of Being a Wallflower is a coming-of-age epistolary novel by American writer Stephen Chbosky that was first published on February 1, 1999 by Pocket Books. Set in the early 1990s, the novel follows Charlie, an introverted teenager, through his freshman year of high school in a Pittsburgh suburb. The Perks of Being a Wallflower is a 2012 American coming-of-age drama film written and directed by Stephen Chbosky, based on Chbosky's 1999 novel of Being a Wallflower.", "prediction 3": "The Perks of Being a Wallflower is a coming-of-age epistolary novel by American writer Stephen Chbosky, which was first published on February 1, 1999, by Pocket Books. Set in the early 1990s, the novel follows Charlie, an introverted teenager, through his freshman year of high school in a Pittsburgh suburb. The 2012 American coming-of-age drama film based on Chbosky\u2019s 1999 novel stars Logan Lerman as Charlie who writes to an unnamed friend, and chronicles chronicle his trials, tribulations, and triumphs as he goes through his freshman year of high school making new friends.", "prediction 4": "The Perks of Being a Wallflower is a coming-of-age epistolary novel written by American writer Stephen Chbosky, which was first published on February 1, 1999 by Pocket Books. The novel follows Charlie, an introverted teenager, through his freshman year of high school in a Pittsburgh suburb. In 2012, American filmmaker Stephen Chbosky himself adapted and directed a remake of the novel, starring Logan Lerman, Emma Watson, and Ezra Miller.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 246, "end": 427}, {"error type": "Irrelevant", "explanation": "", "start": 544, "end": 590}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 2, "sentence_id": [2]}], "corrected-prediction": "The Perks of Being a Wallflower is a coming-of-age epistolary novel by American writer Stephen Chbosky, set in the early 1990s. The story follows Charlie, an introverted teenager, through his freshman year of high school in a suburb of Pittsburgh, Pennsylvania. The novel was adapted into an American coming-of-age drama film, also written and directed by Stephen Chbosky."}, "preference": [1, 1, 1, 2, 1, 1], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Mr. Mudd\nS1. Mr. Mudd  Mr. Mudd is a film production company founded in 1998 by Lianne Halfon, John Malkovich, and Russell Smith.\nS2. The production company is also well known for producing the films \"Ghost World\", \"Juno\" and \"The Perks of Being a Wallflower\", all three of which received critical acclaim.\nS3. The company is named for a Thai man (and convicted murderer) named Mr. Mudd who acted as Malkovich's driver while he was making \"The Killing Fields\" in 1983.\nS4. Malkovich met Russell Smith in high school, where Smith was a star basketball player for the Lanphier High School Lions in Springfield, Illinois.\nS5. The two later became freshman roommates at Eastern Illinois University.\nS6. Malkovich later co-founded the Steppenwolf Theater Company, and invited Smith to become a writer for the troupe.\nS7. Smith later produced a number of Steppenwolf plays, then moved into film production.\nS8. Malkovich and Smith formed the Smith-Malkovich film production company in 1994.\nS9. Malkovich met Lianne Halfon in the late 1980s while she was an executive at A&M Films.\nS10. Malkovich and Halfon were both bidding for the film rights to author Don DeLillo's 1988 novel about Lee Harvey Oswald, \"Libra\".\nS11. A&M films won the auction, and Halfon asked Malkovich to help develop the property.\n\nPassage 2: Title (S0) - The Perks of Being a Wallflower\nS1. The Perks of Being a Wallflower  The Perks of Being a Wallflower is a coming-of-age epistolary novel by American writer Stephen Chbosky, which was first published on February 1, 1999, by Pocket Books.\nS2. Set in the early 1990s, the novel follows Charlie, an introverted teenager, through his freshman year of high school in a Pittsburgh suburb.\nS3. The novel details Charlie\u2019s unconventional style of thinking as he navigates between the worlds of adolescence and adulthood, and attempts to deal with poignant questions spurred by his interactions with both his friends and family.\nS4. Chbosky took five years to develop and publish \"The Perks of Being a Wallflower\" , creating the characters and other aspects of the story from his own memories.\nS5. The novel addresses themes permeating adolescence, including introversion, sexuality, drug use, and mental health, while also making several references to other literary works, films, and pop culture in general.\nS6. Because of the mentioned themes, it was banned in some American schools for its content.\nS7. In 2012, Chbosky himself adapted and directed a film version starring Logan Lerman, Emma Watson and Ezra Miller.\nS8. The film boosted the novel's sales, and the book reached \"The New York Times\" Best Seller list.\n\nPassage 3: Title (S0) - The Perks of Being a Wallflower (film)\nS1. The Perks of Being a Wallflower (film)  The Perks of Being a Wallflower is a 2012 American coming-of-age drama film written and directed by Stephen Chbosky, based on Chbosky\u2019s 1999 novel of the same name.\nS2. Logan Lerman stars as a teenager named Charlie who writes to an unnamed friend, and these epistles chronicle his trials, tribulations, and triumphs as he goes through his first year of high school.\nS3. The film depicts his depression and anxiety as he goes through his journey in high school making new friends.\nS4. The film's ensemble cast also features Emma Watson, Ezra Miller, Mae Whitman, Kate Walsh, Dylan McDermott, Nina Dobrev, Johnny Simmons, Erin Wilhelmi, Melanie Lynskey, Paul Rudd and Joan Cusack.\nS5. John Hughes originally read the novel and attempted to write a screenplay after he got the rights from Chbosky; however, he never finished writing the screenplay.\nS6. Mr. Mudd Productions wanted Chbosky to adapt his own novel; after he finished writing the screenplay, production was approved.\nS7. Filming began in Pittsburgh, Pennsylvania on May 2011 and lasted approximately fifty days.\n    \nInput Question:\nWhere does the perks of being a wallflower take place?\n\nCorrect Response:\nThe Perks of Being a Wallflower is a young adult coming-of-age epistolary novel by American writer Stephen Chbosky, which was first published on February 1, 1999. Set in the early 1990s, the novel follows Charlie, an introverted observing teenager, through his freshman year of high school in a Pittsburgh suburb. The novel details Charlie's unconventional style of thinking as he navigates between the worlds of adolescence and adulthood, and attempts to deal with poignant questions spurred by his interactions with both his friends and family. Stephen Chbosky wrote and directed a film based on the novel in 2012, in which the story was set and filmed in Pittsburgh, Pennsylvania.\n\nModel Prediction:\nThe Perks of Being a Wallflower is a coming-of-age epistolary novel by American writer Stephen Chbosky, set in the early 1990s, which follows Charlie, an introverted teenager, through his freshman year of high school in Pittsburgh, Pennsylvania. The film adaptation of the novel took place in San Francisco and Los Angeles in 2011. It took place in New York City in 2014, in San Francisco in 2015, and in New York City in 2016. The Perks of Being a Wallflower is an American coming-of-of-age drama film written and directed by Stephen Chbosky. It is set in San Francisco in the early 1990s, Pennsylvania.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "The Perks of Being a Wallflower is a coming-of-age epistolary novel by American writer Stephen Chbosky, set in the early 1990s, which follows Charlie, an introverted teenager, through his freshman year of high school in Pittsburgh, Pennsylvania. [The film adaptation of the novel took place in San Francisco and Los Angeles in 2011. It took place in New York City in 2014, in San Francisco in 2015, and in New York City in 2016.] The Perks of Being a Wallflower is an American coming-of-of-age drama film written and directed by Stephen Chbosky. [It is set in San Francisco in the early 1990s,] Pennsylvania.\n\nExplanation:\n1. The information about the film adaptation taking place in various cities in different years is irrelevant to the question. The question asks about the setting of the story, not the filming locations. Therefore, this information is marked as \"Irrelevant\".\n2. The phrase \"It is set in San Francisco in the early 1990s,\" contradicts the correct information provided earlier in the response that the story is set in Pittsburgh, Pennsylvania. This makes the response incoherent. Therefore, this phrase is marked as \"Incoherent\"."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The Perks of Being a Wallflower is a coming-of-age epistolary novel by American writer Stephen Chbosky, set in the early 1990s, which follows Charlie, an introverted teenager, through his freshman year of high school in Pittsburgh, Pennsylvania.\nS2. The film adaptation of the novel took place in San Francisco and Los Angeles in 2011.\nS3. It took place in New York City in 2014, in San Francisco in 2015, and in New York City in 2016.\nS4. The Perks of Being a Wallflower is an American coming-of-of-age drama film written and directed by Stephen Chbosky.\nS5. It is set in San Francisco in the early 1990s, Pennsylvania.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "Inconsistent or Unverifiable Sentences:\n1. S2\n2. S3\n3. S5\n\nExplanation:\n1. The second sentence states that the film adaptation of the novel took place in San Francisco and Los Angeles in 2011. However, this is inconsistent with the information in Passage 3, Sentence 7, which states that filming began in Pittsburgh, Pennsylvania in May 2011.\n2. The third sentence claims that the film took place in various cities in different years. This information is not mentioned in any of the provided passages, making it unverifiable.\n3. The fifth sentence states that the story is set in San Francisco in the early 1990s. This is inconsistent with the information in Passage 2, Sentence 2, which states that the novel is set in a Pittsburgh suburb."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 2, sentence 2 [Missing Answer]\n\nExplanation:\n1. The model prediction does not mention that the story is set during Charlie's freshman year of high school in a Pittsburgh suburb, which is a direct answer to the question. This information is found in Passage 2, Sentence 2."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The Perks of Being a Wallflower is a coming-of-age epistolary novel by American writer Stephen Chbosky, set in the early 1990s. The story follows Charlie, an introverted teenager, through his freshman year of high school in a suburb of Pittsburgh, Pennsylvania. The novel was adapted into an American coming-of-age drama film, also written and directed by Stephen Chbosky."}], "feedback_human": {"errors": [{"error type": "Unverifiable", "explanation": "", "start": 246, "end": 331}, {"error type": "Unverifiable", "explanation": "", "start": 332, "end": 427}, {"error type": "Irrelevant", "explanation": "", "start": 428, "end": 543}, {"error type": "Unverifiable", "explanation": "", "start": 544, "end": 604}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 2, "sentence_id": [3]}, {"error type": "Missing-Major-Auxiliary", "passage_id": 2, "sentence_id": [7]}, {"error type": "Missing-Answer", "passage_id": 3, "sentence_id": [7]}], "corrected-prediction": "The Perks of Being a Wallflower is a coming-of-age epistolary novel by American writer Stephen Chbosky, set in the early 1990s, which follows Charlie, an introverted teenager, through his freshman year of high school in Pittsburgh, Pennsylvania.  The novel details Charlie\u2019s unconventional style of thinking as he navigates between the worlds of adolescence and adulthood, and attempts to deal with poignant questions spurred by his interactions with both his friends and family. Stephen Chbosky wrote and directed a film based on the novel in 2012, in which the story was set and filmed in Pittsburgh, Pennsylvania.              "}}, {"question": "Where are the queen's royal hussars based?", "passages": [["Queen's Royal Hussars", "The regiment, in January 1996, became the first to be deployed in Challenger 1 tanks to Bosnia with NATO's British-led Implementation Force IFOR.", "In August 1996 the regiment deployed to Northern Ireland on Operation Banner and then moved to Athlone Barracks at Sennelager as armoured regiment for 20th Armoured Brigade in January 1998.", "An independent tank squadron deployed to Kosovo in 2001, with the rest of the regiment deploying later that year in the dismounted role.", "December 2003 saw the regiment deploy once again, this time to Iraq on Operation Telic 3.", "The regiment saw its first Military Cross awarded to Lance corporal Christopher Balmforth of B Squadron for his actions during an ambush in Basra.", "April 2006 saw the regiment deploy once again to Iraq on Operation Telic 8 and December 2008 saw the regiment deployed to Iraq on Operation Telic 13.", "As the final Operation Telic the Queen's Royal Hussars were intimately involved in the drawdown from the main British base and spent many hours escorting convoys to and from Kuwait.", "In 2011 the regiment deployed on Operation Herrick 15 as a ground holding Battle Group to Afghanistan in the infantry role: they worked with the Afghan National Police handing over control of checkpoints.", "On return from Afghanistan in 2012 the regiment was called on to support the security for the London Olympic Games.", "The remainder of the year was used to return to the armoured role."], ["Queen's Royal Hussars", "Queen's Royal Hussars\n\nThe Queen's Royal Hussars (The Queen's Own and Royal Irish) (QRH) is the senior United Kingdom armoured regiment.", "It was formed on 1 September 1993 from the amalgamation of the Queen's Own Hussars and the Queen's Royal Irish Hussars.", "The regiment and its antecedents have been awarded 172 Battle Honours and eight Victoria Crosses.", "The regiment is currently based in Sennelager, Germany, where it is the armoured regiment for 20th Armoured Brigade, part of British Forces Germany.", "The Queen's Royal Hussars was formed in Fallingbostel on 1 September 1993 from the amalgamation of the Queen's Own Hussars and the Queen's Royal Irish Hussars.", "The Queen's Own Hussars, normally referred to by the abbreviation QOH, was a cavalry regiment of the British Army, formed from the amalgamation of 3rd", "The King's Own Hussars and the 7th Queen's Own Hussars at Candahar Barracks, Tidworth in 1958.", "The Queen's Royal Irish Hussars, abbreviated as QRIH, was a cavalry regiment of the British Army formed from the amalgamation of the 4th Queen's Own Hussars and the 8th King's Royal Irish Hussars in Hohne, West Germany in 1958."]], "gold": "The Queen's Royal Irish Hussars, abbreviated as QRIH, was a cavalry regiment of the British Army formed from the amalgamation of the 4th Queen's Own Hussars and the 8th King's Royal Irish Hussars in Hohne, West Germany in 1958. In August 1996 the regiment deployed to Northern Ireland on Operation Banner, and then moved to Athlone Barracks at Sennelager as armored regiment for 20th Armored Brigade in January 1998.  ", "prediction 1": "The Queen's Royal Hussars (The Queen's Own and Royal Irish) is the senior United Kingdom armoured regiment. It was formed on 1 September 1993 from the amalgamation of the Queen's Own Hussars and the Queen's Royal Irish Hussars. The regiment is currently based in Sennelager, Germany, where it is the armoured regiment for 20th Armoured Brigade, part of British Forces Germany.", "prediction 2": "The Queen's Royal Hussars is the senior United Kingdom armoured regiment. It was formed on 1 September 1993 from the amalgamation of the Queen's Own Hussars and the Queen's Royal Irish Hussars. The regiment is currently based in Germany, where it is the armoured regiment for 20th Armoured Brigade, part of British Forces Germany.", "prediction 3": "The Queen's Royal Hussars is the senior United Kingdom armoured regiment, formed on 1 September 1993 from the amalgamation of the Queen's Own Hussars and the Queen's Royal Irish Hussars. It is based at Athlone Barracks at Sennelager, Germany, and acts as the armoured regiment for 20th Armoured Brigade, part of British Forces Germany.", "prediction 4": "Queen's Royal Hussars is the senior United Kingdom armoured regiment. It was formed on 1 September 1993 from the amalgamation of the Queen's Own Hussars and the Queen's Royal Irish Hussars. The regiment is currently based in Sennelager, Germany, where it is the armoured regiment for 20th Armoured Brigade, part of British Forces Germany.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 108, "end": 227}], "missing-info": [], "corrected-prediction": "The Queen's Royal Hussars (The Queen's Own and Royal Irish) is the senior United Kingdom armoured regiment. The regiment is currently based in Sennelager, Germany, where it is the armoured regiment for 20th Armoured Brigade, part of British Forces Germany."}, "preference": [0, 0, 0, 0, 0, 0], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Queen's Royal Hussars\nS1. The regiment, in January 1996, became the first to be deployed in Challenger 1 tanks to Bosnia with NATO's British-led Implementation Force IFOR.\nS2. In August 1996 the regiment deployed to Northern Ireland on Operation Banner and then moved to Athlone Barracks at Sennelager as armoured regiment for 20th Armoured Brigade in January 1998.\nS3. An independent tank squadron deployed to Kosovo in 2001, with the rest of the regiment deploying later that year in the dismounted role.\nS4. December 2003 saw the regiment deploy once again, this time to Iraq on Operation Telic 3.\nS5. The regiment saw its first Military Cross awarded to Lance corporal Christopher Balmforth of B Squadron for his actions during an ambush in Basra.\nS6. April 2006 saw the regiment deploy once again to Iraq on Operation Telic 8 and December 2008 saw the regiment deployed to Iraq on Operation Telic 13.\nS7. As the final Operation Telic the Queen's Royal Hussars were intimately involved in the drawdown from the main British base and spent many hours escorting convoys to and from Kuwait.\nS8. In 2011 the regiment deployed on Operation Herrick 15 as a ground holding Battle Group to Afghanistan in the infantry role: they worked with the Afghan National Police handing over control of checkpoints.\nS9. On return from Afghanistan in 2012 the regiment was called on to support the security for the London Olympic Games.\nS10. The remainder of the year was used to return to the armoured role.\n\nPassage 2: Title (S0) - Queen's Royal Hussars\nS1. Queen's Royal Hussars  The Queen's Royal Hussars (The Queen's Own and Royal Irish) (QRH) is the senior United Kingdom armoured regiment.\nS2. It was formed on 1 September 1993 from the amalgamation of the Queen's Own Hussars and the Queen's Royal Irish Hussars.\nS3. The regiment and its antecedents have been awarded 172 Battle Honours and eight Victoria Crosses.\nS4. The regiment is currently based in Sennelager, Germany, where it is the armoured regiment for 20th Armoured Brigade, part of British Forces Germany.\nS5. The Queen's Royal Hussars was formed in Fallingbostel on 1 September 1993 from the amalgamation of the Queen's Own Hussars and the Queen's Royal Irish Hussars.\nS6. The Queen's Own Hussars, normally referred to by the abbreviation QOH, was a cavalry regiment of the British Army, formed from the amalgamation of 3rd\nS7. The King's Own Hussars and the 7th Queen's Own Hussars at Candahar Barracks, Tidworth in 1958.\nS8. The Queen's Royal Irish Hussars, abbreviated as QRIH, was a cavalry regiment of the British Army formed from the amalgamation of the 4th Queen's Own Hussars and the 8th King's Royal Irish Hussars in Hohne, West Germany in 1958.\n    \nInput Question:\nWhere are the queen's royal hussars based?\n\nCorrect Response:\nThe Queen's Royal Irish Hussars, abbreviated as QRIH, was a cavalry regiment of the British Army formed from the amalgamation of the 4th Queen's Own Hussars and the 8th King's Royal Irish Hussars in Hohne, West Germany in 1958. In August 1996 the regiment deployed to Northern Ireland on Operation Banner, and then moved to Athlone Barracks at Sennelager as armored regiment for 20th Armored Brigade in January 1998.  \n\nModel Prediction:\nThe Queen's Royal Hussars (The Queen's Own and Royal Irish) is the senior United Kingdom armoured regiment. It was formed on 1 September 1993 from the amalgamation of the Queen's Own Hussars and the Queen's Royal Irish Hussars. The regiment is currently based in Sennelager, Germany, where it is the armoured regiment for 20th Armoured Brigade, part of British Forces Germany.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "The Queen's Royal Hussars (The Queen's Own and Royal Irish) is the senior United Kingdom armoured regiment. [It was formed on 1 September 1993 from the amalgamation of the Queen's Own Hussars and the Queen's Royal Irish Hussars.] The regiment is currently based in Sennelager, Germany, where it is the armoured regiment for 20th Armoured Brigade, part of British Forces Germany.\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\"."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The Queen's Royal Hussars (The Queen's Own and Royal Irish) is the senior United Kingdom armoured regiment.\nS2. It was formed on 1 September 1993 from the amalgamation of the Queen's Own Hussars and the Queen's Royal Irish Hussars.\nS3. The regiment is currently based in Sennelager, Germany, where it is the armoured regiment for 20th Armoured Brigade, part of British Forces Germany.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation:\nAll the facts in the model prediction are consistent with the information provided in the passages."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "None\n\nExplanation:\nThe model prediction includes all the necessary information to answer the question. It correctly states that the Queen's Royal Hussars are based in Sennelager, Germany, which is the direct answer to the question. There is no missing information in the model prediction."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The Queen's Royal Hussars (The Queen's Own and Royal Irish) is the senior United Kingdom armoured regiment. The regiment is currently based in Sennelager, Germany, where it is the armoured regiment for 20th Armoured Brigade, part of British Forces Germany."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 60, "end": 107}, {"error type": "Irrelevant", "explanation": "", "start": 108, "end": 227}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [2]}, {"error type": "Missing-Minor-Auxiliary", "passage_id": 2, "sentence_id": [8]}], "corrected-prediction": "The Queen's Royal Hussars the regiment deployed to Northern Ireland on Operation Banner, in August 1996, and then moved to Athlone Barracks at Sennelager, Germany, as armoured regiment for 20th Armoured Brigade in January 1998.  The regiment is currently based in Sennelager, Germany. The Queen's Own and Royal Irish was a cavalry regiment of the British Army formed from the amalgamation of the 4th Queen's Own Hussars and the 8th King's Royal Irish Hussars in Hohne, West Germany in 1958."}}, {"question": "When did bill knapps go out of business?", "passages": [["Bill Knapp's", "In 2001, Bill Knapp's tried to reverse course by announcing that \"The Tradition is Back,\" restoring the original menu and some original d\u00e9cor, but by then it was too late.", "On Tuesday May 21, 2002, Bill Knapp\u2019s filed for voluntary Chapter 11 protection in U.S. Bankruptcy Court for the Western District of Michigan.", "At the time company operated 29 restaurants.", "By the end of 2002, the chain's last restaurant had closed.", "Bill Knapp's 6-inch chocolate birthday cakes, officially known as Bill Knapp's Celebration Cakes, were regarded as one of the chain's dearest features.", "Because of the popularity of the cakes, Awrey's Bakery purchased the rights to make them, following Bill Knapp's original recipe.", "The cakes are available from Awrey's in-store bakery and at many Kroger Stores as well.", "Winn-Dixie and Kroger now also carry Bill Knapp's Chocolate, Nutty, and Glazed Dunkers."], ["Bill Knapp's", "Bill Knapp's\n\nBill Knapp's was an American family restaurant chain.", "It was founded by\nClinton B. Knapp (March 13, 1907 \u2013 October 15, 1974), in Battle Creek, Michigan, in 1948.", "The chain operated in Michigan, Ohio, Florida, Illinois and Indiana, with more than 60 locations at its peak.", "Bill Knapp's featured a menu primarily filled with typical family dining items.", "The menu included a limited breakfast, sandwiches, baskets, and luncheon and dinner plates.", "A children's menu, featuring meals named for animals, was also offered.", "Recipes for their fried chicken, bean soup, ham croquettes, vegetable soup, onion rings, au gratin potatoes, and chocolate cakes (later purchased by Awrey Bakeries) were also featured.", "Locations replenished inventory on a daily basis from the commissary in Battle Creek, Mich. with their own fleet of trucks.", "Bill Knapp placed great emphasis on the quality and freshness of the food, with added emphasis on preparing the food \"from scratch.\"", "Bill Knapp \"was interested in providing decent food for a reasonable price with friendly service.\"", "The target clientele of his restaurants was families, often three generations eating together at long tables pushed together."]], "gold": "Bill Knapp's was an American family restaurant chain that was founded by Clinton B. Knapp in Battle Creek, Michigan in 1948. It featured a menu filled with typical family fare as well as a children's menu. Bill Knapp placed great emphasis on the quality and freshness of the food served in his restaurant, which was prepared from scratch. Bill Knapp's filed for Chapter 11 bankruptcy on May 21, 2002, and by the end of 2002, the last restaurant in the chain closed.", "prediction 1": "Bill Knapp's was an American family restaurant chain that was founded by Clinton B. Knapp, March 13, 1907 \u2013 October 15, 1974, in Battle Creek, Michigan, in 1948. The company operated in Michigan, Ohio, Florida, Illinois and Indiana, with more than 60 locations at its peak. In 2002, Bill Knapp's filed for voluntary Chapter 11 protection in U.S. Bankruptcy Court for the Western District of Michigan. In 2001, the company tried to reverse course by announcing that \"The Tradition is Back.\" But by then it was too late.", "prediction 2": "Bill Knapp's was an American family restaurant chain which operated in Michigan, Ohio, Florida, Illinois and Indiana. At its peak, the chain operated in more than 60 locations in ten states and two Canadian provinces. The chain went out of business on May 21, 2002 when the company filed for voluntary Chapter 11 protection in U.S. Bankruptcy Court for the Western District of Michigan.", "prediction 3": "Bill Knapp's was an American family restaurant chain. It was founded by Clinton B. Knapp on March 13, 1907 and operated in Michigan, Ohio, Florida, Illinois and Indiana, with more than 60 locations at its peak. On May 21, 2002, the restaurant filed for voluntary Chapter 11 protection in U.S. Bankruptcy Court for the Western District of Michigan.", "prediction 4": "Bill Knapp's was an American family restaurant chain, founded by Clinton B. Knapp in 1948 in Battle Creek, Michigan. The chain operated in Michigan, Ohio, Florida, Illinois and Indiana, with more than 60 locations at its peak. Bill Knapp's was interested in providing decent food for a reasonable price with friendly service. It was filed for Chapter 11 protection in U.S. Bankruptcy Court for the Western District of Michigan on May 21, 2002.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 401, "end": 489}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 1, "sentence_id": [4]}], "corrected-prediction": "Bill Knapp's was an American family restaurant chain that was founded by Clinton B. Knapp, March 13, 1907 \u2013 October 15, 1974, in Battle Creek, Michigan, in 1948. The company operated in Michigan, Ohio, Florida, Illinois and Indiana, with more than 60 locations at its peak. In 2002, Bill Knapp's filed for voluntary Chapter 11 protection in U.S. Bankruptcy Court for the Western District of Michigan. By the end of 2002, the last restaurant in the chain had closed."}, "preference": [1, 1, 1, 1, 1, 2], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Bill Knapp's\nS1. In 2001, Bill Knapp's tried to reverse course by announcing that \"The Tradition is Back,\" restoring the original menu and some original d\u00e9cor, but by then it was too late.\nS2. On Tuesday May 21, 2002, Bill Knapp\u2019s filed for voluntary Chapter 11 protection in U.S. Bankruptcy Court for the Western District of Michigan.\nS3. At the time company operated 29 restaurants.\nS4. By the end of 2002, the chain's last restaurant had closed.\nS5. Bill Knapp's 6-inch chocolate birthday cakes, officially known as Bill Knapp's Celebration Cakes, were regarded as one of the chain's dearest features.\nS6. Because of the popularity of the cakes, Awrey's Bakery purchased the rights to make them, following Bill Knapp's original recipe.\nS7. The cakes are available from Awrey's in-store bakery and at many Kroger Stores as well.\nS8. Winn-Dixie and Kroger now also carry Bill Knapp's Chocolate, Nutty, and Glazed Dunkers.\n\nPassage 2: Title (S0) - Bill Knapp's\nS1. Bill Knapp's  Bill Knapp's was an American family restaurant chain.\nS2. It was founded by Clinton B. Knapp (March 13, 1907 \u2013 October 15, 1974), in Battle Creek, Michigan, in 1948.\nS3. The chain operated in Michigan, Ohio, Florida, Illinois and Indiana, with more than 60 locations at its peak.\nS4. Bill Knapp's featured a menu primarily filled with typical family dining items.\nS5. The menu included a limited breakfast, sandwiches, baskets, and luncheon and dinner plates.\nS6. A children's menu, featuring meals named for animals, was also offered.\nS7. Recipes for their fried chicken, bean soup, ham croquettes, vegetable soup, onion rings, au gratin potatoes, and chocolate cakes (later purchased by Awrey Bakeries) were also featured.\nS8. Locations replenished inventory on a daily basis from the commissary in Battle Creek, Mich. with their own fleet of trucks.\nS9. Bill Knapp placed great emphasis on the quality and freshness of the food, with added emphasis on preparing the food \"from scratch.\"\nS10. Bill Knapp \"was interested in providing decent food for a reasonable price with friendly service.\"\nS11. The target clientele of his restaurants was families, often three generations eating together at long tables pushed together.\n    \nInput Question:\nWhen did bill knapps go out of business?\n\nCorrect Response:\nBill Knapp's was an American family restaurant chain that was founded by Clinton B. Knapp in Battle Creek, Michigan in 1948. It featured a menu filled with typical family fare as well as a children's menu. Bill Knapp placed great emphasis on the quality and freshness of the food served in his restaurant, which was prepared from scratch. Bill Knapp's filed for Chapter 11 bankruptcy on May 21, 2002, and by the end of 2002, the last restaurant in the chain closed.\n\nModel Prediction:\nBill Knapp's was an American family restaurant chain that was founded by Clinton B. Knapp, March 13, 1907 \u2013 October 15, 1974, in Battle Creek, Michigan, in 1948. The company operated in Michigan, Ohio, Florida, Illinois and Indiana, with more than 60 locations at its peak. In 2002, Bill Knapp's filed for voluntary Chapter 11 protection in U.S. Bankruptcy Court for the Western District of Michigan. In 2001, the company tried to reverse course by announcing that \"The Tradition is Back.\" But by then it was too late.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "Bill Knapp's was an American family restaurant chain that was founded by Clinton B. Knapp, March 13, 1907 \u2013 October 15, 1974, in Battle Creek, Michigan, in 1948. The company operated in Michigan, Ohio, Florida, Illinois and Indiana, with more than 60 locations at its peak. In 2002, Bill Knapp's filed for voluntary Chapter 11 protection in U.S. Bankruptcy Court for the Western District of Michigan. [In 2001, the company tried to reverse course by announcing that \"The Tradition is Back.\"] But by then it was too late.\n\nExplanation:\nThe sentence \"In 2001, the company tried to reverse course by announcing that \"The Tradition is Back.\"\" is irrelevant to the question asked. The question is asking about when the company went out of business, not about its attempts to reverse its fortunes. Therefore, this sentence is marked as irrelevant."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. Bill Knapp's was an American family restaurant chain that was founded by Clinton B. Knapp, March 13, 1907 \u2013 October 15, 1974, in Battle Creek, Michigan, in 1948.\nS2. The company operated in Michigan, Ohio, Florida, Illinois and Indiana, with more than 60 locations at its peak.\nS3. In 2002, Bill Knapp's filed for voluntary Chapter 11 protection in U.S. Bankruptcy Court for the Western District of Michigan.\nS4. In 2001, the company tried to reverse course by announcing that \"The Tradition is Back.\"\nS5. But by then it was too late.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation:\nAll the facts presented in the model prediction are consistent with the information provided in the passages. There are no unverifiable or inconsistent facts in the model prediction."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 4 [Missing Answer]\n\nExplanation:\n1. The model prediction does not include the specific information that the last restaurant in the Bill Knapp's chain closed by the end of 2002, which is a direct answer to the question. This information can be found in Passage 1, sentence 4."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "Bill Knapp's was an American family restaurant chain that was founded by Clinton B. Knapp, March 13, 1907 \u2013 October 15, 1974, in Battle Creek, Michigan, in 1948. The company operated in Michigan, Ohio, Florida, Illinois and Indiana, with more than 60 locations at its peak. In 2002, Bill Knapp's filed for voluntary Chapter 11 protection in U.S. Bankruptcy Court for the Western District of Michigan. By the end of 2002, the last restaurant in the chain had closed."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 162, "end": 273}, {"error type": "Irrelevant", "explanation": "", "start": 363, "end": 400}, {"error type": "Irrelevant", "explanation": "", "start": 401, "end": 518}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 2, "sentence_id": [4]}, {"error type": "Missing-Major-Auxiliary", "passage_id": 2, "sentence_id": [9]}, {"error type": "Missing-Minor-Auxiliary", "passage_id": 1, "sentence_id": [2]}, {"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [4]}], "corrected-prediction": "Bill Knapp's was an American family restaurant chain that was founded by Clinton B. Knapp, March 13, 1907 \u2013 October 15, 1974, in Battle Creek, Michigan, in 1948. Bill Knapp's featured a menu primarily filled with typical family dining items. Bill Knapp placed great emphasis on the quality and freshness of the food, with added emphasis on preparing the food \"from scratch.\" In May 21, 2002, Bill Knapp's filed for voluntary Chapter 11 protection in U.S. Bankruptcy Court. By the end of 2002, the chain's last restaurant had closed."}}, {"question": "When does carrie find out about sebastian and maggie?", "passages": [["The Carrie Diaries (TV series)", "The Carrie Diaries (TV series)\n\n", "The Carrie Diaries is an American teen comedy-drama television series that aired for two seasons on The CW from January 14, 2013, to January 31, 2014.", "It is a prequel to the HBO television series \"Sex and the City\" and based on the 2010 book of the same name by Candace Bushnell.", "The first season focuses on Carrie Bradshaw (AnnaSophia Robb) during her junior year of high school in 1984 as she explores life in New York City while interning at a law firm office, and also secretly working at a magazine company, while the second season focuses more on her expanding life in the city as well as the lives of her friends and boyfriend.", "The pilot was picked up by The CW to a series order of 13 episodes in May 2012.", "Four months into the first season, the network renewed \"The Carrie Diaries\" for a second season, which premiered in October 2013.", "In May 2014, The CW canceled the series after two seasons.", "In September 2011, it was officially announced that The CW was moving forward with a television series as a prequel to the original series, based on \"The Carrie Diaries\".", "The project is produced by \"Gossip Girl\" producers Josh Schwartz and Stephanie Savage.", "Former \"Sex and the City\" writer Amy B. Harris penned the adaptation."], ["The Carrie Diaries (season 1)", "The Carrie Diaries (season 1)\n\nThe first season of \"The Carrie Diaries\", an American teen drama series based on the novel of the same name by Candace Bushnell, premiered on The CW on January 14, 2013.", "Developed by Amy B. Harris, the series serves as a prequel to the HBO series \"Sex and the City\".", "\"The Carrie Diaries\" was officially picked up for the 2012\u201313 television season on May 11, 2012.", "Premiering mid-season, the series concluded its first season on April 8, 2013.", "They never get back together because Tom dose not want thrm getting back together er and Sebastian ends up with Maggie and dose not regret anything.", "<onlyinclude></onlyinclude>"], ["Carrie Bradshaw", "A TV series was made after the production of \"Sex and the City\", called \"The Carrie Diaries\" which featured Carrie's life as a teenager prior to her life in \"Sex and the City\".", "It focused mainly on Carrie who lived with her father and younger sister, Dorrit.", "She had a few relationships, the main one being her on and off relationship with Sebastian Kydd.", "She started working at \"Interview\", a magazine firm, juggling between her school and work life.", "The series was discontinued after Season 2 as it was said that it was not economically feasible although it got positive feedback from its audience.", "Candace Bushnell, author of \"Sex and the City\", recently released her new book, \"Summer and the City: A Carrie Diaries Novel\" as part of her young adult series that follows the \"Sex and the City\" characters as teenagers.", "This novel reveals that Carrie attended the prestigious Ivy League University, Brown, in the 1980s.", "It also reveals that she took summer classes at the New School.", "\"TV Guide\" described the young version of Carrie Bradshaw as \"Even when she's trying to play adult in the city with her fashion-forward style and 'grown-up' conversations, she still exudes an aura that manages to be innocent, cute and self-confident at the same time.\""]], "gold": "The Carrie Diaries is an American teen comedy-drama television series that served as a prequel to the HBO series Sex and the City. The show focuses on Carrie's life as a teenager, time in which she had a few relationships, the main one being her on and off relationship with Sebastian Kydd. During the show, Sebastian is involved at different times with Maggie, Carrie's best friend, and Carrie finds out about them in at least two different occasions. The first of them happened during Season 1 Episode 13, titled Kiss Yesterday Goodbye, and later during Season 2 Episode 6, The Safety Dance.", "prediction 1": "The first season of The Carrie Diaries is an American teen comedy-drama television series that aired for two seasons on The CW from January 14, 2013, to January 31, 2014. It is a prequel to the HBO television series Sex and the City and based on the 2010 book of the same name by Candace Bushnell. In the first season, Carrie finds out about Sebastian and Maggie and they go on a date. In the second season, Carrie finds out about Sebastian and Maggie and they end up dating and Carrie finds out about their relationship.", "prediction 2": "The first season of The Carrie Diaries is a teen comedy-drama television series that aired for two seasons on The CW from January 14, 2013, to January 31, 2014. It is a prequel to the HBO television series Sex and the City and based on the 2010 book of the same name by Candace Bushnell. The second season focuses more on Carrie's expanding life in the city as well as the lives of her friends and boyfriend. In season 1 of the show, Carrie finds out about Sebastian and Maggie.", "prediction 3": "The first season of The Carrie Diaries, an American teen comedy-drama television series that aired for two seasons on The CW from January 14, 2013, to January 31, 2014, focuses on Carrie Bradshaw during her junior year of high school in 1984 as she explores life in New York City while interning at a law firm office, and also secretly working at a magazine company, while the second season focuses more on her expanding life in the city as well as the lives of her friends and boyfriend.", "prediction 4": "The first season of The Carrie Diaries, an American teen comedy-drama television series that aired for two seasons on The CW from January 14, 2013, to January 31, 2014, features Carrie Bradshaw as a teenager prior to her life in Sex and the City. Sebastian has been with Maggie for four years and they never get back together, but Sebastian finds out about his girlfriend after the first season premiered.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 298, "end": 521}], "missing-info": [], "corrected-prediction": "The Carrie Diaries is an American teen comedy-drama television series that aired for two seasons on The CW from January 14, 2013, to January 31, 2014. It is a prequel to the HBO television series Sex and the City and based on the 2010 book of the same name by Candace Bushnell. The series does not provide specific details about when Carrie finds out about Sebastian and Maggie."}, "preference": [1, 1, 1, 1, 1, 1], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - The Carrie Diaries (TV series)\nS1. The Carrie Diaries (TV series)  \nS2. The Carrie Diaries is an American teen comedy-drama television series that aired for two seasons on The CW from January 14, 2013, to January 31, 2014.\nS3. It is a prequel to the HBO television series \"Sex and the City\" and based on the 2010 book of the same name by Candace Bushnell.\nS4. The first season focuses on Carrie Bradshaw (AnnaSophia Robb) during her junior year of high school in 1984 as she explores life in New York City while interning at a law firm office, and also secretly working at a magazine company, while the second season focuses more on her expanding life in the city as well as the lives of her friends and boyfriend.\nS5. The pilot was picked up by The CW to a series order of 13 episodes in May 2012.\nS6. Four months into the first season, the network renewed \"The Carrie Diaries\" for a second season, which premiered in October 2013.\nS7. In May 2014, The CW canceled the series after two seasons.\nS8. In September 2011, it was officially announced that The CW was moving forward with a television series as a prequel to the original series, based on \"The Carrie Diaries\".\nS9. The project is produced by \"Gossip Girl\" producers Josh Schwartz and Stephanie Savage.\nS10. Former \"Sex and the City\" writer Amy B. Harris penned the adaptation.\n\nPassage 2: Title (S0) - The Carrie Diaries (season 1)\nS1. The Carrie Diaries (season 1)  The first season of \"The Carrie Diaries\", an American teen drama series based on the novel of the same name by Candace Bushnell, premiered on The CW on January 14, 2013.\nS2. Developed by Amy B. Harris, the series serves as a prequel to the HBO series \"Sex and the City\".\nS3. \"The Carrie Diaries\" was officially picked up for the 2012\u201313 television season on May 11, 2012.\nS4. Premiering mid-season, the series concluded its first season on April 8, 2013.\nS5. They never get back together because Tom dose not want thrm getting back together er and Sebastian ends up with Maggie and dose not regret anything.\nS6. <onlyinclude></onlyinclude>\n\nPassage 3: Title (S0) - Carrie Bradshaw\nS1. A TV series was made after the production of \"Sex and the City\", called \"The Carrie Diaries\" which featured Carrie's life as a teenager prior to her life in \"Sex and the City\".\nS2. It focused mainly on Carrie who lived with her father and younger sister, Dorrit.\nS3. She had a few relationships, the main one being her on and off relationship with Sebastian Kydd.\nS4. She started working at \"Interview\", a magazine firm, juggling between her school and work life.\nS5. The series was discontinued after Season 2 as it was said that it was not economically feasible although it got positive feedback from its audience.\nS6. Candace Bushnell, author of \"Sex and the City\", recently released her new book, \"Summer and the City: A Carrie Diaries Novel\" as part of her young adult series that follows the \"Sex and the City\" characters as teenagers.\nS7. This novel reveals that Carrie attended the prestigious Ivy League University, Brown, in the 1980s.\nS8. It also reveals that she took summer classes at the New School.\nS9. \"TV Guide\" described the young version of Carrie Bradshaw as \"Even when she's trying to play adult in the city with her fashion-forward style and 'grown-up' conversations, she still exudes an aura that manages to be innocent, cute and self-confident at the same time.\"\n    \nInput Question:\nWhen does carrie find out about sebastian and maggie?\n\nCorrect Response:\nThe Carrie Diaries is an American teen comedy-drama television series that served as a prequel to the HBO series Sex and the City. The show focuses on Carrie's life as a teenager, time in which she had a few relationships, the main one being her on and off relationship with Sebastian Kydd. During the show, Sebastian is involved at different times with Maggie, Carrie's best friend, and Carrie finds out about them in at least two different occasions. The first of them happened during Season 1 Episode 13, titled Kiss Yesterday Goodbye, and later during Season 2 Episode 6, The Safety Dance.\n\nModel Prediction:\nThe first season of The Carrie Diaries is an American teen comedy-drama television series that aired for two seasons on The CW from January 14, 2013, to January 31, 2014. It is a prequel to the HBO television series Sex and the City and based on the 2010 book of the same name by Candace Bushnell. In the first season, Carrie finds out about Sebastian and Maggie and they go on a date. In the second season, Carrie finds out about Sebastian and Maggie and they end up dating and Carrie finds out about their relationship.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "The first season of The Carrie Diaries is an American teen comedy-drama television series that aired for two seasons on The CW from January 14, 2013, to January 31, 2014. It is a prequel to the HBO television series Sex and the City and based on the 2010 book of the same name by Candace Bushnell. [In the first season, Carrie finds out about Sebastian and Maggie and they go on a date. In the second season, Carrie finds out about Sebastian and Maggie and they end up dating and Carrie finds out about their relationship.]\n\nExplanation:\nThe information about Carrie finding out about Sebastian and Maggie going on a date and them dating in the second season is not found in the passages, making it irrelevant. Additionally, the phrase \"Carrie finds out about Sebastian and Maggie\" is repeated twice, making it repetitive."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The first season of The Carrie Diaries is an American teen comedy-drama television series that aired for two seasons on The CW from January 14, 2013, to January 31, 2014.\nS2. It is a prequel to the HBO television series Sex and the City and based on the 2010 book of the same name by Candace Bushnell.\nS3. In the first season, Carrie finds out about Sebastian and Maggie and they go on a date.\nS4. In the second season, Carrie finds out about Sebastian and Maggie and they end up dating and Carrie finds out about their relationship.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "Inconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The third sentence of the model prediction mentions that \"Carrie finds out about Sebastian and Maggie and they go on a date\" in the first season. This information is not mentioned in any of the passages, making it an unverifiable fact.\n2. The fourth sentence of the model prediction states that \"In the second season, Carrie finds out about Sebastian and Maggie and they end up dating and Carrie finds out about their relationship.\" This information is also not mentioned in any of the passages, making it an unverifiable fact."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "None\n\nExplanation:\nThe model prediction does not miss any crucial information from the passages that directly answers the question or serves as crucial auxiliary information."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The Carrie Diaries is an American teen comedy-drama television series that aired for two seasons on The CW from January 14, 2013, to January 31, 2014. It is a prequel to the HBO television series Sex and the City and based on the 2010 book of the same name by Candace Bushnell. The series does not provide specific details about when Carrie finds out about Sebastian and Maggie."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 90, "end": 170}, {"error type": "Irrelevant", "explanation": "", "start": 233, "end": 297}, {"error type": "Wrong-Grounding", "explanation": "{\"passage_id\":2,\"sentence_id\":[5]}", "start": 319, "end": 385}, {"error type": "Irrelevant", "explanation": "", "start": 386, "end": 521}], "missing-info": [{"error type": "Missing-Minor-Auxiliary", "passage_id": 3, "sentence_id": [1]}, {"error type": "Missing-Minor-Auxiliary", "passage_id": 3, "sentence_id": [3]}], "corrected-prediction": "The first season of The Carrie Diaries is an American teen comedy-drama television series. It is a prequel to the HBO television series Sex and the City. The show focuses on Carrie's life as a teenager, time in which she had a few relationships, the main one being her on and off relationship with Sebastian Kydd.  In the first season, Sebastian ends up with Maggie."}}, {"question": "Who sings in the movie walk the line?", "passages": [["Walk the Line", "On February 28, 2006, a single-disc DVD and a two-disc collector edition DVD were released; these editions sold three million copies on their first day of release.", "On March 25, 2008, a two-disc 'extended cut' DVD was released for region one.", "The feature on disc one is 17 minutes longer than the theatrical release, and disc two features eight extended musical sequences with introductions and documentaries about the making of the film.", "The film has been released on Blu-ray Disc in France, Sweden and the UK in the form of its extended cut.", "The American Blu-ray features the shorter theatrical cut.", "Wind-up Records released the soundtrack in November 2005.", "It featured nine songs performed by Joaquin Phoenix, four songs by Reese Witherspoon, two songs by Tyler Hilton, and one song each by Waylon Payne, Johnathan Rice, and Shooter Jennings.", "The album received a Grammy at the 49th Annual Grammy Awards for Best Compilation Soundtrack Album for Motion Pictures, Television or Other Visual Media."], ["Walk the Line", "Walk the Line\n\nWalk the Line is a 2005 American biographical drama film directed by James Mangold.", "The screenplay, written by Mangold and Gill Dennis, is based on two autobiographies authored by singer-songwriter Johnny Cash\u2014\"\" and \"\".", "The film follows Cash's early life, his romance with June Carter, and his ascent to the country music scene.", "It stars Joaquin Phoenix as Cash, Reese Witherspoon as Carter, Ginnifer Goodwin as Vivian Liberto, and Robert Patrick as Cash's father.", "\"Walk the Line\" previewed at the Telluride Film Festival on September 4, 2005, and went into wide release on November 18.", "The film was nominated for five Oscars at the 78th Academy Awards, including Best Actor (Phoenix), Best Actress (Witherspoon, which she won), and Best Costume Design (Arianne Phillips).", "The film grossed more than $186 million worldwide.", "In 1968, as an audience of inmates at Folsom State Prison cheer for Johnny Cash's band, he waits backstage near a table saw, reminding him of his early life.", "In 1944, Johnny, then known as J.R., is raised on a cotton farm in Dyess, Arkansas with his brother Jack, father Ray, and mother Carrie."]], "gold": "Walk the Line is a 2005 American biographical musical romantic drama  based on the life of Johnny Cash. It featured nine songs performed by Joaquin Phoenix, who played Cash on the movie, four songs by Reese Witherspoon, two songs by Tyler Hilton, and one song each by Waylon Payne, Johnathan Rice, Shooter Jennings. ", "prediction 1": "Walking the Line is a 2005 American biographical drama film directed by James Mangold. The screenplay, written by Mangold and Gill Dennis, is based on two autobiographies authored by singer-songwriter Johnny Cash\u2014\"\" and \"\". It follows Cash's early life, his romance with June Carter, and his ascent to the country music scene. It stars Joaquin Phoenix as Cash, Reese Witherspoon as Carter, Ginnifer Goodwin as Vivian Liberto, and Robert Patrick as Cash. The album features nine songs performing by Reesesesesesesese Witherspoon, four songs by Tyler Hilton, and one song each by Waylon Payne, Johnathan Rice, Johnathan Rice, Johnathan Rice, Johnathan Rice, Johnathan Rice, and Shooter Jennings.", "prediction 2": "Walk the Line is a 2005 American biographical drama film directed by James Mangold. The screenplay, written by Mangold and Gill Dennis, is based on two autobiographies authored by singer-songwriter Johnny Cash\u2014\"\" and \"\". The soundtrack features nine songs performed by Joaquin Phoenix, four songs by Reese Witherspoon, two songs by Tyler Hilton, and one song each by Waylon Payne, Johnathan Rice, and Shooter Jennings.", "prediction 3": "Walk the Line is a 2005 American biographical drama film directed by James Mangold. The screenplay is based on two autobiographies authored by singer-songwriter Johnny Cash\u2014\"\" and \"\". The soundtrack features nine songs performed by Joaquin Phoenix, four songs by Reese Witherspoon, two songs by Tyler Hilton, one song each by Waylon Payne, Johnathan Rice, and Shooter Jennings.", "prediction 4": "Walk the Line is a 2005 American biographical drama film directed by James Mangold. The screenplay, written by Mangold and Gill Dennis, is based on two autobiographies authored by singer-songwriter Johnny Cash, \"\" and \"\". The soundtrack features nine songs performed by Joaquin Phoenix, four songs by Reese Witherspoon, two songs by Tyler Hilton, and one song each by Waylon Payne, Johnathan Rice, and Shooter Jennings.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 484, "end": 527}, {"error type": "Irrelevant", "explanation": "", "start": 592, "end": 670}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 1, "sentence_id": [7]}], "corrected-prediction": "Walk the Line is a 2005 American biographical drama film directed by James Mangold. The screenplay, written by Mangold and Gill Dennis, is based on two autobiographies authored by singer-songwriter Johnny Cash. It follows Cash's early life, his romance with June Carter, and his ascent to the country music scene. It stars Joaquin Phoenix as Cash, Reese Witherspoon as Carter, Ginnifer Goodwin as Vivian Liberto, and Robert Patrick as Cash. The soundtrack features nine songs performed by Joaquin Phoenix, four songs by Reese Witherspoon, two songs by Tyler Hilton, and one song each by Waylon Payne, Johnathan Rice, and Shooter Jennings."}, "preference": [2, 2, 2, 1, 0, 2], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Walk the Line\nS1. On February 28, 2006, a single-disc DVD and a two-disc collector edition DVD were released; these editions sold three million copies on their first day of release.\nS2. On March 25, 2008, a two-disc 'extended cut' DVD was released for region one.\nS3. The feature on disc one is 17 minutes longer than the theatrical release, and disc two features eight extended musical sequences with introductions and documentaries about the making of the film.\nS4. The film has been released on Blu-ray Disc in France, Sweden and the UK in the form of its extended cut.\nS5. The American Blu-ray features the shorter theatrical cut.\nS6. Wind-up Records released the soundtrack in November 2005.\nS7. It featured nine songs performed by Joaquin Phoenix, four songs by Reese Witherspoon, two songs by Tyler Hilton, and one song each by Waylon Payne, Johnathan Rice, and Shooter Jennings.\nS8. The album received a Grammy at the 49th Annual Grammy Awards for Best Compilation Soundtrack Album for Motion Pictures, Television or Other Visual Media.\n\nPassage 2: Title (S0) - Walk the Line\nS1. Walk the Line  Walk the Line is a 2005 American biographical drama film directed by James Mangold.\nS2. The screenplay, written by Mangold and Gill Dennis, is based on two autobiographies authored by singer-songwriter Johnny Cash\u2014\"\" and \"\".\nS3. The film follows Cash's early life, his romance with June Carter, and his ascent to the country music scene.\nS4. It stars Joaquin Phoenix as Cash, Reese Witherspoon as Carter, Ginnifer Goodwin as Vivian Liberto, and Robert Patrick as Cash's father.\nS5. \"Walk the Line\" previewed at the Telluride Film Festival on September 4, 2005, and went into wide release on November 18.\nS6. The film was nominated for five Oscars at the 78th Academy Awards, including Best Actor (Phoenix), Best Actress (Witherspoon, which she won), and Best Costume Design (Arianne Phillips).\nS7. The film grossed more than $186 million worldwide.\nS8. In 1968, as an audience of inmates at Folsom State Prison cheer for Johnny Cash's band, he waits backstage near a table saw, reminding him of his early life.\nS9. In 1944, Johnny, then known as J.R., is raised on a cotton farm in Dyess, Arkansas with his brother Jack, father Ray, and mother Carrie.\n    \nInput Question:\nWho sings in the movie walk the line?\n\nCorrect Response:\nWalk the Line is a 2005 American biographical musical romantic drama  based on the life of Johnny Cash. It featured nine songs performed by Joaquin Phoenix, who played Cash on the movie, four songs by Reese Witherspoon, two songs by Tyler Hilton, and one song each by Waylon Payne, Johnathan Rice, Shooter Jennings. \n\nModel Prediction:\nWalking the Line is a 2005 American biographical drama film directed by James Mangold. The screenplay, written by Mangold and Gill Dennis, is based on two autobiographies authored by singer-songwriter Johnny Cash\u2014\"\" and \"\". It follows Cash's early life, his romance with June Carter, and his ascent to the country music scene. It stars Joaquin Phoenix as Cash, Reese Witherspoon as Carter, Ginnifer Goodwin as Vivian Liberto, and Robert Patrick as Cash. The album features nine songs performing by Reesesesesesesese Witherspoon, four songs by Tyler Hilton, and one song each by Waylon Payne, Johnathan Rice, Johnathan Rice, Johnathan Rice, Johnathan Rice, Johnathan Rice, and Shooter Jennings.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "Walking the Line is a 2005 American biographical drama film directed by James Mangold. The screenplay, written by Mangold and Gill Dennis, is based on two autobiographies authored by singer-songwriter Johnny Cash\u2014\"\" and \"\". It follows Cash's early life, his romance with June Carter, and his ascent to the country music scene. It stars Joaquin Phoenix as Cash, Reese Witherspoon as Carter, Ginnifer Goodwin as Vivian Liberto, and Robert Patrick as Cash. The album features nine songs [performing by Reesesesesesesese Witherspoon], four songs by Tyler Hilton, and one song each by Waylon Payne, [Johnathan Rice, Johnathan Rice, Johnathan Rice, Johnathan Rice, Johnathan Rice], and Shooter Jennings.\n\nExplanation:\n1. The phrase \"performing by Reesesesesesesese Witherspoon\" is incoherent due to a major grammatical error and a typo in the name \"Reese Witherspoon\".\n2. The name \"Johnathan Rice\" is repeated multiple times, which is unnecessary and repetitive. Only one mention of \"Johnathan Rice\" is needed."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. Walking the Line is a 2005 American biographical drama film directed by James Mangold.\nS2. The screenplay, written by Mangold and Gill Dennis, is based on two autobiographies authored by singer-songwriter Johnny Cash\u2014\"\" and \"\".\nS3. It follows Cash's early life, his romance with June Carter, and his ascent to the country music scene.\nS4. It stars Joaquin Phoenix as Cash, Reese Witherspoon as Carter, Ginnifer Goodwin as Vivian Liberto, and Robert Patrick as Cash.\nS5. The album features nine songs performing by Reesesesesesesese Witherspoon, four songs by Tyler Hilton, and one song each by Waylon Payne, Johnathan Rice, Johnathan Rice, Johnathan Rice, Johnathan Rice, Johnathan Rice, and Shooter Jennings.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "Inconsistent or Unverifiable Sentences:\n1. S1\n2. S5\n\nExplanation:\n1. The title of the movie is incorrectly stated as \"Walking the Line\" in sentence 1, which is inconsistent with the information provided in the passages. The correct title is \"Walk the Line\".\n2. Sentence 5 incorrectly states that Reese Witherspoon performed nine songs, which is inconsistent with the information in Passage 1, Sentence 7 that states Joaquin Phoenix performed nine songs."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 7 [Missing Answer]\n2. Passage 1, sentence 7 [Missing Answer]\n\nExplanation:\n1. The model prediction fails to mention that Joaquin Phoenix performed nine songs in the movie, which is a direct answer to the question.\n2. The model prediction also omits the fact that Reese Witherspoon performed four songs in the movie, which is another direct answer to the question."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "Walk the Line is a 2005 American biographical drama film directed by James Mangold. The screenplay, written by Mangold and Gill Dennis, is based on two autobiographies authored by singer-songwriter Johnny Cash. It follows Cash's early life, his romance with June Carter, and his ascent to the country music scene. It stars Joaquin Phoenix as Cash, Reese Witherspoon as Carter, Ginnifer Goodwin as Vivian Liberto, and Robert Patrick as Cash. The soundtrack features nine songs performed by Joaquin Phoenix, four songs by Reese Witherspoon, two songs by Tyler Hilton, and one song each by Waylon Payne, Johnathan Rice, and Shooter Jennings."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 60, "end": 138}, {"error type": "Irrelevant", "explanation": "", "start": 208, "end": 223}, {"error type": "Irrelevant", "explanation": "", "start": 224, "end": 326}, {"error type": "Irrelevant", "explanation": "", "start": 327, "end": 453}, {"error type": "Wrong-Grounding", "explanation": "{\"passage_id\":1,\"sentence_id\":[7]}", "start": 498, "end": 556}], "missing-info": [], "corrected-prediction": "Walking the Line is a 2005 American biographical drama film based on two autobiographies authored by singer-songwriter Johnny Cash. It featured nine songs performed by Joaquin Phoenix, four songs by Reese Witherspoon, two songs by Tyler Hilton, and one song each by Waylon Payne, Johnathan Rice, and Shooter Jennings."}}, {"question": "Who is minister of magic after voldemort dies?", "passages": [["Ministry of Magic", "Later, Dawlish is sent to arrest Augusta Longbottom.", "After a struggle, her defence places Dawlish in St Mungo's Hospital.", "Dawlish's first name is not revealed in the books or films.", "However, Rowling said in an interview with the podcast \"PotterCast\" that she named him John, owing to host John Noe's appreciation of the character.", "Dawlish was portrayed by Richard Leaf in the film adaptation of \"Harry Potter and the Order of the Phoenix\".", "Cornelius Oswald Fudge is first mentioned in \"Harry Potter and the Philosopher's Stone\" as the Minister for Magic of the United Kingdom.", "He makes his first appearance in \"Harry Potter and the Chamber of Secrets\" when he arrives at the school to take Hagrid to Azkaban, even though he does not firmly believe that Hagrid is guilty.", "He also removes Dumbledore as Headmaster when pressured by Lucius Malfoy who insisted that all the school governors had voted on it.", "However, it is not until \"Harry Potter and the Prisoner of Azkaban\" that Fudge meets Harry for the first time.", "Fudge does not press charges against Harry for accidentally inflating Aunt Marge, and advises him to be careful because an escaped convict is at large."], ["Ministry of Magic", "At times, the Ministry can also seem uninterested in solving serious problems, choosing instead to ignore or cover up bad news.", "In \"Harry Potter and the Chamber of Secrets\", Fudge takes a long time to respond to the attacks on Hogwarts.", "In the fourth and fifth instalments, Fudge refuses to believe that Lord Voldemort has returned, despite mounting evidence.", "The Ministry even mounts a campaign to damage Harry Potter's credibility, an effort fuelled in part by Fudge's fear that Albus Dumbledore wants to forcibly remove him from his position.", "Eventually, the Ministry is forced to acknowledge the emergency and act on it.", "Fudge is subsequently removed from office for incompetence and replaced by Rufus Scrimgeour.", "When interviewed, Rowling stated that when Harry, Ron and Hermione work for the Ministry, they change it drastically, making it less corrupt.", "The Department of Magical Law Enforcement is a combination of police and justice facilities.", "It is located on the second level of the Ministry of Magic.", "At the beginning of the series, it is headed by Amelia Bones, who is replaced by Pius Thicknesse after Voldemort murders her.", "Thicknesse is replaced by Yaxley in \"Harry Potter and the Deathly Hallows\" after Voldemort has Thicknesse appointed the puppet Minister for his regime."], ["Ministry of Magic", "Thicknesse is described as a man with long hair and a beard, which are mostly black but tinged with some grey, along with a great overhanging forehead and glinting eyes.", "Harry's immediate impression is of \"a crab looking out from beneath a rock.\"", "After the coup in which Scrimgeour is killed, the Ministry comes under the de facto control of Voldemort, who appoints Thicknesse as his puppet Minister.", "Thicknesse joins the ranks of the Death Eaters for the rest of the book and fights with them at the Battle of Hogwarts, where he duels against Percy Weasley (who Transfigures him into a sea urchin).", "Following the end of the battle, the Imperius Curse that was placed upon him is broken.", "Kingsley Shacklebolt replaces him as interim (later permanent) Minister for Magic.", "Not much is known about the \"real\" nature of Thicknesse, as he has been under the control of Yaxley for nearly the entire book.", "Guy Henry plays Thicknesse in \"Harry Potter and the Deathly Hallows \u2013 Part 1\" and \"Part 2\", in which he is portrayed as being a Death Eater even before Scrimgeour's death; there is no mention of the Imperius Curse being used to secure his support."], ["Ministry of Magic", "Ministry of Magic\n\nThe Ministry of Magic is the government of the Magical community of Britain in \"J. K. Rowling's Wizarding World\".", "The magical government in Britain is \nfirst mentioned in \"Harry Potter and the Philosopher's Stone\"; the Ministry makes its first proper appearance in \"Harry Potter and the Order of the Phoenix\".", "Throughout the books, it is generally depicted as either corrupt, incompetent, or both, with its high officials blind to actual events and dangers.", "It reaches a zenith of corruption before being effectively taken over by Lord Voldemort.", "At the end of the final book, following Voldemort's death, Kingsley Shacklebolt takes over the ministry, changing it for the better.", "By the time of \"Harry Potter and the Cursed Child\", Hermione Granger is the Minister for Magic.", "Each new Muggle Prime Minister receives a visit from the Minister for Magic, who informs him or her that the wizarding world exists.", "He explains that he will contact the Prime Minister only in circumstances in which the events of the wizard world may affect Muggles.", "For example, the Minister has to inform the Prime Minister if dangerous magical artefacts or animals are to be brought into Britain.", "The Ministry keeps in touch with the British Prime Minister via a wizard's portrait in the Prime Minister's office at 10 Downing Street."], ["Ministry of Magic", "Voldemort irreparably damaged her mentally and physically while breaking the Memory Charm, through which he gained information about the Triwizard Tournament and Crouch Jr..", "During the duel between Harry and Voldemort in the graveyard at Little Hangleton, Bertha is one of the shadows that spills out from Voldemort's wand and helps Harry escape.", "She appears to be wiser after her death, and supports Harry during \"The Goblet of Fire\" so he can defeat Voldemort, her murderer.", "Bertha Jorkins' character was written out of the film adaptation of \"Goblet of Fire\" due to time constraints.", "Rufus Scrimgeour serves as the Minister for Magic of the United Kingdom, succeeding Cornelius Fudge who was ousted by the wizarding community for his failure to announce the return of Voldemort, discrediting Harry Potter and Albus Dumbledore, and allowing Dolores Umbridge to become Headmistress of Hogwarts, from \"Harry Potter and the Half-Blood Prince\" until his death in the following book.", "He is described as looking like an old lion with tawny hair and bushy eyebrows, yellow eyes and wire-rimmed spectacles."], ["Ministry of Magic", "Scrimgeour makes a short appearance, looking tired and grim due to the pressures of his position, in \"Harry Potter and the Deathly Hallows\" at The Burrow with Dumbledore's will; a final argument promptly breaks out between Harry and him.", "Scrimgeour is assassinated shortly after the visit when Death Eaters take over the Ministry.", "He is rumoured to have been tortured for Harry's whereabouts by Ministry officials, under the control of the Imperius Curse, before he is killed.", "Harry felt a \"rush of gratitude\" to hear that Scrimgeour, in his final act, attempted to protect Harry by refusing to disclose his location.", "With the Ministry in Death Eaters' hands, the official line for Scrimgeour's death is that he resigned.", "Bill Nighy played Scrimgeour in \"Harry Potter and the Deathly Hallows \u2013 Part 1\", in which he is played as being Welsh.", "Pius Thicknesse is first introduced in \"Harry Potter and the Deathly Hallows\".", "He is the Head of the Department of Magical Law Enforcement at the start of the book, when he is placed under the Imperius Curse by Corban Yaxley, who uses his position to infiltrate the senior ranks of the Ministry."], ["Order of the Phoenix (fictional organisation)", "Firstly in \"Philosopher's Stone,\" Harry sees James and Lily in the Mirror of Erised.", "Secondly during Harry's struggle with Voldemort in \"Goblet of Fire,\" they appear momentarily, along with other victims killed by Voldemort's wand.", "They appear in Snape's memories in both \"Order of the Phoenix\" and \"Deathly Hallows\", and finally in \"Deathly Hallows\" when Harry makes his self-sacrificing walk into the Forbidden Forest, determined to let Voldemort kill him without offering resistance, Harry's parents walk at his side and Lily tells him how proud they are of him.", "In an interview conducted by Daniel Radcliffe, Rowling revealed that Lily Potter's maiden name, Evans, was based on the real name of the author George Eliot, Mary Anne Evans.", "Lily is portrayed by Geraldine Somerville as an adult in the film series, and by Susie Shinner as a teenager and Ellie Darcey-Alden as a child.", "Kingsley Shacklebolt is a senior Auror who acts as informer for the Order within the Ministry of Magic."], ["Ministry of Magic", "Before his resignation, he makes several attempts to have Dumbledore arrange a meeting between himself and Harry so that Harry can lie on Fudge's behalf and make it look as though the Ministry is winning the war, but Dumbledore refuses, knowing how ridiculous Harry would find the idea.", "Fudge is last mentioned in the series as one of the attendees at Dumbledore's funeral; his fate during Voldemort's takeover of the Ministry during the following year is unknown.", "In the film series, Fudge was portrayed by Robert Hardy.", "Bertha Jorkins was a student at Hogwarts at the same time as James Potter and company.", "She was known as nosy, with a good head for gossip.", "She became a Ministry of Magic employee after leaving Hogwarts.", "In the summer before the events of \"Harry Potter and the Goblet of Fire\", she was killed by Voldemort.", "Rowling later revealed that her death was used to turn Nagini, Voldemort's snake, into a Horcrux.", "Some months before her murder, she accidentally discovered that Barty Crouch Jr., who supposedly died in Azkaban prison, was still alive and being hidden by his father.", "Barty Crouch Sr. silenced her with a powerful Memory Charm, which made her a little befuddled."]], "gold": "At the end of Harry Potter and the Deathly Hallows, following Voldemort's death, Kingsley Shacklebolt takes over as the Minster for Magic, changing the ministry for the better. George Harris is the actor who plays Kingsley in the Harry Potter movies Order of the Phoenix and Deathly Hallows Part 1 and Part 2. By the time of Harry Potter and the Cursed Child, Hermione Granger is the Minister for Magic. However, in the beginning of the Harry Potter series, Cornelius Oswald Fudge is first mentioned in Harry Potter and the Philosopher's Stone as the Minister for Magic of the United Kingdom. Fudge was portrayed by Robert Hardy in the film series. Then, Rufus Scrimgeour serves as the Minister for Magic of the United Kingdom from Harry Potter and the Half-Blood Prince until his death, succeeding Cornelius Fudge who was ousted by the wizarding community for his failure to announce the return of Voldemort. Bill Nighy is the actor who plays Scrimgeour in Harry Potter and the Deathly Hallows \u2013 Part 1. Pius Thicknesse is first introduced in Harry Potter and the Deathly Hallows. He is the Head of the Department of Magical Law Enforcement at the start of the book. After the coup in which Scrimgeour is killed, the Ministry comes under the de facto control of Voldemort, who appoints Thicknesse as his puppet Minister. Guy Henry plays Thicknesse in Harry Potter and the Deathly Hallows \u2013 Part 1 and Part 2, in which he is depicted as a Death Eater even before Scrimgeour's death. In Part 2, Thicknesse is killed by Voldemort.", "prediction 1": "The Ministry of Magic is the government of the Magical community of Britain in J. K. Rowling's Wizarding World. The Ministry of Magic is the government of the Magical community of Britain in J. K. Rowling's Wizarding World. The Minister of Magic is Cornelius Oswald Fudge, who is first mentioned in Harry Potter and the Philosopher's Stone as the Minister for Magic of the United Kingdom. Fudge is later removed from office for incompetence and replaced by Rufus Scrimgeour.\n", "prediction 2": "The Ministry of Magic is the government of the Magical community of Britain in J. K. Rowling's Wizarding World. Following the death of Lord Voldemort, Cornelius Oswald Fudge becomes Minister of Magic for the United Kingdom. However, after Fudge's death, Rufus Scrimgeour becomes Minister of Magic until Kingsley Shacklebolt comes in.", "prediction 3": "The Minister of Magic, for the most part, is Cornelius Oswald Fudge. But when Voldemort dies, Thicknesse becomes the puppet minister. The puppet minister position is ended when Yaxley is killed. Along with Thicknesse, Rufus Scrimgeour takes over the ministry when Scrimgeour is killed in a coup and has Thicknesse appointed his temporary minister.", "prediction 4": "The Ministry of Magic, officially the Government of the Magical Community of Britain, is the government of the Magical community of Britain. In Harry Potter and the Deathly Hallows, Rufus Scrimgeour is the Minister of Magic of the United Kingdom, Foyles & Associates, and Cornelius Oswald Fudge is the Minister for Magic. In the movies, Cornelius Oswald Fudge is also the Minister of Magic.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 0, "end": 111}, {"error type": "Irrelevant", "explanation": "", "start": 0, "end": 111}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 4, "sentence_id": [5]}], "corrected-prediction": "After Voldemort's death, Kingsley Shacklebolt takes over as the Minister for Magic, as mentioned in J. K. Rowling's Wizarding World. By the time of \"Harry Potter and the Cursed Child\", Hermione Granger becomes the Minister for Magic. Initially, the Minister of Magic was Cornelius Oswald Fudge, who was later removed from office for incompetence and replaced by Rufus Scrimgeour."}, "preference": [1, 1, 1, 1, 1, 2], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Ministry of Magic\nS1. Later, Dawlish is sent to arrest Augusta Longbottom.\nS2. After a struggle, her defence places Dawlish in St Mungo's Hospital.\nS3. Dawlish's first name is not revealed in the books or films.\nS4. However, Rowling said in an interview with the podcast \"PotterCast\" that she named him John, owing to host John Noe's appreciation of the character.\nS5. Dawlish was portrayed by Richard Leaf in the film adaptation of \"Harry Potter and the Order of the Phoenix\".\nS6. Cornelius Oswald Fudge is first mentioned in \"Harry Potter and the Philosopher's Stone\" as the Minister for Magic of the United Kingdom.\nS7. He makes his first appearance in \"Harry Potter and the Chamber of Secrets\" when he arrives at the school to take Hagrid to Azkaban, even though he does not firmly believe that Hagrid is guilty.\nS8. He also removes Dumbledore as Headmaster when pressured by Lucius Malfoy who insisted that all the school governors had voted on it.\nS9. However, it is not until \"Harry Potter and the Prisoner of Azkaban\" that Fudge meets Harry for the first time.\nS10. Fudge does not press charges against Harry for accidentally inflating Aunt Marge, and advises him to be careful because an escaped convict is at large.\n\nPassage 2: Title (S0) - Ministry of Magic\nS1. At times, the Ministry can also seem uninterested in solving serious problems, choosing instead to ignore or cover up bad news.\nS2. In \"Harry Potter and the Chamber of Secrets\", Fudge takes a long time to respond to the attacks on Hogwarts.\nS3. In the fourth and fifth instalments, Fudge refuses to believe that Lord Voldemort has returned, despite mounting evidence.\nS4. The Ministry even mounts a campaign to damage Harry Potter's credibility, an effort fuelled in part by Fudge's fear that Albus Dumbledore wants to forcibly remove him from his position.\nS5. Eventually, the Ministry is forced to acknowledge the emergency and act on it.\nS6. Fudge is subsequently removed from office for incompetence and replaced by Rufus Scrimgeour.\nS7. When interviewed, Rowling stated that when Harry, Ron and Hermione work for the Ministry, they change it drastically, making it less corrupt.\nS8. The Department of Magical Law Enforcement is a combination of police and justice facilities.\nS9. It is located on the second level of the Ministry of Magic.\nS10. At the beginning of the series, it is headed by Amelia Bones, who is replaced by Pius Thicknesse after Voldemort murders her.\nS11. Thicknesse is replaced by Yaxley in \"Harry Potter and the Deathly Hallows\" after Voldemort has Thicknesse appointed the puppet Minister for his regime.\n\nPassage 3: Title (S0) - Ministry of Magic\nS1. Thicknesse is described as a man with long hair and a beard, which are mostly black but tinged with some grey, along with a great overhanging forehead and glinting eyes.\nS2. Harry's immediate impression is of \"a crab looking out from beneath a rock.\"\nS3. After the coup in which Scrimgeour is killed, the Ministry comes under the de facto control of Voldemort, who appoints Thicknesse as his puppet Minister.\nS4. Thicknesse joins the ranks of the Death Eaters for the rest of the book and fights with them at the Battle of Hogwarts, where he duels against Percy Weasley (who Transfigures him into a sea urchin).\nS5. Following the end of the battle, the Imperius Curse that was placed upon him is broken.\nS6. Kingsley Shacklebolt replaces him as interim (later permanent) Minister for Magic.\nS7. Not much is known about the \"real\" nature of Thicknesse, as he has been under the control of Yaxley for nearly the entire book.\nS8. Guy Henry plays Thicknesse in \"Harry Potter and the Deathly Hallows \u2013 Part 1\" and \"Part 2\", in which he is portrayed as being a Death Eater even before Scrimgeour's death; there is no mention of the Imperius Curse being used to secure his support.\n\nPassage 4: Title (S0) - Ministry of Magic\nS1. Ministry of Magic  The Ministry of Magic is the government of the Magical community of Britain in \"J. K. Rowling's Wizarding World\".\nS2. The magical government in Britain is  first mentioned in \"Harry Potter and the Philosopher's Stone\"; the Ministry makes its first proper appearance in \"Harry Potter and the Order of the Phoenix\".\nS3. Throughout the books, it is generally depicted as either corrupt, incompetent, or both, with its high officials blind to actual events and dangers.\nS4. It reaches a zenith of corruption before being effectively taken over by Lord Voldemort.\nS5. At the end of the final book, following Voldemort's death, Kingsley Shacklebolt takes over the ministry, changing it for the better.\nS6. By the time of \"Harry Potter and the Cursed Child\", Hermione Granger is the Minister for Magic.\nS7. Each new Muggle Prime Minister receives a visit from the Minister for Magic, who informs him or her that the wizarding world exists.\nS8. He explains that he will contact the Prime Minister only in circumstances in which the events of the wizard world may affect Muggles.\nS9. For example, the Minister has to inform the Prime Minister if dangerous magical artefacts or animals are to be brought into Britain.\nS10. The Ministry keeps in touch with the British Prime Minister via a wizard's portrait in the Prime Minister's office at 10 Downing Street.\n\nPassage 5: Title (S0) - Ministry of Magic\nS1. Voldemort irreparably damaged her mentally and physically while breaking the Memory Charm, through which he gained information about the Triwizard Tournament and Crouch Jr..\nS2. During the duel between Harry and Voldemort in the graveyard at Little Hangleton, Bertha is one of the shadows that spills out from Voldemort's wand and helps Harry escape.\nS3. She appears to be wiser after her death, and supports Harry during \"The Goblet of Fire\" so he can defeat Voldemort, her murderer.\nS4. Bertha Jorkins' character was written out of the film adaptation of \"Goblet of Fire\" due to time constraints.\nS5. Rufus Scrimgeour serves as the Minister for Magic of the United Kingdom, succeeding Cornelius Fudge who was ousted by the wizarding community for his failure to announce the return of Voldemort, discrediting Harry Potter and Albus Dumbledore, and allowing Dolores Umbridge to become Headmistress of Hogwarts, from \"Harry Potter and the Half-Blood Prince\" until his death in the following book.\nS6. He is described as looking like an old lion with tawny hair and bushy eyebrows, yellow eyes and wire-rimmed spectacles.\n\nPassage 6: Title (S0) - Ministry of Magic\nS1. Scrimgeour makes a short appearance, looking tired and grim due to the pressures of his position, in \"Harry Potter and the Deathly Hallows\" at The Burrow with Dumbledore's will; a final argument promptly breaks out between Harry and him.\nS2. Scrimgeour is assassinated shortly after the visit when Death Eaters take over the Ministry.\nS3. He is rumoured to have been tortured for Harry's whereabouts by Ministry officials, under the control of the Imperius Curse, before he is killed.\nS4. Harry felt a \"rush of gratitude\" to hear that Scrimgeour, in his final act, attempted to protect Harry by refusing to disclose his location.\nS5. With the Ministry in Death Eaters' hands, the official line for Scrimgeour's death is that he resigned.\nS6. Bill Nighy played Scrimgeour in \"Harry Potter and the Deathly Hallows \u2013 Part 1\", in which he is played as being Welsh.\nS7. Pius Thicknesse is first introduced in \"Harry Potter and the Deathly Hallows\".\nS8. He is the Head of the Department of Magical Law Enforcement at the start of the book, when he is placed under the Imperius Curse by Corban Yaxley, who uses his position to infiltrate the senior ranks of the Ministry.\n\nPassage 7: Title (S0) - Order of the Phoenix (fictional organisation)\nS1. Firstly in \"Philosopher's Stone,\" Harry sees James and Lily in the Mirror of Erised.\nS2. Secondly during Harry's struggle with Voldemort in \"Goblet of Fire,\" they appear momentarily, along with other victims killed by Voldemort's wand.\nS3. They appear in Snape's memories in both \"Order of the Phoenix\" and \"Deathly Hallows\", and finally in \"Deathly Hallows\" when Harry makes his self-sacrificing walk into the Forbidden Forest, determined to let Voldemort kill him without offering resistance, Harry's parents walk at his side and Lily tells him how proud they are of him.\nS4. In an interview conducted by Daniel Radcliffe, Rowling revealed that Lily Potter's maiden name, Evans, was based on the real name of the author George Eliot, Mary Anne Evans.\nS5. Lily is portrayed by Geraldine Somerville as an adult in the film series, and by Susie Shinner as a teenager and Ellie Darcey-Alden as a child.\nS6. Kingsley Shacklebolt is a senior Auror who acts as informer for the Order within the Ministry of Magic.\n\nPassage 8: Title (S0) - Ministry of Magic\nS1. Before his resignation, he makes several attempts to have Dumbledore arrange a meeting between himself and Harry so that Harry can lie on Fudge's behalf and make it look as though the Ministry is winning the war, but Dumbledore refuses, knowing how ridiculous Harry would find the idea.\nS2. Fudge is last mentioned in the series as one of the attendees at Dumbledore's funeral; his fate during Voldemort's takeover of the Ministry during the following year is unknown.\nS3. In the film series, Fudge was portrayed by Robert Hardy.\nS4. Bertha Jorkins was a student at Hogwarts at the same time as James Potter and company.\nS5. She was known as nosy, with a good head for gossip.\nS6. She became a Ministry of Magic employee after leaving Hogwarts.\nS7. In the summer before the events of \"Harry Potter and the Goblet of Fire\", she was killed by Voldemort.\nS8. Rowling later revealed that her death was used to turn Nagini, Voldemort's snake, into a Horcrux.\nS9. Some months before her murder, she accidentally discovered that Barty Crouch Jr., who supposedly died in Azkaban prison, was still alive and being hidden by his father.\nS10. Barty Crouch Sr. silenced her with a powerful Memory Charm, which made her a little befuddled.\n    \nInput Question:\nWho is minister of magic after voldemort dies?\n\nCorrect Response:\nAt the end of Harry Potter and the Deathly Hallows, following Voldemort's death, Kingsley Shacklebolt takes over as the Minster for Magic, changing the ministry for the better. George Harris is the actor who plays Kingsley in the Harry Potter movies Order of the Phoenix and Deathly Hallows Part 1 and Part 2. By the time of Harry Potter and the Cursed Child, Hermione Granger is the Minister for Magic. However, in the beginning of the Harry Potter series, Cornelius Oswald Fudge is first mentioned in Harry Potter and the Philosopher's Stone as the Minister for Magic of the United Kingdom. Fudge was portrayed by Robert Hardy in the film series. Then, Rufus Scrimgeour serves as the Minister for Magic of the United Kingdom from Harry Potter and the Half-Blood Prince until his death, succeeding Cornelius Fudge who was ousted by the wizarding community for his failure to announce the return of Voldemort. Bill Nighy is the actor who plays Scrimgeour in Harry Potter and the Deathly Hallows \u2013 Part 1. Pius Thicknesse is first introduced in Harry Potter and the Deathly Hallows. He is the Head of the Department of Magical Law Enforcement at the start of the book. After the coup in which Scrimgeour is killed, the Ministry comes under the de facto control of Voldemort, who appoints Thicknesse as his puppet Minister. Guy Henry plays Thicknesse in Harry Potter and the Deathly Hallows \u2013 Part 1 and Part 2, in which he is depicted as a Death Eater even before Scrimgeour's death. In Part 2, Thicknesse is killed by Voldemort.\n\nModel Prediction:\nThe Ministry of Magic is the government of the Magical community of Britain in J. K. Rowling's Wizarding World. The Ministry of Magic is the government of the Magical community of Britain in J. K. Rowling's Wizarding World. The Minister of Magic is Cornelius Oswald Fudge, who is first mentioned in Harry Potter and the Philosopher's Stone as the Minister for Magic of the United Kingdom. Fudge is later removed from office for incompetence and replaced by Rufus Scrimgeour.\n\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "[The Ministry of Magic is the government of the Magical community of Britain in J. K. Rowling's Wizarding World.] [The Ministry of Magic is the government of the Magical community of Britain in J. K. Rowling's Wizarding World.] The Minister of Magic is Cornelius Oswald Fudge, who is first mentioned in Harry Potter and the Philosopher's Stone as the Minister for Magic of the United Kingdom. Fudge is later removed from office for incompetence and replaced by Rufus Scrimgeour.\n\nExplanation:\n1. The first and second sentences are repetitive, as they contain the same information. The first sentence is also irrelevant, as it does not directly answer the question or provide crucial auxiliary information.\n2. The third and fourth sentences, while providing some background information, do not directly answer the question about who becomes the Minister of Magic after Voldemort's death. Therefore, they are also irrelevant."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The Ministry of Magic is the government of the Magical community of Britain in J. K. Rowling's Wizarding World.\nS2. The Ministry of Magic is the government of the Magical community of Britain in J. K. Rowling's Wizarding World.\nS3. The Minister of Magic is Cornelius Oswald Fudge, who is first mentioned in Harry Potter and the Philosopher's Stone as the Minister for Magic of the United Kingdom.\nS4. Fudge is later removed from office for incompetence and replaced by Rufus Scrimgeour.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation:\nAll the facts presented in the model prediction are consistent with the information provided in the passages. However, the model prediction fails to answer the question correctly, which is about who becomes the Minister of Magic after Voldemort's death."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 4, sentence 5 [Missing Answer]\n2. Passage 4, sentence 6 [Missing Major Auxiliary Information]\n\nExplanation:\n1. The model prediction fails to mention that Kingsley Shacklebolt becomes the Minister for Magic after Voldemort's death, which is the direct answer to the question. This information can be found in Passage 4, sentence 5.\n2. The model prediction also omits the major auxiliary information that Hermione Granger becomes the Minister for Magic by the time of \"Harry Potter and the Cursed Child\". This information can be found in Passage 4, sentence 6."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "After Voldemort's death, Kingsley Shacklebolt takes over as the Minister for Magic, as mentioned in J. K. Rowling's Wizarding World. By the time of \"Harry Potter and the Cursed Child\", Hermione Granger becomes the Minister for Magic. Initially, the Minister of Magic was Cornelius Oswald Fudge, who was later removed from office for incompetence and replaced by Rufus Scrimgeour."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 0, "end": 111}, {"error type": "Redundant", "explanation": "The Ministry of Magic is the government of the Magical community of Britain in J. K. Rowling's Wizarding World. ", "start": 112, "end": 223}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 3, "sentence_id": [3]}, {"error type": "Missing-Minor-Auxiliary", "passage_id": 3, "sentence_id": [8]}, {"error type": "Missing-Answer", "passage_id": 4, "sentence_id": [6]}, {"error type": "Missing-Major-Auxiliary", "passage_id": 5, "sentence_id": [5]}, {"error type": "Missing-Minor-Auxiliary", "passage_id": 6, "sentence_id": [6]}, {"error type": "Missing-Minor-Auxiliary", "passage_id": 6, "sentence_id": [8]}, {"error type": "Missing-Minor-Auxiliary", "passage_id": 8, "sentence_id": [3]}, {"error type": "Missing-Answer", "passage_id": 4, "sentence_id": [5]}], "corrected-prediction": "The Minister of Magic is Cornelius Oswald Fudge, who is first mentioned in Harry Potter and the Philosopher's Stone as the Minister for Magic of the United Kingdom. Fudge is later removed from office for incompetence and replaced by Rufus Scrimgeour. His incompetence was his failure to announce the return of Voldemort. Fudge was portrayed by Robert Hardy in the film series. Scrimgeour was Prime Minister in \"Harry Potter and the Half-Blood Prince\" until his death. Bill Nighy played Scrimgeour in \"Harry Potter and the Deathly Hallows \u2013 Part 1\". After the coup in which Scrimgeour is killed, the Ministry comes under the de facto control of Voldemort, who appoints Thicknesse as his puppet Minister. Guy Henry plays Thicknesse in \"Harry Potter and the Deathly Hallows \u2013 Part 1\" and \"Part 2\", in which he is portrayed as being a Death Eater even before Scrimgeour's death. Thicknesse is first introduced in \"Harry Potter and the Deathly Hallows\". He is the Head of the Department of Magical Law Enforcement at the start of the book. At the end of the final book, following Voldemort's death, Kingsley Shacklebolt takes over the ministry, changing it for the better. By the time of \"Harry Potter and the Cursed Child\", Hermione Granger is the Minister for Magic."}}, {"question": "What is the big letter at the beginning of a paragraph called?", "passages": [["Historiated initial", "Historiated initial\n\nA historiated initial is an initial, an enlarged letter at the beginning of a paragraph or other section of text, that contains a picture.", "Strictly speaking, a historiated initial depicts an identifiable figure or a specific scene, while an inhabited initial contains figures (human or animal) that are decorative only, without forming a subject.", "Both sorts became very common and elaborate in luxury illuminated manuscripts.", "These illustrated initials were first seen in the Insular art of the early 8th century.", "The earliest known example is in the Saint Petersburg Bede, an Insular manuscript of 731-46, and the Vespasian Psalter has another.", "The size and decoration of the initial further gives clues to both its importance and location.", "Letters that began a new section of a text or a particularly noteworthy section might receive more flourishes and space.", "In luxury manuscripts an entire page might be devoted to a historiated initial.", "Both the size and the ostentatiousness of a manuscript reflect both on the status of the manuscript and on its owner.", "Manuscripts meant for everyday use, typically by friars or university students, often had little illumination, and hardly any elaborate historiated initials or flourishes.", "Manuscripts commissioned by wealthy patrons or for a wealthy monastery were often illuminated, and in gold or silver rather than pen and ink."], ["Initial", "Alternatively, the initial may be in the left margin, with the text indented, as shown here.", "In word processors and HTML, this may be implemented using a table with two cells, one for the initial and one for the rest of the text.", "The difference between this and a true drop cap may be seen when the text extends below the initial.", "For example:\n\nWith a drop cap, the initial sits within the margins and runs several lines deep into the paragraph, indenting some normal-sized text in these lines.", "This keeps the left and top margins of the paragraph flush.", "In modern computer browsers, this may be achieved with a combination of HTML and CSS by using the float: left; setting.", "A CSS-only solution alternatively can use the :first-letter pseudo-element.", "An example of this format is the following paragraph:\norem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.", "Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat."], ["Initial", "Initial\n\nIn a written or published work, an initial or drop cap is a letter at the beginning of a word, a chapter, or a paragraph that is larger than the rest of the text.", "The word is derived from the Latin \"initialis\", which means \"standing at the beginning\".", "An initial is often several lines in height and in older books or manuscripts, sometimes ornately decorated.", "In illuminated manuscripts, initials with images inside them, such as those illustrated here, are known as historiated initials.", "They were an invention of the Insular art of the British Isles in the eighth century.", "Initials containing, typically, plant-form spirals with small figures of animals or humans that do not represent a specific person or scene are known as \"inhabited\" initials.", "Certain important initials, such as the Beatus initial or \"B\" of \"Beatus vir...\" at the opening of Psalm 1 at the start of a vulgate Latin psalter, could occupy a whole page of a manuscript.", "These specific initials, in an illuminated manuscript, also were called Initiums.", "The classical tradition was slow to use capital letters for initials at all; in surviving Roman texts it often is difficult even to separate the words as spacing was not used either."]], "gold": "A historiated initial is an initial, an enlarged letter at the beginning of a paragraph or other section of text, that contains a picture. Strictly speaking, a historiated initial depicts an identifiable figure or a specific scene, while an inhabited initial contains figures that are decorative only, without forming a subject. In a written or published work, an initial or drop cap is a letter at the beginning of a word, a chapter, or a paragraph that is larger than the rest of the text and is often several lines in height and in older books or manuscripts are known as \"inhabited\" initials. A rubricated initial is an initial in red ink, to provide emphasis, at the beginning of a paragraph in medieval text.", "prediction 1": "In a written or published work, an initial or drop cap is a letter at the beginning of a word, a chapter, or a paragraph that is larger than the rest of the text. The big letter at the beginning of a paragraph is called a historiated initial. An illustrated historiated initial depicts an identifiable figure or a specific scene. In illuminated manuscripts, initials with large figures inside them, such as those illustrated here, are known as historiated initials.", "prediction 2": "In a written or published work, an initial or drop cap is a letter at the beginning of a word, a chapter, or a paragraph that is larger than the rest of the text. These letters are often several lines in height and in older books or manuscripts, sometimes ornately decorated. In illuminated manuscripts, initials with images inside them, such as those illustrated here, are known as historiated initials. In an illuminated manuscript, specific initials, in an illuminated manuscript, also were called Initiums.", "prediction 3": "In a written or published work, an initial or drop cap is a letter at the beginning of a word, a chapter, or a paragraph that is larger than the rest of the text. The word is derived from the Latin initialis, which means \"standing at the beginning\".", "prediction 4": "In a written or published work, an initial or drop cap is a letter at the beginning of a word, a chapter, or a paragraph that is larger than the rest of the text. The word is derived from the Latin \"initialis\", which means \"standing at the beginning\".", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 243, "end": 465}], "missing-info": [], "corrected-prediction": "In a written or published work, an initial or drop cap is a letter at the beginning of a word, a chapter, or a paragraph that is larger than the rest of the text. The big letter at the beginning of a paragraph is called a historiated initial."}, "preference": [1, 1, 1, 1, 1, 2], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Historiated initial\nS1. Historiated initial  A historiated initial is an initial, an enlarged letter at the beginning of a paragraph or other section of text, that contains a picture.\nS2. Strictly speaking, a historiated initial depicts an identifiable figure or a specific scene, while an inhabited initial contains figures (human or animal) that are decorative only, without forming a subject.\nS3. Both sorts became very common and elaborate in luxury illuminated manuscripts.\nS4. These illustrated initials were first seen in the Insular art of the early 8th century.\nS5. The earliest known example is in the Saint Petersburg Bede, an Insular manuscript of 731-46, and the Vespasian Psalter has another.\nS6. The size and decoration of the initial further gives clues to both its importance and location.\nS7. Letters that began a new section of a text or a particularly noteworthy section might receive more flourishes and space.\nS8. In luxury manuscripts an entire page might be devoted to a historiated initial.\nS9. Both the size and the ostentatiousness of a manuscript reflect both on the status of the manuscript and on its owner.\nS10. Manuscripts meant for everyday use, typically by friars or university students, often had little illumination, and hardly any elaborate historiated initials or flourishes.\nS11. Manuscripts commissioned by wealthy patrons or for a wealthy monastery were often illuminated, and in gold or silver rather than pen and ink.\n\nPassage 2: Title (S0) - Initial\nS1. Alternatively, the initial may be in the left margin, with the text indented, as shown here.\nS2. In word processors and HTML, this may be implemented using a table with two cells, one for the initial and one for the rest of the text.\nS3. The difference between this and a true drop cap may be seen when the text extends below the initial.\nS4. For example:  With a drop cap, the initial sits within the margins and runs several lines deep into the paragraph, indenting some normal-sized text in these lines.\nS5. This keeps the left and top margins of the paragraph flush.\nS6. In modern computer browsers, this may be achieved with a combination of HTML and CSS by using the float: left; setting.\nS7. A CSS-only solution alternatively can use the :first-letter pseudo-element.\nS8. An example of this format is the following paragraph: orem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.\nS9. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.\n\nPassage 3: Title (S0) - Initial\nS1. Initial  In a written or published work, an initial or drop cap is a letter at the beginning of a word, a chapter, or a paragraph that is larger than the rest of the text.\nS2. The word is derived from the Latin \"initialis\", which means \"standing at the beginning\".\nS3. An initial is often several lines in height and in older books or manuscripts, sometimes ornately decorated.\nS4. In illuminated manuscripts, initials with images inside them, such as those illustrated here, are known as historiated initials.\nS5. They were an invention of the Insular art of the British Isles in the eighth century.\nS6. Initials containing, typically, plant-form spirals with small figures of animals or humans that do not represent a specific person or scene are known as \"inhabited\" initials.\nS7. Certain important initials, such as the Beatus initial or \"B\" of \"Beatus vir...\" at the opening of Psalm 1 at the start of a vulgate Latin psalter, could occupy a whole page of a manuscript.\nS8. These specific initials, in an illuminated manuscript, also were called Initiums.\nS9. The classical tradition was slow to use capital letters for initials at all; in surviving Roman texts it often is difficult even to separate the words as spacing was not used either.\n    \nInput Question:\nWhat is the big letter at the beginning of a paragraph called?\n\nCorrect Response:\nA historiated initial is an initial, an enlarged letter at the beginning of a paragraph or other section of text, that contains a picture. Strictly speaking, a historiated initial depicts an identifiable figure or a specific scene, while an inhabited initial contains figures that are decorative only, without forming a subject. In a written or published work, an initial or drop cap is a letter at the beginning of a word, a chapter, or a paragraph that is larger than the rest of the text and is often several lines in height and in older books or manuscripts are known as \"inhabited\" initials. A rubricated initial is an initial in red ink, to provide emphasis, at the beginning of a paragraph in medieval text.\n\nModel Prediction:\nIn a written or published work, an initial or drop cap is a letter at the beginning of a word, a chapter, or a paragraph that is larger than the rest of the text. The big letter at the beginning of a paragraph is called a historiated initial. An illustrated historiated initial depicts an identifiable figure or a specific scene. In illuminated manuscripts, initials with large figures inside them, such as those illustrated here, are known as historiated initials.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "In a written or published work, an initial or drop cap is a letter at the beginning of a word, a chapter, or a paragraph that is larger than the rest of the text. The big letter at the beginning of a paragraph is called a historiated initial. [An illustrated historiated initial depicts an identifiable figure or a specific scene. In illuminated manuscripts, initials with large figures inside them, such as those illustrated here, are known as historiated initials.]\n\nExplanation:\nThe last two sentences in the model prediction are irrelevant because they provide additional information about historiated initials, which is not asked for in the question. The question only asks for the term used to describe the large letter at the beginning of a paragraph, not for a detailed description of historiated initials. Therefore, these sentences should be marked as \"Irrelevant\"."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. In a written or published work, an initial or drop cap is a letter at the beginning of a word, a chapter, or a paragraph that is larger than the rest of the text.\nS2. The big letter at the beginning of a paragraph is called a historiated initial.\nS3. An illustrated historiated initial depicts an identifiable figure or a specific scene.\nS4. In illuminated manuscripts, initials with large figures inside them, such as those illustrated here, are known as historiated initials.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation:\nAll the facts presented in the model prediction are consistent with the information provided in the passages. Therefore, there are no spans in the model prediction that contain inconsistent or unverifiable facts."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "None\n\nExplanation:\nThe model prediction adequately answers the question by stating that the big letter at the beginning of a paragraph is called an initial or drop cap. It also provides additional information about historiated initials. Therefore, there is no missing information in the model prediction."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "In a written or published work, an initial or drop cap is a letter at the beginning of a word, a chapter, or a paragraph that is larger than the rest of the text. The big letter at the beginning of a paragraph is called a historiated initial."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 330, "end": 465}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [1]}, {"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [2]}, {"error type": "Missing-Major-Auxiliary", "passage_id": 3, "sentence_id": [6]}], "corrected-prediction": "A historiated initial is an initial, an enlarged letter at the beginning of a paragraph or other section of text, that contains a picture. Strictly speaking, a historiated initial depicts an identifiable figure or a specific scene, while an inhabited initial contains figures that are decorative only, without forming a subject. In a written or published work, an initial or drop cap is a letter at the beginning of a word, a chapter, or a paragraph that is larger than the rest of the text and is often several lines in height and in older books or manuscripts are known as \"inhabited\" initials.                             "}}, {"question": "What years have leinster won the heineken cup?", "passages": [["European Rugby Champions Cup", "European Rugby Champions Cup\n\nThe European Rugby Champions Cup (known as the Heineken Champions Cup for sponsorship reasons) is an annual rugby union tournament organised by European Professional Club Rugby (EPCR).", "It is the top-tier competition for clubs whose countries' national teams compete in the Six Nations Championship.", "Clubs qualify for the Heineken Champions Cup via their final positions in their respective national/regional leagues (Gallagher Premiership, TOP 14, and Guinness Pro14) or via winning the second-tier Challenge Cup; those who do not qualify are instead eligible to compete in the second-tier Challenge Cup.", "Between 1995 and 2014, the competition was known as the Heineken Cup but was changed to European Rugby Champions Cup, following disagreements between its shareholders over the structure and governance of the competition.", "Heineken returned as sponsor for the 2018\u201319 season, running the competition alongside the EPCR, resulting in the competition being known as the Heineken Champions Cup.", "Leinster are the current holders of the title, having won their fourth title by beating Racing 92 in the 2018 final.", "Leinster Rugby and Toulouse have both won the competition a record four times.", "The Heineken Cup was launched in the summer of 1995 on the initiative of the then Five Nations Committee to provide a new level of professional cross border competition."], ["Leinster Rugby", "In the 2008\u201309 season, Leinster topped their European Cup pool despite away losses to French side Castres and English side Wasps.", "Victory over Harlequins in the quarter-finals followed, despite the Bloodgate Scandal.", "Leinster overcame Munster 25\u20136 in a semi-final in Dublin's Croke Park that broke the world record attendance for a \"club\" rugby union game with a crowd of over 82,200.", "Leinster won the 2009 European Cup Final in Murrayfield Stadium in Edinburgh, beating Leicester Tigers 19\u201316 to claim their first European crown.", "In 2009\u201310 Leinster was eliminated from the European Cup at the semi-final stage by eventual winners Toulouse.", "Also despite having topped the Pro12 league during the regular season, Leinster lost the first ever Play-off Final 17\u201312 on their home ground to the Ospreys.", "In the 2010\u201311 European Cup, Leinster defeated the top English teams (Leicester Tigers, Saracens & Northampton Saints), as well as top French sides, Toulouse (who were the defending European champions), Racing Metro & Clermont Auvergne, (the French Champions).", "to go on to regain their title as champions of Europe in the 2011 European Cup Final at the Millennium Stadium in Cardiff."]], "gold": "The European Rugby Champions Cup, also known as the Heineken Champions Cup, is an annual rugby union tournament organized by European Professional Club Rugby. Leinster won the title in 2009 in their first ever final. Then, Leinster won their second Heineken Cup in 2010-11, their third Heineken Cup in 2011-12 and their fourth Heineken Cup in 2017-18.", "prediction 1": "The Heineken Champions Cup is an annual rugby union tournament organised by European Professional Club Rugby (EPCR). It is the top-tier competition for clubs whose countries' national teams compete in the Six Nations Championship. Leinster have won the Heineken Cup in 2009, 2010 and 2011 respectively.", "prediction 2": "The European Rugby Champions Cup is an annual rugby union tournament organised by European Professional Club Rugby (EPCR). It is the top-tier competition for clubs whose countries' national teams compete in the Six Nations Championship. Between 1995 and 2014, the competition was known as the Heineken Cup but was changed to the European Rugby Champions Cup, following disagreements between its shareholders over the structure and governance of the competition. In 2018 Leinster won their fourth title by beating Racing 92 in the final. In 2009\u201310 Leinster was eliminated from the European Cup at the semi-final stage by eventual winners Toulouse. In 2011, Leinster won the Heineken Champions Cup Final at the Millennium Stadium in Cardiff.", "prediction 3": "The Heineken Champions Cup is an annual rugby union tournament organised by European Professional Club Rugby (EPCR). Leinster have won the Heineken Cup in 3 of the last 4 seasons. In the 2009, 2010 and 2011 seasons, Leinster won the Heineken Cup. In the 2015 and 2016, Leinster won the Heineken Cup in 2015 and 2016, and in 2016 they won it in 2017.", "prediction 4": "The European Rugby Champions Cup, also known as the Heineken Champions Cup for sponsorship reasons, is an annual rugby union tournament organised by European Professional Club Rugby (EPCR). Leinster won the 2009 European Cup Final in Murrayfield Stadium in Edinburgh, beating Leicester Tigers 19\u201316 to claim their first European crown. In the 2010\u201311 European Cup, Leinster defeated the top English teams (Leicester Tigers, Saracens & Northampton Saints), as well as top French sides, Toulouse (who were the defending champions) Racing 92 in the 2018 final.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 0, "end": 230}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 1, "sentence_id": [6]}], "corrected-prediction": "Leinster have won the Heineken Cup in 2009, 2011 and 2018."}, "preference": [1, 1, 1, 2, 2, 1], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - European Rugby Champions Cup\nS1. European Rugby Champions Cup  The European Rugby Champions Cup (known as the Heineken Champions Cup for sponsorship reasons) is an annual rugby union tournament organised by European Professional Club Rugby (EPCR).\nS2. It is the top-tier competition for clubs whose countries' national teams compete in the Six Nations Championship.\nS3. Clubs qualify for the Heineken Champions Cup via their final positions in their respective national/regional leagues (Gallagher Premiership, TOP 14, and Guinness Pro14) or via winning the second-tier Challenge Cup; those who do not qualify are instead eligible to compete in the second-tier Challenge Cup.\nS4. Between 1995 and 2014, the competition was known as the Heineken Cup but was changed to European Rugby Champions Cup, following disagreements between its shareholders over the structure and governance of the competition.\nS5. Heineken returned as sponsor for the 2018\u201319 season, running the competition alongside the EPCR, resulting in the competition being known as the Heineken Champions Cup.\nS6. Leinster are the current holders of the title, having won their fourth title by beating Racing 92 in the 2018 final.\nS7. Leinster Rugby and Toulouse have both won the competition a record four times.\nS8. The Heineken Cup was launched in the summer of 1995 on the initiative of the then Five Nations Committee to provide a new level of professional cross border competition.\n\nPassage 2: Title (S0) - Leinster Rugby\nS1. In the 2008\u201309 season, Leinster topped their European Cup pool despite away losses to French side Castres and English side Wasps.\nS2. Victory over Harlequins in the quarter-finals followed, despite the Bloodgate Scandal.\nS3. Leinster overcame Munster 25\u20136 in a semi-final in Dublin's Croke Park that broke the world record attendance for a \"club\" rugby union game with a crowd of over 82,200.\nS4. Leinster won the 2009 European Cup Final in Murrayfield Stadium in Edinburgh, beating Leicester Tigers 19\u201316 to claim their first European crown.\nS5. In 2009\u201310 Leinster was eliminated from the European Cup at the semi-final stage by eventual winners Toulouse.\nS6. Also despite having topped the Pro12 league during the regular season, Leinster lost the first ever Play-off Final 17\u201312 on their home ground to the Ospreys.\nS7. In the 2010\u201311 European Cup, Leinster defeated the top English teams (Leicester Tigers, Saracens & Northampton Saints), as well as top French sides, Toulouse (who were the defending European champions), Racing Metro & Clermont Auvergne, (the French Champions).\nS8. to go on to regain their title as champions of Europe in the 2011 European Cup Final at the Millennium Stadium in Cardiff.\n    \nInput Question:\nWhat years have leinster won the heineken cup?\n\nCorrect Response:\nThe European Rugby Champions Cup, also known as the Heineken Champions Cup, is an annual rugby union tournament organized by European Professional Club Rugby. Leinster won the title in 2009 in their first ever final. Then, Leinster won their second Heineken Cup in 2010-11, their third Heineken Cup in 2011-12 and their fourth Heineken Cup in 2017-18.\n\nModel Prediction:\nThe Heineken Champions Cup is an annual rugby union tournament organised by European Professional Club Rugby (EPCR). It is the top-tier competition for clubs whose countries' national teams compete in the Six Nations Championship. Leinster have won the Heineken Cup in 2009, 2010 and 2011 respectively.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "[The Heineken Champions Cup is an annual rugby union tournament organised by European Professional Club Rugby (EPCR). It is the top-tier competition for clubs whose countries' national teams compete in the Six Nations Championship.] Leinster have won the Heineken Cup in 2009, 2010 and 2011 respectively.\n\nExplanation:\n1. The first two sentences in the model prediction are neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, they should be marked as \"Irrelevant\". \n2. There are no repetitive or incoherent spans in the model prediction."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The Heineken Champions Cup is an annual rugby union tournament organised by European Professional Club Rugby (EPCR).\nS2. It is the top-tier competition for clubs whose countries' national teams compete in the Six Nations Championship.\nS3. Leinster have won the Heineken Cup in 2009, 2010 and 2011 respectively.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "S3\n\nExplanation:\n1. The statement that Leinster won the Heineken Cup in 2010 is not verifiable from the passages. According to Passage 2, sentence 5, Leinster was eliminated from the European Cup at the semi-final stage by eventual winners Toulouse in the 2009\u201310 season. Therefore, the claim that they won in 2010 is an \"Unverifiable Fact\"."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 6 [Missing Answer]\n2. Passage 2, sentence 8 [Missing Answer]\n\nExplanation:\n1. The model prediction does not mention that Leinster won their fourth title in 2018, which is stated in Passage 1, sentence 6. This is a [Missing Answer].\n2. The model prediction also does not mention that Leinster won their second title in the 2010\u201311 season, which is stated in Passage 2, sentence 8. This is another [Missing Answer]."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "Leinster have won the Heineken Cup in 2009, 2011 and 2018."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 109, "end": 116}, {"error type": "Irrelevant", "explanation": "", "start": 117, "end": 230}, {"error type": "Wrong-Grounding", "explanation": "{\"passage_id\":2,\"sentence_id\":[5]}", "start": 275, "end": 279}], "missing-info": [{"error type": "Missing-Minor-Auxiliary", "passage_id": 1, "sentence_id": [1]}, {"error type": "Missing-Answer", "passage_id": 1, "sentence_id": [6]}], "corrected-prediction": "The Heineken Champions Cup, also known as the European Rugby Champions Cup, is an annual rugby union tournament organised by European Professional Club Rugby . Leinster have won the Heineken Cup in 2009, 2011, and 2018. In total, they have won four times."}}, {"question": "When is the sunday times rich list 2018 published?", "passages": [["Sunday Times Rich List 2017", "Sunday Times Rich List 2017\n\nThe Sunday Times Rich List 2017 is the 29th annual survey of the wealthiest people resident in the United Kingdom, published by \"The Sunday Times\" on 7 May 2017.", "The List was edited by Robert Watts who succeeded long-term compiler Philip Beresford this year.", "The list was previewed in the previous week's \"Sunday Times\" and widely reported by other media."], ["Sunday Times Rich List 2016", "Sunday Times Rich List 2016\n\nThe Sunday Times Rich List 2016 is the 28th annual survey of the wealthiest people resident in the United Kingdom, published by \"The Sunday Times\" on 24 April 2016.", "Long-term compiler Philip Beresford was joined by Robert Watts for the 2016 list.", "An estimated wealth of \u00a3103 million is required for entry in the 2016 list.", "Newly added to the list for the first time, and ranked in the top 100, are John Grayken, Christo Wiese, Sunil Vaswani & Family, and Martin Moller.", "The \"Daily Mail\" noted that \"Britain's Super Rich have taken a hammering in the last year, as it was revealed 10 men have been downgraded from billionaires to mere multi-millionaires.\""], ["Sunday Times Rich List 2015", "Sunday Times Rich List 2015\n\nThe Sunday Times Rich List 2015 is the 27th annual survey of the wealthiest people resident in the United Kingdom, published by \"The Sunday Times\" on 26 April 2015.", "\"The Guardian\" reported that the collective wealth of Britain\u2019s 1,000 richest people had more than doubled in the last 10 years with a combined fortune of just over \u00a3547bn and a fortune of \u00a3100m was now required to qualify for the list.", "This year's list marked the first year Queen Elizabeth II was not among the list's top 300 most wealthy since the list began in 1989."], ["Sunday Times Rich List", "Sunday Times Rich List\n\nThe Sunday Times Rich List is a list of the 1,000 wealthiest people or families resident in the United Kingdom ranked by net wealth.", "The list is updated annually in April and published as a magazine supplement by British national Sunday newspaper \"The Sunday Times\" since 1989.", "The editorial decisions governing the compilation of the \"Rich List\" are published in the newspaper and online as its \"Rules of engagement.\"", "The \"Rich List\" is not limited to British citizens and it includes individuals and families born overseas but who predominantly work and/or live in Britain.", "This excludes some individuals with prominent financial assets in Britain.", "The editors estimate subjects' wealth from a range of public information, based on values in January each year.", "They typically explain their actions by stating: \"We measure identifiable wealth, whether land, property, racehorses, art or significant shares in publicly quoted companies.", "We exclude bank accounts\u2014to which we have no access...", "We try to give due consideration to liabilities.\"", "The 2015 list marked the first year Queen Elizabeth II was not among the list's top 300 most wealthy since the list began in 1989.", "She was number one on the list when it began in 1989.", "The most recent list was published on 13 May 2018.", "A fuller version of the \"Rich List\" is also published in a reference book edition, edited by Philip Beresford."], ["Sunday Times Rich List 2018", "Sunday Times Rich List 2018\n\nThe Sunday Times Rich List 2018 is the 30th annual survey of the wealthiest people resident in the United Kingdom, published by \"The Sunday Times\" on 13 May 2018.", "The List was edited by Robert Watts who succeeded long-term compiler Philip Beresford last year.", "The List was previewed in the previous week's \"Sunday Times\" and widely reported by other media."]], "gold": "The Sunday Times Rich List is a list of the 1,000 wealthiest people or families resident in the United Kingdom ranked by net wealth. The list is updated annually in April and published as a magazine supplement by British national Sunday newspaper The Sunday Times since 1989. The Sunday Times Rich List 2018 was the 30th annual survey of the wealthiest people resident in the United Kingdom, and was published on 13 May 2018. The Sunday Time Rich list in 2017 was published 7 May 2017, with the 2016 list being published 24 April 2016, and the 2015 list being published 26 April 2015.", "prediction 1": "Sunday Times Rich List is a list of the 1,000 wealthiest people or families resident in the United Kingdom ranked by net wealth. The list is updated annually in April and published as a magazine supplement by British national Sunday newspaper The Sunday Times since 1989. The Sunday Times Rich List 2018 is the 30th annual survey of the wealthiest people resident in the United Kingdom, published by \"The Sunday Times\" on 13 May 2018. The List was edited by Robert Watts who succeeded long-term compiler Philip Beresford last year.", "prediction 2": "The Sunday Times Rich List is a list of the 1,000 wealthiest people or families resident in the United Kingdom ranked by net wealth. The list is updated annually in April and published as a magazine supplement by British national Sunday newspaper The Sunday Times since 1989. The most recent list was published on 13 May 2018.", "prediction 3": "The Sunday Times Rich List is a list of the 1,000 wealthiest people or families resident in the United Kingdom ranked by net wealth. The list is updated annually in April and published as a magazine supplement by British national Sunday newspaper The Sunday Times since 1989. In 2018, the Sunday Times Rich List was published on 13 May 2018. In 2015, the Sunday Times Rich List was published on 26 April 2015. In 2016, the Sunday Times Rich List was published on 27 April 2015. In 2018, the Sunday Times Rich List was published on 13 May 2018.", "prediction 4": "Sunday Times Rich List is a list of the 1,000 wealthiest people or families resident in the United Kingdom ranked by net wealth. It is updated annually in April and published as a magazine supplement by British national Sunday newspaper \"The Sunday Times\" since 1989. The Sunday Times Rich List 2018 is the 30th annual survey of the wealthiest people resident in the United Kingdom, published by \"The Sunday Times\" on 13 May 2018. The List was edited by Robert Watts who succeeded long-term compiler Philip Beresford this year.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 435, "end": 531}], "missing-info": [{"error type": "Missing-Minor-Auxiliary", "passage_id": 1, "sentence_id": [1]}], "corrected-prediction": "The Sunday Times Rich List is a list of the 1,000 wealthiest people or families resident in the United Kingdom ranked by net wealth. The list is updated annually in April and published as a magazine supplement by British national Sunday newspaper The Sunday Times since 1989. The Sunday Times Rich List 2018 is the 30th annual survey of the wealthiest people resident in the United Kingdom, published by \"The Sunday Times\" on 13 May 2018. The Sunday Times Rich List in 2017 was published on 7 May 2017, with the 2016 list being published on 24 April 2016, and the 2015 list being published on 26 April 2015."}, "preference": [1, 2, 0, 2, 2, 1], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Sunday Times Rich List 2017\nS1. Sunday Times Rich List 2017  The Sunday Times Rich List 2017 is the 29th annual survey of the wealthiest people resident in the United Kingdom, published by \"The Sunday Times\" on 7 May 2017.\nS2. The List was edited by Robert Watts who succeeded long-term compiler Philip Beresford this year.\nS3. The list was previewed in the previous week's \"Sunday Times\" and widely reported by other media.\n\nPassage 2: Title (S0) - Sunday Times Rich List 2016\nS1. Sunday Times Rich List 2016  The Sunday Times Rich List 2016 is the 28th annual survey of the wealthiest people resident in the United Kingdom, published by \"The Sunday Times\" on 24 April 2016.\nS2. Long-term compiler Philip Beresford was joined by Robert Watts for the 2016 list.\nS3. An estimated wealth of \u00a3103 million is required for entry in the 2016 list.\nS4. Newly added to the list for the first time, and ranked in the top 100, are John Grayken, Christo Wiese, Sunil Vaswani & Family, and Martin Moller.\nS5. The \"Daily Mail\" noted that \"Britain's Super Rich have taken a hammering in the last year, as it was revealed 10 men have been downgraded from billionaires to mere multi-millionaires.\"\n\nPassage 3: Title (S0) - Sunday Times Rich List 2015\nS1. Sunday Times Rich List 2015  The Sunday Times Rich List 2015 is the 27th annual survey of the wealthiest people resident in the United Kingdom, published by \"The Sunday Times\" on 26 April 2015.\nS2. \"The Guardian\" reported that the collective wealth of Britain\u2019s 1,000 richest people had more than doubled in the last 10 years with a combined fortune of just over \u00a3547bn and a fortune of \u00a3100m was now required to qualify for the list.\nS3. This year's list marked the first year Queen Elizabeth II was not among the list's top 300 most wealthy since the list began in 1989.\n\nPassage 4: Title (S0) - Sunday Times Rich List\nS1. Sunday Times Rich List  The Sunday Times Rich List is a list of the 1,000 wealthiest people or families resident in the United Kingdom ranked by net wealth.\nS2. The list is updated annually in April and published as a magazine supplement by British national Sunday newspaper \"The Sunday Times\" since 1989.\nS3. The editorial decisions governing the compilation of the \"Rich List\" are published in the newspaper and online as its \"Rules of engagement.\"\nS4. The \"Rich List\" is not limited to British citizens and it includes individuals and families born overseas but who predominantly work and/or live in Britain.\nS5. This excludes some individuals with prominent financial assets in Britain.\nS6. The editors estimate subjects' wealth from a range of public information, based on values in January each year.\nS7. They typically explain their actions by stating: \"We measure identifiable wealth, whether land, property, racehorses, art or significant shares in publicly quoted companies.\nS8. We exclude bank accounts\u2014to which we have no access...\nS9. We try to give due consideration to liabilities.\"\nS10. The 2015 list marked the first year Queen Elizabeth II was not among the list's top 300 most wealthy since the list began in 1989.\nS11. She was number one on the list when it began in 1989.\nS12. The most recent list was published on 13 May 2018.\nS13. A fuller version of the \"Rich List\" is also published in a reference book edition, edited by Philip Beresford.\n\nPassage 5: Title (S0) - Sunday Times Rich List 2018\nS1. Sunday Times Rich List 2018  The Sunday Times Rich List 2018 is the 30th annual survey of the wealthiest people resident in the United Kingdom, published by \"The Sunday Times\" on 13 May 2018.\nS2. The List was edited by Robert Watts who succeeded long-term compiler Philip Beresford last year.\nS3. The List was previewed in the previous week's \"Sunday Times\" and widely reported by other media.\n    \nInput Question:\nWhen is the sunday times rich list 2018 published?\n\nCorrect Response:\nThe Sunday Times Rich List is a list of the 1,000 wealthiest people or families resident in the United Kingdom ranked by net wealth. The list is updated annually in April and published as a magazine supplement by British national Sunday newspaper The Sunday Times since 1989. The Sunday Times Rich List 2018 was the 30th annual survey of the wealthiest people resident in the United Kingdom, and was published on 13 May 2018. The Sunday Time Rich list in 2017 was published 7 May 2017, with the 2016 list being published 24 April 2016, and the 2015 list being published 26 April 2015.\n\nModel Prediction:\nSunday Times Rich List is a list of the 1,000 wealthiest people or families resident in the United Kingdom ranked by net wealth. The list is updated annually in April and published as a magazine supplement by British national Sunday newspaper The Sunday Times since 1989. The Sunday Times Rich List 2018 is the 30th annual survey of the wealthiest people resident in the United Kingdom, published by \"The Sunday Times\" on 13 May 2018. The List was edited by Robert Watts who succeeded long-term compiler Philip Beresford last year.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "Sunday Times Rich List is a list of the 1,000 wealthiest people or families resident in the United Kingdom ranked by net wealth. The list is updated annually in April and published as a magazine supplement by British national Sunday newspaper The Sunday Times since 1989. The Sunday Times Rich List 2018 is the 30th annual survey of the wealthiest people resident in the United Kingdom, published by \"The Sunday Times\" on 13 May 2018. [The List was edited by Robert Watts who succeeded long-term compiler Philip Beresford last year.]\n\nExplanation:\nThe last sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\"."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. Sunday Times Rich List is a list of the 1,000 wealthiest people or families resident in the United Kingdom ranked by net wealth.\nS2. The list is updated annually in April and published as a magazine supplement by British national Sunday newspaper The Sunday Times since 1989.\nS3. The Sunday Times Rich List 2018 is the 30th annual survey of the wealthiest people resident in the United Kingdom, published by \"The Sunday Times\" on 13 May 2018.\nS4. The List was edited by Robert Watts who succeeded long-term compiler Philip Beresford last year.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation:\nAll the facts in the model prediction are consistent with the information provided in the passages."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 1 [Missing Minor Auxiliary Information]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n3. Passage 3, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. The reference contains auxiliary information about the publication dates of the Sunday Times Rich List in previous years (2017, 2016, and 2015) that can be found in passages 1, 2, and 3. This information is not included in the model prediction. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The Sunday Times Rich List is a list of the 1,000 wealthiest people or families resident in the United Kingdom ranked by net wealth. The list is updated annually in April and published as a magazine supplement by British national Sunday newspaper The Sunday Times since 1989. The Sunday Times Rich List 2018 is the 30th annual survey of the wealthiest people resident in the United Kingdom, published by \"The Sunday Times\" on 13 May 2018. The Sunday Times Rich List in 2017 was published on 7 May 2017, with the 2016 list being published on 24 April 2016, and the 2015 list being published on 26 April 2015."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 435, "end": 531}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 3, "sentence_id": [1]}], "corrected-prediction": "Sunday Times Rich List is a list of the 1,000 wealthiest people or families resident in the United Kingdom ranked by net wealth. The list is updated annually in April and published as a magazine supplement by British national Sunday newspaper The Sunday Times since 1989. The Sunday Times Rich List 2018 is the 30th annual survey of the wealthiest people resident in the United Kingdom, published by \"The Sunday Times\" on 13 May 2018. The Sunday Time Rich List 2015 was published on 26 April 2015. The Sunday Time Rich List 2016 was published on 24 April 2016. And the Sunday Time  Rich List 2017 was published on 7 May 2017."}}, {"question": "Who sings my future's so bright i gotta wear shades?", "passages": [["The Future's So Bright, I Gotta Wear Shades", "The Future's So Bright, I Gotta Wear Shades\n\n\"The Future's So Bright, I Gotta Wear Shades\" is a song by Timbuk3.", "It is the opening track from their debut album, \"Greetings from Timbuk3\".", "Released as the album's first single in 1986, it was the band's only significant mainstream hit.", "The inspiration for the song, and the title specifically, came when Barbara MacDonald said to her husband singer/songwriter Pat MacDonald, \"The future is looking so bright, we'll have to wear sunglasses!\"", "But, while Barbara had made the comment in earnest \u2013 it was the early '80s, the two had met and married and were starting a family, their first EP was coming, their book was filling up with gigs \u2013 Pat heard the comment as an ironic quip and wrote down instead, \"The future's so bright, I gotta wear shades.\"", "From there, the lyrics to the song were born, but not the song as it ended up in the minds of popular culture.", "While Pat wrote a song of a young nuclear scientist and his rich future, listening audiences heard a graduation theme song."]], "gold": "\"The Future's So Bright, I Gotta Wear Shades\" is a song by Timbuk 3. It is the opening track from their debut album, \"Greetings from Timbuk3\". Released as the album's first single in 1986, it was the band's only significant mainstream hit. The inspiration for the song, and the title specifically, came when Barbara MacDonald said to her husband singer/songwriter Pat MacDonald, \"The future is looking so bright, we'll have to wear sunglasses!\" ", "prediction 1": "\"The Future's So Bright, I Gotta Wear Shades\" is a song by Timbuk3. It is the opening track from their debut album, \"Greetings from Timbuk3\". Released as the album's first single in 1986, it was the band's only significant mainstream hit.", "prediction 2": "\"The Future's So Bright, I Gotta Wear Shades\" is a song by Timbuk3. It is the opening track from their debut album, Greetings from Timbuk3. Released as the album's first single in 1986, it was the band's only significant mainstream hit. The inspiration for the song, and the title specifically, came when Barbara MacDonald said to her husband singer/songwriter Pat MacDonald, \"The future is looking so bright, we'll have to wear shades!\"", "prediction 3": "\"The Future's So Bright, I Gotta Wear Shades\" is a song by Timbuk3. It is the opening track from their debut album, Greetings from Timbuk3. Released as the album's first single in 1986, it was the band's only significant mainstream hit.", "prediction 4": "\"The Future's So Bright, I Gotta Wear Shades\" is a song by Timbuk3. It is the opening track from their debut album, \"Greetings from Timbuk3\". Released as the album's first single in 1986, it was the band's only significant mainstream hit. The inspiration for the song, and the title specifically, came when Barbara MacDonald said to her husband singer/songwriter Pat MacDonald, \"The future is looking so bright, we'll have to wear sunglasses!\"", "feedback": {"errors": [], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [4]}], "corrected-prediction": "\"The Future's So Bright, I Gotta Wear Shades\" is a song by Timbuk3. It is the opening track from their debut album, \"Greetings from Timbuk3\". Released as the album's first single in 1986, it was the band's only significant mainstream hit. The inspiration for the song, and the title specifically, came when Barbara MacDonald said to her husband singer/songwriter Pat MacDonald, \"The future is looking so bright, we'll have to wear sunglasses!\""}, "preference": [2, 0, 2, 1, 0, 2], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - The Future's So Bright, I Gotta Wear Shades\nS1. The Future's So Bright, I Gotta Wear Shades  \"The Future's So Bright, I Gotta Wear Shades\" is a song by Timbuk3.\nS2. It is the opening track from their debut album, \"Greetings from Timbuk3\".\nS3. Released as the album's first single in 1986, it was the band's only significant mainstream hit.\nS4. The inspiration for the song, and the title specifically, came when Barbara MacDonald said to her husband singer/songwriter Pat MacDonald, \"The future is looking so bright, we'll have to wear sunglasses!\"\nS5. But, while Barbara had made the comment in earnest \u2013 it was the early '80s, the two had met and married and were starting a family, their first EP was coming, their book was filling up with gigs \u2013 Pat heard the comment as an ironic quip and wrote down instead, \"The future's so bright, I gotta wear shades.\"\nS6. From there, the lyrics to the song were born, but not the song as it ended up in the minds of popular culture.\nS7. While Pat wrote a song of a young nuclear scientist and his rich future, listening audiences heard a graduation theme song.\n    \nInput Question:\nWho sings my future's so bright i gotta wear shades?\n\nCorrect Response:\n\"The Future's So Bright, I Gotta Wear Shades\" is a song by Timbuk 3. It is the opening track from their debut album, \"Greetings from Timbuk3\". Released as the album's first single in 1986, it was the band's only significant mainstream hit. The inspiration for the song, and the title specifically, came when Barbara MacDonald said to her husband singer/songwriter Pat MacDonald, \"The future is looking so bright, we'll have to wear sunglasses!\" \n\nModel Prediction:\n\"The Future's So Bright, I Gotta Wear Shades\" is a song by Timbuk3. It is the opening track from their debut album, \"Greetings from Timbuk3\". Released as the album's first single in 1986, it was the band's only significant mainstream hit.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "\"The Future's So Bright, I Gotta Wear Shades\" is a song by Timbuk3. It is the opening track from their debut album, \"Greetings from Timbuk3\". Released as the album's first single in 1986, it was the band's only significant mainstream hit.\n\nExplanation: There are no irrelevant, incoherent, or repetitive spans in the model prediction. The information provided is relevant to the question, coherent, and not repetitive."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. \"The Future's So Bright, I Gotta Wear Shades\" is a song by Timbuk3.\nS2. It is the opening track from their debut album, \"Greetings from Timbuk3\".\nS3. Released as the album's first single in 1986, it was the band's only significant mainstream hit.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation: All the facts in the model prediction are consistent with the passages and can be verified."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 4 [Missing Major Auxiliary Information]\n\nExplanation:\n1. The model prediction is missing the information about the inspiration for the song, which is a crucial auxiliary information that helps in understanding the context of the song. This information can be found in Passage 1, sentence 4."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "\"The Future's So Bright, I Gotta Wear Shades\" is a song by Timbuk3. It is the opening track from their debut album, \"Greetings from Timbuk3\". Released as the album's first single in 1986, it was the band's only significant mainstream hit. The inspiration for the song, and the title specifically, came when Barbara MacDonald said to her husband singer/songwriter Pat MacDonald, \"The future is looking so bright, we'll have to wear sunglasses!\""}], "feedback_human": {"errors": [], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [4]}], "corrected-prediction": "\"The Future's So Bright, I Gotta Wear Shades\" is a song by Timbuk3. It is the opening track from their debut album, \"Greetings from Timbuk3\". Released as the album's first single in 1986, it was the band's only significant mainstream hit. The inspiration for the song, and the title specifically, came when Barbara MacDonald said to her husband singer/songwriter Pat MacDonald, \"The future is looking so bright, we'll have to wear sunglasses!\""}}, {"question": "Which country receives the most us foreign aid?", "passages": [["United States foreign aid", "United States foreign aid\n\nUnited States foreign aid is aid given by the United States government to other governments.", "It does not include money from private charitable organizations based in the United States, or remittances sent between family members.", "There are two broad categories: military aid and economic assistance.", "The Congressional Research Service divides it into five categories: bilateral development aid, economic assistance, humanitarian aid, multilateral economic contributions, and military aid.", "Foreign aid recipients include developing countries, countries of strategic importance to the United States, and countries recovering from war.", "The government channels about half of its economic assistance through a specialized agency, the United States Agency for International Development (USAID).", "Government-sponsored foreign aid began a systematic fashion after World War II; there were numerous programs of which the largest were the Marshall Plan of 1948 and the Mutual Security Act of 1951-61.", "Military aid provided to foreign countries varies mostly on what natural resources the foreign country has to offer.", "Foreign aid is generally unpopular with the general public, with a 2017 poll finding 57% favor a cut and 6% who want increased aid.", "On the other hand, foreign aid has bipartisan support in Congress, and most Americans overestimate foreign aid as a share of the total federal budget.", "In the past, less than 1% of the national budget went to foreign assistance."], ["Foreign relations of the United States", "Foreign relations of the United States\n\nThe United States has formal diplomatic relations with most nations.", "This includes all U.N. member states except for Bhutan, Iran, North Korea, and Syria.", "Additionally, the U.S. has diplomatic relations with the European Union, the Holy See and Kosovo.", "The United States federal statutes relating to foreign relations can be found in Title 22 of the United States Code.", "American relations with Eastern Europe are influenced by the legacy of the Cold War.", "Since the collapse of the Soviet Union, former Communist-bloc states in Europe have gradually transitioned to democracy and capitalism.", "Many have also joined the European Union and NATO, strengthening economic ties with the broader Western world and gaining the military protection of the United States via the North Atlantic Treaty.", "The United States has many important allies in the Greater Middle East region.", "These allies are Turkey, Saudi Arabia, Morocco, Jordan, Afghanistan, Israel, Egypt, Kuwait, Bahrain and Qatar.", "Israel and Egypt are leading recipients of United States foreign aid, receiving $2.775 billion and 1.75 billion in 2010.", "Turkey is an ally of the United States through its membership in NATO, while all of the other countries except Saudi Arabia and Qatar are major non-NATO allies.", "The United States toppled the government of Saddam Hussein during the 2003 invasion of Iraq."]], "gold": "United States foreign aid, sometimes referred to as US foreign assistance, is aid the US supplies to other countries to support global peace, security, and development efforts, and provide humanitarian relief during crisis. The country with the most total foreign US aid is Afghanistan, who receives the most economic and military US foreign aid. Israel receives the most US foreign aid per capita.", "prediction 1": "The United States gives the most foreign aid, which is aid given by the United States government to other governments. In 2010, the United States gave the most foreign aid to Israel, and the second-most to Egypt.", "prediction 2": "United States foreign aid is aid given by the United States government to other governments. There are two broad categories: military aid and economic assistance. Israel and Egypt are leading recipients of United States foreign aid, receiving $2.775 billion and 1.75 billion respectively in 2010.", "prediction 3": "The United States gives foreign aid to other countries in two broad categories: military aid and economic assistance. Israel receives the most foreign aid, while Egypt receives the most, with $2.775 billion and 1.75 billion in 2010.", "prediction 4": "United States foreign aid is aid given by the United States government to other governments. There are two broad categories: military aid and economic assistance. Israel and Egypt are leading recipients of United States foreign aid, receiving $2.775 billion and 1.75 billion in 2010.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 0, "end": 118}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 1, "sentence_id": [5]}], "corrected-prediction": "The United States provides foreign aid to various countries, including developing countries, countries of strategic importance to the United States, and countries recovering from war. This aid falls into two broad categories: military aid and economic assistance. However, the specific country that receives the most US foreign aid is not specified in the provided passages."}, "preference": [2, 1, 2, 1, 0, 2], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - United States foreign aid\nS1. United States foreign aid  United States foreign aid is aid given by the United States government to other governments.\nS2. It does not include money from private charitable organizations based in the United States, or remittances sent between family members.\nS3. There are two broad categories: military aid and economic assistance.\nS4. The Congressional Research Service divides it into five categories: bilateral development aid, economic assistance, humanitarian aid, multilateral economic contributions, and military aid.\nS5. Foreign aid recipients include developing countries, countries of strategic importance to the United States, and countries recovering from war.\nS6. The government channels about half of its economic assistance through a specialized agency, the United States Agency for International Development (USAID).\nS7. Government-sponsored foreign aid began a systematic fashion after World War II; there were numerous programs of which the largest were the Marshall Plan of 1948 and the Mutual Security Act of 1951-61.\nS8. Military aid provided to foreign countries varies mostly on what natural resources the foreign country has to offer.\nS9. Foreign aid is generally unpopular with the general public, with a 2017 poll finding 57% favor a cut and 6% who want increased aid.\nS10. On the other hand, foreign aid has bipartisan support in Congress, and most Americans overestimate foreign aid as a share of the total federal budget.\nS11. In the past, less than 1% of the national budget went to foreign assistance.\n\nPassage 2: Title (S0) - Foreign relations of the United States\nS1. Foreign relations of the United States  The United States has formal diplomatic relations with most nations.\nS2. This includes all U.N. member states except for Bhutan, Iran, North Korea, and Syria.\nS3. Additionally, the U.S. has diplomatic relations with the European Union, the Holy See and Kosovo.\nS4. The United States federal statutes relating to foreign relations can be found in Title 22 of the United States Code.\nS5. American relations with Eastern Europe are influenced by the legacy of the Cold War.\nS6. Since the collapse of the Soviet Union, former Communist-bloc states in Europe have gradually transitioned to democracy and capitalism.\nS7. Many have also joined the European Union and NATO, strengthening economic ties with the broader Western world and gaining the military protection of the United States via the North Atlantic Treaty.\nS8. The United States has many important allies in the Greater Middle East region.\nS9. These allies are Turkey, Saudi Arabia, Morocco, Jordan, Afghanistan, Israel, Egypt, Kuwait, Bahrain and Qatar.\nS10. Israel and Egypt are leading recipients of United States foreign aid, receiving $2.775 billion and 1.75 billion in 2010.\nS11. Turkey is an ally of the United States through its membership in NATO, while all of the other countries except Saudi Arabia and Qatar are major non-NATO allies.\nS12. The United States toppled the government of Saddam Hussein during the 2003 invasion of Iraq.\n    \nInput Question:\nWhich country receives the most us foreign aid?\n\nCorrect Response:\nUnited States foreign aid, sometimes referred to as US foreign assistance, is aid the US supplies to other countries to support global peace, security, and development efforts, and provide humanitarian relief during crisis. The country with the most total foreign US aid is Afghanistan, who receives the most economic and military US foreign aid. Israel receives the most US foreign aid per capita.\n\nModel Prediction:\nThe United States gives the most foreign aid, which is aid given by the United States government to other governments. In 2010, the United States gave the most foreign aid to Israel, and the second-most to Egypt.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "[The United States gives the most foreign aid, which is aid given by the United States government to other governments.] In 2010, the United States gave the most foreign aid to Israel, and the second-most to Egypt.\n\nExplanation:\n1. The first sentence in the model prediction is irrelevant as it does not answer the question nor provide crucial auxiliary information. The question asks about which country receives the most US foreign aid, not about the definition of US foreign aid."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The United States gives the most foreign aid, which is aid given by the United States government to other governments.\nS2. In 2010, the United States gave the most foreign aid to Israel, and the second-most to Egypt.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "S2\n\nExplanation:\n1. The second sentence of the model prediction states that the United States gave the most foreign aid to Israel in 2010, but this information is not verifiable from the provided passages. The passages do not provide specific information about which country received the most US foreign aid in 2010. Therefore, this is an \"Unverifiable Fact\"."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 5 [Missing Answer]\n2. Passage 1, sentence 3 [Missing Major Auxiliary Information]\n\nExplanation:\n1. The model prediction does not mention that the foreign aid recipients include developing countries, countries of strategic importance to the United States, and countries recovering from war, which is a missing answer from Passage 1, sentence 5.\n2. The model prediction also lacks the auxiliary information that there are two broad categories of US foreign aid: military aid and economic assistance, which is a major auxiliary information from Passage 1, sentence 3. This information is crucial to understanding the different types of aid the US provides to other countries."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The United States provides foreign aid to various countries, including developing countries, countries of strategic importance to the United States, and countries recovering from war. This aid falls into two broad categories: military aid and economic assistance. However, the specific country that receives the most US foreign aid is not specified in the provided passages."}], "feedback_human": {"errors": [], "missing-info": [], "corrected-prediction": "The United States gives the most foreign aid, which is aid given by the United States government to other governments. In 2010, the United States gave the most foreign aid to Israel, and the second-most to Egypt."}}, {"question": "Who has the highest number of likes on instagram?", "passages": [["Instagram", "Instagram\n\nInstagram (also known as IG) is a photo and video-sharing social networking service owned by Facebook, Inc.", "It was created by Kevin Systrom and Mike Krieger, and launched in October 2010 exclusively on iOS.", "A version for Android devices was released a year and 6 months later, in April 2012, followed by a feature-limited website interface in November 2012, and apps for Windows 10 Mobile and Windows 10 in April 2016 and October 2016 respectively.", "The app allows users to upload photos and videos to the service, which can be edited with various filters, and organized with tags and location information.", "An account's posts can be shared publicly or with pre-approved followers.", "Users can browse other users' content by tags and locations, and view trending content.", "Users can \"like\" photos, and follow other users to add their content to a feed.", "The service was originally distinguished by only allowing content to be framed in a square (1:1) aspect ratio, but these restrictions were eased in 2015.", "The service also added messaging features, the ability to include multiple images or videos in a single post, as well as \"Stories\"\u2014similar to its main competitor Snapchat\u2014which allows users to post photos and videos to a sequential feed, with each post accessible by others for 24 hours each."], ["Like button", "Some reactions included \"Love\", \"Haha\", \"Wow\", \"Sad\", or \"Angry\".", "In 2010, as part of a wider redesign of the service, YouTube switched from a star-based rating system to Like/Dislike buttons.", "Under the previous system, users could rate videos on a scale from 1 to 5 stars; YouTube staff argued that this change reflected common usage of the system, as 2-, 3-, and 4-star ratings were not used as often.", "In 2012, YouTube briefly experimented with replacing the Like and Dislike buttons with a Google+ +1 button.", "Google has a like button called the +1 (Internet jargon for \"I like that\" or \"I agree\"), which was introduced in June 2011.", "In August 2011 the +1 button also became a share icon.", "Instagram has a like button.", "It is a heart symbol () similar to those in Twitter, Tumblr and VK.", "On the mobile app, double-tapping a photo also acts as a like button.", "On Reddit (a system of message boards), users can upvote and downvote posts (and comments on posts).", "The votes contribute to posters' and commenters' \"karma\" (Reddit's name for a user's overall rating)."], ["Like button", "Like button\n\nA like button, like option, or recommend button is a feature in communication software such as social networking services, Internet forums, news websites and blogs where the user can express that they like, enjoy or support certain content.", "Internet services that feature like buttons usually display the number of users who liked each content, and may show a full or partial list of them.", "This is a quantitative alternative to other methods of expressing reaction to content, like writing a reply text.", "Some websites also include a dislike button, so the user can either vote in favour, against or neutrally.", "Other websites include more complex Web content voting systems, for example five stars or reaction buttons to show a wider range of emotion to the content.", "The like button was first announced as a FriendFeed feature on October 30, 2007 and was popularized within that community.", "Later the feature was integrated into Facebook before FriendFeed was acquired by Facebook August 10, 2009.", "The Facebook like button is designed as a hand giving \"thumbs up\".", "It was originally discussed to have been a star or a plus sign, and during development the feature was referred to as \"awesome\" instead of \"like\".", "It was introduced on 9 February 2009.", "During May 2016, Facebook introduced reactions - a new way to express peoples emotions to Facebook posts."]], "gold": "Instagram is a photo and video-sharing social networking service that allows users to like content that is provided by its owners by double tapping a heart symbol on the post. Instagram usually displays the number of users who liked each piece of content, and the post with the most likes changes over time. The person with the highest number of likes on Instagram in 2015 was Kendall Jenner. In 2016, Selena Gomez received the highest number, and in 2017, Beyonce had the highest number.", "prediction 1": "Instagram is a photo and video-sharing social networking service owned by Facebook, Inc. It was created by Kevin Systrom and Mike Krieger, and launched in October 2010 exclusively on iOS. The number one user with the most likes on Instagram is a musician called Liam Payne.", "prediction 2": "Instagram is a photo and video-sharing social networking service owned by Facebook, Inc. it was created by Kevin Systrom and Mike Krieger, and launched in October 2010 exclusively on iOS. The person with the most likes on Instagram is the owner of the account IG.com, a photo and video sharing app owned by Facebook. The person with the highest number of likes on Instagram is the owner of the account IG.com. The person with the highest number of likes on Instagram is the owner of the account IG.com the user has the highest number of followers.", "prediction 3": "Instagram is a photo and video-sharing social networking service owned by Facebook, Inc. It was created by Kevin Systrom and Mike Krieger and launched in October 2010 exclusively on iOS. The user with the most likes is a user named john kim, whose account has the most likes.", "prediction 4": "Instagram is a photo and video-sharing social networking service owned by Facebook, Inc. It was created by Kevin Systrom and Mike Krieger, and launched in October 2010 exclusively on iOS. The most-liked user is emily j. ross, with over 1.3 million likes. The most-followed user is emily j. ross, with over 1.6 million likes.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 0, "end": 187}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [7]}], "corrected-prediction": "On Instagram, a photo and video-sharing social networking service, users can \"like\" photos, and this can be done by double-tapping a photo on the mobile app. Instagram usually displays the number of users who liked each content. However, the specific user with the highest number of likes on Instagram is not provided in the available information."}, "preference": [2, 1, 1, 1, 1, 2], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Instagram\nS1. Instagram  Instagram (also known as IG) is a photo and video-sharing social networking service owned by Facebook, Inc.\nS2. It was created by Kevin Systrom and Mike Krieger, and launched in October 2010 exclusively on iOS.\nS3. A version for Android devices was released a year and 6 months later, in April 2012, followed by a feature-limited website interface in November 2012, and apps for Windows 10 Mobile and Windows 10 in April 2016 and October 2016 respectively.\nS4. The app allows users to upload photos and videos to the service, which can be edited with various filters, and organized with tags and location information.\nS5. An account's posts can be shared publicly or with pre-approved followers.\nS6. Users can browse other users' content by tags and locations, and view trending content.\nS7. Users can \"like\" photos, and follow other users to add their content to a feed.\nS8. The service was originally distinguished by only allowing content to be framed in a square (1:1) aspect ratio, but these restrictions were eased in 2015.\nS9. The service also added messaging features, the ability to include multiple images or videos in a single post, as well as \"Stories\"\u2014similar to its main competitor Snapchat\u2014which allows users to post photos and videos to a sequential feed, with each post accessible by others for 24 hours each.\n\nPassage 2: Title (S0) - Like button\nS1. Some reactions included \"Love\", \"Haha\", \"Wow\", \"Sad\", or \"Angry\".\nS2. In 2010, as part of a wider redesign of the service, YouTube switched from a star-based rating system to Like/Dislike buttons.\nS3. Under the previous system, users could rate videos on a scale from 1 to 5 stars; YouTube staff argued that this change reflected common usage of the system, as 2-, 3-, and 4-star ratings were not used as often.\nS4. In 2012, YouTube briefly experimented with replacing the Like and Dislike buttons with a Google+ +1 button.\nS5. Google has a like button called the +1 (Internet jargon for \"I like that\" or \"I agree\"), which was introduced in June 2011.\nS6. In August 2011 the +1 button also became a share icon.\nS7. Instagram has a like button.\nS8. It is a heart symbol () similar to those in Twitter, Tumblr and VK.\nS9. On the mobile app, double-tapping a photo also acts as a like button.\nS10. On Reddit (a system of message boards), users can upvote and downvote posts (and comments on posts).\nS11. The votes contribute to posters' and commenters' \"karma\" (Reddit's name for a user's overall rating).\n\nPassage 3: Title (S0) - Like button\nS1. Like button  A like button, like option, or recommend button is a feature in communication software such as social networking services, Internet forums, news websites and blogs where the user can express that they like, enjoy or support certain content.\nS2. Internet services that feature like buttons usually display the number of users who liked each content, and may show a full or partial list of them.\nS3. This is a quantitative alternative to other methods of expressing reaction to content, like writing a reply text.\nS4. Some websites also include a dislike button, so the user can either vote in favour, against or neutrally.\nS5. Other websites include more complex Web content voting systems, for example five stars or reaction buttons to show a wider range of emotion to the content.\nS6. The like button was first announced as a FriendFeed feature on October 30, 2007 and was popularized within that community.\nS7. Later the feature was integrated into Facebook before FriendFeed was acquired by Facebook August 10, 2009.\nS8. The Facebook like button is designed as a hand giving \"thumbs up\".\nS9. It was originally discussed to have been a star or a plus sign, and during development the feature was referred to as \"awesome\" instead of \"like\".\nS10. It was introduced on 9 February 2009.\nS11. During May 2016, Facebook introduced reactions - a new way to express peoples emotions to Facebook posts.\n    \nInput Question:\nWho has the highest number of likes on instagram?\n\nCorrect Response:\nInstagram is a photo and video-sharing social networking service that allows users to like content that is provided by its owners by double tapping a heart symbol on the post. Instagram usually displays the number of users who liked each piece of content, and the post with the most likes changes over time. The person with the highest number of likes on Instagram in 2015 was Kendall Jenner. In 2016, Selena Gomez received the highest number, and in 2017, Beyonce had the highest number.\n\nModel Prediction:\nInstagram is a photo and video-sharing social networking service owned by Facebook, Inc. It was created by Kevin Systrom and Mike Krieger, and launched in October 2010 exclusively on iOS. The number one user with the most likes on Instagram is a musician called Liam Payne.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "[Instagram is a photo and video-sharing social networking service owned by Facebook, Inc. It was created by Kevin Systrom and Mike Krieger, and launched in October 2010 exclusively on iOS.] The number one user with the most likes on Instagram is a musician called Liam Payne.\n\nExplanation:\n1. The first sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\"."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. Instagram is a photo and video-sharing social networking service owned by Facebook, Inc.\nS2. It was created by Kevin Systrom and Mike Krieger, and launched in October 2010 exclusively on iOS.\nS3. The number one user with the most likes on Instagram is a musician called Liam Payne.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "S3\n\nExplanation:\n1. The claim that \"Liam Payne\" is the user with the most likes on Instagram is not verifiable from the provided passages. Therefore, it is marked as an \"Unverifiable Fact\"."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 7 [Missing Major Auxiliary Information]\n2. Passage 2, sentence 9 [Missing Major Auxiliary Information]\n3. Passage 3, sentence 2 [Missing Major Auxiliary Information]\n\nExplanation:\n1. The model prediction does not mention that users can \"like\" photos on Instagram, which is crucial auxiliary information found in Passage 1, sentence 7.\n2. The model prediction does not mention that on the mobile app, double-tapping a photo also acts as a like button, which is crucial auxiliary information found in Passage 2, sentence 9.\n3. The model prediction does not mention that Instagram usually displays the number of users who liked each content, which is crucial auxiliary information found in Passage 3, sentence 2."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "On Instagram, a photo and video-sharing social networking service, users can \"like\" photos, and this can be done by double-tapping a photo on the mobile app. Instagram usually displays the number of users who liked each content. However, the specific user with the highest number of likes on Instagram is not provided in the available information."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 65, "end": 88}, {"error type": "Irrelevant", "explanation": "", "start": 89, "end": 187}, {"error type": "Unverifiable", "explanation": "", "start": 217, "end": 273}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [7]}, {"error type": "Missing-Minor-Auxiliary", "passage_id": 2, "sentence_id": [8]}], "corrected-prediction": "Instagram is a photo and video-sharing social networking service, users can \"like\" photos, the like button is a heart symbol. "}}, {"question": "Who plays kate pearson's mom on this is us?", "passages": [["This Is Us (season 3)", "Main cast members Milo Ventimiglia, Mandy Moore, Sterling K. Brown, Chrissy Metz, Justin Hartley, Susan Kelechi Watson, Chris Sullivan, Jon Huertas and Ron Cephas Jones return from the second season as Jack Pearson, Rebecca Pearson, Randall Pearson, Kate Pearson, Kevin Pearson, Beth Pearson, Toby Damon, Miguel Rivas, and William H. Hill, respectively.", "Lyric Ross, who recurred as D\u00e9j\u00e0 throughout the second season, was subsequently promoted to the principal cast in the third season.", "In August 2018, Michael Angarano was cast to recur as Nick Pearson, Jack Pearson's brother; the character was first mentioned in the second season, and previously was depicted only briefly as a child.", "Melanie Liburd was promoted to series regular after guest starring in the second season as Zoe, Beth Pearson's cousin and Kevin Pearson's new love interest.", "Production on the season officially began on July 10, 2018, in Los Angeles.", "General references"], ["This Is Us (season 1)", "This Is Us (season 1)\n\nThe first season of the American television series \"This Is Us\" follows the family lives and connections of several people who all share the same birthday and the ways in which they are similar and different.", "The season is produced by Rhode Island Ave.", "Productions, Zaftig Films, and 20th Century Fox Television, with Fogelman and Don Todd serving as showrunners.", "The season stars an ensemble cast featuring Milo Ventimiglia, Mandy Moore, Sterling K. Brown, Chrissy Metz, Justin Hartley, Susan Kelechi Watson, Chris Sullivan, and Ron Cephas Jones.", "The season, which premiered on NBC on September 20, 2016, and ran until March 14, 2017, over 18 episodes, received generally positive reviews from critics.", "It was chosen by the American Film Institute as one of the top ten television programs of 2016, and received ten nominations for the 69th Primetime Emmy Awards, including Outstanding Drama Series with Brown winning for Outstanding Lead Actor in a Drama Series, as well as receiving nominations for the Golden Globe Award for Best Television Series \u2013 Drama and the Critics' Choice Television Award for Best Drama Series.", "The series was renewed for a second and third season on January 18, 2017.", "<onlyinclude></onlyinclude>\n\nDan Fogelman and Don Todd served as the season's showrunners."]], "gold": "Rebecca Pearson is a character from the American drama television series This is Us. She is Jack Pearson's widow and the mother of Kevin, Kate, and Randall Pearson. Throughout the show, she is shown at different stages of her life, portrayed by different actresses. Early-childhood Kate is played by Kya Kruse, mid-childhood by Ava Castro and Mandy Moore takes on the role for the scenes where she's an adult.", "prediction 1": "This Is Us follows the family lives and connections of several people who all share the same birthday and the ways they are similar and different. The first season stars Milo Ventimiglia as Kate Pearson's mom, Sterling K. Brown as Randall Pearson's mom and Susan Kelechi Watson as her mom. Jon Huertas plays Randall Pearson's dad on the show, while Susan Kelechi Watson plays Kate Pearson's mom.", "prediction 2": "Kate Pearson is the main character on the American television show This Is Us and the mother of Kevin and Beth Pearson. Kate's mother is played by Sterling K. Brown.", "prediction 3": "This Is Us has been in the news a lot lately. The character Kate Pearson's mom has been a character on the show since season 2 and she is played by Elizabeth Banks.", "prediction 4": "This Is Us is an American television series about the lives and connections of several people who all share the same birthday and the ways they are similar and different. Kate Pearson's mother is played by Sterling K. Brown. Randall Pearson is played by Sterling K. Brown. Sterling K. Brown plays Randall Pearson's father on the series.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 0, "end": 146}, {"error type": "Irrelevant", "explanation": "", "start": 257, "end": 395}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 1, "sentence_id": [1]}], "corrected-prediction": "Mandy Moore plays the role of Rebecca Pearson, who is Kate Pearson's mom, on the television series This Is Us."}, "preference": [1, 1, 1, 1, 2, 2], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - This Is Us (season 3)\nS1. Main cast members Milo Ventimiglia, Mandy Moore, Sterling K. Brown, Chrissy Metz, Justin Hartley, Susan Kelechi Watson, Chris Sullivan, Jon Huertas and Ron Cephas Jones return from the second season as Jack Pearson, Rebecca Pearson, Randall Pearson, Kate Pearson, Kevin Pearson, Beth Pearson, Toby Damon, Miguel Rivas, and William H. Hill, respectively.\nS2. Lyric Ross, who recurred as D\u00e9j\u00e0 throughout the second season, was subsequently promoted to the principal cast in the third season.\nS3. In August 2018, Michael Angarano was cast to recur as Nick Pearson, Jack Pearson's brother; the character was first mentioned in the second season, and previously was depicted only briefly as a child.\nS4. Melanie Liburd was promoted to series regular after guest starring in the second season as Zoe, Beth Pearson's cousin and Kevin Pearson's new love interest.\nS5. Production on the season officially began on July 10, 2018, in Los Angeles.\nS6. General references\n\nPassage 2: Title (S0) - This Is Us (season 1)\nS1. This Is Us (season 1)  The first season of the American television series \"This Is Us\" follows the family lives and connections of several people who all share the same birthday and the ways in which they are similar and different.\nS2. The season is produced by Rhode Island Ave.\nS3. Productions, Zaftig Films, and 20th Century Fox Television, with Fogelman and Don Todd serving as showrunners.\nS4. The season stars an ensemble cast featuring Milo Ventimiglia, Mandy Moore, Sterling K. Brown, Chrissy Metz, Justin Hartley, Susan Kelechi Watson, Chris Sullivan, and Ron Cephas Jones.\nS5. The season, which premiered on NBC on September 20, 2016, and ran until March 14, 2017, over 18 episodes, received generally positive reviews from critics.\nS6. It was chosen by the American Film Institute as one of the top ten television programs of 2016, and received ten nominations for the 69th Primetime Emmy Awards, including Outstanding Drama Series with Brown winning for Outstanding Lead Actor in a Drama Series, as well as receiving nominations for the Golden Globe Award for Best Television Series \u2013 Drama and the Critics' Choice Television Award for Best Drama Series.\nS7. The series was renewed for a second and third season on January 18, 2017.\nS8. <onlyinclude></onlyinclude>  Dan Fogelman and Don Todd served as the season's showrunners.\n    \nInput Question:\nWho plays kate pearson's mom on this is us?\n\nCorrect Response:\nRebecca Pearson is a character from the American drama television series This is Us. She is Jack Pearson's widow and the mother of Kevin, Kate, and Randall Pearson. Throughout the show, she is shown at different stages of her life, portrayed by different actresses. Early-childhood Kate is played by Kya Kruse, mid-childhood by Ava Castro and Mandy Moore takes on the role for the scenes where she's an adult.\n\nModel Prediction:\nThis Is Us follows the family lives and connections of several people who all share the same birthday and the ways they are similar and different. The first season stars Milo Ventimiglia as Kate Pearson's mom, Sterling K. Brown as Randall Pearson's mom and Susan Kelechi Watson as her mom. Jon Huertas plays Randall Pearson's dad on the show, while Susan Kelechi Watson plays Kate Pearson's mom.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "[This Is Us follows the family lives and connections of several people who all share the same birthday and the ways they are similar and different.] The first season stars Milo Ventimiglia as Kate Pearson's mom, Sterling K. Brown as Randall Pearson's mom and [Susan Kelechi Watson as her mom. Jon Huertas plays Randall Pearson's dad on the show, while Susan Kelechi Watson plays Kate Pearson's mom.]\n\nExplanation:\n1. The first sentence is irrelevant to the question as it does not provide any information about who plays Kate Pearson's mom on This Is Us.\n2. The second sentence is incoherent as it incorrectly states that Milo Ventimiglia and Sterling K. Brown play Kate Pearson's mom. Also, it repeats the incorrect information that Susan Kelechi Watson plays Kate Pearson's mom.\n3. The third sentence is repetitive as it repeats the incorrect information that Susan Kelechi Watson plays Kate Pearson's mom. It also includes irrelevant information about Jon Huertas playing Randall Pearson's dad."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. This Is Us follows the family lives and connections of several people who all share the same birthday and the ways they are similar and different.\nS2. The first season stars Milo Ventimiglia as Kate Pearson's mom, Sterling K. Brown as Randall Pearson's mom and Susan Kelechi Watson as her mom.\nS3. Jon Huertas plays Randall Pearson's dad on the show, while Susan Kelechi Watson plays Kate Pearson's mom.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "S2\nS3\n\nExplanation:\n1. In sentence 2, the model prediction incorrectly states that Milo Ventimiglia, Sterling K. Brown, and Susan Kelechi Watson play Kate Pearson's mom. According to Passage 1, Sentence 1, Mandy Moore plays Rebecca Pearson, who is Kate Pearson's mom.\n2. In sentence 3, the model prediction incorrectly states that Susan Kelechi Watson plays Kate Pearson's mom. According to Passage 1, Sentence 1, Mandy Moore plays Rebecca Pearson, who is Kate Pearson's mom. The model prediction also incorrectly states that Jon Huertas plays Randall Pearson's dad. According to Passage 1, Sentence 1, Jon Huertas plays Miguel Rivas."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 1 [Missing Answer]\n\nExplanation:\n1. The model prediction does not mention that Mandy Moore plays Rebecca Pearson, who is Kate Pearson's mom. This is a missing answer."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "Mandy Moore plays the role of Rebecca Pearson, who is Kate Pearson's mom, on the television series This Is Us."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 11, "end": 146}, {"error type": "Wrong-Grounding", "explanation": "{\"passage_id\":1,\"sentence_id\":[1]}", "start": 190, "end": 209}, {"error type": "Irrelevant", "explanation": "", "start": 164, "end": 186}, {"error type": "Wrong-Grounding", "explanation": "{\"passage_id\":1,\"sentence_id\":[1]}", "start": 249, "end": 252}, {"error type": "Irrelevant", "explanation": "", "start": 210, "end": 227}, {"error type": "Unverifiable", "explanation": "", "start": 278, "end": 289}, {"error type": "Unverifiable", "explanation": "", "start": 308, "end": 342}, {"error type": "Redundant", "explanation": "and Susan Kelechi Watson as her mom. ", "start": 349, "end": 395}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [1]}], "corrected-prediction": "Rebecca Pearson is a character on the This is Us show. She is played by Mandy Moore. "}}, {"question": "When did the united states start regulating immigration?", "passages": [["Chinese Exclusion Act", "Chinese Exclusion Act\n\nThe Chinese Exclusion Act was a United States federal law signed by President Chester A. Arthur on May 6, 1882, prohibiting all immigration of Chinese laborers.", "Building on the 1875 Page Act, which banned Chinese women from immigrating to the United States, the Chinese Exclusion Act was the first law implemented to prevent all members of a specific ethnic or national group from immigrating.", "The act followed the Angell Treaty of 1880, a set of revisions to the U.S.\u2013China Burlingame Treaty of 1868 that allowed the U.S. to suspend Chinese immigration.", "The act was initially intended to last for 10 years, but was renewed in 1892 with the Geary Act and made permanent in 1902.", "It was repealed by the Magnuson Act on December 17, 1943, which allowed 105 Chinese to enter per year.", "Chinese immigration later increased with the passage of the Immigration and Nationality Act of 1952, which abolished direct racial barriers, and later by Immigration and Nationality Act of 1965, which abolished the National Origins Formula.", "The first significant Chinese immigration to North America began with the California Gold Rush of 1848\u20131855 and it continued with subsequent large labor projects, such as the building of the First Transcontinental Railroad.", "During the early stages of the gold rush, when surface gold was plentiful, the Chinese were tolerated by white people, if not well received."]], "gold": "The United States introduced in the House the first bill that ended up regulating immigration on April 12, 1882. The first bill which started regulating immigration was signed into law on May 6, 1882, when President Chester A. Arther signed the Chinese Exclusion Act which prohibited all immigration of Chinese laborers.", "prediction 1": "The United States started regulating immigration in 1880. In 1882, President Chester Arthur signed the Chinese Exclusion Act, a federal law prohibiting all immigration of Chinese laborers. The Act was initially intended to last for 10 years, but was renewed in 1892 with the Geary Act and made permanent in 1902. It was repealed by the Magnuson Act on December 17, 1943, which allowed 105 Chinese to enter per year. Chinese immigration later increased with the passage of the Immigration and Nationality Act of 1952, which abolished direct racial barriers, and later by the Immigration and Nationality Act of 1965, which abolished the National Origins Formula.", "prediction 2": "The first significant Chinese immigration to North America began with the California Gold Rush of 1848\u20131855 and it continued with subsequent large labor projects, such as the building of the First Transcontinental Railroad. The Chinese Exclusion Act was a United States federal law signed by President Chester A. Arthur on May 6, 1882, prohibiting all immigration of Chinese laborers. Building on the 1875 Page Act, which banned Chinese women from immigrating to the United States, the Chinese Exclusion Act was the first law implemented to prevent all members of a specific ethnic or national group from immigrating.", "prediction 3": "The United States started regulating immigration in 1882 with the signing of the Chinese Exclusion Act, a federal law signed by President Chester A. Arthur on May 6, 1882. Building on the 1875 Page Act, which banned Chinese women from immigrating to the United States, the Chinese Exclusion Act was the first law implemented to prevent all members of a specific ethnic or national group from immigrating.", "prediction 4": "The United States first started regulating immigration in 1870, when President Chester A. Arthur signed the Angell Treaty of 1880, a set of revisions to the U.S.\u2013China Burlingame Treaty of 1868 that allowed the U.S. to suspend Chinese immigration. The American Citizenship and Immigration Act of 1871 banned Chinese laborers from entering the United States. The Chinese Exclusion Act was a federal law signed by President Chester A. Arthur on May 6, 1882, prohibiting all immigration of Chinese laborers. The Immigration and Nationality Act of 1952 abolished direct racial barriers, and later by the Immigration and Nationality Act of 1965, which abolished direct racial barriers.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 313, "end": 660}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [1]}], "corrected-prediction": "The United States started regulating immigration on May 6, 1882, when President Chester Arthur signed the Chinese Exclusion Act, a federal law prohibiting all immigration of Chinese laborers. The Act was initially intended to last for 10 years, but was renewed in 1892 with the Geary Act and made permanent in 1902."}, "preference": [1, 1, 1, 1, 1, 1], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Chinese Exclusion Act\nS1. Chinese Exclusion Act  The Chinese Exclusion Act was a United States federal law signed by President Chester A. Arthur on May 6, 1882, prohibiting all immigration of Chinese laborers.\nS2. Building on the 1875 Page Act, which banned Chinese women from immigrating to the United States, the Chinese Exclusion Act was the first law implemented to prevent all members of a specific ethnic or national group from immigrating.\nS3. The act followed the Angell Treaty of 1880, a set of revisions to the U.S.\u2013China Burlingame Treaty of 1868 that allowed the U.S. to suspend Chinese immigration.\nS4. The act was initially intended to last for 10 years, but was renewed in 1892 with the Geary Act and made permanent in 1902.\nS5. It was repealed by the Magnuson Act on December 17, 1943, which allowed 105 Chinese to enter per year.\nS6. Chinese immigration later increased with the passage of the Immigration and Nationality Act of 1952, which abolished direct racial barriers, and later by Immigration and Nationality Act of 1965, which abolished the National Origins Formula.\nS7. The first significant Chinese immigration to North America began with the California Gold Rush of 1848\u20131855 and it continued with subsequent large labor projects, such as the building of the First Transcontinental Railroad.\nS8. During the early stages of the gold rush, when surface gold was plentiful, the Chinese were tolerated by white people, if not well received.\n    \nInput Question:\nWhen did the united states start regulating immigration?\n\nCorrect Response:\nThe United States introduced in the House the first bill that ended up regulating immigration on April 12, 1882. The first bill which started regulating immigration was signed into law on May 6, 1882, when President Chester A. Arther signed the Chinese Exclusion Act which prohibited all immigration of Chinese laborers.\n\nModel Prediction:\nThe United States started regulating immigration in 1880. In 1882, President Chester Arthur signed the Chinese Exclusion Act, a federal law prohibiting all immigration of Chinese laborers. The Act was initially intended to last for 10 years, but was renewed in 1892 with the Geary Act and made permanent in 1902. It was repealed by the Magnuson Act on December 17, 1943, which allowed 105 Chinese to enter per year. Chinese immigration later increased with the passage of the Immigration and Nationality Act of 1952, which abolished direct racial barriers, and later by the Immigration and Nationality Act of 1965, which abolished the National Origins Formula.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "The United States started regulating immigration in 1880. In 1882, President Chester Arthur signed the Chinese Exclusion Act, a federal law prohibiting all immigration of Chinese laborers. The Act was initially intended to last for 10 years, but was renewed in 1892 with the Geary Act and made permanent in 1902. [It was repealed by the Magnuson Act on December 17, 1943, which allowed 105 Chinese to enter per year. Chinese immigration later increased with the passage of the Immigration and Nationality Act of 1952, which abolished direct racial barriers, and later by the Immigration and Nationality Act of 1965, which abolished the National Origins Formula.]\n\nExplanation:\nThe information about the Magnuson Act, Immigration and Nationality Act of 1952, and Immigration and Nationality Act of 1965 is irrelevant to the question asked. The question is about when the United States started regulating immigration, not about the subsequent changes to immigration laws. Therefore, this information should be marked as \"Irrelevant\"."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The United States started regulating immigration in 1880.\nS2. In 1882, President Chester Arthur signed the Chinese Exclusion Act, a federal law prohibiting all immigration of Chinese laborers.\nS3. The Act was initially intended to last for 10 years, but was renewed in 1892 with the Geary Act and made permanent in 1902.\nS4. It was repealed by the Magnuson Act on December 17, 1943, which allowed 105 Chinese to enter per year.\nS5. Chinese immigration later increased with the passage of the Immigration and Nationality Act of 1952, which abolished direct racial barriers, and later by the Immigration and Nationality Act of 1965, which abolished the National Origins Formula.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "Inconsistent or Unverifiable Sentences:\n1. S1\n\nExplanation:\n1. The first sentence of the model prediction states that the United States started regulating immigration in 1880. However, according to the passages, the Chinese Exclusion Act, which was the first law implemented to prevent all members of a specific ethnic or national group from immigrating, was signed in 1882. Therefore, the claim that the United States started regulating immigration in 1880 is an \"Unverifiable Fact\"."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 1 [Missing Major Auxiliary Information]\n\nExplanation:\n1. The model prediction is missing the specific date of May 6, 1882, when the Chinese Exclusion Act was signed by President Chester A. Arthur. This information is crucial to accurately answering the question about when the United States started regulating immigration. Therefore, it should be labeled as \"Missing Major Auxiliary Information\"."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The United States started regulating immigration on May 6, 1882, when President Chester Arthur signed the Chinese Exclusion Act, a federal law prohibiting all immigration of Chinese laborers. The Act was initially intended to last for 10 years, but was renewed in 1892 with the Geary Act and made permanent in 1902."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 189, "end": 312}, {"error type": "Irrelevant", "explanation": "", "start": 313, "end": 415}, {"error type": "Irrelevant", "explanation": "", "start": 416, "end": 660}], "missing-info": [], "corrected-prediction": "The United States started regulating immigration in 1880. In 1882, President Chester Arthur signed the Chinese Exclusion Act, a federal law prohibiting all immigration of Chinese laborers. "}}, {"question": "When do jim and pam kiss in the office?", "passages": [["Pam Beesly", "Pam ultimately calls off her wedding to Roy, but they remain friendly and he is determined to win her back by being less of a jerk.", "She reconciles with Roy at Phyllis's wedding as a response to watching Jim date Karen.", "In an attempt at a fresh start with Roy, Pam comes clean about Jim kissing her during \"Casino Night\".", "Roy flies into a violent rage and Pam ends the relationship on the spot.", "The next day, Roy attempts to attack Jim in the office but is stopped by Dwight's pepper spray and is summarily fired.", "After losing his job, Roy meets Pam for coffee and says that even though Jim is dating Karen, she should at least make an effort to date him (in as much as she called off the wedding because of him).", "In season 5, Jim and Roy run into each other at a bar and Roy learns that Jim and Pam are engaged.", "The mood is somewhat awkward, but Roy is congratulatory, but then makes a somewhat passive-aggressive comment, seemingly meant to make Jim feel insecure about his current role in Pam's life, which tempts him to drive to Pratt, where she is attending art classes.", "Jim gets on the freeway, but changes his mind and remembers that he trusts Pam.", "Jim didn't want to treat Pam the same way Roy treated her."], ["Pam Beesly", "The office ultimately learns of their relationship in \"Dunder Mifflin Infinity\".", "In \"Chair Model\", after teasing Pam about his impending proposal, Jim tells the documentary crew he is not kidding around about an engagement and shows them a ring he bought a week after he and Pam started dating.", "In the next few episodes, Jim fake-proposes to Pam multiple times.", "In \"Goodbye, Toby\", Pam discovers she's been accepted at Pratt Institute, an art and design school in Brooklyn .", "In an interview later in the episode, Jim announces that he will propose to Pam that evening.", "Just as Jim is preparing to propose, however, Andy Bernard stands up and makes his own impromptu proposal to Angela.", "Having had his thunder stolen by Andy, Jim reluctantly puts the ring back in his jacket pocket, leaving Pam visibly disappointed as she was expecting Jim to propose that night.", "In the Season 5 premiere, \"Weight Loss\", Pam begins her three-month course at the Pratt Institute.", "In this episode, Jim proposes in the pouring rain at a rest stop, saying that he \"can't wait\".", "In \"Business Trip\", Pam learns that she is failing one of her classes and will have to remain in New York another three months to retake it."], ["Pam Beesly", "Pam Beesly\n\nPamela Morgan Halpert (n\u00e9e Beesly) is a fictional character on the U.S. television sitcom \"The Office\", played by Jenna Fischer.", "Her counterpart in the original UK series of \"The Office\" is Dawn Tinsley.", "Her character is initially the receptionist at the paper distribution company Dunder Mifflin, before becoming a saleswoman and eventually office administrator until she left in the series finale.", "Her character is shy, growing assertive but amiable, and artistically inclined, and shares romantic interest with Jim Halpert, whom she begins dating in the fourth season and marries and starts a family with as the series continues.", "The character was originally created to be very similar to the British counterpart, Dawn Tinsley.", "Even minute details, such as how Pam wore her hair each day, were considered by executive producer, Greg Daniels.", "\"When I went in for \"The Office\", the casting director said to me, 'Please look normal',\" recalls Jenna Fischer.", "\"Don't make yourself all pretty, and dare to bore me with your audition.", "Those were her words.", "Dare to bore me.\"", "Heeding the advice, Fischer said little during the auditions, during which she was interviewed in character by show producers, in an improvisational format, to imitate the show's documentary premise."], ["Casino Night", "Jim tells Jan that he's made a decision about the transfer.", "After Roy leaves, Jim tells Pam that he is in love with her.", "After a stunned pause, she states she cannot be with him.", "He tells her he wants to be more than friends, but she is sorry he \"misinterpreted things.\"", "Heartbroken, Jim apologizes for misinterpreting their friendship and discreetly wipes a tear from his cheek as he walks away.", "Jan leaves Michael and Carol, noticeably upset at the night's events, and it is revealed she packed an overnight bag in her car, implying she had planned to spend the night with Michael.", "Pam returns to the office and talks to her mother over the phone about Jim's statement.", "Jim enters the room and approaches her as she hastily hangs up.", "She begins to say something but Jim kisses her, and after hesitating, she returns the kiss, with the two staring at each other in silence.", "\"Casino Night\" was the first episode of the series written by Steve Carell.", "Initially, Carell suggested to executive producer Greg Daniels that an episode should revolve around a casino night.", "When it came time to plan the finale for the show, Daniels chose the idea and picked Carell to write the script."], ["Fun Run", "Fun Run\n\n\"Fun Run\" is the first and second episode of the fourth season of the American comedy television series \"The Office\", and the show's fifty-fourth and fifty-fifth episode overall.", "Written and directed by executive producer and showrunner Greg Daniels, the episode first aired on NBC in the United States on September 27, 2007.", "In the episode, Michael Scott (Steve Carell) believes the office is cursed after he accidentally hits Meredith Palmer (Kate Flannery) with his car.", "After being taken to the hospital, Meredith is found to have rabies.", "In an attempt to make amends with Meredith, Michael sponsors a fun run for rabies.", "Meanwhile, it is revealed that Jim Halpert (John Krasinski) and Pam Beesly (Jenna Fischer) are dating, while Angela Martin (Angela Kinsey) is mad at Dwight Schrute (Rainn Wilson) for killing her cat Sprinkles.", "The episode received mixed reviews from the varying critics, while most praised the episode for Jim and Pam's relationship.", "However, critics had differing opinions when it came to how Michael behaved throughout the episode."], ["Dunder Mifflin Infinity", "Dunder Mifflin Infinity\n\n\"Dunder Mifflin Infinity\" is the third and fourth episode of the fourth season of the American comedy television series \"The Office\", and the show's fifty-sixth and fifty-seventh episode overall.", "The episode was written by Michael Schur, who also acts in the show, and directed by Craig Zisk.", "It first aired in the United States on October 4, 2007 on NBC.", "In this episode, Ryan returns to his old office and reveals his plan to bring technology to Dunder Mifflin.", "Michael and Dwight try to prove that the personal touch is better than technology.", "Meanwhile, Jim and Pam reveal their relationship to the rest of the office, Kelly attempts to reunite with Ryan, and Dwight and Angela's relationship continues to plummet.", "Ryan Howard (B. J. Novak) returns to the Scranton, Pennsylvania branch of Dunder Mifflin for the first time since his promotion to the corporate headquarters.", "Although he sports a much more urbane look and attitude, he garners little respect from his former peers.", "Ryan introduces \"Dunder Mifflin Infinity,\" his initiative to revitalize the company with new technology."]], "gold": "Pamela Halpert is a fictional character on the U.S. television sitcom The Office, played by Jenna Fischer. Her character shares romantic interest with Jim Halpert, whom she begins dating in the fourth season. In episode 22 named Casino Night, Jim and Pam kiss after Jim tells Pam that he is in love with her. This episode aired on May 11, 2006. In the season 4 premiere Fun Run, Jim and Pam confess that they have started dating after the camera crew catches them kissing. The office ultimately learns of their relationship in Dunder Mifflin Infinity. Fun Run aired on September 27, 2007 and Dunder Mifflin Infinity aired on October 4, 2007.", "prediction 1": "Pam Beesly is a fictional character on the U.S. television sitcom The Office, played by Jenna Fischer. In season 5, Jim and Roy run into each other at a bar and Roy learns that Jim and Pam are engaged. In season 5 episode 5, \"Chair Model\", Jim proposes to Pam in the pouring rain at a rest stop.\n", "prediction 2": "In the U.S. television sitcom, The Office, actress Jenna Fischer plays Pam Beesly, a character from the original UK series. In season four, Jim and Pam run into each other at a bar and Roy learns that Jim and Pam are engaged. In season five, Jim and Pam run into each other at a bar and Roy learns that Jim and Pam are engaged.", "prediction 3": "In the US version of The Office, during episode 4, \"Goodbye, Toby,\" all three of Pam Beesly's boyfriends kiss. During season 5, \"Casino Night\", and \"Chair Model\", Jim proposes to Pam.", "prediction 4": "On the television sitcom The Office, the characters Pam Beesly and Jim Halpert kiss from time to time. Jim and Pam kiss at the end of an episode when she is on her way to staff dinner and Jim announces his engagement to her.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 103, "end": 201}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 4, "sentence_id": [9]}], "corrected-prediction": "Pam Beesly is a fictional character on the U.S. television sitcom The Office, played by Jenna Fischer. In the episode \"Casino Night\", Jim tells Pam that he is in love with her and they share a kiss. Later, in the season 4 premiere \"Fun Run\", Jim and Pam confess that they have started dating after the camera crew catches them kissing."}, "preference": [1, 1, 1, 1, 2, 2], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Pam Beesly\nS1. Pam ultimately calls off her wedding to Roy, but they remain friendly and he is determined to win her back by being less of a jerk.\nS2. She reconciles with Roy at Phyllis's wedding as a response to watching Jim date Karen.\nS3. In an attempt at a fresh start with Roy, Pam comes clean about Jim kissing her during \"Casino Night\".\nS4. Roy flies into a violent rage and Pam ends the relationship on the spot.\nS5. The next day, Roy attempts to attack Jim in the office but is stopped by Dwight's pepper spray and is summarily fired.\nS6. After losing his job, Roy meets Pam for coffee and says that even though Jim is dating Karen, she should at least make an effort to date him (in as much as she called off the wedding because of him).\nS7. In season 5, Jim and Roy run into each other at a bar and Roy learns that Jim and Pam are engaged.\nS8. The mood is somewhat awkward, but Roy is congratulatory, but then makes a somewhat passive-aggressive comment, seemingly meant to make Jim feel insecure about his current role in Pam's life, which tempts him to drive to Pratt, where she is attending art classes.\nS9. Jim gets on the freeway, but changes his mind and remembers that he trusts Pam.\nS10. Jim didn't want to treat Pam the same way Roy treated her.\n\nPassage 2: Title (S0) - Pam Beesly\nS1. The office ultimately learns of their relationship in \"Dunder Mifflin Infinity\".\nS2. In \"Chair Model\", after teasing Pam about his impending proposal, Jim tells the documentary crew he is not kidding around about an engagement and shows them a ring he bought a week after he and Pam started dating.\nS3. In the next few episodes, Jim fake-proposes to Pam multiple times.\nS4. In \"Goodbye, Toby\", Pam discovers she's been accepted at Pratt Institute, an art and design school in Brooklyn .\nS5. In an interview later in the episode, Jim announces that he will propose to Pam that evening.\nS6. Just as Jim is preparing to propose, however, Andy Bernard stands up and makes his own impromptu proposal to Angela.\nS7. Having had his thunder stolen by Andy, Jim reluctantly puts the ring back in his jacket pocket, leaving Pam visibly disappointed as she was expecting Jim to propose that night.\nS8. In the Season 5 premiere, \"Weight Loss\", Pam begins her three-month course at the Pratt Institute.\nS9. In this episode, Jim proposes in the pouring rain at a rest stop, saying that he \"can't wait\".\nS10. In \"Business Trip\", Pam learns that she is failing one of her classes and will have to remain in New York another three months to retake it.\n\nPassage 3: Title (S0) - Pam Beesly\nS1. Pam Beesly  Pamela Morgan Halpert (n\u00e9e Beesly) is a fictional character on the U.S. television sitcom \"The Office\", played by Jenna Fischer.\nS2. Her counterpart in the original UK series of \"The Office\" is Dawn Tinsley.\nS3. Her character is initially the receptionist at the paper distribution company Dunder Mifflin, before becoming a saleswoman and eventually office administrator until she left in the series finale.\nS4. Her character is shy, growing assertive but amiable, and artistically inclined, and shares romantic interest with Jim Halpert, whom she begins dating in the fourth season and marries and starts a family with as the series continues.\nS5. The character was originally created to be very similar to the British counterpart, Dawn Tinsley.\nS6. Even minute details, such as how Pam wore her hair each day, were considered by executive producer, Greg Daniels.\nS7. \"When I went in for \"The Office\", the casting director said to me, 'Please look normal',\" recalls Jenna Fischer.\nS8. \"Don't make yourself all pretty, and dare to bore me with your audition.\nS9. Those were her words.\nS10. Dare to bore me.\"\nS11. Heeding the advice, Fischer said little during the auditions, during which she was interviewed in character by show producers, in an improvisational format, to imitate the show's documentary premise.\n\nPassage 4: Title (S0) - Casino Night\nS1. Jim tells Jan that he's made a decision about the transfer.\nS2. After Roy leaves, Jim tells Pam that he is in love with her.\nS3. After a stunned pause, she states she cannot be with him.\nS4. He tells her he wants to be more than friends, but she is sorry he \"misinterpreted things.\"\nS5. Heartbroken, Jim apologizes for misinterpreting their friendship and discreetly wipes a tear from his cheek as he walks away.\nS6. Jan leaves Michael and Carol, noticeably upset at the night's events, and it is revealed she packed an overnight bag in her car, implying she had planned to spend the night with Michael.\nS7. Pam returns to the office and talks to her mother over the phone about Jim's statement.\nS8. Jim enters the room and approaches her as she hastily hangs up.\nS9. She begins to say something but Jim kisses her, and after hesitating, she returns the kiss, with the two staring at each other in silence.\nS10. \"Casino Night\" was the first episode of the series written by Steve Carell.\nS11. Initially, Carell suggested to executive producer Greg Daniels that an episode should revolve around a casino night.\nS12. When it came time to plan the finale for the show, Daniels chose the idea and picked Carell to write the script.\n\nPassage 5: Title (S0) - Fun Run\nS1. Fun Run  \"Fun Run\" is the first and second episode of the fourth season of the American comedy television series \"The Office\", and the show's fifty-fourth and fifty-fifth episode overall.\nS2. Written and directed by executive producer and showrunner Greg Daniels, the episode first aired on NBC in the United States on September 27, 2007.\nS3. In the episode, Michael Scott (Steve Carell) believes the office is cursed after he accidentally hits Meredith Palmer (Kate Flannery) with his car.\nS4. After being taken to the hospital, Meredith is found to have rabies.\nS5. In an attempt to make amends with Meredith, Michael sponsors a fun run for rabies.\nS6. Meanwhile, it is revealed that Jim Halpert (John Krasinski) and Pam Beesly (Jenna Fischer) are dating, while Angela Martin (Angela Kinsey) is mad at Dwight Schrute (Rainn Wilson) for killing her cat Sprinkles.\nS7. The episode received mixed reviews from the varying critics, while most praised the episode for Jim and Pam's relationship.\nS8. However, critics had differing opinions when it came to how Michael behaved throughout the episode.\n\nPassage 6: Title (S0) - Dunder Mifflin Infinity\nS1. Dunder Mifflin Infinity  \"Dunder Mifflin Infinity\" is the third and fourth episode of the fourth season of the American comedy television series \"The Office\", and the show's fifty-sixth and fifty-seventh episode overall.\nS2. The episode was written by Michael Schur, who also acts in the show, and directed by Craig Zisk.\nS3. It first aired in the United States on October 4, 2007 on NBC.\nS4. In this episode, Ryan returns to his old office and reveals his plan to bring technology to Dunder Mifflin.\nS5. Michael and Dwight try to prove that the personal touch is better than technology.\nS6. Meanwhile, Jim and Pam reveal their relationship to the rest of the office, Kelly attempts to reunite with Ryan, and Dwight and Angela's relationship continues to plummet.\nS7. Ryan Howard (B. J. Novak) returns to the Scranton, Pennsylvania branch of Dunder Mifflin for the first time since his promotion to the corporate headquarters.\nS8. Although he sports a much more urbane look and attitude, he garners little respect from his former peers.\nS9. Ryan introduces \"Dunder Mifflin Infinity,\" his initiative to revitalize the company with new technology.\n    \nInput Question:\nWhen do jim and pam kiss in the office?\n\nCorrect Response:\nPamela Halpert is a fictional character on the U.S. television sitcom The Office, played by Jenna Fischer. Her character shares romantic interest with Jim Halpert, whom she begins dating in the fourth season. In episode 22 named Casino Night, Jim and Pam kiss after Jim tells Pam that he is in love with her. This episode aired on May 11, 2006. In the season 4 premiere Fun Run, Jim and Pam confess that they have started dating after the camera crew catches them kissing. The office ultimately learns of their relationship in Dunder Mifflin Infinity. Fun Run aired on September 27, 2007 and Dunder Mifflin Infinity aired on October 4, 2007.\n\nModel Prediction:\nPam Beesly is a fictional character on the U.S. television sitcom The Office, played by Jenna Fischer. In season 5, Jim and Roy run into each other at a bar and Roy learns that Jim and Pam are engaged. In season 5 episode 5, \"Chair Model\", Jim proposes to Pam in the pouring rain at a rest stop.\n\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "Pam Beesly is a fictional character on the U.S. television sitcom The Office, played by Jenna Fischer. [In season 5, Jim and Roy run into each other at a bar and Roy learns that Jim and Pam are engaged.] In season 5 episode 5, \"Chair Model\", Jim proposes to Pam in the pouring rain at a rest stop.\n\nExplanation:\n1. The information about Jim and Roy running into each other at a bar and Roy learning about Jim and Pam's engagement is irrelevant to the question about when Jim and Pam first kissed in the series. Therefore, it should be marked as \"Irrelevant\"."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. Pam Beesly is a fictional character on the U.S. television sitcom The Office, played by Jenna Fischer.\nS2. In season 5, Jim and Roy run into each other at a bar and Roy learns that Jim and Pam are engaged.\nS3. In season 5 episode 5, \"Chair Model\", Jim proposes to Pam in the pouring rain at a rest stop.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation:\nAll the facts presented in the model prediction are consistent with the information provided in the passages. There are no factual inconsistencies or unverifiable facts in the model prediction."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 4, sentence 9 [Missing Answer]\n2. Passage 5, sentence 6 [Missing Answer]\n\nExplanation:\n1. The model prediction does not mention the first time Jim and Pam kissed, which occurred in the episode \"Casino Night\" as stated in Passage 4, sentence 9. This is a missing answer.\n2. The model prediction also does not mention the second time Jim and Pam kissed, which is revealed in the episode \"Fun Run\" as stated in Passage 5, sentence 6. This is another missing answer."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "Pam Beesly is a fictional character on the U.S. television sitcom The Office, played by Jenna Fischer. In the episode \"Casino Night\", Jim tells Pam that he is in love with her and they share a kiss. Later, in the season 4 premiere \"Fun Run\", Jim and Pam confess that they have started dating after the camera crew catches them kissing."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 103, "end": 201}, {"error type": "Irrelevant", "explanation": "", "start": 202, "end": 296}], "missing-info": [{"error type": "Missing-Minor-Auxiliary", "passage_id": 3, "sentence_id": [4]}, {"error type": "Missing-Minor-Auxiliary", "passage_id": 4, "sentence_id": [2]}, {"error type": "Missing-Answer", "passage_id": 4, "sentence_id": [9]}, {"error type": "Missing-Minor-Auxiliary", "passage_id": 5, "sentence_id": [6]}, {"error type": "Missing-Minor-Auxiliary", "passage_id": 6, "sentence_id": [3]}, {"error type": "Missing-Minor-Auxiliary", "passage_id": 6, "sentence_id": [6]}, {"error type": "Missing-Minor-Auxiliary", "passage_id": 5, "sentence_id": [2]}], "corrected-prediction": "Pam Beesly is a fictional character on the U.S. television sitcom The Office, played by Jenna Fischer. Her character shares a romantic interest with Jim Halpert, whom she begins dating in the fourth season. In \"Casino Night\", Jim and Pam kiss after Jim tells Pam that he is in love with her. In \"Fun Run\",premiered on September 27, 2007,  it is revealed that Jim and Pam are dating.  The office ultimately learns of their relationship in Dunder Mifflin Infinity, which aired on October 4, 2007.\n"}}, {"question": "Who sings do you think im a nasty girl?", "passages": [["Nasty Girl (Vanity 6 song)", "Nasty Girl (Vanity 6 song)\n\n\"Nasty Girl\" is a song written and composed by American musician Prince.", "The song was first recorded by his prot\u00e9g\u00e9 girl group Vanity 6 in 1982, who charted at number one on the US Hot Dance Club Play chart with their version.", "Prince gave the songwriting credit to lead singer Vanity, although he was the writer and composer.", "Inaya Day recorded a hit cover version of the song in 2004 that reached number 9 in the UK Singles Chart.", "There have also been several other versions of this song.", "\"Nasty Girl\" was originally recorded by Vanity 6 on the Warner Bros. Records label for their self-titled debut studio album \"Vanity 6\".", "The song was produced by Prince and issued as the album's second single on September 24, 1982.", "Due to its explicit lyrics, \"Nasty Girl\" met with resistance on mainstream American radio, peaking within the US Bubbling Under Hot 100 Singles chart.", "It did, however, become a sizable hit on US R&B radio and it hit number one on the US Hot Dance Club Play chart for four weeks in November 1982.", "The song was knocked off the number one position by Prince's own \"1999.\""], ["Nasty Girl (Nitty song)", "Nasty Girl (Nitty song)\n\n\"Nasty Girl\" is a hip hop song by American rapper Nitty.", "It is the third track on his album \"Player's Paradise\".", "It reached number one in Australia.", "There are four verses, including three similar verses and a different final verse.", "The chorus of the song is an interpolation of the 1969 hit song \"Sugar, Sugar\" by The Archies.", "The music video features Nitty driving his red Cadillac convertible to a gas station.", "Here, two girls fill his car while Nitty begins to sing.", "In the 2008 film, \"Sex Drive\", the song can be heard when Ian, played by Josh Zuckerman, find outs that Ms. Tasty, played by Katrina Bowden, \"wants the D\"."], ["Nitty (musician)", "Nitty (musician)\n\nFrank Ross (born December 23, 1977), better known by stage name Nitty, is an American hip hop recording artist from The Bronx, New York.", "He is perhaps best known for his debut single \"Nasty Girl\" and his pop rap style of hip hop, which he calls \"playboy rap\".", "His singles include \"Nasty Girl\" and \"Hey Bitty,\" the former reaching #1 in sales in the United States in October 2004, and also debuting at #1 in Australia in 2005.", "The following album, \"Player's Paradise\", was released in 2005.", "In an interview with the former Australian music television show \"So Fresh\", Nitty explained that he did not want to jump into rap as a mean, edgy type of rapper that is the current trend, but more of a nice-guy rapper, with lighthearted songs and videos.", "He calls this style \"playboy rap.\"", "Since \"Player's Paradise\" Nitty has gone on to continue his career as a producer.", "He is currently an independent artist.", "In the recent film \"Sex Drive\", his song \"Nasty Girl\" was on the soundtrack."]], "gold": "There are several \"Nasty Girl\" songs. One \"Nasty Girl\" is a song written and composed by American musician Prince. The song was first recorded by his prot\u00e9g\u00e9 girl group Vanity 6 in 1982, who charted at number one on the US Hot Dance Club Play chart with their version. One \"Nasty Girl\" is a song by American rapper Nitty which was the third track on his second studio album, Player's Paradise (2005), on August 30, 2004. Another \"Nasty Girl\" is a song by rapper The Notorious B.I.G. that was released in 2005 in the US and on January 16, 2006 in the UK. Another \"Nasty Girl\" is a song by American recording group Destiny's Child from their third studio album, Survivor.", "prediction 1": "\"Nasty Girl\" is a song written and composed by American musician Prince. The song was first recorded by his prot\u00e9g\u00e9 girl group Vanity 6 in 1982, who charted at number one on the US Hot Dance Club Play chart with their version. Nasty Girl is also a hip hop song by American rapper Nitty. It is the third track on his album Player's Paradise. There are four verses, including three similar verses and a different final verse. In the 2008 film, Sex Drive, the song can be heard when Ian, played by Josh Zuckerman, finds out that Ms. Tasty, played by Katrina Bowden, \"wants the D\".", "prediction 2": "\"Nasty Girl\" is a song written and composed by American musician Prince that was first recorded by his prot\u00e9g\u00e9 girl group Vanity 6 in 1982, who charted at number one on the US Hot Dance Club Play chart with their version. Nasty Girl is also a hip hop song by American rapper Nitty. It is the third track on his album Player's Paradise, and reached number one in Australia. In the 2008 film, Sex Drive, the song can be heard when Ian, played by Josh Zuckerman, finds out that Ms. Tasty, played by Katrina Bowden, wants the D.", "prediction 3": "\"Nasty Girl\" is a song written and composed by American musician Prince. The song was first recorded by his prot\u00e9g\u00e9 girl group Vanity 6 in 1982, who charted at number one on the US Hot Dance Club Play chart with their version. \"Nasty Girl\" is also a hip hop song by American rapper Nitty. It is the third track on his album Player's Paradise and reached number one in Australia. In the 2008 film, \"Sex Drive\", the song can be heard when Ian, played by Josh Zuckerman, finds out that Ms. Tasty, played by Katrina Bowden, wants the D.", "prediction 4": "\"Nasty Girl\" is a song by American hip hop recording artist Nitty. It is the third track on his album Player's Paradise. \"Nasty Girl\" is also a song by his prot\u00e9g\u00e9 girl group Vanity 6. Inaya Day recorded a hit cover version of the song in 2004 that reached number 9 in the UK Singles Chart. In the 2008 film, \"Sex Drive\", the song can be heard when Ian, played by Josh Zuckerman, finds outs that Ms. Tasty, played by Katrina Bowden, \"wants the D.\"", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 341, "end": 423}, {"error type": "Irrelevant", "explanation": "", "start": 424, "end": 577}], "missing-info": [], "corrected-prediction": "\"Nasty Girl\" is a song written and composed by American musician Prince. The song was first recorded by his prot\u00e9g\u00e9 girl group Vanity 6 in 1982, who charted at number one on the US Hot Dance Club Play chart with their version. Nasty Girl is also a hip hop song by American rapper Nitty. It is the third track on his album Player's Paradise."}, "preference": [0, 0, 1, 0, 1, 1], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Nasty Girl (Vanity 6 song)\nS1. Nasty Girl (Vanity 6 song)  \"Nasty Girl\" is a song written and composed by American musician Prince.\nS2. The song was first recorded by his prot\u00e9g\u00e9 girl group Vanity 6 in 1982, who charted at number one on the US Hot Dance Club Play chart with their version.\nS3. Prince gave the songwriting credit to lead singer Vanity, although he was the writer and composer.\nS4. Inaya Day recorded a hit cover version of the song in 2004 that reached number 9 in the UK Singles Chart.\nS5. There have also been several other versions of this song.\nS6. \"Nasty Girl\" was originally recorded by Vanity 6 on the Warner Bros. Records label for their self-titled debut studio album \"Vanity 6\".\nS7. The song was produced by Prince and issued as the album's second single on September 24, 1982.\nS8. Due to its explicit lyrics, \"Nasty Girl\" met with resistance on mainstream American radio, peaking within the US Bubbling Under Hot 100 Singles chart.\nS9. It did, however, become a sizable hit on US R&B radio and it hit number one on the US Hot Dance Club Play chart for four weeks in November 1982.\nS10. The song was knocked off the number one position by Prince's own \"1999.\"\n\nPassage 2: Title (S0) - Nasty Girl (Nitty song)\nS1. Nasty Girl (Nitty song)  \"Nasty Girl\" is a hip hop song by American rapper Nitty.\nS2. It is the third track on his album \"Player's Paradise\".\nS3. It reached number one in Australia.\nS4. There are four verses, including three similar verses and a different final verse.\nS5. The chorus of the song is an interpolation of the 1969 hit song \"Sugar, Sugar\" by The Archies.\nS6. The music video features Nitty driving his red Cadillac convertible to a gas station.\nS7. Here, two girls fill his car while Nitty begins to sing.\nS8. In the 2008 film, \"Sex Drive\", the song can be heard when Ian, played by Josh Zuckerman, find outs that Ms. Tasty, played by Katrina Bowden, \"wants the D\".\n\nPassage 3: Title (S0) - Nitty (musician)\nS1. Nitty (musician)  Frank Ross (born December 23, 1977), better known by stage name Nitty, is an American hip hop recording artist from The Bronx, New York.\nS2. He is perhaps best known for his debut single \"Nasty Girl\" and his pop rap style of hip hop, which he calls \"playboy rap\".\nS3. His singles include \"Nasty Girl\" and \"Hey Bitty,\" the former reaching #1 in sales in the United States in October 2004, and also debuting at #1 in Australia in 2005.\nS4. The following album, \"Player's Paradise\", was released in 2005.\nS5. In an interview with the former Australian music television show \"So Fresh\", Nitty explained that he did not want to jump into rap as a mean, edgy type of rapper that is the current trend, but more of a nice-guy rapper, with lighthearted songs and videos.\nS6. He calls this style \"playboy rap.\"\nS7. Since \"Player's Paradise\" Nitty has gone on to continue his career as a producer.\nS8. He is currently an independent artist.\nS9. In the recent film \"Sex Drive\", his song \"Nasty Girl\" was on the soundtrack.\n    \nInput Question:\nWho sings do you think im a nasty girl?\n\nCorrect Response:\nThere are several \"Nasty Girl\" songs. One \"Nasty Girl\" is a song written and composed by American musician Prince. The song was first recorded by his prot\u00e9g\u00e9 girl group Vanity 6 in 1982, who charted at number one on the US Hot Dance Club Play chart with their version. One \"Nasty Girl\" is a song by American rapper Nitty which was the third track on his second studio album, Player's Paradise (2005), on August 30, 2004. Another \"Nasty Girl\" is a song by rapper The Notorious B.I.G. that was released in 2005 in the US and on January 16, 2006 in the UK. Another \"Nasty Girl\" is a song by American recording group Destiny's Child from their third studio album, Survivor.\n\nModel Prediction:\n\"Nasty Girl\" is a song written and composed by American musician Prince. The song was first recorded by his prot\u00e9g\u00e9 girl group Vanity 6 in 1982, who charted at number one on the US Hot Dance Club Play chart with their version. Nasty Girl is also a hip hop song by American rapper Nitty. It is the third track on his album Player's Paradise. There are four verses, including three similar verses and a different final verse. In the 2008 film, Sex Drive, the song can be heard when Ian, played by Josh Zuckerman, finds out that Ms. Tasty, played by Katrina Bowden, \"wants the D\".\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "\"Nasty Girl\" is a song written and composed by American musician Prince. The song was first recorded by his prot\u00e9g\u00e9 girl group Vanity 6 in 1982, who charted at number one on the US Hot Dance Club Play chart with their version. Nasty Girl is also a hip hop song by American rapper Nitty. It is the third track on his album Player's Paradise. [There are four verses, including three similar verses and a different final verse.] [In the 2008 film, Sex Drive, the song can be heard when Ian, played by Josh Zuckerman, finds out that Ms. Tasty, played by Katrina Bowden, \"wants the D\".]\n\nExplanation:\n1. The information about the structure of the song (i.e., \"There are four verses, including three similar verses and a different final verse.\") is irrelevant to the question asked.\n2. The information about the song being featured in the film \"Sex Drive\" is also irrelevant to the question asked. The question is about who sings the song, not where it has been featured."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. \"Nasty Girl\" is a song written and composed by American musician Prince.\nS2. The song was first recorded by his prot\u00e9g\u00e9 girl group Vanity 6 in 1982, who charted at number one on the US Hot Dance Club Play chart with their version.\nS3. Nasty Girl is also a hip hop song by American rapper Nitty.\nS4. It is the third track on his album Player's Paradise.\nS5. There are four verses, including three similar verses and a different final verse.\nS6. In the 2008 film, Sex Drive, the song can be heard when Ian, played by Josh Zuckerman, finds out that Ms. Tasty, played by Katrina Bowden, \"wants the D\".\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation:\nAll the facts presented in the model prediction are consistent with the information provided in the passages. There are no factual inconsistencies or unverifiable facts in the model prediction."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "None\n\nExplanation:\nThe model prediction includes all the relevant information from the passages. There is no missing information in the model prediction."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "\"Nasty Girl\" is a song written and composed by American musician Prince. The song was first recorded by his prot\u00e9g\u00e9 girl group Vanity 6 in 1982, who charted at number one on the US Hot Dance Club Play chart with their version. Nasty Girl is also a hip hop song by American rapper Nitty. It is the third track on his album Player's Paradise."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 341, "end": 423}, {"error type": "Irrelevant", "explanation": "", "start": 424, "end": 577}], "missing-info": [{"error type": "Missing-Minor-Auxiliary", "passage_id": 3, "sentence_id": [4]}], "corrected-prediction": "\"Nasty Girl\" is a song written and composed by American musician Prince. The song was first recorded by his prot\u00e9g\u00e9 girl group Vanity 6 in 1982, who charted at number one on the US Hot Dance Club Play chart with their version. Nasty Girl is also a hip hop song by American rapper Nitty. It is the third track on his album Player's Paradise (2005). "}}, {"question": "The un recognises how many regions in asia?", "passages": [["United Nations Regional Groups", "United Nations Regional Groups\n\nThe United Nations Regional Groups are the geopolitical regional groups of member states of the United Nations.", "Originally, UN member states were unofficially grouped into five geopolitical regional groups.", "What began as an informal means of sharing the distribution of posts for General Assembly committees has taken on a much more expansive role.", "Depending on the UN context, regional groups control elections to UN-related positions, on the basis of geographic representation, as well as coordinate substantive policy, and form common fronts for negotiations and voting.", "The groupings have changed over time.", "From the founding of the United Nations until 1966, the regional groups were: British Commonwealth, Eastern Europe and Asia, Latin America, Middle East and Western Europe.", "In 1966, in response to changes in the UN's membership, decolonisation and strategic realignment, the groups were reorganised as: Asia, Eastern Europe, Africa, Latin America and Caribbean, and Western Europe and Others.", "In 2011, the Asia Group was renamed Asia-Pacific.", "As of May 2014, 192 of the 193 UN member states are divided into five regional groups:\n\n\nKiribati is not included in any of the above-mentioned regional groups (see below for more details)."], ["United Nations Regional Groups", "In the rotation of the post of the President of the United Nations General Assembly, the group is eligible for having its nationals elected to this post in years ending with 4 and 9; most recently, Sam Kutesa of Uganda was elected to this position in 2014.", "Member states of the African Group, as of July 2011:\n\nThe Asia-Pacific Group (formerly the Asian Group) has 53 members (27.5% of all UN members) and is the second largest regional group by number of member states (one fewer than the African Group).", "Its territory is composed of much of the continents of Asia and Oceania.", "However, Russia and the Caucasian states are members of the Eastern European Group and Australia, New Zealand, Israel, and Turkey are all members of the Western European and Others Group.", "The Asia-Pacific Group has three seats on the Security Council:", "China's permanent seat, and two non-permanent seats.", "The Group also has 11 seats on the United Nations Economic and Social Council and 13 seats on the United Nations Human Rights Council.", "In the rotation of the post of the President of the United Nations General Assembly, the group is eligible for having its nationals elected to this post in years ending with 1 and 6; most recently, Peter Thomson of Fiji was elected to this position in 2016."], ["United Nations Economic and Social Commission for Asia and the Pacific", "United Nations Economic and Social Commission for Asia and the Pacific\n\nThe Economic and Social Commission for Asia and the Pacific (UNESCAP or ESCAP), located in the United Nations Building in Rajadamnern Nok Avenue in Bangkok, Thailand, is one of the five regional commissions of the United Nations Economic and Social Council, under the administrative direction of the United Nations headquarters.", "It was established in 1947 (then as the UN Economic Commission for Asia and the Far East, ECAFE) to encourage economic cooperation among its member states.", "The name was changed to the current in 1974.", "ESCAP has 53 member States and nine Associate members, home to more than two-third of the world population.", "As well as countries in Asia and the Pacific, it includes France, the Netherlands, the United Kingdom and the United States.", "ESCAP's regional focus is managing globalization through programs in environmentally sustainable development, trade, and human rights.", "ESCAP is headed by Executive Secretary Armida Alisjahbana of Indonesia, who succeeded Shamshad Akhtar of Pakistan in September 2018.", "ESCAP works to overcome some of the region's greatest challenges by providing results oriented projects, technical assistance and capacity building to member States in the following areas:"]], "gold": "The United Nations Regional Groups are the geopolitical regional groups of member states of the United Nations, which were originally unofficially grouped into five geopolitical regional groups. The UN identifies 1 regional group in Asia and recognizes 53 member states in Asia and the Pacific Group. It is the second largest regional group by number of member states after the African Group. Its territory is composed of much of the continents of Asia and Oceania with the exception of a few countries.", "prediction 1": "The United Nations recognises the number of regions in Asia. Originally, UN member states were unofficially grouped into five geopolitical regional groups. Then, in 1966, in response to changes in the UN's membership, decolonisation and strategic realignment, the groups were reorganised as: Asia, Eastern Europe, Africa, Latin America and Caribbean, and Western Europe and Others. In 2011, the Asia Group was renamed Asia-Pacific. As of May 2014, 192 of the 193 UN member states are divided into five regional groups.", "prediction 2": "There are currently 192 UN member states divided into five geopolitical regional groups of member states of the United Nations. In the past, the United Nations recognised five Asia-Pacific regions. As of May 2014, 192 of the 193 UN member states are divided into five regional groups. The United Nations Economic and Social Commission for Asia and the Pacific (UNESCAP), located in the United Nations Building in Rajadamnern Nok Avenue in Bangkok, Thailand, is one of the five regional commissions of the United Nations Economic and Social Council, under the administrative direction of the United Nations headquarters. The Asia was established in 1947.", "prediction 3": "The United Nations recognises several regions in Asia. The first was the Asia-Pacific region, established in 1947, the second was the Asia-Pacific region, located in the United Nations Building in Rajadamnern Nok Avenue in Bangkok, Thailand. The third is the Asian Economic and Social Commission, which was established in 1991, with six more regions to be added later.", "prediction 4": "The United Nations recognises five regional groups in Asia. As of May 2014, 192 of the 193 UN member states are divided into five regional groups. The ASEAN countries are currently divided into five regional groups. The Asia-Pacific region has 53 members. The United Nations Economic and Social Commission for Asia and the Pacific (UNESCAP), located in the United Nations Building in Rajadamnern Nok Avenue in Bangkok, Thailand, is one of the five regional commissions of the United Nations Economic and Social Council, under the administrative direction of United Nations headquarters.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 432, "end": 518}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 2, "sentence_id": [2]}], "corrected-prediction": "The United Nations recognises one regional group in Asia, known as the Asia-Pacific Group. Originally, UN member states were unofficially grouped into five geopolitical regional groups. Then, in 1966, in response to changes in the UN's membership, decolonisation and strategic realignment, the groups were reorganised and the Asia Group was formed. In 2011, the Asia Group was renamed Asia-Pacific. The Asia-Pacific Group has 53 member states and its territory is composed of much of the continents of Asia and Oceania."}, "preference": [1, 1, 1, 2, 0, 1], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - United Nations Regional Groups\nS1. United Nations Regional Groups  The United Nations Regional Groups are the geopolitical regional groups of member states of the United Nations.\nS2. Originally, UN member states were unofficially grouped into five geopolitical regional groups.\nS3. What began as an informal means of sharing the distribution of posts for General Assembly committees has taken on a much more expansive role.\nS4. Depending on the UN context, regional groups control elections to UN-related positions, on the basis of geographic representation, as well as coordinate substantive policy, and form common fronts for negotiations and voting.\nS5. The groupings have changed over time.\nS6. From the founding of the United Nations until 1966, the regional groups were: British Commonwealth, Eastern Europe and Asia, Latin America, Middle East and Western Europe.\nS7. In 1966, in response to changes in the UN's membership, decolonisation and strategic realignment, the groups were reorganised as: Asia, Eastern Europe, Africa, Latin America and Caribbean, and Western Europe and Others.\nS8. In 2011, the Asia Group was renamed Asia-Pacific.\nS9. As of May 2014, 192 of the 193 UN member states are divided into five regional groups:   Kiribati is not included in any of the above-mentioned regional groups (see below for more details).\n\nPassage 2: Title (S0) - United Nations Regional Groups\nS1. In the rotation of the post of the President of the United Nations General Assembly, the group is eligible for having its nationals elected to this post in years ending with 4 and 9; most recently, Sam Kutesa of Uganda was elected to this position in 2014.\nS2. Member states of the African Group, as of July 2011:  The Asia-Pacific Group (formerly the Asian Group) has 53 members (27.5% of all UN members) and is the second largest regional group by number of member states (one fewer than the African Group).\nS3. Its territory is composed of much of the continents of Asia and Oceania.\nS4. However, Russia and the Caucasian states are members of the Eastern European Group and Australia, New Zealand, Israel, and Turkey are all members of the Western European and Others Group.\nS5. The Asia-Pacific Group has three seats on the Security Council:\nS6. China's permanent seat, and two non-permanent seats.\nS7. The Group also has 11 seats on the United Nations Economic and Social Council and 13 seats on the United Nations Human Rights Council.\nS8. In the rotation of the post of the President of the United Nations General Assembly, the group is eligible for having its nationals elected to this post in years ending with 1 and 6; most recently, Peter Thomson of Fiji was elected to this position in 2016.\n\nPassage 3: Title (S0) - United Nations Economic and Social Commission for Asia and the Pacific\nS1. United Nations Economic and Social Commission for Asia and the Pacific  The Economic and Social Commission for Asia and the Pacific (UNESCAP or ESCAP), located in the United Nations Building in Rajadamnern Nok Avenue in Bangkok, Thailand, is one of the five regional commissions of the United Nations Economic and Social Council, under the administrative direction of the United Nations headquarters.\nS2. It was established in 1947 (then as the UN Economic Commission for Asia and the Far East, ECAFE) to encourage economic cooperation among its member states.\nS3. The name was changed to the current in 1974.\nS4. ESCAP has 53 member States and nine Associate members, home to more than two-third of the world population.\nS5. As well as countries in Asia and the Pacific, it includes France, the Netherlands, the United Kingdom and the United States.\nS6. ESCAP's regional focus is managing globalization through programs in environmentally sustainable development, trade, and human rights.\nS7. ESCAP is headed by Executive Secretary Armida Alisjahbana of Indonesia, who succeeded Shamshad Akhtar of Pakistan in September 2018.\nS8. ESCAP works to overcome some of the region's greatest challenges by providing results oriented projects, technical assistance and capacity building to member States in the following areas:\n    \nInput Question:\nThe un recognises how many regions in asia?\n\nCorrect Response:\nThe United Nations Regional Groups are the geopolitical regional groups of member states of the United Nations, which were originally unofficially grouped into five geopolitical regional groups. The UN identifies 1 regional group in Asia and recognizes 53 member states in Asia and the Pacific Group. It is the second largest regional group by number of member states after the African Group. Its territory is composed of much of the continents of Asia and Oceania with the exception of a few countries.\n\nModel Prediction:\nThe United Nations recognises the number of regions in Asia. Originally, UN member states were unofficially grouped into five geopolitical regional groups. Then, in 1966, in response to changes in the UN's membership, decolonisation and strategic realignment, the groups were reorganised as: Asia, Eastern Europe, Africa, Latin America and Caribbean, and Western Europe and Others. In 2011, the Asia Group was renamed Asia-Pacific. As of May 2014, 192 of the 193 UN member states are divided into five regional groups.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "The United Nations recognises the number of regions in Asia. Originally, UN member states were unofficially grouped into five geopolitical regional groups. Then, in 1966, in response to changes in the UN's membership, decolonisation and strategic realignment, the groups were reorganised as: Asia, Eastern Europe, Africa, Latin America and Caribbean, and Western Europe and Others. In 2011, the Asia Group was renamed Asia-Pacific. [As of May 2014, 192 of the 193 UN member states are divided into five regional groups.]\n\nExplanation:\nThe last sentence in the model prediction is irrelevant to the question as it does not provide any information about the number of regions in Asia recognized by the UN. It instead talks about the division of UN member states into regional groups."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The United Nations recognises the number of regions in Asia.\nS2. Originally, UN member states were unofficially grouped into five geopolitical regional groups.\nS3. Then, in 1966, in response to changes in the UN's membership, decolonisation and strategic realignment, the groups were reorganised as: Asia, Eastern Europe, Africa, Latin America and Caribbean, and Western Europe and Others.\nS4. In 2011, the Asia Group was renamed Asia-Pacific.\nS5. As of May 2014, 192 of the 193 UN member states are divided into five regional groups.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation:\nAll the facts presented in the model prediction are consistent with the information provided in the passages and can be verified. Therefore, there are no spans that contain inconsistent or unverifiable facts."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 2, sentence 2 [Missing Answer]\n2. Passage 2, sentence 3 [Missing Major Auxiliary Information]\n\nExplanation:\n1. The model prediction does not mention the specific number of member states in the Asia-Pacific Group, which is a direct answer to the question. This information can be found in Passage 2, sentence 2.\n2. The model prediction also misses the information about the territory of the Asia-Pacific Group, which is a crucial auxiliary information for understanding the answer. This information can be found in Passage 2, sentence 3."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The United Nations recognises one regional group in Asia, known as the Asia-Pacific Group. Originally, UN member states were unofficially grouped into five geopolitical regional groups. Then, in 1966, in response to changes in the UN's membership, decolonisation and strategic realignment, the groups were reorganised and the Asia Group was formed. In 2011, the Asia Group was renamed Asia-Pacific. The Asia-Pacific Group has 53 member states and its territory is composed of much of the continents of Asia and Oceania."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 61, "end": 155}, {"error type": "Irrelevant", "explanation": "", "start": 156, "end": 381}, {"error type": "Irrelevant", "explanation": "", "start": 382, "end": 518}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [1, 2]}, {"error type": "Missing-Answer", "passage_id": 2, "sentence_id": [2]}, {"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [3]}], "corrected-prediction": "The United Nations Regional Groups are the geopolitical regional groups of member states of the United Nations, which were originally unofficially grouped into five geopolitical regional groups. The United Nations recognizes the Asian region as being made of 53 members, and it is the second largest regional group by number of member states after the African Group.  Its territory is composed of much of the continents of Asia and Oceania."}}, {"question": "When is it mothering sunday in the uk?", "passages": [["Mothering Sunday", "Mothering Sunday\n\nMothering Sunday is a holiday celebrated by Catholic and Protestant Christians in the UK and some other parts of the world.", "It is generally observed in parishes of the Church of England, as well as in the rest of the UK and many Anglican parishes throughout the world, especially in Canada and Australia.", "It falls on the fourth Sunday in Lent, exactly three weeks before Easter Day.", "Once observed as a day on which people would visit their \"mother\" church, it has become an occasion for honouring the mothers of children and giving them presents.", "It is increasingly being called Mother's Day, although that name properly belongs to the American holiday which is quite distinct from the original Mothering Sunday.", "In the UK and the Republic of Ireland, Mothering Sunday is celebrated in a similar way as Mother's Day is celebrated in the USA.", "During the 16th century, people returned to their mother church for a service to be held on Laetare Sunday; in this context, one's 'mother church' was either the church where one was baptised, or the local parish church, or the nearest cathedral (the latter being the mother church of all the parish churches in a diocese).", "Anyone who did this was commonly said to have gone \"a-mothering\", although whether this term preceded the observance of Mothering Sunday is unclear."], ["Mother's Day", "The United Kingdom celebrates Mothering Sunday, which falls on the fourth Sunday of Lent (26 March in 2017).", "This holiday has its roots in the church and was originally unrelated to the American holiday.", "Most historians believe that Mothering Sunday evolved from the 16th-century Christian practice of visiting one's mother church annually on Laetare Sunday.", "As a result of this tradition, most mothers were reunited with their children on this day when young apprentices and young women in service were released by their masters for that weekend.", "As a result of the influence of the American Mother's Day, Mothering Sunday transformed into the tradition of showing appreciation to one's mother.", "The holiday is still recognized in the original historical sense by many churches, with attention paid to Mary the mother of Jesus Christ and the concept of the Mother Church.", "The custom was still popular by the start of the 19th century, but with the Industrial Revolution, traditions changed and the Mothering Day customs declined.", "By 1935, Mothering Sunday was less celebrated in Europe.", "Constance Penswick-Smith worked unsuccessfully to revive the festival in the 1910s\u20131920s.", "However, US World War II soldiers brought the US Mother's Day celebration to the UK, and the holiday was merged with the Mothering Sunday traditions still celebrated in the Church of England."]], "gold": "Mothering Sunday is a day honoring mothers and mother churches, celebrated in the United Kingdom and Ireland, and elsewhere in the English-speaking world on the fourth Sunday in Lent since the Middle Ages. In 2015, Mothering Sunday in the UK was on 15 March. In 2016, Mothering Sunday in the UK was on 6 March, and in 2017, it was on 26 March.", "prediction 1": "The United Kingdom celebrates Mothering Sunday, which falls on the fourth Sunday of Lent, exactly three weeks before Easter Day. Mothering Sunday is a holiday celebrated by Catholic and Protestant Christians in the UK and some other parts of the world. It is generally observed in parishes of the Church of England, as well as in the rest of the UK and in many Anglican parishes throughout the world, especially in Canada and Australia.", "prediction 2": "Mothering Sunday is a holiday celebrated by Catholic and Protestant Christians in the United Kingdom and some other parts of the world. It is generally observed in parishes of the Church of England, as well as in the rest of the UK and many Anglican parishes throughout the world, especially in Canada and Australia. The United Kingdom celebrates Mothering Sunday, which falls on the fourth Sunday of Lent, exactly three weeks before Easter Day.", "prediction 3": "Mothering Sunday is a holiday celebrated by Catholic and Protestant Christians in the UK and some other parts of the world. It is generally observed in parishes of the Church of England, as well as in the rest of the UK and many Anglican parishes throughout the world, especially in Canada and Australia. Once observed as a day on which people would visit their \"mother\" church, it has become an occasion for honouring the mothers of children and giving them presents. In the UK and the Republic of Ireland, Mothering Sunday is celebrated in a similar way as Mother's Day is celebrated in the United States.", "prediction 4": "The United Kingdom celebrates Mothering Sunday, which falls on the fourth Sunday of Lent, exactly three weeks before Easter Day. There are many parishes of the Church of England which observe the holiday. In the Church of England, the fourth Sunday in Lent, is observed as Mothering Sunday, and in many Anglican parishes throughout the world it is observed on the third Sunday of Lent, the fifth Sunday of Lent.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 129, "end": 436}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 1, "sentence_id": [3]}], "corrected-prediction": "The United Kingdom celebrates Mothering Sunday, which falls on the fourth Sunday of Lent, exactly three weeks before Easter Day. In 2015, Mothering Sunday in the UK was on 15 March. In 2016, it was on 6 March, and in 2017, it was on 26 March."}, "preference": [0, 1, 1, 1, 1, 1], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Mothering Sunday\nS1. Mothering Sunday  Mothering Sunday is a holiday celebrated by Catholic and Protestant Christians in the UK and some other parts of the world.\nS2. It is generally observed in parishes of the Church of England, as well as in the rest of the UK and many Anglican parishes throughout the world, especially in Canada and Australia.\nS3. It falls on the fourth Sunday in Lent, exactly three weeks before Easter Day.\nS4. Once observed as a day on which people would visit their \"mother\" church, it has become an occasion for honouring the mothers of children and giving them presents.\nS5. It is increasingly being called Mother's Day, although that name properly belongs to the American holiday which is quite distinct from the original Mothering Sunday.\nS6. In the UK and the Republic of Ireland, Mothering Sunday is celebrated in a similar way as Mother's Day is celebrated in the USA.\nS7. During the 16th century, people returned to their mother church for a service to be held on Laetare Sunday; in this context, one's 'mother church' was either the church where one was baptised, or the local parish church, or the nearest cathedral (the latter being the mother church of all the parish churches in a diocese).\nS8. Anyone who did this was commonly said to have gone \"a-mothering\", although whether this term preceded the observance of Mothering Sunday is unclear.\n\nPassage 2: Title (S0) - Mother's Day\nS1. The United Kingdom celebrates Mothering Sunday, which falls on the fourth Sunday of Lent (26 March in 2017).\nS2. This holiday has its roots in the church and was originally unrelated to the American holiday.\nS3. Most historians believe that Mothering Sunday evolved from the 16th-century Christian practice of visiting one's mother church annually on Laetare Sunday.\nS4. As a result of this tradition, most mothers were reunited with their children on this day when young apprentices and young women in service were released by their masters for that weekend.\nS5. As a result of the influence of the American Mother's Day, Mothering Sunday transformed into the tradition of showing appreciation to one's mother.\nS6. The holiday is still recognized in the original historical sense by many churches, with attention paid to Mary the mother of Jesus Christ and the concept of the Mother Church.\nS7. The custom was still popular by the start of the 19th century, but with the Industrial Revolution, traditions changed and the Mothering Day customs declined.\nS8. By 1935, Mothering Sunday was less celebrated in Europe.\nS9. Constance Penswick-Smith worked unsuccessfully to revive the festival in the 1910s\u20131920s.\nS10. However, US World War II soldiers brought the US Mother's Day celebration to the UK, and the holiday was merged with the Mothering Sunday traditions still celebrated in the Church of England.\n    \nInput Question:\nWhen is it mothering sunday in the uk?\n\nCorrect Response:\nMothering Sunday is a day honoring mothers and mother churches, celebrated in the United Kingdom and Ireland, and elsewhere in the English-speaking world on the fourth Sunday in Lent since the Middle Ages. In 2015, Mothering Sunday in the UK was on 15 March. In 2016, Mothering Sunday in the UK was on 6 March, and in 2017, it was on 26 March.\n\nModel Prediction:\nThe United Kingdom celebrates Mothering Sunday, which falls on the fourth Sunday of Lent, exactly three weeks before Easter Day. Mothering Sunday is a holiday celebrated by Catholic and Protestant Christians in the UK and some other parts of the world. It is generally observed in parishes of the Church of England, as well as in the rest of the UK and in many Anglican parishes throughout the world, especially in Canada and Australia.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "The United Kingdom celebrates Mothering Sunday, which falls on the fourth Sunday of Lent, exactly three weeks before Easter Day. [Mothering Sunday is a holiday celebrated by Catholic and Protestant Christians in the UK and some other parts of the world. It is generally observed in parishes of the Church of England, as well as in the rest of the UK and in many Anglican parishes throughout the world, especially in Canada and Australia.]\n\nExplanation:\nThe second and third sentences in the model prediction are neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, they should be marked as \"Irrelevant\"."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The United Kingdom celebrates Mothering Sunday, which falls on the fourth Sunday of Lent, exactly three weeks before Easter Day.\nS2. Mothering Sunday is a holiday celebrated by Catholic and Protestant Christians in the UK and some other parts of the world.\nS3. It is generally observed in parishes of the Church of England, as well as in the rest of the UK and in many Anglican parishes throughout the world, especially in Canada and Australia.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation:\nAll the facts in the model prediction are consistent with the passages and can be verified."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 3 [Missing Answer]\n\nExplanation:\nThe model prediction does not provide the specific dates of Mothering Sunday in the UK for the years 2015, 2016, and 2017 which are part of the answer to the question."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The United Kingdom celebrates Mothering Sunday, which falls on the fourth Sunday of Lent, exactly three weeks before Easter Day. In 2015, Mothering Sunday in the UK was on 15 March. In 2016, it was on 6 March, and in 2017, it was on 26 March."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 90, "end": 128}, {"error type": "Irrelevant", "explanation": "", "start": 170, "end": 207}, {"error type": "Irrelevant", "explanation": "", "start": 253, "end": 436}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 2, "sentence_id": [1]}], "corrected-prediction": "The United Kingdom celebrates Mothering Sunday, which falls on the fourth Sunday of Lent. Mothering Sunday is a holiday celebrated in the UK and some other parts of the world. It occurred on 26 March in 2017. "}}, {"question": "Based on their shape the bones of the skull can be classified as?", "passages": [["Skull", "Most commonly these are found in the course of the lambdoid suture.", "The human skull is generally considered to consist of twenty-two bones\u2014eight cranial bones and fourteen facial skeleton bones.", "In the neurocranium these are the occipital bone, two temporal bones, two parietal bones, the sphenoid, ethmoid and frontal bones.", "The bones of the facial skeleton(14) are the vomer, two inferior nasal conchae, two nasal bones, two maxilla, the mandible, two palatine bones, two zygomatic bones, and two lacrimal bones.", "Some sources count a paired bone as one, or the maxilla as having two bones (as its parts); some sources include the hyoid bone or the three ossicles of the middle ear but the overall general consensus of the number of bones in the human skull is the stated twenty-two.", "Some of these bones\u2014the occipital, parietal, frontal, in the neurocranium, and the nasal, lacrimal, and vomer, in the facial skeleton are flat bones.", "The skull also contains sinuses, air-filled cavities known as paranasal sinuses, and numerous foramina.", "The sinuses are lined with respiratory epithelium."], ["Irregular bone", "Irregular bone\n\nThe irregular bones are bones which, from their peculiar form, cannot be grouped as long, short, flat or sesamoid bones.", "Irregular bones serve various purposes in the body, such as protection of nervous tissue (such as the vertebrae protect the spinal cord), affording multiple anchor points for skeletal muscle attachment (as with the sacrum), and maintaining pharynx and trachea support, and tongue attachment (such as the hyoid bone).", "They consist of cancellous tissue enclosed within a thin layer of compact bone.", "Irregular bones can also be used for joining all parts of the spinal column together.", "The spine is the place in the human body where the most irregular bones can be found.", "There are, in all, 33 irregular bones found here.", "The irregular bones are: the vertebrae, sacrum, coccyx, temporal, sphenoid, ethmoid, zygomatic, maxilla, mandible, palatine, inferior nasal concha, and hyoid."], ["Skull", "The skull is made up of a number of fused flat bones, and contains many foramina, fossae, processes, and several cavities or sinuses.", "In zoology there are openings in the skull called fenestrae.", "The human skull is the bony structure that forms the head in the human skeleton.", "It supports the structures of the face and forms a cavity for the brain.", "Like the skulls of other vertebrates, it protects the brain from injury.", "The skull consists of two parts, of different embryological origin\u2014the neurocranium and the facial skeleton (also called the \"membraneous viscerocranium\").", "The neurocranium (or \"braincase\") forms the protective cranial cavity that surrounds and houses the brain and brainstem.", "The upper areas of the cranial bones form the calvaria (skullcap).", "The membranous viscerocranium includes the mandible.", "The facial skeleton is formed by the bones supporting the face.", "Except for the mandible, all of the bones of the skull are joined together by sutures\u2014synarthrodial (immovable) joints formed by bony ossification, with Sharpey's fibres permitting some flexibility.", "Sometimes there can be extra bone pieces within the suture known as wormian bones or \"sutural bones\"."]], "gold": "The skull is a bone structure that forms the head in vertebrates and is made up of a number of bones. Some of the bones, the occipital, parietal, frontal, nasal, lacrimal, and vomer bones, are classified as flat bones based on their shape. But other bones in the skull, such as the sphenoid, ethmoid, zygomatic, maxilla, mandible, palatine, and inferior nasal concha are categorized as irregular bones based on their shape. Irregular bones are bones which cannot be grouped as long, short, flat, or sesamoid.", "prediction 1": "The human skull is the bony structure that forms the head in the human skeleton. It supports the structures of the face and forms a cavity for the brain. Based on their shape the bones of the skull can be classified as long, short, flat, sesamoid, irregular, or sesamoid. Irregular bones are bones which, from their peculiar form, cannot be grouped as long, short, flat, or sesamoid bones.", "prediction 2": "The human skull is generally considered to consist of twenty-two bones\u2014eight cranial bones and fourteen facial skeleton bones. The irregular bones are bones which, from their peculiar form, cannot be grouped as long, short, flat or sesamoid bones. Irregular bones serve various purposes in the body, such as protection of nervous tissue, affording multiple anchor points for skeletal muscle attachment, and maintaining pharynx and trachea support, and tongue attachment (such as the hyoid bone). Irregular bones serve various purposes in the body, such as protection of nervous tissue, affording multiple anchor points for skeletal muscle attachment, affording multiple anchor points for skeletal muscle attachment, and maintaining pharynx, and pharynx.", "prediction 3": "The skull is the bony structure that forms the head in the human skeleton. Based on their shape the bones of the skull can be classified as long, short, flat, sesamoid, irregular, and sesamoid. The irregular bones are bones which, from their peculiar form, cannot be grouped as long, short, flat, or sesamoid.", "prediction 4": "The human skull is the bony structure that forms the head in the human skeleton. It supports the structures of the face and forms a cavity for the brain. Based on their shape the bones of the skull can be classified as long, short, flat, sesamoid or irregular. Irregular bones are bones which, from their peculiar form, cannot be grouped as long, short, flat or sesamoid bones.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 219, "end": 270}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 1, "sentence_id": [6]}], "corrected-prediction": "The human skull is the bony structure that forms the head in the human skeleton. It supports the structures of the face and forms a cavity for the brain. Based on their shape, some of the bones of the skull, such as the occipital, parietal, frontal, nasal, lacrimal, and vomer bones, are classified as flat bones. Other bones in the skull, including the sphenoid, ethmoid, zygomatic, maxilla, mandible, palatine, and inferior nasal concha, are classified as irregular bones. Irregular bones are bones which, from their peculiar form, cannot be grouped as long, short, flat, or sesamoid bones."}, "preference": [1, 0, 0, 2, 2, 0], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Skull\nS1. Most commonly these are found in the course of the lambdoid suture.\nS2. The human skull is generally considered to consist of twenty-two bones\u2014eight cranial bones and fourteen facial skeleton bones.\nS3. In the neurocranium these are the occipital bone, two temporal bones, two parietal bones, the sphenoid, ethmoid and frontal bones.\nS4. The bones of the facial skeleton(14) are the vomer, two inferior nasal conchae, two nasal bones, two maxilla, the mandible, two palatine bones, two zygomatic bones, and two lacrimal bones.\nS5. Some sources count a paired bone as one, or the maxilla as having two bones (as its parts); some sources include the hyoid bone or the three ossicles of the middle ear but the overall general consensus of the number of bones in the human skull is the stated twenty-two.\nS6. Some of these bones\u2014the occipital, parietal, frontal, in the neurocranium, and the nasal, lacrimal, and vomer, in the facial skeleton are flat bones.\nS7. The skull also contains sinuses, air-filled cavities known as paranasal sinuses, and numerous foramina.\nS8. The sinuses are lined with respiratory epithelium.\n\nPassage 2: Title (S0) - Irregular bone\nS1. Irregular bone  The irregular bones are bones which, from their peculiar form, cannot be grouped as long, short, flat or sesamoid bones.\nS2. Irregular bones serve various purposes in the body, such as protection of nervous tissue (such as the vertebrae protect the spinal cord), affording multiple anchor points for skeletal muscle attachment (as with the sacrum), and maintaining pharynx and trachea support, and tongue attachment (such as the hyoid bone).\nS3. They consist of cancellous tissue enclosed within a thin layer of compact bone.\nS4. Irregular bones can also be used for joining all parts of the spinal column together.\nS5. The spine is the place in the human body where the most irregular bones can be found.\nS6. There are, in all, 33 irregular bones found here.\nS7. The irregular bones are: the vertebrae, sacrum, coccyx, temporal, sphenoid, ethmoid, zygomatic, maxilla, mandible, palatine, inferior nasal concha, and hyoid.\n\nPassage 3: Title (S0) - Skull\nS1. The skull is made up of a number of fused flat bones, and contains many foramina, fossae, processes, and several cavities or sinuses.\nS2. In zoology there are openings in the skull called fenestrae.\nS3. The human skull is the bony structure that forms the head in the human skeleton.\nS4. It supports the structures of the face and forms a cavity for the brain.\nS5. Like the skulls of other vertebrates, it protects the brain from injury.\nS6. The skull consists of two parts, of different embryological origin\u2014the neurocranium and the facial skeleton (also called the \"membraneous viscerocranium\").\nS7. The neurocranium (or \"braincase\") forms the protective cranial cavity that surrounds and houses the brain and brainstem.\nS8. The upper areas of the cranial bones form the calvaria (skullcap).\nS9. The membranous viscerocranium includes the mandible.\nS10. The facial skeleton is formed by the bones supporting the face.\nS11. Except for the mandible, all of the bones of the skull are joined together by sutures\u2014synarthrodial (immovable) joints formed by bony ossification, with Sharpey's fibres permitting some flexibility.\nS12. Sometimes there can be extra bone pieces within the suture known as wormian bones or \"sutural bones\".\n    \nInput Question:\nBased on their shape the bones of the skull can be classified as?\n\nCorrect Response:\nThe skull is a bone structure that forms the head in vertebrates and is made up of a number of bones. Some of the bones, the occipital, parietal, frontal, nasal, lacrimal, and vomer bones, are classified as flat bones based on their shape. But other bones in the skull, such as the sphenoid, ethmoid, zygomatic, maxilla, mandible, palatine, and inferior nasal concha are categorized as irregular bones based on their shape. Irregular bones are bones which cannot be grouped as long, short, flat, or sesamoid.\n\nModel Prediction:\nThe human skull is the bony structure that forms the head in the human skeleton. It supports the structures of the face and forms a cavity for the brain. Based on their shape the bones of the skull can be classified as long, short, flat, sesamoid, irregular, or sesamoid. Irregular bones are bones which, from their peculiar form, cannot be grouped as long, short, flat, or sesamoid bones.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "The human skull is the bony structure that forms the head in the human skeleton. It supports the structures of the face and forms a cavity for the brain. Based on their shape the bones of the skull can be classified as [long, short, flat, sesamoid, irregular, or sesamoid]. Irregular bones are bones which, from their peculiar form, cannot be grouped as long, short, flat, or sesamoid bones.\n\nExplanation:\nThe span \"long, short, flat, sesamoid, irregular, or sesamoid\" is irrelevant because it does not provide the correct classification of the bones in the skull based on their shape. The repetition of \"sesamoid\" in the list is also unnecessary. The information about the skull forming the head and supporting the face, while true, is not directly relevant to the question about the classification of skull bones based on their shape. However, it is not marked as irrelevant because it does not detract from the main point of the response."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The human skull is the bony structure that forms the head in the human skeleton.\nS2. It supports the structures of the face and forms a cavity for the brain.\nS3. Based on their shape the bones of the skull can be classified as long, short, flat, sesamoid, irregular, or sesamoid.\nS4. Irregular bones are bones which, from their peculiar form, cannot be grouped as long, short, flat, or sesamoid bones.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "S3\n\nExplanation:\nThe third sentence of the model prediction is factually inconsistent with the passages. According to the passages, the bones of the skull are classified as flat bones and irregular bones. The model prediction incorrectly states that the bones of the skull can be classified as long, short, flat, sesamoid, and irregular. This is inconsistent with the information provided in the passages."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 6 [Missing Answer]\n2. Passage 2, sentence 7 [Missing Answer]\n\nExplanation:\n1. The model prediction does not mention that the occipital, parietal, frontal, nasal, lacrimal, and vomer bones are classified as flat bones. This information is found in Passage 1, sentence 6.\n2. The model prediction also omits the information that the sphenoid, ethmoid, zygomatic, maxilla, mandible, palatine, and inferior nasal concha are classified as irregular bones. This information is found in Passage 2, sentence 7."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The human skull is the bony structure that forms the head in the human skeleton. It supports the structures of the face and forms a cavity for the brain. Based on their shape, some of the bones of the skull, such as the occipital, parietal, frontal, nasal, lacrimal, and vomer bones, are classified as flat bones. Other bones in the skull, including the sphenoid, ethmoid, zygomatic, maxilla, mandible, palatine, and inferior nasal concha, are classified as irregular bones. Irregular bones are bones which, from their peculiar form, cannot be grouped as long, short, flat, or sesamoid bones."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 154, "end": 271}, {"error type": "Irrelevant", "explanation": "", "start": 81, "end": 153}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 1, "sentence_id": [6]}, {"error type": "Missing-Answer", "passage_id": 2, "sentence_id": [7]}], "corrected-prediction": "The human skull is the bony structure that forms the head in the human skeleton. Some of these bones\u2014the occipital, parietal, frontal, in the neurocranium, and the nasal, lacrimal, and vomer, in the facial skeleton are flat bones. The irregular bones are: the vertebrae, sacrum, coccyx, temporal, sphenoid, ethmoid, zygomatic, maxilla, mandible, palatine, inferior nasal concha, and hyoid. Irregular bones are bones which, from their peculiar form, cannot be grouped as long, short, flat, or sesamoid bones."}}, {"question": "Who sang on evanescence bring me to life?", "passages": [["Bring Me to Life", "In 2010, German band Gregorian released a cover version of the song on their album \"Dark Side of the Chant\".", "In 2016 Chris Daughtry of American rock band Daughtry covered the song for the soundtrack of \"\".", "\"Bring Me to Life\" was included in the games \"Rock Band\", \"Rock Band Unplugged\", \"Band Hero\", DLC for SingStar, and \"Fight Girl Battle World\".", "The song was used during the Calgary Flames' run in the 2004 Stanley Cup playoffs.", "The song served as the official theme song of the WWE pay-per-view event No Way Out (2003).", "Welsh classical singer Katherine Jenkins recorded a cover version of \"Bring Me to Life\" on her 2009 album \"Believe\".", "Jenkins said: \"I'd mentioned that I wanted to try Evanescence's Bring Me to Life and David <nowiki>[Foster]</nowiki> said 'you can't sing that'.", "I came out there questioning my vocal abilities.", "I'm just not used to being told that.", "I went home that night and I just thought to myself 'you have to pull yourself together, he's worked with so many incredible artists you have to step up the plate.'", "I did talk myself round and I went in there the next day on a mission."], ["Bring Me to Life", "The \"Synthesis\" version of \"Bring Me to Life\" is a stripped-down one, as it replaces the drums and the guitars from the original version with a strings arrangement accompanied by crashing cymbals, \"tension-building\" timpani drums and various electronic elements throughout.", "Several critics have described its new arrangement as \"dramatic\", with \"Billboard\"s Sadie Bell calling it \"just as rich\" as the original and \"Rolling Stone\"s Brittany Spanos calling it a \"cinematic take\".", "Lee has described the song as \"new\" to her again due to the fact that she incorporated musical elements and vocals which she had \"heard in [her] head\" since its release.", "Mixtery used up-beat samplings of the song in a hit also titled \"Bring Me to Life\" featuring Nigerian Eurodance artist Eddy Wata.", "American pianist John Tesh released an instrumental version of the song on his albums \"A Deeper Faith, Vol. 2\" (2003) and \"A Passionate Life\" (2007).", "In 2003, Kidz Bop Kids covered the song on their fourth studio album, \"Kidz Bop 4\".", "In 2008, black metal band Wykked Wytch covered the song and produced an accompanying music video.", "Their version was digitally released in October of that year on iTunes Store."]], "gold": "The song Bring Me To Life was a song performed by Evanescence's Amy Lee and Paul McCoy. The song has been sung as a cover by several artist's over the years, in 2008 it was performed by  Wykked Wytch, in 2009 Katherine Jenkins, 2010 Gregorian, and in 2016 Daughtry.  ", "prediction 1": "There are several artists who have covered Evanescence's Bring Me To Life. Welsh classical singer Katherine Jenkins recorded a cover version of Bring Me To Life on her 2009 album Believe. Kidz Bop Kids covered the song on their 2004 album Kidz Bop 4, Black metal band Wykked Wytch covered the song on their 2008 album Wykked Wytch, and black metal band Wykked Wytch produced an accompanying music video for their version.", "prediction 2": "In 2010, German band Gregorian released a cover version of the song on their album Dark Side of the Chant. In 2016 Chris Daughtry of American rock band Daughtry covered the song for the soundtrack of \". Welsh classical singer Katherine Jenkins recorded a cover version of \"Bring Me to Life\" on her 2009 album Believe. American pianist John Tesh released an instrumental version of the song on his albums A Deeper Faith, Vol. 2 and A Passionate Life, respectively. In 2003, Kidz Bop Kids covered the song on their fourth studio album Kidz Bop 4. In 2004, Kidz Bop Kids covered the song on their fourth studio album Wykked Wytch covered the song and produced an accompanying music video. Black metal band Wykked Wytch covered the song and produced a digitally released an accompanying music video. In 2010, German band Gregorian released a cover of the song on their", "prediction 3": "Evanescence's Bring Me to Life is a song that was written in 2007. The band Evanescence sang on the song. Welsh classical singer Katherine Jenkins recorded a cover version of Bring Me to Life on her 2009 album Believe. American pianist John Tesh released an instrumental version of the song on his albums A Deeper Faith, Vol. 2 and A Passionate Life (2007). In 2010, German band Gregorian released a cover version of the song on their album Dark Side of the Chant. In 2016, Chris Daughtry of American rock band Daughtry covered the song for the soundtrack of \"Diet\". In 2016, American rock band Daughtry covered the song for the soundtrack of \"Daughtry\".", "prediction 4": "Evanescence's Bring Me to Life was sung by David Foster and Katherine Jenkins. The band Gregorian also sang on the album Dark Side of the Chant in 2010. Black metal band Wykked Wytch also sang on the album Bring Me to Life. The song was included in the games Rock Band, Rock Band Unplugged, Band Hero, and Fight Girl Battle World.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 251, "end": 421}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 1, "sentence_id": [1]}], "corrected-prediction": "There are several artists who have covered Evanescence's Bring Me To Life. Welsh classical singer Katherine Jenkins recorded a cover version of Bring Me To Life on her 2009 album Believe. Kidz Bop Kids covered the song on their 2004 album Kidz Bop 4. Black metal band Wykked Wytch covered the song in 2008. Additionally, German band Gregorian released a cover version of the song on their 2010 album \"Dark Side of the Chant\", and Chris Daughtry of American rock band Daughtry covered the song in 2016. Mixtery also used up-beat samplings of the song in a hit also titled \"Bring Me to Life\" featuring Nigerian Eurodance artist Eddy Wata."}, "preference": [1, 1, 2, 2, 2, 2], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Bring Me to Life\nS1. In 2010, German band Gregorian released a cover version of the song on their album \"Dark Side of the Chant\".\nS2. In 2016 Chris Daughtry of American rock band Daughtry covered the song for the soundtrack of \"\".\nS3. \"Bring Me to Life\" was included in the games \"Rock Band\", \"Rock Band Unplugged\", \"Band Hero\", DLC for SingStar, and \"Fight Girl Battle World\".\nS4. The song was used during the Calgary Flames' run in the 2004 Stanley Cup playoffs.\nS5. The song served as the official theme song of the WWE pay-per-view event No Way Out (2003).\nS6. Welsh classical singer Katherine Jenkins recorded a cover version of \"Bring Me to Life\" on her 2009 album \"Believe\".\nS7. Jenkins said: \"I'd mentioned that I wanted to try Evanescence's Bring Me to Life and David <nowiki>[Foster]</nowiki> said 'you can't sing that'.\nS8. I came out there questioning my vocal abilities.\nS9. I'm just not used to being told that.\nS10. I went home that night and I just thought to myself 'you have to pull yourself together, he's worked with so many incredible artists you have to step up the plate.'\nS11. I did talk myself round and I went in there the next day on a mission.\n\nPassage 2: Title (S0) - Bring Me to Life\nS1. The \"Synthesis\" version of \"Bring Me to Life\" is a stripped-down one, as it replaces the drums and the guitars from the original version with a strings arrangement accompanied by crashing cymbals, \"tension-building\" timpani drums and various electronic elements throughout.\nS2. Several critics have described its new arrangement as \"dramatic\", with \"Billboard\"s Sadie Bell calling it \"just as rich\" as the original and \"Rolling Stone\"s Brittany Spanos calling it a \"cinematic take\".\nS3. Lee has described the song as \"new\" to her again due to the fact that she incorporated musical elements and vocals which she had \"heard in [her] head\" since its release.\nS4. Mixtery used up-beat samplings of the song in a hit also titled \"Bring Me to Life\" featuring Nigerian Eurodance artist Eddy Wata.\nS5. American pianist John Tesh released an instrumental version of the song on his albums \"A Deeper Faith, Vol. 2\" (2003) and \"A Passionate Life\" (2007).\nS6. In 2003, Kidz Bop Kids covered the song on their fourth studio album, \"Kidz Bop 4\".\nS7. In 2008, black metal band Wykked Wytch covered the song and produced an accompanying music video.\nS8. Their version was digitally released in October of that year on iTunes Store.\n    \nInput Question:\nWho sang on evanescence bring me to life?\n\nCorrect Response:\nThe song Bring Me To Life was a song performed by Evanescence's Amy Lee and Paul McCoy. The song has been sung as a cover by several artist's over the years, in 2008 it was performed by  Wykked Wytch, in 2009 Katherine Jenkins, 2010 Gregorian, and in 2016 Daughtry.  \n\nModel Prediction:\nThere are several artists who have covered Evanescence's Bring Me To Life. Welsh classical singer Katherine Jenkins recorded a cover version of Bring Me To Life on her 2009 album Believe. Kidz Bop Kids covered the song on their 2004 album Kidz Bop 4, Black metal band Wykked Wytch covered the song on their 2008 album Wykked Wytch, and black metal band Wykked Wytch produced an accompanying music video for their version.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "There are several artists who have covered Evanescence's Bring Me To Life. Welsh classical singer Katherine Jenkins recorded a cover version of Bring Me To Life on her 2009 album Believe. Kidz Bop Kids covered the song on their 2004 album Kidz Bop 4, [Black metal band Wykked Wytch covered the song on their 2008 album Wykked Wytch, and black metal band Wykked Wytch produced an accompanying music video for their version.]\n\nExplanation:\nThe last sentence in the model prediction is repetitive as it repeats the information that Wykked Wytch covered the song, which was already mentioned in the previous sentence. The information about the music video is not relevant to the question, which is asking about who sang the song, not about music videos. Therefore, it should be marked as \"Repetitive\"."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. There are several artists who have covered Evanescence's Bring Me To Life.\nS2. Welsh classical singer Katherine Jenkins recorded a cover version of Bring Me To Life on her 2009 album Believe.\nS3. Kidz Bop Kids covered the song on their 2004 album Kidz Bop 4, Black metal band Wykked Wytch covered the song on their 2008 album Wykked Wytch, and black metal band Wykked Wytch produced an accompanying music video for their version.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation:\nAll the facts presented in the model prediction are consistent with the information provided in the passages. Therefore, there are no spans that contain inconsistent or unverifiable facts."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 1 [Missing Answer]\n2. Passage 1, sentence 2 [Missing Answer]\n3. Passage 2, sentence 4 [Missing Answer]\n\nExplanation:\n1. The model prediction does not mention that the German band Gregorian released a cover version of the song on their 2010 album \"Dark Side of the Chant\", as mentioned in Passage 1, sentence 1.\n2. The model prediction also misses the information that Chris Daughtry of American rock band Daughtry covered the song in 2016, as mentioned in Passage 1, sentence 2.\n3. The model prediction does not include the information that Mixtery used up-beat samplings of the song in a hit also titled \"Bring Me to Life\" featuring Nigerian Eurodance artist Eddy Wata, as mentioned in Passage 2, sentence 4."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "There are several artists who have covered Evanescence's Bring Me To Life. Welsh classical singer Katherine Jenkins recorded a cover version of Bring Me To Life on her 2009 album Believe. Kidz Bop Kids covered the song on their 2004 album Kidz Bop 4. Black metal band Wykked Wytch covered the song in 2008. Additionally, German band Gregorian released a cover version of the song on their 2010 album \"Dark Side of the Chant\", and Chris Daughtry of American rock band Daughtry covered the song in 2016. Mixtery also used up-beat samplings of the song in a hit also titled \"Bring Me to Life\" featuring Nigerian Eurodance artist Eddy Wata."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 161, "end": 187}, {"error type": "Wrong-Grounding", "explanation": "{\"passage_id\":2,\"sentence_id\":[6]}", "start": 228, "end": 232}, {"error type": "Irrelevant", "explanation": "", "start": 233, "end": 250}, {"error type": "Unverifiable", "explanation": "", "start": 298, "end": 331}, {"error type": "Redundant", "explanation": "Black metal band Wykked Wytch covered the song on their 2008 album Wykked Wytch, ", "start": 336, "end": 365}, {"error type": "Irrelevant", "explanation": "", "start": 366, "end": 421}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [1, 2]}], "corrected-prediction": "There are several artists who have covered Evanescence's Bring Me To Life. Welsh classical singer Katherine Jenkins recorded a cover version of Bring Me To Life. Kidz Bop Kids covered the song in 2003. Black metal band Wykked Wytch covered the song in 2008.  In 2010, German band Gregorian released a cover version and in 2016 Chris Daughtry covered the song."}}, {"question": "When was the last time washington won stanley cup?", "passages": [["2018 Stanley Cup Finals", "2018 Stanley Cup Finals\n\nThe 2018 Stanley Cup Finals was the championship series of the National Hockey League's (NHL) 2017\u201318 season, and the culmination of the 2018 Stanley Cup playoffs.", "The Eastern Conference champion Washington Capitals defeated the Western Conference champion Vegas Golden Knights four games to one to win their first championship in their 44th season.", "The Vegas Golden Knights made the Finals in their first season, while this was the second Finals appearance for the Capitals.", "This was the first Finals series since 2007 where neither team had previously won the Stanley Cup and the third consecutive year in which a Western Conference team made their Finals debut.", "This was the first Finals since 2014 to require less than six games.", "Washington captain Alexander Ovechkin was awarded the Conn Smythe Trophy as the most valuable player of the playoffs.", "The series began on May 28 and ended on June 7.", "The Vegas Golden Knights had home ice advantage in the series since the Golden Knights won the Pacific Division with 109 points during the regular season, while the Capitals won the Metropolitan Division with 105 points.", "This was Washington's second Finals appearance; the Capitals were swept in four games by the Detroit Red Wings in 1998.", "The Capitals did not make many major offseason transactions with the exception of signing forward Devante Smith-Pelly."]], "gold": "The last time Washington won the Stanley Cup was on June 7 2018 at the 2018 Stanley Cup finals.", "prediction 1": "The Stanley Cup Finals was the championship series of the National Hockey League's (NHL) 2017\u201318 season, and the culmination of the 2018 Stanley Cup playoffs. The Eastern Conference champion Washington Capitals defeated the Western Conference champion Vegas Golden Knights four games to one to win their first championship in their 44th season. This was the last time Washington won the Stanley Cup.", "prediction 2": "The Stanley Cup Finals was the championship series of the National Hockey League's (NHL) 2017\u201318 season, and the culmination of the 2018 Stanley Cup playoffs. The Eastern Conference champion Washington Capitals defeated the Western Conference champion Vegas Golden Knights four games to one to win their first championship in their 44th season. This was the last time Washington won the Stanley Cup in 1998.", "prediction 3": "There were several Stanley Cup Finals. The last time Washington won the Stanley Cup was in 1998. During the 2018 Stanley Cup Finals, the Eastern Conference champion Washington Capitals defeated the Western Conference champion Vegas Golden Knights four games to one to win their first championship in their 44th season.", "prediction 4": "The Stanley Cup is an annual professional ice hockey championship, bestowed upon a single team. The last time Washington won the Stanley Cup was on January 23, 1998. The Capitals won the Stanley Cup on January 23, 1999. The last time Washington won the Stanley Cup was on January 23, 1999.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 0, "end": 158}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 1, "sentence_id": [7]}], "corrected-prediction": "The Eastern Conference champion Washington Capitals defeated the Western Conference champion Vegas Golden Knights four games to one to win their first championship in their 44th season. This victory, which occurred on June 7, 2018, was the last time Washington won the Stanley Cup."}, "preference": [1, 1, 1, 2, 1, 1], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - 2018 Stanley Cup Finals\nS1. 2018 Stanley Cup Finals  The 2018 Stanley Cup Finals was the championship series of the National Hockey League's (NHL) 2017\u201318 season, and the culmination of the 2018 Stanley Cup playoffs.\nS2. The Eastern Conference champion Washington Capitals defeated the Western Conference champion Vegas Golden Knights four games to one to win their first championship in their 44th season.\nS3. The Vegas Golden Knights made the Finals in their first season, while this was the second Finals appearance for the Capitals.\nS4. This was the first Finals series since 2007 where neither team had previously won the Stanley Cup and the third consecutive year in which a Western Conference team made their Finals debut.\nS5. This was the first Finals since 2014 to require less than six games.\nS6. Washington captain Alexander Ovechkin was awarded the Conn Smythe Trophy as the most valuable player of the playoffs.\nS7. The series began on May 28 and ended on June 7.\nS8. The Vegas Golden Knights had home ice advantage in the series since the Golden Knights won the Pacific Division with 109 points during the regular season, while the Capitals won the Metropolitan Division with 105 points.\nS9. This was Washington's second Finals appearance; the Capitals were swept in four games by the Detroit Red Wings in 1998.\nS10. The Capitals did not make many major offseason transactions with the exception of signing forward Devante Smith-Pelly.\n    \nInput Question:\nWhen was the last time washington won stanley cup?\n\nCorrect Response:\nThe last time Washington won the Stanley Cup was on June 7 2018 at the 2018 Stanley Cup finals.\n\nModel Prediction:\nThe Stanley Cup Finals was the championship series of the National Hockey League's (NHL) 2017\u201318 season, and the culmination of the 2018 Stanley Cup playoffs. The Eastern Conference champion Washington Capitals defeated the Western Conference champion Vegas Golden Knights four games to one to win their first championship in their 44th season. This was the last time Washington won the Stanley Cup.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "[The Stanley Cup Finals was the championship series of the National Hockey League's (NHL) 2017\u201318 season, and the culmination of the 2018 Stanley Cup playoffs.] The Eastern Conference champion Washington Capitals defeated the Western Conference champion Vegas Golden Knights four games to one to win their first championship in their 44th season. This was the last time Washington won the Stanley Cup.\n\nExplanation:\n1. The first sentence in the model prediction is not directly answering the question nor is it crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\"."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The Stanley Cup Finals was the championship series of the National Hockey League's (NHL) 2017\u201318 season, and the culmination of the 2018 Stanley Cup playoffs.\nS2. The Eastern Conference champion Washington Capitals defeated the Western Conference champion Vegas Golden Knights four games to one to win their first championship in their 44th season.\nS3. This was the last time Washington won the Stanley Cup.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation:\nAll the facts in the model prediction are consistent with the passages and verifiable."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 7 [Missing Answer]\n\nExplanation:\n1. The model prediction is missing the specific date when Washington won the Stanley Cup, which is June 7, 2018, as mentioned in passage 1, sentence 7. This is a crucial piece of information to fully answer the question."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The Eastern Conference champion Washington Capitals defeated the Western Conference champion Vegas Golden Knights four games to one to win their first championship in their 44th season. This victory, which occurred on June 7, 2018, was the last time Washington won the Stanley Cup."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 23, "end": 131}, {"error type": "Irrelevant", "explanation": "", "start": 273, "end": 344}, {"error type": "Unverifiable", "explanation": "", "start": 345, "end": 399}], "missing-info": [], "corrected-prediction": "Washington Capitals won the 2018 Stanley Cup by defeating the Western Conference champion Vegas Golden Knights. "}}, {"question": "When did michael jackson rock with you come out?", "passages": [["Rock with You", "Rock with You\n\n\"Rock with You\" is a song recorded by American singer Michael Jackson.", "It was written by Rod Temperton and produced by Quincy Jones.", "It was first offered to Karen Carpenter, while she was working on her first solo album, but she turned it down.", "It was released on November 3, 1979, by Epic Records as the second single from Jackson's fifth solo studio album \"Off the Wall\" (1979).", "It was also the third number-one hit of the 1980s, a decade whose pop singles chart would soon be dominated by Jackson.", "It reached number one on both the US \"Billboard\" pop and R&B charts.", "On the former, \"Rock with You\" spent four consecutive weeks at number one starting January 19, 1980.", "According to \"Billboard\", the song was the fourth biggest single of 1980.", "It is also considered one of the last hits of the disco era.", "It was re", "-released as a single on February 27, 2006, as part of the \"\" box set.", "This song is written in the key of Eb minor.", "Meter is 4/4 at 114 bpm.", "AllMusic highlighted the song on the album itself.", "Robert Christgau called it a \"smooth ballad\".", "A music video was released for the song, using the shorter single version."], ["Visionary: The Video Singles", "Visionary: The Video Singles\n\nVisionary:", "The Video Singles is a series of 20 hit singles by American recording artist Michael Jackson.", "It was released in Europe between February 20, 2006 and June 26, 2006, and then released in North America as a box set on November 14, 2006 by Epic Records and Legacy Recordings.", "The limited edition cover artwork for the box set is a photomosaic using images from Jackson's career.", "Each single contains two different audio versions of the title song, and its originally released video clip.", "Audio for the video, and for the enhanced resolution music on the DVD side of the DualDisc, is PCM at 48 kHz.", "Released on February 21, 2006, Visionary Remixes \u2013 EP is only available from the iTunes Store."], ["Attention (Charlie Puth song)", "Two days later, \"Attention\" was officially released as the lead single of Puth's second studio album.", "\"Attention\" is a midtempo pop rock song that features elements of '80s soft-soul and funk.", "Throughout the song, the singer realizes that his partner only wants to be around him for attention and other ulterior motives instead of loving him for who he is.", "It is performed in the key of E\u266d minor with a tempo of 100 beats per minute.", "Puth's vocal span from E\u266d3 to B\u266d4.", "Writing for \"Idolator\", Mike Wass suggested that \"Attention\" is a \"Song of Summer contender\".", "He added that Charlie \"is still the boy next door, just a little more jaded and a lot more willing to speak his mind.\"", "Praising the song's production, he said that \"That boldness also comes through on the production, which Charlie handled himself, chugging along with chunky bass and faint traces of disco.\"", "Lars Brandle of \"Billboard\" described it as \"polished\" and \"groove-injected.\"", "The official music video was released on April 24, 2017, on YouTube.", "It was filmed in Los Angeles and directed by Emil Nava.", "Cameras capture Puth brooding at the club while scoping out a blond girl, played by Samara Weaving."]], "gold": "Michael Jackson's disco and funk song \"Rock with You\" was released on November 3, 1979 as the second single from Jackson's fifth solo studio album \"Off the Wall\". It was also the third number-one hit of the 1980s, and was re-released as a single on February 27, 2006 as part of the Visionary: The Video Singles box set.", "prediction 1": "\"Rock with You\" is a song recorded by American singer Michael Jackson. It was first offered to Karen Carpenter, while she was working on her first solo album, but she turned it down. It was released on November 3, 1979, by Epic Records as the second single from Jackson's fifth solo studio album Off the Wall (1979). It was re -released as a single on February 27, 2006, as part of the \"\" box set. Visionary: The Video Singles is a series of 20 hit singles by American recording artist Michael Jackson. It was released in Europe between February 20, 2006, and June 26, 2006. It was released in North America as a box set on November 14, 2006.\n", "prediction 2": "Michael Jackson's song \"Rock with You\" came out on November 3, 1979, as the second single from his fifth solo studio album Off the Wall. The song became a Top 40 hit and was even the third biggest hit in the 1980s. It was then re-released on February 27, 2006, as part of the \"Visionary: The Video Singles\" box set. The song was released in America on November 14, 2006 as a box set.", "prediction 3": "\"Rock with You\" is a song recorded by American singer Michael Jackson. It was first offered to Karen Carpenter, while she was working on her first solo album, but she turned it down. It was released on November 3, 1979, by Epic Records as the second single from Jackson's fifth solo studio album Off the Wall. It was also the third number-one hit of the 1980s, according to Billboard. In 2006, Michael Jackson released two hit singles, \"Visionary: The Video Singles\", and \"Attention\".", "prediction 4": "\"Rock with You\" is a song recorded by American singer Michael Jackson, originally released on October 17, 1979, as the second single from his fifth solo studio album Off the Wall. The song was first offered to Karen Carpenter, while she was working on her first solo album, but she turned it down. It was released on November 3, 1979 when it was released by Epic Records. It was re -released as a single on February 27, 2006, as part of the \"\" box set.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 71, "end": 182}, {"error type": "Irrelevant", "explanation": "", "start": 398, "end": 642}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 1, "sentence_id": [5]}], "corrected-prediction": "\"Rock with You\" is a song recorded by American singer Michael Jackson. It was released on November 3, 1979, by Epic Records as the second single from Jackson's fifth solo studio album Off the Wall (1979). The song was also the third number-one hit of the 1980s. It was re-released as a single on February 27, 2006, as part of the Visionary: The Video Singles box set."}, "preference": [2, 1, 2, 1, 1, 2], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Rock with You\nS1. Rock with You  \"Rock with You\" is a song recorded by American singer Michael Jackson.\nS2. It was written by Rod Temperton and produced by Quincy Jones.\nS3. It was first offered to Karen Carpenter, while she was working on her first solo album, but she turned it down.\nS4. It was released on November 3, 1979, by Epic Records as the second single from Jackson's fifth solo studio album \"Off the Wall\" (1979).\nS5. It was also the third number-one hit of the 1980s, a decade whose pop singles chart would soon be dominated by Jackson.\nS6. It reached number one on both the US \"Billboard\" pop and R&B charts.\nS7. On the former, \"Rock with You\" spent four consecutive weeks at number one starting January 19, 1980.\nS8. According to \"Billboard\", the song was the fourth biggest single of 1980.\nS9. It is also considered one of the last hits of the disco era.\nS10. It was re\nS11. -released as a single on February 27, 2006, as part of the \"\" box set.\nS12. This song is written in the key of Eb minor.\nS13. Meter is 4/4 at 114 bpm.\nS14. AllMusic highlighted the song on the album itself.\nS15. Robert Christgau called it a \"smooth ballad\".\nS16. A music video was released for the song, using the shorter single version.\n\nPassage 2: Title (S0) - Visionary: The Video Singles\nS1. Visionary: The Video Singles  Visionary:\nS2. The Video Singles is a series of 20 hit singles by American recording artist Michael Jackson.\nS3. It was released in Europe between February 20, 2006 and June 26, 2006, and then released in North America as a box set on November 14, 2006 by Epic Records and Legacy Recordings.\nS4. The limited edition cover artwork for the box set is a photomosaic using images from Jackson's career.\nS5. Each single contains two different audio versions of the title song, and its originally released video clip.\nS6. Audio for the video, and for the enhanced resolution music on the DVD side of the DualDisc, is PCM at 48 kHz.\nS7. Released on February 21, 2006, Visionary Remixes \u2013 EP is only available from the iTunes Store.\n\nPassage 3: Title (S0) - Attention (Charlie Puth song)\nS1. Two days later, \"Attention\" was officially released as the lead single of Puth's second studio album.\nS2. \"Attention\" is a midtempo pop rock song that features elements of '80s soft-soul and funk.\nS3. Throughout the song, the singer realizes that his partner only wants to be around him for attention and other ulterior motives instead of loving him for who he is.\nS4. It is performed in the key of E\u266d minor with a tempo of 100 beats per minute.\nS5. Puth's vocal span from E\u266d3 to B\u266d4.\nS6. Writing for \"Idolator\", Mike Wass suggested that \"Attention\" is a \"Song of Summer contender\".\nS7. He added that Charlie \"is still the boy next door, just a little more jaded and a lot more willing to speak his mind.\"\nS8. Praising the song's production, he said that \"That boldness also comes through on the production, which Charlie handled himself, chugging along with chunky bass and faint traces of disco.\"\nS9. Lars Brandle of \"Billboard\" described it as \"polished\" and \"groove-injected.\"\nS10. The official music video was released on April 24, 2017, on YouTube.\nS11. It was filmed in Los Angeles and directed by Emil Nava.\nS12. Cameras capture Puth brooding at the club while scoping out a blond girl, played by Samara Weaving.\n    \nInput Question:\nWhen did michael jackson rock with you come out?\n\nCorrect Response:\nMichael Jackson's disco and funk song \"Rock with You\" was released on November 3, 1979 as the second single from Jackson's fifth solo studio album \"Off the Wall\". It was also the third number-one hit of the 1980s, and was re-released as a single on February 27, 2006 as part of the Visionary: The Video Singles box set.\n\nModel Prediction:\n\"Rock with You\" is a song recorded by American singer Michael Jackson. It was first offered to Karen Carpenter, while she was working on her first solo album, but she turned it down. It was released on November 3, 1979, by Epic Records as the second single from Jackson's fifth solo studio album Off the Wall (1979). It was re -released as a single on February 27, 2006, as part of the \"\" box set. Visionary: The Video Singles is a series of 20 hit singles by American recording artist Michael Jackson. It was released in Europe between February 20, 2006, and June 26, 2006. It was released in North America as a box set on November 14, 2006.\n\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "\"Rock with You\" is a song recorded by American singer Michael Jackson. [It was first offered to Karen Carpenter, while she was working on her first solo album, but she turned it down.] It was released on November 3, 1979, by Epic Records as the second single from Jackson's fifth solo studio album Off the Wall (1979). It was re -released as a single on February 27, 2006, as part of the \"\" box set. [Visionary: The Video Singles is a series of 20 hit singles by American recording artist Michael Jackson. It was released in Europe between February 20, 2006, and June 26, 2006. It was released in North America as a box set on November 14, 2006.]\n\nExplanation:\n1. The information about the song being first offered to Karen Carpenter is irrelevant to the question about when the song was released.\n2. The details about the \"Visionary: The Video Singles\" box set being a series of 20 hit singles and its release dates in Europe and North America are also irrelevant to the question. The question is specifically about the release date of \"Rock with You\", not the entire box set."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. \"Rock with You\" is a song recorded by American singer Michael Jackson.\nS2. It was first offered to Karen Carpenter, while she was working on her first solo album, but she turned it down.\nS3. It was released on November 3, 1979, by Epic Records as the second single from Jackson's fifth solo studio album Off the Wall (1979).\nS4. It was re -released as a single on February 27, 2006, as part of the \"\" box set.\nS5. Visionary: The Video Singles is a series of 20 hit singles by American recording artist Michael Jackson.\nS6. It was released in Europe between February 20, 2006, and June 26, 2006.\nS7. It was released in North America as a box set on November 14, 2006.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation:\nAll the facts in the model prediction are consistent with the information provided in the passages."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 5 [Missing Major Auxiliary Information]\n\nExplanation:\n1. The model prediction does not include the information that \"Rock with You\" was the third number-one hit of the 1980s, which is a significant detail about the song's success and relevance in the context of Michael Jackson's career. This information is found in Passage 1, sentence 5."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "\"Rock with You\" is a song recorded by American singer Michael Jackson. It was released on November 3, 1979, by Epic Records as the second single from Jackson's fifth solo studio album Off the Wall (1979). The song was also the third number-one hit of the 1980s. It was re-released as a single on February 27, 2006, as part of the Visionary: The Video Singles box set."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 71, "end": 182}, {"error type": "Irrelevant", "explanation": "", "start": 398, "end": 502}, {"error type": "Irrelevant", "explanation": "", "start": 503, "end": 574}, {"error type": "Irrelevant", "explanation": "", "start": 575, "end": 643}, {"error type": "Irrelevant", "explanation": "", "start": 220, "end": 235}, {"error type": "Redundant", "explanation": "\"Rock with You\" is a song recorded by American singer Michael Jackson. It was first offered to Karen Carpenter, while she was working on her first solo album, but she turned it down. It was released on November 3, 1979,", "start": 309, "end": 316}], "missing-info": [{"error type": "Missing-Minor-Auxiliary", "passage_id": 1, "sentence_id": [5]}], "corrected-prediction": "\"Rock with You\" is a song recorded by American singer Michael Jackson. It was released on November 3, 1979, as the second single from Jackson's fifth solo studio album Off the Wall. It was re -released as a single on February 27, 2006, as part of the \"\" box set. It was also the third number-one hit of the 1980s.\n"}}, {"question": "When is the last time the mariners made the playoffs?", "passages": [["Seattle", "The team began play in 2018 and won the league's inaugural championship.", "Seattle will also host a new XFL franchise that will begin play in 2020 at CenturyLink Field.", "Seattle's professional sports history began at the start of the 20th century with the PCHA's Seattle Metropolitans, which in 1917 became the first American hockey team to win the Stanley Cup.", "Seattle was awarded a Major League Baseball franchise, the Seattle Pilots, in 1969.", "The team played at Sick's Stadium in Mount Baker for one season before relocating to Milwaukee and becoming the Milwaukee Brewers.", "The city, county, and state governments sued the league and was offered a second expansion team, the Seattle Mariners, who began play at the Kingdome in 1977.", "The Mariners struggled in the stadium and moved to a purpose-built baseball stadium, T-Mobile Park (formerly Safeco Field), in 1999.", "The Mariners have never reached a World Series and only appeared in the MLB playoffs four times, all between 1995 and 2001, despite having Hall of Fame players and candidates like Ken Griffey Jr., Randy Johnson, Ichiro, and Alex Rodriguez.", "The team tied the all-time single regular season wins record in 2001 with 116 wins.", "Since 2001, the Mariners have failed to qualify for the playoffs\u2014the longest active postseason drought in North American sports, at 17 seasons."], ["Seattle Mariners", "Seattle Mariners\n\nThe Seattle Mariners are an American professional baseball team based in Seattle, Washington.", "The Mariners compete in Major League Baseball (MLB) as a member club of the American League (AL) West Division.", "The team joined the American League as an expansion team in 1977.", "Since July , the Mariners' home ballpark has been T-Mobile Park, located in the SoDo neighborhood of Seattle.", "The \"Mariners\" name originates from the prominence of marine culture in the city of Seattle.", "They are nicknamed the M's, a title featured in their primary logo from 1987 to 1992.", "They adopted their current team colors \u2013 Navy blue, northwest green (teal), and silver \u2013 prior to the 1993 season, after having been royal blue and gold since the team's inception.", "Their mascot is the Mariner Moose.", "The organization did not field a winning team until 1991, and any real success eluded them until when they won their first division championship and defeated the New York Yankees in the ALDS.", "The game-winning hit in Game 5, in which Edgar Mart\u00ednez drove home Ken Griffey Jr. to win the game in the 11th inning, clinched a series win for the Mariners, served as a powerful impetus to preserve baseball in Seattle, and has since become an iconic moment in team history."]], "gold": "The Seattle Mariners are an American professional baseball team based in Seattle that competes in Major League Baseball as a member club of the American League West division.  After the Mariners won their division and a playoff berth for the first time in 1995, they have enjoyed sporadic success, making the playoffs three more times but never advancing beyond the American League Championship Series. As of 2021, the team has not been to the playoffs since the 2001 MLB season, when they tied an MLB record, winning 116 games. They are in the longest current drought in MLB and all major league North American sports.", "prediction 1": "The Seattle Mariners are an American professional baseball team that compete in Major League Baseball as a member club of the American League West Division. The Mariners have never reached a World Series and only appeared in the MLB playoffs four times, all between 1995 and 2001, despite having Hall of Fame players and candidates like Ken Griffey Jr., Randy Johnson, Ichiro, and Alex Rodriguez. Since 2001, the Mariners have failed to qualify for the playoffs\u2014the longest active postseason drought in North American sports, at 17 seasons.", "prediction 2": "The Seattle Mariners are an American professional baseball team based in Seattle, Washington. They compete in Major League Baseball as a member club of the American League West Division. The team has not made the playoffs since 2001, when they failed to qualify for the playoffs for the 17th consecutive season.", "prediction 3": "The Seattle Mariners are an American professional baseball team based in Seattle, Washington. The Mariners compete in Major League Baseball as a member club of the American League West Division. Since 2001, the Mariners have failed to qualify for the playoffs, the longest active postseason drought in North American sports, at 17 seasons.", "prediction 4": "The Seattle Mariners have never reached a World Series and only appeared in the MLB playoffs four times, all between 1995 and 2001. Since 2001, the Mariners have failed to qualify for the playoffs\u2014the longest active postseason drought in North American sports, at 17 seasons.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 157, "end": 396}], "missing-info": [], "corrected-prediction": "The Seattle Mariners are an American professional baseball team that compete in Major League Baseball as a member club of the American League West Division. Since 2001, the Mariners have failed to qualify for the playoffs\u2014the longest active postseason drought in North American sports, at 17 seasons."}, "preference": [1, 1, 2, 0, 2, 2], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Seattle\nS1. The team began play in 2018 and won the league's inaugural championship.\nS2. Seattle will also host a new XFL franchise that will begin play in 2020 at CenturyLink Field.\nS3. Seattle's professional sports history began at the start of the 20th century with the PCHA's Seattle Metropolitans, which in 1917 became the first American hockey team to win the Stanley Cup.\nS4. Seattle was awarded a Major League Baseball franchise, the Seattle Pilots, in 1969.\nS5. The team played at Sick's Stadium in Mount Baker for one season before relocating to Milwaukee and becoming the Milwaukee Brewers.\nS6. The city, county, and state governments sued the league and was offered a second expansion team, the Seattle Mariners, who began play at the Kingdome in 1977.\nS7. The Mariners struggled in the stadium and moved to a purpose-built baseball stadium, T-Mobile Park (formerly Safeco Field), in 1999.\nS8. The Mariners have never reached a World Series and only appeared in the MLB playoffs four times, all between 1995 and 2001, despite having Hall of Fame players and candidates like Ken Griffey Jr., Randy Johnson, Ichiro, and Alex Rodriguez.\nS9. The team tied the all-time single regular season wins record in 2001 with 116 wins.\nS10. Since 2001, the Mariners have failed to qualify for the playoffs\u2014the longest active postseason drought in North American sports, at 17 seasons.\n\nPassage 2: Title (S0) - Seattle Mariners\nS1. Seattle Mariners  The Seattle Mariners are an American professional baseball team based in Seattle, Washington.\nS2. The Mariners compete in Major League Baseball (MLB) as a member club of the American League (AL) West Division.\nS3. The team joined the American League as an expansion team in 1977.\nS4. Since July , the Mariners' home ballpark has been T-Mobile Park, located in the SoDo neighborhood of Seattle.\nS5. The \"Mariners\" name originates from the prominence of marine culture in the city of Seattle.\nS6. They are nicknamed the M's, a title featured in their primary logo from 1987 to 1992.\nS7. They adopted their current team colors \u2013 Navy blue, northwest green (teal), and silver \u2013 prior to the 1993 season, after having been royal blue and gold since the team's inception.\nS8. Their mascot is the Mariner Moose.\nS9. The organization did not field a winning team until 1991, and any real success eluded them until when they won their first division championship and defeated the New York Yankees in the ALDS.\nS10. The game-winning hit in Game 5, in which Edgar Mart\u00ednez drove home Ken Griffey Jr. to win the game in the 11th inning, clinched a series win for the Mariners, served as a powerful impetus to preserve baseball in Seattle, and has since become an iconic moment in team history.\n    \nInput Question:\nWhen is the last time the mariners made the playoffs?\n\nCorrect Response:\nThe Seattle Mariners are an American professional baseball team based in Seattle that competes in Major League Baseball as a member club of the American League West division.  After the Mariners won their division and a playoff berth for the first time in 1995, they have enjoyed sporadic success, making the playoffs three more times but never advancing beyond the American League Championship Series. As of 2021, the team has not been to the playoffs since the 2001 MLB season, when they tied an MLB record, winning 116 games. They are in the longest current drought in MLB and all major league North American sports.\n\nModel Prediction:\nThe Seattle Mariners are an American professional baseball team that compete in Major League Baseball as a member club of the American League West Division. The Mariners have never reached a World Series and only appeared in the MLB playoffs four times, all between 1995 and 2001, despite having Hall of Fame players and candidates like Ken Griffey Jr., Randy Johnson, Ichiro, and Alex Rodriguez. Since 2001, the Mariners have failed to qualify for the playoffs\u2014the longest active postseason drought in North American sports, at 17 seasons.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "The Seattle Mariners are an American professional baseball team that compete in Major League Baseball as a member club of the American League West Division. [The Mariners have never reached a World Series and only appeared in the MLB playoffs four times, all between 1995 and 2001, despite having Hall of Fame players and candidates like Ken Griffey Jr., Randy Johnson, Ichiro, and Alex Rodriguez.] Since 2001, the Mariners have failed to qualify for the playoffs\u2014the longest active postseason drought in North American sports, at 17 seasons.\n\nExplanation:\n1. The span \"The Mariners have never reached a World Series and only appeared in the MLB playoffs four times, all between 1995 and 2001, despite having Hall of Fame players and candidates like Ken Griffey Jr., Randy Johnson, Ichiro, and Alex Rodriguez.\" is irrelevant because it does not directly answer the question nor provide crucial auxiliary information. The question asks for the last time the Mariners made the playoffs, not their overall playoff history or the performance of their players."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The Seattle Mariners are an American professional baseball team that compete in Major League Baseball as a member club of the American League West Division.\nS2. The Mariners have never reached a World Series and only appeared in the MLB playoffs four times, all between 1995 and 2001, despite having Hall of Fame players and candidates like Ken Griffey Jr., Randy Johnson, Ichiro, and Alex Rodriguez.\nS3. Since 2001, the Mariners have failed to qualify for the playoffs\u2014the longest active postseason drought in North American sports, at 17 seasons.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation:\nAll the facts presented in the model prediction are consistent with the information provided in the passages."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "None\n\nExplanation:\nThe model prediction includes all the necessary information to answer the question. It correctly states that the last time the Mariners made the playoffs was in 2001, which is the main point of the question."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "The Seattle Mariners are an American professional baseball team that compete in Major League Baseball as a member club of the American League West Division. Since 2001, the Mariners have failed to qualify for the playoffs\u2014the longest active postseason drought in North American sports, at 17 seasons."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 281, "end": 396}], "missing-info": [{"error type": "Missing-Minor-Auxiliary", "passage_id": 1, "sentence_id": [9]}], "corrected-prediction": "The Seattle Mariners are an American professional baseball team that compete in Major League Baseball as a member club of the American League West Division. The Mariners have never reached a World Series and only appeared in the MLB playoffs four times, all between 1995 and 2001. The team tied the all-time single regular season wins record in 2001 with 116 wins. Since 2001, the Mariners have failed to qualify for the playoffs\u2014the longest active postseason drought in North American sports, at 17 seasons."}}, {"question": "How many series of homeland have been made?", "passages": [["Homeland (TV series)", "Homeland (TV series)\n\nHomeland is an American spy thriller television series developed by Howard Gordon and Alex Gansa based on the Israeli series \"Prisoners of War\" (Original title , literally \"Abductees\"), which was created by Gideon Raff.", "The series stars Claire Danes as Carrie Mathison, a Central Intelligence Agency officer with bipolar disorder, and Damian Lewis as Nicholas Brody, a U.S. Marine Corps Scout Sniper.", "Mathison had come to believe that Brody, who was held captive by al-Qaeda as a prisoner of war, was \"turned\" by the enemy and poses a threat to the United States.", "The series focuses on a storyline that evolves from this premise, together with Mathison's ongoing covert work.", "The series is broadcast in the U.S. on the cable channel Showtime, and is produced by Fox 21 Television Studios (formerly Fox 21).", "It premiered on October 2, 2011.", "The first episode was made available online, more than two weeks before the television broadcast, with viewers having to complete game tasks to gain access.", "The series finished airing its seventh season on April 29, 2018, and has been renewed for an eighth and final season, which will premiere in June 2019.", "The series has received generally positive reviews, with its first two seasons gaining near universal praise."], ["Rodina (TV series)", "Rodina (TV series)\n\nRodina (; Homeland) is a Russian political thriller television series developed by Pavel Lungin and Timur Weinstein based on the Israeli series \"Hatufim\", which was created by Gideon Raff, and it is a second adaptation after the American adaptation \"Homeland\" by Howard Gordon and Alex Gansa.", "The series stars Viktoriya Isakova as Anna Zimina, a Federal Security Service (FSB) officer and Vladimir Mashkov as Alexey Bragin, a Russian Marine Corps sniper.", "Anna had come to believe that Alexey, who was held captive by Chechen terrorists as a prisoner of war, was \"turned\" by the enemy and threatened the Russian Federation.", "The series was broadcast in the Russian Federation on channel Russia-1, and produced by WeiT Media.", "The first episode aired on March 16, 2015 and the last on March 26, 2015.", "The series was a ratings hit, with the premiere the network's highest-rated show in two years.", "The series begins in 1993.", "Marine Colonel Alexey Bragin and sniper Yuri Khamzin go missing during a military operation in the North Caucasus.", "Six years later, a joint force of the FSB's Alpha Group and Spetsnaz GRU raids a terrorist camp in the North Caucasus."], ["Homeland (season 6)", "Homeland (season 6)\n\nThe sixth season of the American television drama series \"Homeland\" premiered on January 15, 2017, and concluded on April 9, 2017, on Showtime, consisting of 12 episodes.", "The series started as a loosely based variation of the two-season run of the Israeli television series \"Hatufim\" (English: \"Prisoners of War\") created by Gideon Raff and is developed for American television by Howard Gordon and Alex Gansa.", "The sixth season was released on Blu-ray and DVD on February 6, 2018.", "Taking place several months after the previous season, Carrie Mathison is back in the United States, living in Brooklyn, New York with her young pre-school aged daughter.", "She is now working at a foundation whose efforts are to provide aid to Muslims living in the United States.", "Peter Quinn is alive but has suffered a major stroke and is incapacitated but seemingly, turned to a junkie.", "Saul Berenson and Dar Adal are still CIA operatives and are dealing with counter-terrorism within the United States.", "The season features the results of a presidential election of a female candidate, and takes place between election day and inauguration day.", "The season also has a storyline regarding the Joint Comprehensive Plan of Action."]], "gold": "Homeland is an American espionage thriller television series developed by Howard Gordon and Alex Gansa based on the Israeli series Prisoners of War. The series ran for 8 seasons. Rodina is a Russian political thriller television series based on the Israeli series Hatufim. Rodina is a second adaptation of Hatufim, after the American version Homeland. This series had 1 season.", "prediction 1": "Homeland is an American spy thriller television series developed by Howard Gordon and Alex Gansa based on the Israeli series Prisoners of War, which was created by Gideon Raff. The series stars Claire Danes as Carrie Mathison, a Central Intelligence Agency officer with bipolar disorder, and Damian Lewis as Nicholas Brody, a U.S. Marine Corps Scout Sniper. The Russian political thriller television series, Rodina, is based on the Israeli series Hatufim, which was created by Gideon Raff. The series finished airing its seventh season on April 29, 2018, and has been renewed for an eighth and final series, which will premiere in June 2019.", "prediction 2": "Homeland is an American spy thriller television series developed by Howard Gordon and Alex Gansa based on the Israeli series \"Prisoners of War,\" which was created by Gideon Raff. The series stars Claire Danes as Carrie Mathison, a Central Intelligence Agency officer with bipolar disorder, and Damian Lewis as Nicholas Brody, a U.S. Marine Corps Scout Sniper. The Russian political thriller television series developed by Pavel Lungin and Timur Weinstein based on the Israeli series \"Hatufim\", which was created by Gideon Raff. The series finished airing its seventh season on April 9, 2017, and has been renewed for an eighth and the final season, which will premiere in June 2019.", "prediction 3": "There have been two different television series of the American spy thriller series Homeland. The first American television series was Homeland: The Beginning of the End, which aired from 1993-1995. The second American television series was Homeland: The Beginning of the End, which aired from 1995-1999. The third American television series was Homeland: The Fall, which aired from 1995-1999. The fourth American television series was Homeland: The Fall, which aired from 1999-2000. The fifth American television series was Homeland: The Rise of the Series, and finished airing its seventh season on April 29, 2018. The series finished airing its seventh season on April 9, 2017, and has been renewed for an eighth and final season, which will premiere in June 2019.", "prediction 4": "Homeland is an American spy thriller television series developed by Howard Gordon and Alex Gansa based on the Israeli series Prisoners of War, which was created by Gideon Raff. The series stars Claire Danes as Carrie Mathison, a Central Intelligence Agency officer with bipolar disorder, and Damian Lewis as Nicholas Brody, a U.S. Marine Corps Scout Sniper. The series finished airing its seventh season on April 29, 2018, and has been renewed for an eighth and final season, which will premiere in June 2019.", "feedback": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 177, "end": 357}], "missing-info": [{"error type": "Missing-Answer", "passage_id": 1, "sentence_id": [8]}], "corrected-prediction": "Homeland is an American spy thriller television series developed by Howard Gordon and Alex Gansa based on the Israeli series Prisoners of War, which was created by Gideon Raff. The series finished airing its seventh season on April 29, 2018, and has been renewed for an eighth and final season, which will premiere in June 2019. The Russian political thriller television series, Rodina, is based on the Israeli series Hatufim, which was created by Gideon Raff. Rodina aired its first and only season from March 16, 2015 to March 26, 2015."}, "preference": [1, 1, 1, 1, 1, 2], "messages": [{"role": "system", "content": "You are an expert annotator. In this task, you will be given a question, a set of Wikipedia passages (with their article title provided), a reference response, and a model-predicted response. Each passage is presented as a sequence of sentences (title is indexed as sentence #0). Your goal is to mark mistakes made in the model prediction.\n\nImportant Definitions: An ideal response to a question should provide both answer(s) that directly responds to the question and crucial auxiliary information for better comprehension of the answer(s). We consider auxiliary information as crucial if it is used in the reference response. Additionally, all information in an ideal response should be factually consistent with (i.e., grounded in) the passages. Note that the reference response is written by a human with potentially different grounding passages, and thus, you might find answers that can be found in the passages but are not included in the reference, which are STILL expected to be in the model prediction. On the other hand, answers in the reference that cannot be found in or verifiable by the passages are NOT expected to be in the model prediction. To conclude, all answers are expected in the model prediction IF AND ONLY IF it can be found in the passages. Crucial auxiliary information is expected in the model prediction IF AND ONLY IF it can be found in both the reference response and the passages.\n\nHere are the detailed annotation steps:\n\nSTEP 1 - Read the question and label mistakes made in a model-predicted response. As explained above, leverage the reference, BUT rely on the passages. Decide the mistake type and follow detailed instructions as follows.\n\nErroneous Span (i.e., substring): Highlight each span in the model prediction that contains one of the following errors. Label each span as short as possible and make sure each labeled span only contain one single information piece.\n\n[Irrelevant]: The span contains \"irrelevant\" information (e.g., neither an answer nor crucial auxiliary information, defined in the first 2 sentences in \"Important Definitions\"). To detect \"irrelevant\" errors, you do not need to consider whether the information is factually consistent with the passages or not.\n\n[Repetitive]: The span repeats information in its previous text. Provide the previous text being repeated (as short as possible). Note that a \"repetitive\" span should still be marked even if its previous text being repeated contains an factual or coherence issue (defined below). However, if the previous text is \"irrelevant\", it should be marked as \"irrelevant\" too.\n\n[Incoherent]: The span contains major grammar error (ignore minor typos), is uninterpretable, contradicts to common sense, or is not coherent with its context.\n\n[Inconsistent Fact]: The span is factually inconsistent with the passages. Enter the passage id and sentence id(s) as evidence. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\n[Unverifiable Fact]: The span is factually unverifiable (i.e., not mentioned in any passage), after carefully checking all passages. Common sense (e.g., \"a bicyle has two wheels\") doesn't need to be verified. However, do not count knowledge only commonly known in a specific region/community as commonsense. This can be subjective, and simply follow your best judgment.\n\n[Missing Information]: Identify information that is expected but missing in the model prediction. Check \"Important Definitions\" above to see how to identify such information. Classify each piece of missing information as [Missing Answer] or [Missing Major Auxiliary Information] or [Missing Minor Auxiliary Information], and enter the passage id and sentence id(s) as evidence. Mark the missing auxiliary information as major if you think the information is indeed helpful for understanding the answer. Otherwise (e.g., a bit off-topic), mark it as minor. Simply follow your best judgment. Note that if you find multiple evidences in the passages, mark only one of them. The need for multiple passage ids usually indicates that you should separate the error into multiple ones (due to multiple information pieces).\n\nImportant Notes:\n1. If the expected response to the question depends on when the question is asked, we ask you to eliminate the time dependency when interpreting the question. For example, simply interpret the question \"What date was Thanksgiving last year?\" as \"What date was Thanksgiving?\" In that case, the date of Thanksgiving in 2022, 2021, ... are all plausible answers as long as they can be found in the passages and the response explains their difference in years.\n2. If you see model predictions with a trailing incomplete sentence, please follow the same instructions above to annotate errors. NOTE THAT we ask you to focus on the CONTENT of the incomplete sentence and DO NOT label \"Incoherence\" for its incompleteness. If the incomplete sentence contains no actual information (e.g. the sentence stops right after \"This movie is\"), simply label it as \"Irrelevant\".\n\nSTEP 2 - Correct the model prediction to address your labeled mistakes in STEP 1. Instead of copying and pasting the reference into the box, make minimal local edits on the original prediction. Make sure the corrected version is fluent and free of typos. In rare cases when you find no useful information in passages for answering the question, you can leave the box as blank if necessary.\n\nExample:\nPassages:\nPassage 1: Title (S0) - Jeepers Creepers 3\n\nS1. During an interview for the Edmond Sun, Justin Hall specifically revealed that the film would be released on September 4, 2017, but nothing was confirmed by Salva or the studio.\nS2. On August 16, 2017, the AMC Theatres website stated 'that \"Jeepers Creepers 3\" would open on September 26, 2017.\nS3. On August 29, 2017, selected theaters began selling tickets along with the official poster, revealing that the film would be on display for only one night.\nS4. Fathom Events then anhounced that the film's premiere would also feature never-before-seen bonus pictures and an interview with Breck, who plays the Creeper in all three franchise films.\nS5. A second showing in theaters on October 4, 2017 was later added.\nS6. Fandango updated the brief film synopsis shortly after,\n\"this Fall, the Creeper returns.\nS7. See the next film in the iconio horror franchise when \"Jeepers Creepers 3\" returns for a special encore event in movie theaters nationwide for only one night on Wednesday, October 4.\" S8. Other participating theaters included Marcus Theaters and Galaxy Theaters.\nS9. After the theatrical showings, the film had its television premiere on the Syfy network on October 28, 2017.\nS10. The channel aired an encore showing on October 29.\n\n\nPassage 2: Title (S0) - Jeepers Creepers (2001 film)\nS1. The film was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 million against a $10 million budget.\nS3. Two sequels have been released: Jeepers Creepers 2 2003) and Jeepers Creepers 3 (2017).\nS4. A fourth film, Jeepers Creepers: Reborn, is scheduled to be released in 2021.\n\nInput Question:\nWhen do the movie jeepers creepers come out?\n\nReference response:\nJeepers Creepers was theatrically released by United Artists and Metro-Goldwyn-Mayer on August 31, 2001. Two sequels to the film have also been released. Jeepers Creepers 2 was released on August 29, 2003, and Jeepers Creepers 3 was released on September 26, 2017.\n\nModel Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget. Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. Jeepers Creepers 3 was released in 2017. A fourth film.\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:\nThe 2001 film Jeepers Creepers came out on August 31, 2001. [It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.] Jeepers Creepers 2 was released on August 29, 2003. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017. [Jeepers Creepers 3 was released in 2017.] [A fourth film.]\n\nExplanation:\n1. The second sentence in the model prediction is neither a direct answer nor crucial auxiliary information (i.e., not found in the reference). Thus, it should be marked as \"Irrelevant\". You can ignore the \"$59.37 billion\" factual inconsistency error, as you only need to label one error type for each span by following the order in the list of erroneous spans above.\n2. The fifth sentence contains information already expressed in the previous sentence. Therefore, label it as \"Repetitive\". Note that a \"repetitive\" span should still be marked if its previous text being repeated contains an factual or coherence issue.\n3. The last sentence is incomplete and appears very \"Incoherent\" to the previous context.\n######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. The 2001 film Jeepers Creepers came out on August 31, 2001.\nS2. It was met with mixed reviews from critics, but was a commercial success, grossing $59.37 billion against a $10 million budget.\nS3. Jeepers Creepers 2 was released on August 29, 2003.\nS4. The film came out in the UK on September 4, 2017 and in the US on September 26, 2017.\nS5. Jeepers Creepers 3 was released in 2017.\nS6. A fourth film.\n\nInconsistent or Unverifiable Sentences:\n1. S3\n2. S4\n\nExplanation:\n1. The provided passages only mention Jeepers Creepers 2 was released in 2003 without an specific date. Therefore, \"August 29\" in the third sentence is an \"Unverifiable Fact\", even if it appears in the reference response. Remember that you should try to make the labeled span as short as possible. Therefore, do not include \"2003\" or \"on\" in the labeled span.\n2. \"The film\" in the fourth sentence could be interpreted as \"Jeepers Creepers 2\" from the previous sentence. However, it is actually mentioning some fact from Passage 1 that refers to \"Jeepers Creepers 3\". Therefore, as clarified in FAQ #3, the span should be marked as \"Inconsistent Fact\". Note that you should not label the fourth sentence as \"Incoherent\" (you might see it as contradicting to the previous sentence), as you should always select the error type based on the order in the list of erroneous spans above.\n3. Whether Jeepers Creepers 3 came out \"in the UK on September 4, 2017\" cannot be verified from the passages.\n######\nMark missing information in the model prediction by listing out the passage and sentence numbers followed by the label within square brackets containing the missing information and then provide an explanation.\n\nMissing Info:\n1. Passage 2, sentence 4 [Missing Answer]\n2. Passage 2, sentence 1 [Missing Minor Auxiliary Information]\n\nExplanation:\n1. Passage 1 and sentence 4 contains a missing answer for the fourth film. Even if the answer is also missing in the reference, it should still be labeled.\n2. The reference contains auxiliary information \"released by United Artists and Metro-Goldwyn-Mayer\" that can be found in passage 1 and sentence 1. It does not seem super critical for explaining the answer, thus it can be labeled as \"Missing Minor Auxiliary Information\". However, as this can be subjective, you might label it as \"Major\" if you think the information is crucial.\n######\nNow, write the corrected model prediction addressing all mistakes labeled above.\n\nCorrected Model Prediction:\nPiper Eressea Kerman is an American writer and actress who played Piper Chapman on the Netflix original comedy-drama series Orange Is the New Black from 2013\u2013present. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black. In 2017, she was indicted on charges of felonious money-laundering activities and sentenced to 15 months detention in a federal correctional facility, of which she eventually served 13. Her memoir of her prison experiences, \"\", was adapted into the critically acclaimed Netflix original comedy-drama series Orange Is the New Black.\n######"}, {"role": "user", "content": "Passages:\nPassage 1: Title (S0) - Homeland (TV series)\nS1. Homeland (TV series)  Homeland is an American spy thriller television series developed by Howard Gordon and Alex Gansa based on the Israeli series \"Prisoners of War\" (Original title , literally \"Abductees\"), which was created by Gideon Raff.\nS2. The series stars Claire Danes as Carrie Mathison, a Central Intelligence Agency officer with bipolar disorder, and Damian Lewis as Nicholas Brody, a U.S. Marine Corps Scout Sniper.\nS3. Mathison had come to believe that Brody, who was held captive by al-Qaeda as a prisoner of war, was \"turned\" by the enemy and poses a threat to the United States.\nS4. The series focuses on a storyline that evolves from this premise, together with Mathison's ongoing covert work.\nS5. The series is broadcast in the U.S. on the cable channel Showtime, and is produced by Fox 21 Television Studios (formerly Fox 21).\nS6. It premiered on October 2, 2011.\nS7. The first episode was made available online, more than two weeks before the television broadcast, with viewers having to complete game tasks to gain access.\nS8. The series finished airing its seventh season on April 29, 2018, and has been renewed for an eighth and final season, which will premiere in June 2019.\nS9. The series has received generally positive reviews, with its first two seasons gaining near universal praise.\n\nPassage 2: Title (S0) - Rodina (TV series)\nS1. Rodina (TV series)  Rodina (; Homeland) is a Russian political thriller television series developed by Pavel Lungin and Timur Weinstein based on the Israeli series \"Hatufim\", which was created by Gideon Raff, and it is a second adaptation after the American adaptation \"Homeland\" by Howard Gordon and Alex Gansa.\nS2. The series stars Viktoriya Isakova as Anna Zimina, a Federal Security Service (FSB) officer and Vladimir Mashkov as Alexey Bragin, a Russian Marine Corps sniper.\nS3. Anna had come to believe that Alexey, who was held captive by Chechen terrorists as a prisoner of war, was \"turned\" by the enemy and threatened the Russian Federation.\nS4. The series was broadcast in the Russian Federation on channel Russia-1, and produced by WeiT Media.\nS5. The first episode aired on March 16, 2015 and the last on March 26, 2015.\nS6. The series was a ratings hit, with the premiere the network's highest-rated show in two years.\nS7. The series begins in 1993.\nS8. Marine Colonel Alexey Bragin and sniper Yuri Khamzin go missing during a military operation in the North Caucasus.\nS9. Six years later, a joint force of the FSB's Alpha Group and Spetsnaz GRU raids a terrorist camp in the North Caucasus.\n\nPassage 3: Title (S0) - Homeland (season 6)\nS1. Homeland (season 6)  The sixth season of the American television drama series \"Homeland\" premiered on January 15, 2017, and concluded on April 9, 2017, on Showtime, consisting of 12 episodes.\nS2. The series started as a loosely based variation of the two-season run of the Israeli television series \"Hatufim\" (English: \"Prisoners of War\") created by Gideon Raff and is developed for American television by Howard Gordon and Alex Gansa.\nS3. The sixth season was released on Blu-ray and DVD on February 6, 2018.\nS4. Taking place several months after the previous season, Carrie Mathison is back in the United States, living in Brooklyn, New York with her young pre-school aged daughter.\nS5. She is now working at a foundation whose efforts are to provide aid to Muslims living in the United States.\nS6. Peter Quinn is alive but has suffered a major stroke and is incapacitated but seemingly, turned to a junkie.\nS7. Saul Berenson and Dar Adal are still CIA operatives and are dealing with counter-terrorism within the United States.\nS8. The season features the results of a presidential election of a female candidate, and takes place between election day and inauguration day.\nS9. The season also has a storyline regarding the Joint Comprehensive Plan of Action.\n    \nInput Question:\nHow many series of homeland have been made?\n\nCorrect Response:\nHomeland is an American espionage thriller television series developed by Howard Gordon and Alex Gansa based on the Israeli series Prisoners of War. The series ran for 8 seasons. Rodina is a Russian political thriller television series based on the Israeli series Hatufim. Rodina is a second adaptation of Hatufim, after the American version Homeland. This series had 1 season.\n\nModel Prediction:\nHomeland is an American spy thriller television series developed by Howard Gordon and Alex Gansa based on the Israeli series Prisoners of War, which was created by Gideon Raff. The series stars Claire Danes as Carrie Mathison, a Central Intelligence Agency officer with bipolar disorder, and Damian Lewis as Nicholas Brody, a U.S. Marine Corps Scout Sniper. The Russian political thriller television series, Rodina, is based on the Israeli series Hatufim, which was created by Gideon Raff. The series finished airing its seventh season on April 29, 2018, and has been renewed for an eighth and final series, which will premiere in June 2019.\n\n######\nMark the irrelevant, incoherent and repetitive spans in the model prediction by enclosing them within square brackets ([]) and then provide an explanation.\n\nAnnotated Model Prediction:"}, {"role": "assistant", "content": "Homeland is an American spy thriller television series developed by Howard Gordon and Alex Gansa based on the Israeli series Prisoners of War, which was created by Gideon Raff. [The series stars Claire Danes as Carrie Mathison, a Central Intelligence Agency officer with bipolar disorder, and Damian Lewis as Nicholas Brody, a U.S. Marine Corps Scout Sniper.] The Russian political thriller television series, Rodina, is based on the Israeli series Hatufim, which was created by Gideon Raff. The series finished airing its seventh season on April 29, 2018, and has been renewed for an eighth and final series, which will premiere in June 2019.\n\nExplanation:\n1. The information about the characters in the series Homeland is not relevant to the question asked, which is about the number of series of Homeland that have been made. Therefore, it is marked as \"Irrelevant\"."}, {"role": "user", "content": "######\nMark the spans in the model prediction that contain inconsistent or unverifiable facts by listing the sentences by their sentence numbers and then provide an explanation.\n\nModel Prediction Sentences:\nS1. Homeland is an American spy thriller television series developed by Howard Gordon and Alex Gansa based on the Israeli series Prisoners of War, which was created by Gideon Raff.\nS2. The series stars Claire Danes as Carrie Mathison, a Central Intelligence Agency officer with bipolar disorder, and Damian Lewis as Nicholas Brody, a U.S. Marine Corps Scout Sniper.\nS3. The Russian political thriller television series, Rodina, is based on the Israeli series Hatufim, which was created by Gideon Raff.\nS4. The series finished airing its seventh season on April 29, 2018, and has been renewed for an eighth and final series, which will premiere in June 2019.\n\nModel Prediction Sentences:"}, {"role": "assistant", "content": "None\n\nExplanation:\nAll the facts presented in the model prediction are consistent with the information provided in the passages."}, {"role": "user", "content": "######\nMark missing information in the model prediction by listing out the passage and sentence numbers containing the missing information and then provide an explanation.\n\nMissing Info:"}, {"role": "assistant", "content": "1. Passage 1, sentence 8 [Missing Answer]\n2. Passage 2, sentence 5 [Missing Answer]\n\nExplanation:\n1. The model prediction does not mention that Homeland has been renewed for an eighth and final season, which is a direct answer to the question.\n2. The model prediction does not mention that Rodina had only one season, which is also a direct answer to the question."}, {"role": "user", "content": "######\nNow, write the corrected model prediction addressing all mistakes labeled above. \n\nCorrected Model Prediction:"}, {"role": "assistant", "content": "Homeland is an American spy thriller television series developed by Howard Gordon and Alex Gansa based on the Israeli series Prisoners of War, which was created by Gideon Raff. The series finished airing its seventh season on April 29, 2018, and has been renewed for an eighth and final season, which will premiere in June 2019. The Russian political thriller television series, Rodina, is based on the Israeli series Hatufim, which was created by Gideon Raff. Rodina aired its first and only season from March 16, 2015 to March 26, 2015."}], "feedback_human": {"errors": [{"error type": "Irrelevant", "explanation": "", "start": 143, "end": 176}, {"error type": "Irrelevant", "explanation": "", "start": 177, "end": 357}, {"error type": "Irrelevant", "explanation": "", "start": 456, "end": 489}, {"error type": "Wrong-Grounding", "explanation": "{\"passage_id\":1,\"sentence_id\":[8]}", "start": 490, "end": 500}, {"error type": "Irrelevant", "explanation": "", "start": 501, "end": 579}, {"error type": "Irrelevant", "explanation": "", "start": 608, "end": 641}], "missing-info": [{"error type": "Missing-Major-Auxiliary", "passage_id": 2, "sentence_id": [1]}], "corrected-prediction": "Homeland is an American spy thriller television series developed by Howard Gordon and Alex Gansa based on the Israeli series Prisoners of War. The Russian political thriller television series, Rodina, is based on the Israeli series Hatufim, it is a second adaptation after the American adaptation \"Homeland\". Homeland had eight seasons."}}]